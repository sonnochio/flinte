{
  "nodes": [
    {
      "id": "2411.09702v1",
      "title": "On the Surprising Effectiveness of Attention Transfer for Vision Transformers",
      "summary": "Conventional wisdom suggests that pre-training Vision Transformers (ViT)\nimproves downstream performance by learning useful representations. Is this\nactually true? We investigate this question and find that the features and\nrepresentations learned during pre-training are not essential. Surprisingly,\nusing only the attention patterns from pre-training (i.e., guiding how\ninformation flows between tokens) is sufficient for models to learn high\nquality features from scratch and achieve comparable downstream performance. We\nshow this by introducing a simple method called attention transfer, where only\nthe attention patterns from a pre-trained teacher ViT are transferred to a\nstudent, either by copying or distilling the attention maps. Since attention\ntransfer lets the student learn its own features, ensembling it with a\nfine-tuned teacher also further improves accuracy on ImageNet. We\nsystematically study various aspects of our findings on the sufficiency of\nattention maps, including distribution shift settings where they underperform\nfine-tuning. We hope our exploration provides a better understanding of what\npre-training accomplishes and leads to a useful alternative to the standard\npractice of fine-tuning"
    },
    {
      "id": "2411.09694v1",
      "title": "A Bayesian Optimization Approach to Machine Translation Reranking",
      "summary": "Reranking a list of candidates from a machine translation system with an\nexternal scoring model and returning the highest-scoring candidate remains a\nsimple and effective method for improving the overall output quality.\nTranslation scoring models continue to grow in size, with the best models being\ncomparable to generation models. Thus, reranking can add substantial\ncomputational cost to the translation pipeline. In this work, we pose reranking\nas a Bayesian optimization (BayesOpt) problem. By strategically selecting\ncandidates to score based on a balance of exploration and exploitation, we show\nthat it is possible to find top-scoring candidates when scoring only a fraction\nof the candidate list. For instance, our method achieves the same CometKiwi\nscore using only 70 scoring evaluations compared a baseline system using 180.\nWe present a multi-fidelity setting for BayesOpt, where the candidates are\nfirst scored with a cheaper but noisier proxy scoring model, which further\nimproves the cost-performance tradeoff when using smaller but well-trained\ndistilled proxy scorers."
    },
    {
      "id": "2411.09689v1",
      "title": "LLM Hallucination Reasoning with Zero-shot Knowledge Test",
      "summary": "LLM hallucination, where LLMs occasionally generate unfaithful text, poses\nsignificant challenges for their practical applications. Most existing\ndetection methods rely on external knowledge, LLM fine-tuning, or\nhallucination-labeled datasets, and they do not distinguish between different\ntypes of hallucinations, which are crucial for improving detection performance.\nWe introduce a new task, Hallucination Reasoning, which classifies\nLLM-generated text into one of three categories: aligned, misaligned, and\nfabricated. Our novel zero-shot method assesses whether LLM has enough\nknowledge about a given prompt and text. Our experiments conducted on new\ndatasets demonstrate the effectiveness of our method in hallucination reasoning\nand underscore its importance for enhancing detection performance."
    },
    {
      "id": "2411.09688v1",
      "title": "Squeezed Attention: Accelerating Long Context Length LLM Inference",
      "summary": "Emerging Large Language Model (LLM) applications require long input prompts\nto perform complex downstream tasks like document analysis and code generation.\nFor these long context length applications, the length of the input prompt\nposes a significant challenge in terms of inference efficiency since the\ninference costs increase linearly with sequence length. However, for many of\nthese applications, much of the context in the prompt is fixed across different\nuser inputs, thereby providing the opportunity to perform offline optimizations\nto process user inputs quickly, as they are received. In this work, we propose\nSqueezed Attention as a mechanism to accelerate LLM applications where a large\nportion of the input prompt is fixed. We first leverage K-means clustering\noffline to group the keys for the fixed context based on semantic similarity\nand represent each cluster with a single centroid value. During inference, we\ncompare query tokens from the user input with the centroids to predict which of\nthe keys from the fixed context are semantically relevant and need to be loaded\nduring inference. We then compute exact attention using only these important\nkeys from the fixed context, thereby reducing bandwidth and computational\ncosts. We also extend our method to use a hierarchical centroid lookup to\nidentify important keys, which can reduce the complexity of attention from\nlinear to logarithmic with respect to the context length. We implement\noptimized Triton kernels for centroid comparison and sparse FlashAttention with\nimportant keys, achieving more than 4x speedups during both the prefill and\ngeneration phases for long-context inference. Furthermore, we have extensively\nevaluated our method on various long-context benchmarks including LongBench,\nwhere it achieves a 3x reduction in KV cache budget without accuracy loss and\nup to an 8x reduction with <0.5 point accuracy gap for various models."
    },
    {
      "id": "2411.09686v1",
      "title": "Conditional regression for the Nonlinear Single-Variable Model",
      "summary": "Several statistical models for regression of a function $F$ on $\\mathbb{R}^d$\nwithout the statistical and computational curse of dimensionality exist, for\nexample by imposing and exploiting geometric assumptions on the distribution of\nthe data (e.g. that its support is low-dimensional), or strong smoothness\nassumptions on $F$, or a special structure $F$. Among the latter, compositional\nmodels assume $F=f\\circ g$ with $g$ mapping to $\\mathbb{R}^r$ with $r\\ll d$,\nhave been studied, and include classical single- and multi-index models and\nrecent works on neural networks. While the case where $g$ is linear is rather\nwell-understood, much less is known when $g$ is nonlinear, and in particular\nfor which $g$'s the curse of dimensionality in estimating $F$, or both $f$ and\n$g$, may be circumvented. In this paper, we consider a model\n$F(X):=f(\\Pi_\\gamma X) $ where $\\Pi_\\gamma:\\mathbb{R}^d\\to[0,\\rm{len}_\\gamma]$\nis the closest-point projection onto the parameter of a regular curve $\\gamma:\n[0,\\rm{len}_\\gamma]\\to\\mathbb{R}^d$ and $f:[0,\\rm{len}_\\gamma]\\to\\mathbb{R}^1$.\nThe input data $X$ is not low-dimensional, far from $\\gamma$, conditioned on\n$\\Pi_\\gamma(X)$ being well-defined. The distribution of the data, $\\gamma$ and\n$f$ are unknown. This model is a natural nonlinear generalization of the\nsingle-index model, which corresponds to $\\gamma$ being a line. We propose a\nnonparametric estimator, based on conditional regression, and show that under\nsuitable assumptions, the strongest of which being that $f$ is coarsely\nmonotone, it can achieve the $one$-$dimensional$ optimal min-max rate for\nnon-parametric regression, up to the level of noise in the observations, and be\nconstructed in time $\\mathcal{O}(d^2n\\log n)$. All the constants in the\nlearning bounds, in the minimal number of samples required for our bounds to\nhold, and in the computational complexity are at most low-order polynomials in\n$d$."
    },
    {
      "id": "2411.09683v1",
      "title": "Towards a Classification of Open-Source ML Models and Datasets for Software Engineering",
      "summary": "Background: Open-Source Pre-Trained Models (PTMs) and datasets provide\nextensive resources for various Machine Learning (ML) tasks, yet these\nresources lack a classification tailored to Software Engineering (SE) needs.\nAims: We apply an SE-oriented classification to PTMs and datasets on a popular\nopen-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs\nover time. Method: We conducted a repository mining study. We started with a\nsystematically gathered database of PTMs and datasets from the HF API. Our\nselection was refined by analyzing model and dataset cards and metadata, such\nas tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are\nreplicable, with a publicly accessible replication package. Results: The most\ncommon SE task among PTMs and datasets is code generation, with a primary focus\non software development and limited attention to software management. Popular\nPTMs and datasets mainly target software development. Among ML tasks, text\ngeneration is the most common in SE PTMs and datasets. There has been a marked\nincrease in PTMs for SE since 2023 Q2. Conclusions: This study underscores the\nneed for broader task coverage to enhance the integration of ML within SE\npractices."
    },
    {
      "id": "2411.09678v1",
      "title": "NeuralDEM -- Real-time Simulation of Industrial Particulate Flows",
      "summary": "Advancements in computing power have made it possible to numerically simulate\nlarge-scale fluid-mechanical and/or particulate systems, many of which are\nintegral to core industrial processes. Among the different numerical methods\navailable, the discrete element method (DEM) provides one of the most accurate\nrepresentations of a wide range of physical systems involving granular and\ndiscontinuous materials. Consequently, DEM has become a widely accepted\napproach for tackling engineering problems connected to granular flows and\npowder mechanics. Additionally, DEM can be integrated with grid-based\ncomputational fluid dynamics (CFD) methods, enabling the simulation of chemical\nprocesses taking place, e.g., in fluidized beds. However, DEM is\ncomputationally intensive because of the intrinsic multiscale nature of\nparticulate systems, restricting simulation duration or number of particles.\nTowards this end, NeuralDEM presents an end-to-end approach to replace slow\nnumerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM\nis capable of picturing long-term transport processes across different regimes\nusing macroscopic observables without any reference to microscopic model\nparameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an\nunderlying continuous field, while simultaneously modeling macroscopic behavior\ndirectly as additional auxiliary fields. Second, NeuralDEM introduces\nmulti-branch neural operators scalable to real-time modeling of\nindustrially-sized scenarios - from slow and pseudo-steady to fast and\ntransient. Such scenarios have previously posed insurmountable challenges for\ndeep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM\nfluidized bed reactors of 160k CFD cells and 500k DEM particles for\ntrajectories of 28s. NeuralDEM will open many new doors to advanced engineering\nand much faster process cycles."
    },
    {
      "id": "2411.09661v1",
      "title": "Adaptive Decoding via Latent Preference Optimization",
      "summary": "During language model decoding, it is known that using higher temperature\nsampling gives more creative responses, while lower temperatures are more\nfactually accurate. However, such models are commonly applied to general\ninstruction following, which involves both creative and fact seeking tasks,\nusing a single fixed temperature across all examples and tokens. In this work,\nwe introduce Adaptive Decoding, a layer added to the model to select the\nsampling temperature dynamically at inference time, at either the token or\nexample level, in order to optimize performance. To learn its parameters we\nintroduce Latent Preference Optimization (LPO) a general approach to train\ndiscrete latent variables such as choices of temperature. Our method\noutperforms all fixed decoding temperatures across a range of tasks that\nrequire different temperatures, including UltraFeedback, Creative Story\nWriting, and GSM8K."
    },
    {
      "id": "2411.09648v1",
      "title": "Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information",
      "summary": "This paper introduces Med-Bot, an AI-powered chatbot designed to provide\nusers with accurate and reliable medical information. Utilizing advanced\nlibraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,\nMed-Bot is built to handle the complexities of natural language understanding\nin a healthcare context. The integration of llamaassisted data processing and\nAutoGPT-Q provides enhanced performance in processing and responding to queries\nbased on PDFs of medical literature, ensuring that users receive precise and\ntrustworthy information. This research details the methodologies employed in\ndeveloping Med-Bot and evaluates its effectiveness in disseminating healthcare\ninformation."
    },
    {
      "id": "2411.09645v1",
      "title": "How do Machine Learning Models Change?",
      "summary": "The proliferation of Machine Learning (ML) models and their open-source\nimplementations has transformed Artificial Intelligence research and\napplications. Platforms like Hugging Face (HF) enable the development, sharing,\nand deployment of these models, fostering an evolving ecosystem. While previous\nstudies have examined aspects of models hosted on platforms like HF, a\ncomprehensive longitudinal study of how these models change remains\nunderexplored. This study addresses this gap by utilizing both repository\nmining and longitudinal analysis methods to examine over 200,000 commits and\n1,200 releases from over 50,000 models on HF. We replicate and extend an ML\nchange taxonomy for classifying commits and utilize Bayesian networks to\nuncover patterns in commit and release activities over time. Our findings\nindicate that commit activities align with established data science\nmethodologies, such as CRISP-DM, emphasizing iterative refinement and\ncontinuous improvement. Additionally, release patterns tend to consolidate\nsignificant updates, particularly in documentation, distinguishing between\ngranular changes and milestone-based releases. Furthermore, projects with\nhigher popularity prioritize infrastructure enhancements early in their\nlifecycle, and those with intensive collaboration practices exhibit improved\ndocumentation standards. These and other insights enhance the understanding of\nmodel changes on community platforms and provide valuable guidance for best\npractices in model maintenance."
    },
    {
      "id": "2411.09644v1",
      "title": "Neural Operators Can Play Dynamic Stackelberg Games",
      "summary": "Dynamic Stackelberg games are a broad class of two-player games in which the\nleader acts first, and the follower chooses a response strategy to the leader's\nstrategy. Unfortunately, only stylized Stackelberg games are explicitly\nsolvable since the follower's best-response operator (as a function of the\ncontrol of the leader) is typically analytically intractable. This paper\naddresses this issue by showing that the \\textit{follower's best-response\noperator} can be approximately implemented by an \\textit{attention-based neural\noperator}, uniformly on compact subsets of adapted open-loop controls for the\nleader. We further show that the value of the Stackelberg game where the\nfollower uses the approximate best-response operator approximates the value of\nthe original Stackelberg game. Our main result is obtained using our universal\napproximation theorem for attention-based neural operators between spaces of\nsquare-integrable adapted stochastic processes, as well as stability results\nfor a general class of Stackelberg games."
    },
    {
      "id": "2411.09642v1",
      "title": "On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse",
      "summary": "Specifying all desirable properties of a language model is challenging, but\ncertain requirements seem essential. Given samples from an unknown language,\nthe trained model should produce valid strings not seen in training and be\nexpressive enough to capture the language's full richness. Otherwise,\noutputting invalid strings constitutes \"hallucination,\" and failing to capture\nthe full range leads to \"mode collapse.\" We ask if a language model can meet\nboth requirements.\n  We investigate this within a statistical language generation setting building\non Gold and Angluin. Here, the model receives random samples from a\ndistribution over an unknown language K, which belongs to a possibly infinite\ncollection of languages. The goal is to generate unseen strings from K. We say\nthe model generates from K with consistency and breadth if, as training size\nincreases, its output converges to all unseen strings in K.\n  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in\nlanguage generation are possible. We answer this negatively: for a large class\nof language models, including next-token prediction models, this is impossible\nfor most collections of candidate languages. This contrasts with [KM24]'s\nresult, showing consistent generation without breadth is possible for any\ncountable collection of languages. Our finding highlights that generation with\nbreadth fundamentally differs from generation without breadth.\n  As a byproduct, we establish near-tight bounds on the number of samples\nneeded for generation with or without breadth.\n  Finally, our results offer hope: consistent generation with breadth is\nachievable for any countable collection of languages when negative examples\n(strings outside K) are available alongside positive ones. This suggests that\npost-training feedback, which encodes negative examples, can be crucial in\nreducing hallucinations while limiting mode collapse."
    },
    {
      "id": "2411.09639v1",
      "title": "MCCE: Missingness-aware Causal Concept Explainer",
      "summary": "Causal concept effect estimation is gaining increasing interest in the field\nof interpretable machine learning. This general approach explains the behaviors\nof machine learning models by estimating the causal effect of\nhuman-understandable concepts, which represent high-level knowledge more\ncomprehensibly than raw inputs like tokens. However, existing causal concept\neffect explanation methods assume complete observation of all concepts involved\nwithin the dataset, which can fail in practice due to incomplete annotations or\nmissing concept data. We theoretically demonstrate that unobserved concepts can\nbias the estimation of the causal effects of observed concepts. To address this\nlimitation, we introduce the Missingness-aware Causal Concept Explainer (MCCE),\na novel framework specifically designed to estimate causal concept effects when\nnot all concepts are observable. Our framework learns to account for residual\nbias resulting from missing concepts and utilizes a linear predictor to model\nthe relationships between these concepts and the outputs of black-box machine\nlearning models. It can offer explanations on both local and global levels. We\nconduct validations using a real-world dataset, demonstrating that MCCE\nachieves promising performance compared to state-of-the-art explanation methods\nin causal concept effect estimation."
    },
    {
      "id": "2411.09635v1",
      "title": "Counterfactual Uncertainty Quantification of Factual Estimand of Efficacy from Before-and-After Treatment Repeated Measures Randomized Controlled Trials",
      "summary": "The ideal estimand for comparing a new treatment $Rx$ with a control $C$ is\nthe $\\textit{counterfactual}$ efficacy $Rx:C$, the expected differential\noutcome between $Rx$ and $C$ if each patient were given $\\textit{both}$. While\ncounterfactual $\\textit{point estimation}$ from $\\textit{factual}$ Randomized\nControlled Trials (RCTs) has been available, this article shows\n$\\textit{counterfactual}$ uncertainty quantification (CUQ), quantifying\nuncertainty for factual point estimates but in a counterfactual setting, is\nsurprisingly achievable. We achieve CUQ whose variability is typically smaller\nthan factual UQ, by creating a new statistical modeling principle called ETZ\nwhich is applicable to RCTs with $\\textit{Before-and-After}$ treatment Repeated\nMeasures, common in many therapeutic areas.\n  We urge caution when estimate of the unobservable true condition of a patient\nbefore treatment has measurement error, because that violation of standard\nregression assumption can cause attenuation in estimating treatment effects.\nFortunately, we prove that, for traditional medicine in general, and for\ntargeted therapy with efficacy defined as averaged over the population,\ncounterfactual point estimation is unbiased. However, for targeted therapy,\nboth Real Human and Digital Twins approaches should respect this limitation,\nlest predicted treatment effect in $\\textit{subgroups}$ will have bias."
    },
    {
      "id": "2411.09627v1",
      "title": "One-Shot Manipulation Strategy Learning by Making Contact Analogies",
      "summary": "We present a novel approach, MAGIC (manipulation analogies for generalizable\nintelligent contacts), for one-shot learning of manipulation strategies with\nfast and extensive generalization to novel objects. By leveraging a reference\naction trajectory, MAGIC effectively identifies similar contact points and\nsequences of actions on novel objects to replicate a demonstrated strategy,\nsuch as using different hooks to retrieve distant objects of different shapes\nand sizes. Our method is based on a two-stage contact-point matching process\nthat combines global shape matching using pretrained neural features with local\ncurvature analysis to ensure precise and physically plausible contact points.\nWe experiment with three tasks including scooping, hanging, and hooking\nobjects. MAGIC demonstrates superior performance over existing methods,\nachieving significant improvements in runtime speed and generalization to\ndifferent object categories. Website: https://magic-2024.github.io/ ."
    },
    {
      "id": "2411.09625v1",
      "title": "Local deployment of large-scale music AI models on commodity hardware",
      "summary": "We present the MIDInfinite, a web application capable of generating symbolic\nmusic using a large-scale generative AI model locally on commodity hardware.\nCreating this demo involved porting the Anticipatory Music Transformer, a large\nlanguage model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine\nLearning Compilation (MLC) framework. Once the model is ported, MLC facilitates\ninference on a variety of runtimes including C++, mobile, and the browser. We\nenvision that MLC has the potential to bridge the gap between the landscape of\nincreasingly capable music AI models and technology more familiar to music\nsoftware developers. As a proof of concept, we build a web application that\nallows users to generate endless streams of multi-instrumental MIDI in the\nbrowser, either from scratch or conditioned on a prompt. On commodity hardware\n(an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster\nthan real-time playback for 72.9% of generations, and increases to 86.3% with 2\nseconds of upfront buffering."
    },
    {
      "id": "2411.09623v1",
      "title": "Vision-based Manipulation of Transparent Plastic Bags in Industrial Setups",
      "summary": "This paper addresses the challenges of vision-based manipulation for\nautonomous cutting and unpacking of transparent plastic bags in industrial\nsetups, aligning with the Industry 4.0 paradigm. Industry 4.0, driven by data,\nconnectivity, analytics, and robotics, promises enhanced accessibility and\nsustainability throughout the value chain. The integration of autonomous\nsystems, including collaborative robots (cobots), into industrial processes is\npivotal for efficiency and safety. The proposed solution employs advanced\nMachine Learning algorithms, particularly Convolutional Neural Networks (CNNs),\nto identify transparent plastic bags under varying lighting and background\nconditions. Tracking algorithms and depth sensing technologies are utilized for\n3D spatial awareness during pick and placement. The system addresses challenges\nin grasping and manipulation, considering optimal points, compliance control\nwith vacuum gripping technology, and real-time automation for safe interaction\nin dynamic environments. The system's successful testing and validation in the\nlab with the FRANKA robot arm, showcases its potential for widespread\nindustrial applications, while demonstrating effectiveness in automating the\nunpacking and cutting of transparent plastic bags for an 8-stack bulk-loader\nbased on specific requirements and rigorous testing."
    },
    {
      "id": "2411.09618v1",
      "title": "MICCAI-CDMRI 2023 QuantConn Challenge Findings on Achieving Robust Quantitative Connectivity through Harmonized Preprocessing of Diffusion MRI",
      "summary": "White matter alterations are increasingly implicated in neurological diseases\nand their progression. International-scale studies use diffusion-weighted\nmagnetic resonance imaging (DW-MRI) to qualitatively identify changes in white\nmatter microstructure and connectivity. Yet, quantitative analysis of DW-MRI\ndata is hindered by inconsistencies stemming from varying acquisition\nprotocols. There is a pressing need to harmonize the preprocessing of DW-MRI\ndatasets to ensure the derivation of robust quantitative diffusion metrics\nacross acquisitions. In the MICCAI-CDMRI 2023 QuantConn challenge, participants\nwere provided raw data from the same individuals collected on the same scanner\nbut with two different acquisitions and tasked with preprocessing the DW-MRI to\nminimize acquisition differences while retaining biological variation.\nSubmissions are evaluated on the reproducibility and comparability of\ncross-acquisition bundle-wise microstructure measures, bundle shape features,\nand connectomics. The key innovations of the QuantConn challenge are that (1)\nwe assess bundles and tractography in the context of harmonization for the\nfirst time, (2) we assess connectomics in the context of harmonization for the\nfirst time, and (3) we have 10x additional subjects over prior harmonization\nchallenge, MUSHAC and 100x over SuperMUDI. We find that bundle surface area,\nfractional anisotropy, connectome assortativity, betweenness centrality, edge\ncount, modularity, nodal strength, and participation coefficient measures are\nmost biased by acquisition and that machine learning voxel-wise correction,\nRISH mapping, and NeSH methods effectively reduce these biases. In addition,\nmicrostructure measures AD, MD, RD, bundle length, connectome density,\nefficiency, and path length are least biased by these acquisition differences."
    },
    {
      "id": "2411.09613v1",
      "title": "PTR: Precision-Driven Tool Recommendation for Large Language Models",
      "summary": "By augmenting Large Language Models (LLMs) with external tools, their\ncapacity to solve complex problems has been significantly enhanced. However,\ndespite ongoing advancements in the parsing capabilities of LLMs, incorporating\nall available tools simultaneously in the prompt remains impractical due to the\nvast number of external tools. Consequently, it is essential to provide LLMs\nwith a precise set of tools tailored to the specific task, considering both\nquantity and quality. Current tool retrieval methods primarily focus on\nrefining the ranking list of tools and directly packaging a fixed number of\ntop-ranked tools as the tool set. However, these approaches often fail to equip\nLLMs with the optimal set of tools prior to execution, since the optimal number\nof tools for different tasks could be different, resulting in inefficiencies\nsuch as redundant or unsuitable tools, which impede immediate access to the\nmost relevant tools. This paper addresses the challenge of recommending precise\ntoolsets for LLMs. We introduce the problem of tool recommendation, define its\nscope, and propose a novel Precision-driven Tool Recommendation (PTR) approach.\nPTR captures an initial, concise set of tools by leveraging historical tool\nbundle usage and dynamically adjusts the tool set by performing tool matching,\nculminating in a multi-view-based tool addition. Additionally, we present a new\ndataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness\nof tool recommendation for LLMs. We further validate our design choices through\ncomprehensive experiments, demonstrating promising accuracy across two open\nbenchmarks and our RecTools dataset."
    },
    {
      "id": "2411.09612v1",
      "title": "The Moral Foundations Weibo Corpus",
      "summary": "Moral sentiments expressed in natural language significantly influence both\nonline and offline environments, shaping behavioral styles and interaction\npatterns, including social media selfpresentation, cyberbullying, adherence to\nsocial norms, and ethical decision-making. To effectively measure moral\nsentiments in natural language processing texts, it is crucial to utilize\nlarge, annotated datasets that provide nuanced understanding for accurate\nanalysis and modeltraining. However, existing corpora, while valuable, often\nface linguistic limitations. To address this gap in the Chinese language\ndomain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of\n25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each\ncomment is manually annotated by at least three systematically trained\nannotators based on ten moral categories derived from a grounded theory of\nmorality. To assess annotator reliability, we present the kappa testresults, a\ngold standard for measuring consistency. Additionally, we apply several the\nlatest large language models to supplement the manual annotations, conducting\nanalytical experiments to compare their performance and report baseline results\nfor moral sentiment classification."
    },
    {
      "id": "2411.09607v1",
      "title": "Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the AutoNuggetizer Framework",
      "summary": "This report provides an initial look at partial results from the TREC 2024\nRetrieval-Augmented Generation (RAG) Track. We have identified RAG evaluation\nas a barrier to continued progress in information access (and more broadly,\nnatural language processing and artificial intelligence), and it is our hope\nthat we can contribute to tackling the many challenges in this space. The\ncentral hypothesis we explore in this work is that the nugget evaluation\nmethodology, originally developed for the TREC Question Answering Track in\n2003, provides a solid foundation for evaluating RAG systems. As such, our\nefforts have focused on \"refactoring\" this methodology, specifically applying\nlarge language models to both automatically create nuggets and to automatically\nassign nuggets to system answers. We call this the AutoNuggetizer framework.\nWithin the TREC setup, we are able to calibrate our fully automatic process\nagainst a manual process whereby nuggets are created by human assessors\nsemi-manually and then assigned manually to system answers. Based on initial\nresults across 21 topics from 45 runs, we observe a strong correlation between\nscores derived from a fully automatic nugget evaluation and a (mostly) manual\nnugget evaluation by human assessors. This suggests that our fully automatic\nevaluation process can be used to guide future iterations of RAG systems."
    },
    {
      "id": "2411.09604v1",
      "title": "Local-Global Attention: An Adaptive Mechanism for Multi-Scale Feature Integration",
      "summary": "In recent years, attention mechanisms have significantly enhanced the\nperformance of object detection by focusing on key feature information.\nHowever, prevalent methods still encounter difficulties in effectively\nbalancing local and global features. This imbalance hampers their ability to\ncapture both fine-grained details and broader contextual information-two\ncritical elements for achieving accurate object detection.To address these\nchallenges, we propose a novel attention mechanism, termed Local-Global\nAttention, which is designed to better integrate both local and global\ncontextual features. Specifically, our approach combines multi-scale\nconvolutions with positional encoding, enabling the model to focus on local\ndetails while concurrently considering the broader global context.\nAdditionally, we introduce a learnable parameters, which allow the model to\ndynamically adjust the relative importance of local and global attention,\ndepending on the specific requirements of the task, thereby optimizing feature\nrepresentations across multiple scales.We have thoroughly evaluated the\nLocal-Global Attention mechanism on several widely used object detection and\nclassification datasets. Our experimental results demonstrate that this\napproach significantly enhances the detection of objects at various scales,\nwith particularly strong performance on multi-class and small object detection\ntasks. In comparison to existing attention mechanisms, Local-Global Attention\nconsistently outperforms them across several key metrics, all while maintaining\ncomputational efficiency."
    },
    {
      "id": "2411.09601v1",
      "title": "Accelerating Knowledge Graph and Ontology Engineering with Large Language Models",
      "summary": "Large Language Models bear the promise of significant acceleration of key\nKnowledge Graph and Ontology Engineering tasks, including ontology modeling,\nextension, modification, population, alignment, as well as entity\ndisambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering\nas a new and coming area of research, and argue that modular approaches to\nontologies will be of central importance."
    },
    {
      "id": "2411.09600v1",
      "title": "Latency Optimization in LEO Satellite Communications with Hybrid Beam Pattern and Interference Control",
      "summary": "The rapid advancement of low Earth orbit (LEO) satellite communication\nsystems has significantly enhanced global connectivity, offering high-capacity,\nlow-latency services crucial for next-generation applications. However, the\ndense configuration of LEO constellations poses challenges in resource\nallocation optimization and interference management, complicating coexistence\nwith other communication systems. To address these limitations, this paper\nproposes a novel framework for optimizing the beam scheduling and resource\nallocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic\ndemand, a hybrid beam pattern is employed to enhance the downlink quality of\nservice and minimize the transmission latency from LEO satellites to ground\nuser terminals. Additionally, a dynamic co-channel interference (CCI) control\nmechanism is developed to mitigate inter-beam interference within the LEO\nconstellation and limit cross-system interference affecting protected users\nfrom other networks. The problem of user-beam-frequency allocation with power\noptimization is formulated as a mixed-integer dynamic programming model and\nsolved using a low-complexity neural network-based graph generation algorithm.\nSimulation results show that the proposed approach outperforms the baseline\nmethods of full frequency reuse and single-channel transmission, and highlights\nthe potential for further performance improvement with multi-user\ntransmissions."
    },
    {
      "id": "2411.09595v1",
      "title": "LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models",
      "summary": "This work explores expanding the capabilities of large language models (LLMs)\npretrained on text to generate 3D meshes within a unified model. This offers\nkey advantages of (1) leveraging spatial knowledge already embedded in LLMs,\nderived from textual sources like 3D tutorials, and (2) enabling conversational\n3D generation and mesh understanding. A primary challenge is effectively\ntokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.\nTo address this, we introduce LLaMA-Mesh, a novel approach that represents the\nvertex coordinates and face definitions of 3D meshes as plain text, allowing\ndirect integration with LLMs without expanding the vocabulary. We construct a\nsupervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate\n3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs\nas required, and (3) understand and interpret 3D meshes. Our work is the first\nto demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge\nfor 3D mesh generation in a text-based format, effectively unifying the 3D and\ntext modalities. LLaMA-Mesh achieves mesh generation quality on par with models\ntrained from scratch while maintaining strong text generation performance."
    },
    {
      "id": "2411.09593v1",
      "title": "SMILE-UHURA Challenge -- Small Vessel Segmentation at Mesoscopic Scale from Ultra-High Resolution 7T Magnetic Resonance Angiograms",
      "summary": "The human brain receives nutrients and oxygen through an intricate network of\nblood vessels. Pathology affecting small vessels, at the mesoscopic scale,\nrepresents a critical vulnerability within the cerebral blood supply and can\nlead to severe conditions, such as Cerebral Small Vessel Diseases. The advent\nof 7 Tesla MRI systems has enabled the acquisition of higher spatial resolution\nimages, making it possible to visualise such vessels in the brain. However, the\nlack of publicly available annotated datasets has impeded the development of\nrobust, machine learning-driven segmentation algorithms. To address this, the\nSMILE-UHURA challenge was organised. This challenge, held in conjunction with\nthe ISBI 2023, in Cartagena de Indias, Colombia, aimed to provide a platform\nfor researchers working on related topics. The SMILE-UHURA challenge addresses\nthe gap in publicly available annotated datasets by providing an annotated\ndataset of Time-of-Flight angiography acquired with 7T MRI. This dataset was\ncreated through a combination of automated pre-segmentation and extensive\nmanual refinement. In this manuscript, sixteen submitted methods and two\nbaseline methods are compared both quantitatively and qualitatively on two\ndifferent datasets: held-out test MRAs from the same dataset as the training\ndata (with labels kept secret) and a separate 7T ToF MRA dataset where both\ninput volumes and labels are kept secret. The results demonstrate that most of\nthe submitted deep learning methods, trained on the provided training dataset,\nachieved reliable segmentation performance. Dice scores reached up to 0.838\n$\\pm$ 0.066 and 0.716 $\\pm$ 0.125 on the respective datasets, with an average\nperformance of up to 0.804 $\\pm$ 0.15."
    },
    {
      "id": "2411.09591v1",
      "title": "Expert Study on Interpretable Machine Learning Models with Missing Data",
      "summary": "Inherently interpretable machine learning (IML) models provide valuable\ninsights for clinical decision-making but face challenges when features have\nmissing values. Classical solutions like imputation or excluding incomplete\nrecords are often unsuitable in applications where values are missing at test\ntime. In this work, we conducted a survey with 71 clinicians from 29 trauma\ncenters across France, including 20 complete responses to study the interaction\nbetween medical professionals and IML applied to data with missing values. This\nprovided valuable insights into how missing data is interpreted in clinical\nmachine learning. We used the prediction of hemorrhagic shock as a concrete\nexample to gauge the willingness and readiness of the participants to adopt IML\nmodels from three classes of methods. Our findings show that, while clinicians\nvalue interpretability and are familiar with common IML methods, classical\nimputation techniques often misalign with their intuition, and that models that\nnatively handle missing values are preferred. These results emphasize the need\nto integrate clinical intuition into future IML models for better\nhuman-computer interaction."
    },
    {
      "id": "2411.09590v1",
      "title": "Adopting RAG for LLM-Aided Future Vehicle Design",
      "summary": "In this paper, we explore the integration of Large Language Models (LLMs)\nwith Retrieval-Augmented Generation (RAG) to enhance automated design and\nsoftware development in the automotive industry. We present two case studies: a\nstandardization compliance chatbot and a design copilot, both utilizing RAG to\nprovide accurate, context-aware responses. We evaluate four LLMs-GPT-4o,\nLLAMA3, Mistral, and Mixtral -- comparing their answering accuracy and\nexecution time. Our results demonstrate that while GPT-4 offers superior\nperformance, LLAMA3 and Mistral also show promising capabilities for local\ndeployment, addressing data privacy concerns in automotive applications. This\nstudy highlights the potential of RAG-augmented LLMs in improving design\nworkflows and compliance in automotive engineering."
    },
    {
      "id": "2411.09587v1",
      "title": "BabyLM Challenge: Exploring the Effect of Variation Sets on Language Model Training Efficiency",
      "summary": "While current large language models have achieved a remarkable success, their\ndata efficiency remains a challenge to overcome. Recently it has been suggested\nthat child-directed speech (CDS) can improve training data efficiency of modern\nlanguage models based on Transformer neural networks. However, it is not yet\nunderstood which specific properties of CDS are effective for training these\nmodels. In the context of the BabyLM Challenge, we focus on Variation Sets\n(VSs), sets of consecutive utterances expressing a similar intent with slightly\ndifferent words and structures, which are ubiquitous in CDS. To assess the\nimpact of VSs on training data efficiency, we augment CDS data with different\nproportions of artificial VSs and use these datasets to train an\nauto-regressive model, GPT-2. We find that the best proportion of VSs depends\non the evaluation benchmark: BLiMP and GLUE scores benefit from the presence of\nVSs, but EWOK scores do not. Additionally, the results vary depending on\nmultiple factors such as the number of epochs and the order of utterance\npresentation. Taken together, these findings suggest that VSs can have a\nbeneficial influence on language models, while leaving room for further\ninvestigation."
    },
    {
      "id": "2411.09580v1",
      "title": "Software Performance Engineering for Foundation Model-Powered Software (FMware)",
      "summary": "The rise of Foundation Models (FMs) like Large Language Models (LLMs) is\nrevolutionizing software development. Despite the impressive prototypes,\ntransforming FMware into production-ready products demands complex engineering\nacross various domains. A critical but overlooked aspect is performance\nengineering, which aims at ensuring FMware meets performance goals such as\nthroughput and latency to avoid user dissatisfaction and financial loss. Often,\nperformance considerations are an afterthought, leading to costly optimization\nefforts post-deployment. FMware's high computational resource demands highlight\nthe need for efficient hardware use. Continuous performance engineering is\nessential to prevent degradation. This paper highlights the significance of\nSoftware Performance Engineering (SPE) in FMware, identifying four key\nchallenges: cognitive architecture design, communication protocols, tuning and\noptimization, and deployment. These challenges are based on literature surveys\nand experiences from developing an in-house FMware system. We discuss problems,\ncurrent practices, and innovative paths for the software engineering community."
    },
    {
      "id": "2411.09576v1",
      "title": "Automating Reformulation of Essence Specifications via Graph Rewriting",
      "summary": "Formulating an effective constraint model of a parameterised problem class is\ncrucial to the efficiency with which instances of the class can subsequently be\nsolved. It is difficult to know beforehand which of a set of candidate models\nwill perform best in practice. This paper presents a system that employs graph\nrewriting to reformulate an input model for improved performance automatically.\nBy situating our work in the Essence abstract constraint specification\nlanguage, we can use the structure in its high level variable types to trigger\nrewrites directly. We implement our system via rewrite rules expressed in the\nGraph Programs 2 language, applied to the abstract syntax tree of an input\nspecification. We show how to automatically translate the solution of the\nreformulated problem into a solution of the original problem for verification\nand presentation. We demonstrate the efficacy of our system with a detailed\ncase study."
    },
    {
      "id": "2411.09558v1",
      "title": "Adaptive Deviation Learning for Visual Anomaly Detection with Data Contamination",
      "summary": "Visual anomaly detection targets to detect images that notably differ from\nnormal pattern, and it has found extensive application in identifying defective\nparts within the manufacturing industry. These anomaly detection paradigms\npredominantly focus on training detection models using only clean, unlabeled\nnormal samples, assuming an absence of contamination; a condition often unmet\nin real-world scenarios. The performance of these methods significantly depends\non the quality of the data and usually decreases when exposed to noise. We\nintroduce a systematic adaptive method that employs deviation learning to\ncompute anomaly scores end-to-end while addressing data contamination by\nassigning relative importance to the weights of individual instances. In this\napproach, the anomaly scores for normal instances are designed to approximate\nscalar scores obtained from the known prior distribution. Meanwhile, anomaly\nscores for anomaly examples are adjusted to exhibit statistically significant\ndeviations from these reference scores. Our approach incorporates a constrained\noptimization problem within the deviation learning framework to update instance\nweights, resolving this problem for each mini-batch. Comprehensive experiments\non the MVTec and VisA benchmark datasets indicate that our proposed method\nsurpasses competing techniques and exhibits both stability and robustness in\nthe presence of data contamination."
    },
    {
      "id": "2411.09547v1",
      "title": "Piecing It All Together: Verifying Multi-Hop Multimodal Claims",
      "summary": "Existing claim verification datasets often do not require systems to perform\ncomplex reasoning or effectively interpret multimodal evidence. To address\nthis, we introduce a new task: multi-hop multimodal claim verification. This\ntask challenges models to reason over multiple pieces of evidence from diverse\nsources, including text, images, and tables, and determine whether the combined\nmultimodal evidence supports or refutes a given claim. To study this task, we\nconstruct MMCV, a large-scale dataset comprising 16k multi-hop claims paired\nwith multimodal evidence, generated and refined using large language models,\nwith additional input from human feedback. We show that MMCV is challenging\neven for the latest state-of-the-art multimodal large language models,\nespecially as the number of reasoning hops increases. Additionally, we\nestablish a human performance benchmark on a subset of MMCV. We hope this\ndataset and its evaluation task will encourage future research in multimodal\nmulti-hop claim verification."
    },
    {
      "id": "2411.09545v1",
      "title": "Equation-informed data-driven identification of flow budgets and dynamics",
      "summary": "Computational Fluid Dynamics (CFD) is an indispensable method of fluid\nmodelling in engineering applications, reducing the need for physical\nprototypes and testing for tasks such as design optimisation and performance\nanalysis. Depending on the complexity of the system under consideration, models\nranging from low to high fidelity can be used for prediction, allowing\nsignificant speed-up. However, the choice of model requires information about\nthe actual dynamics of the flow regime. Correctly identifying the\nregions/clusters of flow that share the same dynamics has been a challenging\nresearch topic to date. In this study, we propose a novel hybrid approach to\nflow clustering. It consists of characterising each sample point of the system\nwith equation-based features, i.e. features are budgets that represent the\ncontribution of each term from the original governing equation to the local\ndynamics at each sample point. This was achieved by applying the Sparse\nIdentification of Nonlinear Dynamical systems (SINDy) method pointwise to time\nevolution data. The method proceeds with equation-based clustering using the\nGirvan-Newman algorithm. This allows the detection of communities that share\nthe same physical dynamics. The algorithm is implemented in both Eulerian and\nLagrangian frameworks. In the Lagrangian, i.e. dynamic approach, the clustering\nis performed on the trajectory of each point, allowing the change of clusters\nto be represented also in time. The performance of the algorithm is first\ntested on a flow around a cylinder. The construction of the dynamic clusters in\nthis test case clearly shows the evolution of the wake from the steady state\nsolution through the transient to the oscillatory solution. Dynamic clustering\nwas then successfully tested on turbulent flow data. Two distinct and\nwell-defined clusters were identified and their temporal evolution was\nreconstructed."
    },
    {
      "id": "2411.09543v1",
      "title": "OpenGeMM: A High-Utilization GeMM Accelerator Generator with Lightweight RISC-V Control and Tight Memory Coupling",
      "summary": "Deep neural networks (DNNs) face significant challenges when deployed on\nresource-constrained extreme edge devices due to their computational and\ndata-intensive nature. While standalone accelerators tailored for specific\napplication scenarios suffer from inflexible control and limited\nprogrammability, generic hardware acceleration platforms coupled with RISC-V\nCPUs can enable high reusability and flexibility, yet typically at the expense\nof system level efficiency and low utilization. To fill this gap, we propose\nOpenGeMM, an open-source acceleration platform, jointly demonstrating high\nefficiency and utilization, as well as ease of configurability and\nprogrammability. OpenGeMM encompasses a parameterized Chisel-coded GeMM\naccelerator, a lightweight RISC-V processor, and a tightly coupled multi-banked\nscratchpad memory. The GeMM core utilization and system efficiency are boosted\nthrough three mechanisms: configuration pre-loading, input pre-fetching with\noutput buffering, and programmable strided memory access. Experimental results\nshow that OpenGeMM can consistently achieve hardware utilization ranging from\n81.89% to 99.34% across diverse CNN and Transformer workloads. Compared to the\nSotA open-source Gemmini accelerator, OpenGeMM demonstrates a 3.58x to 16.40x\nspeedup on normalized throughput across a wide variety ofGeMM workloads, while\nachieving 4.68 TOPS/W system efficiency."
    },
    {
      "id": "2411.09540v1",
      "title": "Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models",
      "summary": "Visual prompting (VP) is a new technique that adapts well-trained frozen\nmodels for source domain tasks to target domain tasks. This study examines VP's\nbenefits for black-box model-level backdoor detection. The visual prompt in VP\nmaps class subspaces between source and target domains. We identify a\nmisalignment, termed class subspace inconsistency, between clean and poisoned\ndatasets. Based on this, we introduce \\textsc{BProm}, a black-box model-level\ndetection method to identify backdoors in suspicious models, if any.\n\\textsc{BProm} leverages the low classification accuracy of prompted models\nwhen backdoors are present. Extensive experiments confirm \\textsc{BProm}'s\neffectiveness."
    },
    {
      "id": "2411.09539v1",
      "title": "A Practical Guide to Fine-tuning Language Models with Limited Data",
      "summary": "Employing pre-trained Large Language Models (LLMs) has become the de facto\nstandard in Natural Language Processing (NLP) despite their extensive data\nrequirements. Motivated by the recent surge in research focused on training\nLLMs with limited data, particularly in low-resource domains and languages,\nthis paper surveys recent transfer learning approaches to optimize model\nperformance in downstream tasks where data is scarce. We first address initial\nand continued pre-training strategies to better leverage prior knowledge in\nunseen domains and languages. We then examine how to maximize the utility of\nlimited data during fine-tuning and few-shot learning. The final section takes\na task-specific perspective, reviewing models and methods suited for different\nlevels of data scarcity. Our goal is to provide practitioners with practical\nguidelines for overcoming the challenges posed by constrained data while also\nhighlighting promising directions for future research."
    },
    {
      "id": "2411.09523v1",
      "title": "Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents",
      "summary": "With the continuous development of large language models (LLMs),\ntransformer-based models have made groundbreaking advances in numerous natural\nlanguage processing (NLP) tasks, leading to the emergence of a series of agents\nthat use LLMs as their control hub. While LLMs have achieved success in various\ntasks, they face numerous security and privacy threats, which become even more\nsevere in the agent scenarios. To enhance the reliability of LLM-based\napplications, a range of research has emerged to assess and mitigate these\nrisks from different perspectives.\n  To help researchers gain a comprehensive understanding of various risks, this\nsurvey collects and analyzes the different threats faced by these agents. To\naddress the challenges posed by previous taxonomies in handling cross-module\nand cross-stage threats, we propose a novel taxonomy framework based on the\nsources and impacts. Additionally, we identify six key features of LLM-based\nagents, based on which we summarize the current research progress and analyze\ntheir limitations. Subsequently, we select four representative agents as case\nstudies to analyze the risks they may face in practical use. Finally, based on\nthe aforementioned analyses, we propose future research directions from the\nperspectives of data, methodology, and policy, respectively."
    },
    {
      "id": "2411.09517v1",
      "title": "Randomized Truthful Auctions with Learning Agents",
      "summary": "We study a setting where agents use no-regret learning algorithms to\nparticipate in repeated auctions. \\citet{kolumbus2022auctions} showed, rather\nsurprisingly, that when bidders participate in second-price auctions using\nno-regret bidding algorithms, no matter how large the number of interactions\n$T$ is, the runner-up bidder may not converge to bidding truthfully. Our first\nresult shows that this holds for \\emph{general deterministic} truthful\nauctions. We also show that the ratio of the learning rates of the bidders can\n\\emph{qualitatively} affect the convergence of the bidders. Next, we consider\nthe problem of revenue maximization in this environment. In the setting with\nfully rational bidders, \\citet{myerson1981optimal} showed that revenue can be\nmaximized by using a second-price auction with reserves.We show that, in stark\ncontrast, in our setting with learning bidders, \\emph{randomized} auctions can\nhave strictly better revenue guarantees than second-price auctions with\nreserves, when $T$ is large enough. Finally, we study revenue maximization in\nthe non-asymptotic regime. We define a notion of {\\em auctioneer regret}\ncomparing the revenue generated to the revenue of a second price auction with\ntruthful bids. When the auctioneer has to use the same auction throughout the\ninteraction, we show an (almost) tight regret bound of $\\smash{\\widetilde\n\\Theta(T^{3/4})}.$ If the auctioneer can change auctions during the\ninteraction, but in a way that is oblivious to the bids, we show an (almost)\ntight bound of $\\smash{\\widetilde \\Theta(\\sqrt{T})}.$"
    },
    {
      "id": "2411.09512v1",
      "title": "GAN-Based Architecture for Low-dose Computed Tomography Imaging Denoising",
      "summary": "Generative Adversarial Networks (GANs) have surfaced as a revolutionary\nelement within the domain of low-dose computed tomography (LDCT) imaging,\nproviding an advanced resolution to the enduring issue of reconciling radiation\nexposure with image quality. This comprehensive review synthesizes the rapid\nadvancements in GAN-based LDCT denoising techniques, examining the evolution\nfrom foundational architectures to state-of-the-art models incorporating\nadvanced features such as anatomical priors, perceptual loss functions, and\ninnovative regularization strategies. We critically analyze various GAN\narchitectures, including conditional GANs (cGANs), CycleGANs, and\nSuper-Resolution GANs (SRGANs), elucidating their unique strengths and\nlimitations in the context of LDCT denoising. The evaluation provides both\nqualitative and quantitative results related to the improvements in performance\nin benchmark and clinical datasets with metrics such as PSNR, SSIM, and LPIPS.\nAfter highlighting the positive results, we discuss some of the challenges\npreventing a wider clinical use, including the interpretability of the images\ngenerated by GANs, synthetic artifacts, and the need for clinically relevant\nmetrics. The review concludes by highlighting the essential significance of\nGAN-based methodologies in the progression of precision medicine via tailored\nLDCT denoising models, underlining the transformative possibilities presented\nby artificial intelligence within contemporary radiological practice."
    },
    {
      "id": "2411.09510v1",
      "title": "Communication Compression for Tensor Parallel LLM Inference",
      "summary": "Large Language Models (LLMs) have pushed the frontier of artificial\nintelligence but are comprised of hundreds of billions of parameters and\noperations. For faster inference latency, LLMs are deployed on multiple\nhardware accelerators through various Model Parallelism strategies. Our paper\nlooks into the details on one such strategy - Tensor Parallel - and proposes to\nreduce latency by compressing inter-accelerator communication. We leverage fine\ngrained quantization techniques to compress selected activations by 3.5 - 4.5x.\nOur proposed method leads up to 2x reduction of time-to-first-token (TTFT) with\nnegligible model performance degradation."
    },
    {
      "id": "2411.09507v1",
      "title": "Toward a Cohesive AI and Simulation Software Ecosystem for Scientific Innovation",
      "summary": "In this paper, we discuss the need for an integrated software stack that\nunites artificial intelligence (AI) and modeling and simulation (ModSim) tools\nto advance scientific discovery. The authors advocate for a unified AI/ModSim\nsoftware ecosystem that ensures compatibility across a wide range of software\non diverse high-performance computing systems, promoting ease of deployment,\nversion management, and binary distribution. Key challenges highlighted include\nbalancing the distinct needs of AI and ModSim, especially in terms of software\nbuild practices, dependency management, and compatibility. The document\nunderscores the importance of continuous integration, community-driven\nstewardship, and collaboration with the Department of Energy (DOE) to develop a\nportable and cohesive scientific software ecosystem. Recommendations focus on\nsupporting standardized environments through initiatives like the Extreme-scale\nScientific Software Stack (E4S) and Spack to foster interdisciplinary\ninnovation and facilitate new scientific advancements."
    },
    {
      "id": "2411.09502v1",
      "title": "Golden Noise for Diffusion Models: A Learning Framework",
      "summary": "Text-to-image diffusion model is a popular paradigm that synthesizes\npersonalized images by providing a text prompt and a random Gaussian noise.\nWhile people observe that some noises are ``golden noises'' that can achieve\nbetter text-image alignment and higher human preference than others, we still\nlack a machine learning framework to obtain those golden noises. To learn\ngolden noises for diffusion sampling, we mainly make three contributions in\nthis paper. First, we identify a new concept termed the \\textit{noise prompt},\nwhich aims at turning a random Gaussian noise into a golden noise by adding a\nsmall desirable perturbation derived from the text prompt. Following the\nconcept, we first formulate the \\textit{noise prompt learning} framework that\nsystematically learns ``prompted'' golden noise associated with a text prompt\nfor diffusion models. Second, we design a noise prompt data collection pipeline\nand collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains\n100k pairs of random noises and golden noises with the associated text prompts.\nWith the prepared NPD as the training dataset, we trained a small \\textit{noise\nprompt network}~(NPNet) that can directly learn to transform a random noise\ninto a golden noise. The learned golden noise perturbation can be considered as\na kind of prompt for noise, as it is rich in semantic information and tailored\nto the given text prompt. Third, our extensive experiments demonstrate the\nimpressive effectiveness and generalization of NPNet on improving the quality\nof synthesized images across various diffusion models, including SDXL,\nDreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and\nefficient controller that acts as a plug-and-play module with very limited\nadditional inference and computational costs, as it just provides a golden\nnoise instead of a random noise without accessing the original pipeline."
    },
    {
      "id": "2411.09499v1",
      "title": "Developement of Reinforcement Learning based Optimisation Method for Side-Sill Design",
      "summary": "Optimisation for crashworthiness is a critical part of the vehicle\ndevelopment process. Due to stringent regulations and increasing market\ndemands, multiple factors must be considered within a limited timeframe.\nHowever, for optimal crashworthiness design, multiobjective optimisation is\nnecessary, and for complex parts, multiple design parameters must be evaluated.\nThis crashworthiness analysis requires computationally intensive finite element\nsimulations. This challenge leads to the need for inverse multi-parameter\nmulti-objective optimisation. This challenge leads to the need for\nmulti-parameter, multi-objective inverse optimisation. This article\ninvestigates a machine learning-based method for this type of optimisation,\nfocusing on the design optimisation of a multi-cell side sill to improve\ncrashworthiness results. Furthermore, the optimiser is coupled with an FE\nsolver to achieve improved results."
    },
    {
      "id": "2411.09497v1",
      "title": "The Use of Readability Metrics in Legal Text: A Systematic Literature Review",
      "summary": "Understanding the text in legal documents can be challenging due to their\ncomplex structure and the inclusion of domain-specific jargon. Laws and\nregulations are often crafted in such a manner that engagement with them\nrequires formal training, potentially leading to vastly different\ninterpretations of the same texts. Linguistic complexity is an important\ncontributor to the difficulties experienced by readers. Simplifying texts could\nenhance comprehension across a broader audience, not just among trained\nprofessionals. Various metrics have been developed to measure document\nreadability. Therefore, we adopted a systematic review approach to examine the\nlinguistic and readability metrics currently employed for legal and regulatory\ntexts. A total of 3566 initial papers were screened, with 34 relevant studies\nfound and further assessed. Our primary objective was to identify which current\nmetrics were applied for evaluating readability within the legal field. Sixteen\ndifferent metrics were identified, with the Flesch-Kincaid Grade Level being\nthe most frequently used method. The majority of studies (73.5%) were found in\nthe domain of \"informed consent forms\". From the analysis, it is clear that not\nall legal domains are well represented in terms of readability metrics and that\nthere is a further need to develop more consensus on which metrics should be\napplied for legal documents."
    },
    {
      "id": "2411.09492v1",
      "title": "MM-Eval: A Hierarchical Benchmark for Modern Mongolian Evaluation in LLMs",
      "summary": "Large language models (LLMs) excel in high-resource languages but face\nnotable challenges in low-resource languages like Mongolian. This paper\naddresses these challenges by categorizing capabilities into language abilities\n(syntax and semantics) and cognitive abilities (knowledge and reasoning). To\nsystematically evaluate these areas, we developed MM-Eval, a specialized\ndataset based on Modern Mongolian Language Textbook I and enriched with WebQSP\nand MGSM datasets.\n  Preliminary experiments on models including Qwen2-7B-Instruct, GLM4-9b-chat,\nLlama3.1-8B-Instruct, GPT-4, and DeepseekV2.5 revealed that: 1) all models\nperformed better on syntactic tasks than semantic tasks, highlighting a gap in\ndeeper language understanding; and 2) knowledge tasks showed a moderate\ndecline, suggesting that models can transfer general knowledge from\nhigh-resource to low-resource contexts.\n  The release of MM-Eval, comprising 569 syntax, 677 semantics, 344 knowledge,\nand 250 reasoning tasks, offers valuable insights for advancing NLP and LLMs in\nlow-resource languages like Mongolian. The dataset is available at\nhttps://github.com/joenahm/MM-Eval."
    },
    {
      "id": "2411.09483v1",
      "title": "Sparse Bayesian Generative Modeling for Compressive Sensing",
      "summary": "This work addresses the fundamental linear inverse problem in compressive\nsensing (CS) by introducing a new type of regularizing generative prior. Our\nproposed method utilizes ideas from classical dictionary-based CS and, in\nparticular, sparse Bayesian learning (SBL), to integrate a strong\nregularization towards sparse solutions. At the same time, by leveraging the\nnotion of conditional Gaussianity, it also incorporates the adaptability from\ngenerative models to training data. However, unlike most state-of-the-art\ngenerative models, it is able to learn from a few compressed and noisy data\nsamples and requires no optimization algorithm for solving the inverse problem.\nAdditionally, similar to Dirichlet prior networks, our model parameterizes a\nconjugate prior enabling its application for uncertainty quantification. We\nsupport our approach theoretically through the concept of variational inference\nand validate it empirically using different types of compressible signals."
    },
    {
      "id": "2411.09481v1",
      "title": "What makes a good BIM design: quantitative linking between design behavior and quality",
      "summary": "In the Architecture Engineering & Construction (AEC) industry, how design\nbehaviors impact design quality remains unclear. This study proposes a novel\napproach, which, for the first time, identifies and quantitatively describes\nthe relationship between design behaviors and quality of design based on\nBuilding Information Modeling (BIM). Real-time collection and log mining are\nintegrated to collect raw data of design behaviors. Feature engineering and\nvarious machine learning models are then utilized for quantitative modeling and\ninterpretation. Results confirm an existing quantifiable relationship which can\nbe learned by various models. The best-performing model using Extremely Random\nTrees achieved an R2 value of 0.88 on the test set. Behavioral features related\nto designer's skill level and changes of design intentions are identified to\nhave significant impacts on design quality. These findings deepen our\nunderstanding of the design process and help forming BIM designs with better\nquality."
    },
    {
      "id": "2411.09476v1",
      "title": "Graph Neural Networks and Differential Equations: A hybrid approach for data assimilation of fluid flows",
      "summary": "This study presents a novel hybrid approach that combines Graph Neural\nNetworks (GNNs) with Reynolds-Averaged Navier Stokes (RANS) equations to\nenhance the accuracy of mean flow reconstruction across a range of fluid\ndynamics applications. Traditional purely data-driven Neural Networks (NNs)\nmodels, often struggle maintaining physical consistency. Moreover, they\ntypically require large datasets to achieve reliable performances. The GNN\nframework, which naturally handles unstructured data such as complex geometries\nin Computational Fluid Dynamics (CFD), is here integrated with RANS equations\nas a physical baseline model. The methodology leverages the adjoint method,\nenabling the use of RANS-derived gradients as optimization terms in the GNN\ntraining process. This ensures that the learned model adheres to the governing\nphysics, maintaining physical consistency while improving the prediction\naccuracy. We test our approach on multiple CFD scenarios, including cases\ninvolving generalization with respect to the Reynolds number, sparse\nmeasurements, denoising and inpainting of missing portions of the mean flow.\nThe results demonstrate significant improvements in the accuracy of the\nreconstructed mean flow compared to purely data-driven models, using limited\namounts of data in the training dataset. The key strengths of this study are\nthe integration of physical laws into the training process of the GNN, and the\nability to achieve high-accuracy predictions with a limited amount of data,\nmaking this approach particularly valuable for applications in fluid dynamics\nwhere data is often scarce."
    },
    {
      "id": "2411.09475v1",
      "title": "ResidualDroppath: Enhancing Feature Reuse over Residual Connections",
      "summary": "Residual connections are one of the most important components in neural\nnetwork architectures for mitigating the vanishing gradient problem and\nfacilitating the training of much deeper networks. One possible explanation for\nhow residual connections aid deeper network training is by promoting feature\nreuse. However, we identify and analyze the limitations of feature reuse with\nvanilla residual connections. To address these limitations, we propose\nmodifications in training methods. Specifically, we provide an additional\nopportunity for the model to learn feature reuse with residual connections\nthrough two types of iterations during training. The first type of iteration\ninvolves using droppath, which enforces feature reuse by randomly dropping a\nsubset of layers. The second type of iteration focuses on training the dropped\nparts of the model while freezing the undropped parts. As a result, the dropped\nparts learn in a way that encourages feature reuse, as the model relies on the\nundropped parts with feature reuse in mind. Overall, we demonstrated\nperformance improvements in models with residual connections for image\nclassification in certain cases."
    },
    {
      "id": "2411.09471v1",
      "title": "Renal Cell Carcinoma subtyping: learning from multi-resolution localization",
      "summary": "Renal Cell Carcinoma is typically asymptomatic at the early stages for many\npatients. This leads to a late diagnosis of the tumor, where the curability\nlikelihood is lower, and makes the mortality rate of Renal Cell Carcinoma high,\nwith respect to its incidence rate. To increase the survival chance, a fast and\ncorrect categorization of the tumor subtype is paramount. Nowadays,\ncomputerized methods, based on artificial intelligence, represent an\ninteresting opportunity to improve the productivity and the objectivity of the\nmicroscopy-based Renal Cell Carcinoma diagnosis. Nonetheless, much of their\nexploitation is hampered by the paucity of annotated dataset, essential for a\nproficient training of supervised machine learning technologies. This study\nsets out to investigate a novel self supervised training strategy for machine\nlearning diagnostic tools, based on the multi-resolution nature of the\nhistological samples. We aim at reducing the need of annotated dataset, without\nsignificantly reducing the accuracy of the tool. We demonstrate the\nclassification capability of our tool on a whole slide imaging dataset for\nRenal Cancer subtyping, and we compare our solution with several\nstate-of-the-art classification counterparts."
    },
    {
      "id": "2411.09469v1",
      "title": "An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images",
      "summary": "Cervical cancer remains a major worldwide health issue, with early\nidentification and risk assessment playing critical roles in effective\npreventive interventions. This paper presents the Cervix-AID-Net model for\ncervical precancer risk classification. The study designs and evaluates the\nproposed Cervix-AID-Net model based on patients colposcopy images. The model\ncomprises a Convolutional Block Attention Module (CBAM) and convolutional\nlayers that extract interpretable and representative features of colposcopic\nimages to distinguish high-risk and low-risk cervical precancer. In addition,\nthe proposed Cervix-AID-Net model integrates four explainable techniques,\nnamely gradient class activation maps, Local Interpretable Model-agnostic\nExplanations, CartoonX, and pixel rate distortion explanation based on output\nfeature maps and input features. The evaluation using holdout and ten-fold\ncross-validation techniques yielded a classification accuracy of 99.33\\% and\n99.81\\%. The analysis revealed that CartoonX provides meticulous explanations\nfor the decision of the Cervix-AID-Net model due to its ability to provide the\nrelevant piece-wise smooth part of the image. The effect of Gaussian noise and\nblur on the input shows that the performance remains unchanged up to Gaussian\nnoise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A\ncomparison study of the proposed model's performance compared to other deep\nlearning approaches highlights the Cervix-AID-Net model's potential as a\nsupplemental tool for increasing the effectiveness of cervical precancer risk\nassessment. The proposed method, which incorporates the CBAM and explainable\nartificial integration, has the potential to influence cervical cancer\nprevention and early detection, improving patient outcomes and lowering the\nworldwide burden of this preventable disease."
    },
    {
      "id": "2411.09468v1",
      "title": "Harnessing Machine Learning for Single-Shot Measurement of Free Electron Laser Pulse Power",
      "summary": "Electron beam accelerators are essential in many scientific and technological\nfields. Their operation relies heavily on the stability and precision of the\nelectron beam. Traditional diagnostic techniques encounter difficulties in\naddressing the complex and dynamic nature of electron beams. Particularly in\nthe context of free-electron lasers (FELs), it is fundamentally impossible to\nmeasure the lasing-on and lasingoff electron power profiles for a single\nelectron bunch. This is a crucial hurdle in the exact reconstruction of the\nphoton pulse profile. To overcome this hurdle, we developed a machine learning\nmodel that predicts the temporal power profile of the electron bunch in the\nlasing-off regime using machine parameters that can be obtained when lasing is\non. The model was statistically validated and showed superior predictions\ncompared to the state-of-the-art batch calibrations. The work we present here\nis a critical element for a virtual pulse reconstruction diagnostic (VPRD) tool\ndesigned to reconstruct the power profile of individual photon pulses without\nrequiring repeated measurements in the lasing-off regime. This promises to\nsignificantly enhance the diagnostic capabilities in FELs at large."
    },
    {
      "id": "2411.09459v1",
      "title": "Caravan MultiMet: Extending Caravan with Multiple Weather Nowcasts and Forecasts",
      "summary": "The Caravan large-sample hydrology dataset (Kratzert et al., 2023) was\ncreated to standardize and harmonize streamflow data from various regional\ndatasets, combined with globally available meteorological forcing and catchment\nattributes. This community-driven project also allows researchers to\nconveniently extend the dataset for additional basins, as done 6 times to date\n(see https://github.com/kratzert/Caravan/discussions/10). We present a novel\nextension to Caravan, focusing on enriching the meteorological forcing data.\nOur extension adds three precipitation nowcast products (CPC, IMERG v07 Early,\nand CHIRPS) and three weather forecast products (ECMWF IFS HRES, GraphCast, and\nCHIRPS-GEFS) to the existing ERA5-Land reanalysis data. The inclusion of\ndiverse data sources, particularly weather forecasts, enables more robust\nevaluation and benchmarking of hydrological models, especially for real-time\nforecasting scenarios. To the best of our knowledge, this extension makes\nCaravan the first large-sample hydrology dataset to incorporate weather\nforecast data, significantly enhancing its capabilities and fostering\nadvancements in hydrological research, benchmarking, and real-time hydrologic\nforecasting. The data is publicly available under a CC-BY-4.0 license on Zenodo\nin two parts (https://zenodo.org/records/14161235,\nhttps://zenodo.org/records/14161281) and on Google Cloud Platform (GCP) - see\nmore under the Data Availability chapter."
    },
    {
      "id": "2411.09453v1",
      "title": "Long-Tailed Object Detection Pre-training: Dynamic Rebalancing Contrastive Learning with Dual Reconstruction",
      "summary": "Pre-training plays a vital role in various vision tasks, such as object\nrecognition and detection. Commonly used pre-training methods, which typically\nrely on randomized approaches like uniform or Gaussian distributions to\ninitialize model parameters, often fall short when confronted with long-tailed\ndistributions, especially in detection tasks. This is largely due to extreme\ndata imbalance and the issue of simplicity bias. In this paper, we introduce a\nnovel pre-training framework for object detection, called Dynamic Rebalancing\nContrastive Learning with Dual Reconstruction (2DRCL). Our method builds on a\nHolistic-Local Contrastive Learning mechanism, which aligns pre-training with\nobject detection by capturing both global contextual semantics and detailed\nlocal patterns. To tackle the imbalance inherent in long-tailed data, we design\na dynamic rebalancing strategy that adjusts the sampling of underrepresented\ninstances throughout the pre-training process, ensuring better representation\nof tail classes. Moreover, Dual Reconstruction addresses simplicity bias by\nenforcing a reconstruction task aligned with the self-consistency principle,\nspecifically benefiting underrepresented tail classes. Experiments on COCO and\nLVIS v1.0 datasets demonstrate the effectiveness of our method, particularly in\nimproving the mAP/AP scores for tail classes."
    },
    {
      "id": "2411.09451v1",
      "title": "DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing",
      "summary": "Generating realistic and diverse road scenarios is essential for autonomous\nvehicle testing and validation. Nevertheless, owing to the complexity and\nvariability of real-world road environments, creating authentic and varied\nscenarios for intelligent driving testing is challenging. In this paper, we\npropose DiffRoad, a novel diffusion model designed to produce controllable and\nhigh-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities\nof diffusion models to synthesize road layouts from white noise through an\ninverse denoising process, preserving real-world spatial features. To enhance\nthe quality of generated scenarios, we design the Road-UNet architecture,\noptimizing the balance between backbone and skip connections for high-realism\nscenario generation. Furthermore, we introduce a road scenario evaluation\nmodule that screens adequate and reasonable scenarios for intelligent driving\ntesting using two critical metrics: road continuity and road reasonableness.\nExperimental results on multiple real-world datasets demonstrate DiffRoad's\nability to generate realistic and smooth road structures while maintaining the\noriginal distribution. Additionally, the generated scenarios can be fully\nautomated into the OpenDRIVE format, facilitating generalized autonomous\nvehicle simulation testing. DiffRoad provides a rich and diverse scenario\nlibrary for large-scale autonomous vehicle testing and offers valuable insights\nfor future infrastructure designs that are better suited for autonomous\nvehicles."
    },
    {
      "id": "2411.09444v1",
      "title": "Learning efficient and provably convergent splitting methods",
      "summary": "Splitting methods are widely used for solving initial value problems (IVPs)\ndue to their ability to simplify complicated evolutions into more manageable\nsubproblems which can be solved efficiently and accurately. Traditionally,\nthese methods are derived using analytic and algebraic techniques from\nnumerical analysis, including truncated Taylor series and their Lie algebraic\nanalogue, the Baker--Campbell--Hausdorff formula. These tools enable the\ndevelopment of high-order numerical methods that provide exceptional accuracy\nfor small timesteps. Moreover, these methods often (nearly) conserve important\nphysical invariants, such as mass, unitarity, and energy. However, in many\npractical applications the computational resources are limited. Thus, it is\ncrucial to identify methods that achieve the best accuracy within a fixed\ncomputational budget, which might require taking relatively large timesteps. In\nthis regime, high-order methods derived with traditional methods often exhibit\nlarge errors since they are only designed to be asymptotically optimal. Machine\nLearning techniques offer a potential solution since they can be trained to\nefficiently solve a given IVP with less computational resources. However, they\nare often purely data-driven, come with limited convergence guarantees in the\nsmall-timestep regime and do not necessarily conserve physical invariants. In\nthis work, we propose a framework for finding machine learned splitting methods\nthat are computationally efficient for large timesteps and have provable\nconvergence and conservation guarantees in the small-timestep limit. We\ndemonstrate numerically that the learned methods, which by construction\nconverge quadratically in the timestep size, can be significantly more\nefficient than established methods for the Schr\\\"{o}dinger equation if the\ncomputational budget is limited."
    },
    {
      "id": "2411.09436v1",
      "title": "Robot Tasks with Fuzzy Time Requirements from Natural Language Instructions",
      "summary": "Natural language allows robot programming to be accessible to everyone.\nHowever, the inherent fuzziness in natural language poses challenges for\ninflexible, traditional robot systems. We focus on instructions with fuzzy time\nrequirements (e.g., \"start in a few minutes\"). Building on previous robotics\nresearch, we introduce fuzzy skills. These define an execution by the robot\nwith so-called satisfaction functions representing vague execution time\nrequirements. Such functions express a user's satisfaction over potential\nstarting times for skill execution. When the robot handles multiple fuzzy\nskills, the satisfaction function provides a temporal tolerance window for\nexecution, thus, enabling optimal scheduling based on satisfaction. We\ngeneralized such functions based on individual user expectations with a user\nstudy. The participants rated their satisfaction with an instruction's\nexecution at various times. Our investigations reveal that trapezoidal\nfunctions best approximate the users' satisfaction. Additionally, the results\nsuggest that users are more lenient if the execution is specified further into\nthe future."
    },
    {
      "id": "2411.09431v1",
      "title": "Everyone deserves their voice to be heard: Analyzing Predictive Gender Bias in ASR Models Applied to Dutch Speech Data",
      "summary": "Recent research has shown that state-of-the-art (SotA) Automatic Speech\nRecognition (ASR) systems, such as Whisper, often exhibit predictive biases\nthat disproportionately affect various demographic groups. This study focuses\non identifying the performance disparities of Whisper models on Dutch speech\ndata from the Common Voice dataset and the Dutch National Public Broadcasting\norganisation. We analyzed the word error rate, character error rate and a\nBERT-based semantic similarity across gender groups. We used the moral\nframework of Weerts et al. (2022) to assess quality of service harms and\nfairness, and to provide a nuanced discussion on the implications of these\nbiases, particularly for automatic subtitling. Our findings reveal substantial\ndisparities in word error rate (WER) among gender groups across all model\nsizes, with bias identified through statistical testing."
    },
    {
      "id": "2411.09429v1",
      "title": "AI-driven inverse design of materials: Past, present and future",
      "summary": "The discovery of advanced materials is the cornerstone of human technological\ndevelopment and progress. The structures of materials and their corresponding\nproperties are essentially the result of a complex interplay of multiple\ndegrees of freedom such as lattice, charge, spin, symmetry, and topology. This\nposes significant challenges for the inverse design methods of materials.\nHumans have long explored new materials through a large number of experiments\nand proposed corresponding theoretical systems to predict new material\nproperties and structures. With the improvement of computational power,\nresearchers have gradually developed various electronic structure calculation\nmethods, particularly such as the one based density functional theory, as well\nas high-throughput computational methods. Recently, the rapid development of\nartificial intelligence technology in the field of computer science has enabled\nthe effective characterization of the implicit association between material\nproperties and structures, thus opening up an efficient paradigm for the\ninverse design of functional materials. A significant progress has been made in\ninverse design of materials based on generative and discriminative models,\nattracting widespread attention from researchers. Considering this rapid\ntechnological progress, in this survey, we look back on the latest advancements\nin AI-driven inverse design of materials by introducing the background, key\nfindings, and mainstream technological development routes. In addition, we\nsummarize the remaining issues for future directions. This survey provides the\nlatest overview of AI-driven inverse design of materials, which can serve as a\nuseful resource for researchers."
    },
    {
      "id": "2411.09422v1",
      "title": "An Adaptive Open-Source Dataset Generation Framework for Machine Learning Tasks in Logic Synthesis",
      "summary": "This paper introduces an adaptive logic synthesis dataset generation\nframework designed to enhance machine learning applications within the logic\nsynthesis process. Unlike previous dataset generation flows that were tailored\nfor specific tasks or lacked integrated machine learning capabilities, the\nproposed framework supports a comprehensive range of machine learning tasks by\nencapsulating the three fundamental steps of logic synthesis: Boolean\nrepresentation, logic optimization, and technology mapping. It preserves the\noriginal information in the intermediate files that can be stored in both\nVerilog and Graphmal format. Verilog files enable semi-customizability,\nallowing researchers to add steps and incrementally refine the generated\ndataset. The framework also includes an adaptive circuit engine to facilitate\nthe loading of GraphML files for final dataset packaging and sub-dataset\nextraction. The generated OpenLS-D dataset comprises 46 combinational designs\nfrom established benchmarks, totaling over 966,000 Boolean circuits, with each\ndesign containing 21,000 circuits generated from 1000 synthesis recipes,\nincluding 7000 Boolean networks, 7000 ASIC netlists, and 7000 FPGA netlists.\nFurthermore, OpenLS-D supports integrating newly desired data features, making\nit more versatile for new challenges. The utility of OpenLS-D is demonstrated\nthrough four distinct downstream tasks: circuit classification, circuit\nranking, quality of results (QoR) prediction, and probability prediction. Each\ntask highlights different internal steps of logic synthesis, with the datasets\nextracted and relabeled from the OpenLS-D dataset using the circuit engine. The\nexperimental results confirm the dataset's diversity and extensive\napplicability. The source code and datasets are available at\nhttps://github.com/Logic-Factory/ACE/blob/master/OpenLS-D/readme.md."
    },
    {
      "id": "2411.09420v1",
      "title": "SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph Attention for Vision Transformers",
      "summary": "Image classification is a computer vision task where a model analyzes an\nimage to categorize it into a specific label. Vision Transformers (ViT) improve\nthis task by leveraging self-attention to capture complex patterns and long\nrange relationships between image patches. However, a key challenge for ViTs is\nefficiently incorporating multiscale feature representations, which is inherent\nin CNNs through their hierarchical structure. In this paper, we introduce the\nScale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework\nthat addresses this challenge by integrating multi-scale features. Using\nEfficientNet as a backbone, the model extracts multi-scale feature maps, which\nare divided into patches to preserve semantic information. These patches are\norganized into a graph based on spatial and feature similarities, with a Graph\nAttention Network (GAT) refining the node embeddings. Finally, a Transformer\nencoder captures long-range dependencies and complex interactions. The SAG-ViT\nis evaluated on benchmark datasets, demonstrating its effectiveness in\nenhancing image classification performance."
    },
    {
      "id": "2411.09413v1",
      "title": "Script-centric behavior understanding for assisted autism spectrum disorder diagnosis",
      "summary": "Observing and analyzing children's social behaviors is crucial for the early\ndiagnosis of Autism Spectrum Disorders (ASD). This work focuses on\nautomatically detecting ASD using computer vision techniques and large language\nmodels (LLMs). Existing methods typically rely on supervised learning. However,\nthe scarcity of ASD diagnostic datasets and the lack of interpretability in\ndiagnostic results significantly limits its clinical application. To address\nthese challenges, we introduce a novel unsupervised approach based on\nscript-centric behavior understanding. Our pipeline converts video content into\nscripts that describe the behavior of characters, leveraging the\ngeneralizability of large language models to detect ASD in a zero-shot or\nfew-shot manner. Specifically, we propose a scripts transcription module for\nmultimodal behavior data textualization and a domain prompts module to bridge\nLLMs. Our method achieves an accuracy of 92.00\\% in diagnosing ASD in children\nwith an average age of 24 months, surpassing the performance of supervised\nlearning methods by 3.58\\% absolutely. Extensive experiments confirm the\neffectiveness of our approach and suggest its potential for advancing ASD\nresearch through LLMs."
    },
    {
      "id": "2411.09403v1",
      "title": "Quantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning",
      "summary": "Quantum machine learning (QML) is a rapidly growing field that combines\nquantum computing principles with traditional machine learning. It seeks to\nrevolutionize machine learning by harnessing the unique capabilities of quantum\nmechanics and employs machine learning techniques to advance quantum computing\nresearch. This paper introduces quantum computing for the machine learning\nparadigm, where variational quantum circuits (VQC) are used to develop QML\narchitectures on noisy intermediate-scale quantum (NISQ) devices. We discuss\nmachine learning for the quantum computing paradigm, showcasing our recent\ntheoretical and empirical findings. In particular, we delve into future\ndirections for studying QML, exploring the potential industrial impacts of QML\nresearch."
    },
    {
      "id": "2411.09402v1",
      "title": "Automated Segmentation of Ischemic Stroke Lesions in Non-Contrast Computed Tomography Images for Enhanced Treatment and Prognosis",
      "summary": "Stroke is the second leading cause of death worldwide, and is increasingly\nprevalent in low- and middle-income countries (LMICs). Timely interventions can\nsignificantly influence stroke survivability and the quality of life after\ntreatment. However, the standard and most widely available imaging method for\nconfirming strokes and their sub-types, the NCCT, is more challenging and\ntime-consuming to employ in cases of ischemic stroke. For this reason, we\ndeveloped an automated method for ischemic stroke lesion segmentation in NCCTs\nusing the nnU-Net frame work, aimed at enhancing early treatment and improving\nthe prognosis of ischemic stroke patients. We achieved Dice scores of 0.596 and\nIntersection over Union (IoU) scores of 0.501 on the sampled dataset. After\nadjusting for outliers, these scores improved to 0.752 for the Dice score and\n0.643 for the IoU. Proper delineation of the region of infarction can help\nclinicians better assess the potential impact of the infarction, and guide\ntreatment procedures."
    },
    {
      "id": "2411.09400v1",
      "title": "Imagined Speech and Visual Imagery as Intuitive Paradigms for Brain-Computer Interfaces",
      "summary": "Recent advancements in brain-computer interface (BCI) technology have\nemphasized the promise of imagined speech and visual imagery as effective\nparadigms for intuitive communication. This study investigates the\nclassification performance and brain connectivity patterns associated with\nthese paradigms, focusing on decoding accuracy across selected word classes.\nSixteen participants engaged in tasks involving thirteen imagined speech and\nvisual imagery classes, revealing above-chance classification accuracy for both\nparadigms. Variability in classification accuracy across individual classes\nhighlights the influence of sensory and motor associations in imagined speech\nand vivid visual associations in visual imagery. Connectivity analysis further\ndemonstrated increased functional connectivity in language-related and sensory\nregions for imagined speech, whereas visual imagery activated spatial and\nvisual processing networks. These findings suggest the potential of imagined\nspeech and visual imagery as an intuitive and scalable paradigm for BCI\ncommunication when selecting optimal word classes. Further exploration of the\ndecoding outcomes for these two paradigms could provide insights for practical\nBCI communication."
    },
    {
      "id": "2411.09393v1",
      "title": "Inherently Interpretable and Uncertainty-Aware Models for Online Learning in Cyber-Security Problems",
      "summary": "In this paper, we address the critical need for interpretable and\nuncertainty-aware machine learning models in the context of online learning for\nhigh-risk industries, particularly cyber-security. While deep learning and\nother complex models have demonstrated impressive predictive capabilities,\ntheir opacity and lack of uncertainty quantification present significant\nquestions about their trustworthiness. We propose a novel pipeline for online\nsupervised learning problems in cyber-security, that harnesses the inherent\ninterpretability and uncertainty awareness of Additive Gaussian Processes\n(AGPs) models. Our approach aims to balance predictive performance with\ntransparency while improving the scalability of AGPs, which represents their\nmain drawback, potentially enabling security analysts to better validate threat\ndetection, troubleshoot and reduce false positives, and generally make\ntrustworthy, informed decisions. This work contributes to the growing field of\ninterpretable AI by proposing a class of models that can be significantly\nbeneficial for high-stake decision problems such as the ones typical of the\ncyber-security domain. The source code is available."
    },
    {
      "id": "2411.09389v1",
      "title": "Less is More: Unseen Domain Fake News Detection via Causal Propagation Substructures",
      "summary": "The spread of fake news on social media poses significant threats to\nindividuals and society. Text-based and graph-based models have been employed\nfor fake news detection by analysing news content and propagation networks,\nshowing promising results in specific scenarios. However, these data-driven\nmodels heavily rely on pre-existing in-distribution data for training, limiting\ntheir performance when confronted with fake news from emerging or previously\nunseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake news\nis a challenging yet critical task. In this paper, we introduce the Causal\nSubgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed to\nenhance zero-shot fake news detection by extracting causal substructures from\npropagation graphs using in-distribution data and generalising this approach to\nOOD data. The model employs a graph neural network based mask generation\nprocess to identify dominant nodes and edges within the propagation graph,\nusing these substructures for fake news detection. Additionally, the\nperformance of CSDA is further improved through contrastive learning in\nfew-shot scenarios, where a limited amount of OOD data is available for\ntraining. Extensive experiments on public social media datasets demonstrate\nthat CSDA effectively handles OOD fake news detection, achieving a 7 to 16\npercents accuracy improvement over other state-of-the-art models."
    },
    {
      "id": "2411.09388v1",
      "title": "A survey of probabilistic generative frameworks for molecular simulations",
      "summary": "Generative artificial intelligence is now a widely used tool in molecular\nscience. Despite the popularity of probabilistic generative models, numerical\nexperiments benchmarking their performance on molecular data are lacking. In\nthis work, we introduce and explain several classes of generative models,\nbroadly sorted into two categories: flow-based models and diffusion models. We\nselect three representative models: Neural Spline Flows, Conditional Flow\nMatching, and Denoising Diffusion Probabilistic Models, and examine their\naccuracy, computational cost, and generation speed across datasets with tunable\ndimensionality, complexity, and modal asymmetry. Our findings are varied, with\nno one framework being the best for all purposes. In a nutshell, (i) Neural\nSpline Flows do best at capturing mode asymmetry present in low-dimensional\ndata, (ii) Conditional Flow Matching outperforms other models for\nhigh-dimensional data with low complexity, and (iii) Denoising Diffusion\nProbabilistic Models appears the best for low-dimensional data with high\ncomplexity. Our datasets include a Gaussian mixture model and the dihedral\ntorsion angle distribution of the Aib\\textsubscript{9} peptide, generated via a\nmolecular dynamics simulation. We hope our taxonomy of probabilistic generative\nframeworks and numerical results may guide model selection for a wide range of\nmolecular tasks."
    },
    {
      "id": "2411.09373v1",
      "title": "Are nuclear masks all you need for improved out-of-domain generalisation? A closer look at cancer classification in histopathology",
      "summary": "Domain generalisation in computational histopathology is challenging because\nthe images are substantially affected by differences among hospitals due to\nfactors like fixation and staining of tissue and imaging equipment. We\nhypothesise that focusing on nuclei can improve the out-of-domain (OOD)\ngeneralisation in cancer detection. We propose a simple approach to improve OOD\ngeneralisation for cancer detection by focusing on nuclear morphology and\norganisation, as these are domain-invariant features critical in cancer\ndetection. Our approach integrates original images with nuclear segmentation\nmasks during training, encouraging the model to prioritise nuclei and their\nspatial arrangement. Going beyond mere data augmentation, we introduce a\nregularisation technique that aligns the representations of masks and original\nimages. We show, using multiple datasets, that our method improves OOD\ngeneralisation and also leads to increased robustness to image corruptions and\nadversarial attacks. The source code is available at\nhttps://github.com/undercutspiky/SFL/"
    },
    {
      "id": "2411.09366v1",
      "title": "LTLf+ and PPLTL+: Extending LTLf and PPLTL to Infinite Traces",
      "summary": "We introduce LTLf+ and PPLTL+, two logics to express properties of infinite\ntraces, that are based on the linear-time temporal logics LTLf and PPLTL on\nfinite traces. LTLf+/PPLTL+ use levels of Manna and Pnueli's LTL\nsafety-progress hierarchy, and thus have the same expressive power as LTL.\nHowever, they also retain a crucial characteristic of the reactive synthesis\nproblem for the base logics: the game arena for strategy extraction can be\nderived from deterministic finite automata (DFA). Consequently, these logics\ncircumvent the notorious difficulties associated with determinizing infinite\ntrace automata, typical of LTL reactive synthesis. We present DFA-based\nsynthesis techniques for LTLf+/PPLTL+, and show that synthesis is\n2EXPTIME-complete for LTLf+ (matching LTLf) and EXPTIME-complete for PPLTL+\n(matching PPLTL). Notably, while PPLTL+ retains the full expressive power of\nLTL, reactive synthesis is EXPTIME-complete instead of 2EXPTIME-complete. The\ntechniques are also adapted to optimally solve satisfiability, validity, and\nmodel-checking, to get EXPSPACE-complete for LTLf+ (extending a recent result\nfor the guarantee level using LTLf), and PSPACE-complete for PPLTL+."
    },
    {
      "id": "2411.09365v1",
      "title": "Stability and Generalization for Distributed SGDA",
      "summary": "Minimax optimization is gaining increasing attention in modern machine\nlearning applications. Driven by large-scale models and massive volumes of data\ncollected from edge devices, as well as the concern to preserve client privacy,\ncommunication-efficient distributed minimax optimization algorithms become\npopular, such as Local Stochastic Gradient Descent Ascent (Local-SGDA), and\nLocal Decentralized SGDA (Local-DSGDA). While most existing research on\ndistributed minimax algorithms focuses on convergence rates, computation\ncomplexity, and communication efficiency, the generalization performance\nremains underdeveloped, whereas generalization ability is a pivotal indicator\nfor evaluating the holistic performance of a model when fed with unknown data.\nIn this paper, we propose the stability-based generalization analytical\nframework for Distributed-SGDA, which unifies two popular distributed minimax\nalgorithms including Local-SGDA and Local-DSGDA, and conduct a comprehensive\nanalysis of stability error, generalization gap, and population risk across\ndifferent metrics under various settings, e.g., (S)C-(S)C, PL-SC, and NC-NC\ncases. Our theoretical results reveal the trade-off between the generalization\ngap and optimization error and suggest hyperparameters choice to obtain the\noptimal population risk. Numerical experiments for Local-SGDA and Local-DSGDA\nvalidate the theoretical results."
    },
    {
      "id": "2411.09361v1",
      "title": "Time-to-Event Pretraining for 3D Medical Imaging",
      "summary": "With the rise of medical foundation models and the growing availability of\nimaging data, scalable pretraining techniques offer a promising way to identify\nimaging biomarkers predictive of future disease risk. While current\nself-supervised methods for 3D medical imaging models capture local structural\nfeatures like organ morphology, they fail to link pixel biomarkers with\nlong-term health outcomes due to a missing context problem. Current approaches\nlack the temporal context necessary to identify biomarkers correlated with\ndisease progression, as they rely on supervision derived only from images and\nconcurrent text descriptions. To address this, we introduce time-to-event\npretraining, a pretraining framework for 3D medical imaging models that\nleverages large-scale temporal supervision from paired, longitudinal electronic\nhealth records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D\nimages) and time-to-event distributions across thousands of EHR-derived tasks,\nour method improves outcome prediction, achieving an average AUROC increase of\n23.7% and a 29.4% gain in Harrell's C-index across 8 benchmark tasks.\nImportantly, these gains are achieved without sacrificing diagnostic\nclassification performance. This study lays the foundation for integrating\nlongitudinal EHR and 3D imaging data to advance clinical risk prediction."
    },
    {
      "id": "2411.09359v1",
      "title": "Your Fixed Watermark is Fragile: Towards Semantic-Aware Watermark for EaaS Copyright Protection",
      "summary": "Embedding-as-a-Service (EaaS) has emerged as a successful business pattern\nbut faces significant challenges related to various forms of copyright\ninfringement, including API misuse and different attacks. Various studies have\nproposed backdoor-based watermarking schemes to protect the copyright of EaaS\nservices. In this paper, we reveal that previous watermarking schemes possess\nsemantic-independent characteristics and propose the Semantic Perturbation\nAttack (SPA). Our theoretical and experimental analyses demonstrate that this\nsemantic-independent nature makes current watermarking schemes vulnerable to\nadaptive attacks that exploit semantic perturbations test to bypass watermark\nverification. To address this vulnerability, we propose the Semantic Aware\nWatermarking (SAW) scheme, a robust defense mechanism designed to resist SPA,\nby injecting a watermark that adapts to the text semantics. Extensive\nexperimental results across multiple datasets demonstrate that the True\nPositive Rate (TPR) for detecting watermarked samples under SPA can reach up to\nmore than 95%, rendering previous watermarks ineffective. Meanwhile, our\nwatermarking scheme can resist such attack while ensuring the watermark\nverification capability. Our code is available at\nhttps://github.com/Zk4-ps/EaaS-Embedding-Watermark."
    },
    {
      "id": "2411.09356v1",
      "title": "Multi-scale Generative Modeling for Fast Sampling",
      "summary": "While working within the spatial domain can pose problems associated with\nill-conditioned scores caused by power-law decay, recent advances in\ndiffusion-based generative models have shown that transitioning to the wavelet\ndomain offers a promising alternative. However, within the wavelet domain, we\nencounter unique challenges, especially the sparse representation of\nhigh-frequency coefficients, which deviates significantly from the Gaussian\nassumptions in the diffusion process. To this end, we propose a multi-scale\ngenerative modeling in the wavelet domain that employs distinct strategies for\nhandling low and high-frequency bands. In the wavelet domain, we apply\nscore-based generative modeling with well-conditioned scores for low-frequency\nbands, while utilizing a multi-scale generative adversarial learning for\nhigh-frequency bands. As supported by the theoretical analysis and experimental\nresults, our model significantly improve performance and reduce the number of\ntrainable parameters, sampling steps, and time."
    },
    {
      "id": "2411.09341v1",
      "title": "Approximated Variational Bayesian Inverse Reinforcement Learning for Large Language Model Alignment",
      "summary": "The alignment of large language models (LLMs) is crucial for generating\nhelpful and harmless content. Existing approaches leverage preference-based\nhuman feedback data to learn the reward function and align the LLM with the\nfeedback data. However, these approaches focus on modeling the reward\ndifference between the chosen and rejected demonstrations, rather than directly\nmodeling the true reward from each demonstration. Moreover, these approaches\nassume that the reward is only obtained at the end of the sentence, which\noverlooks the modeling of intermediate rewards. These issues lead to\ninsufficient use of training signals in the feedback data, limiting the\nrepresentation and generalization ability of the reward and potentially\nresulting in reward hacking. In this paper, we formulate LLM alignment as a\nBayesian Inverse Reinforcement Learning (BIRL) problem and propose a novel\ntraining objective, Approximated Variational Alignment (AVA), to perform LLM\nalignment through Approximated Variational Reward Imitation Learning (AVRIL).\nThe BIRL formulation facilitates intermediate reward modeling and direct reward\nmodeling on each single demonstration, which enhances the utilization of\ntraining signals in the feedback data. Experiments show that AVA outperforms\nexisting LLM alignment approaches in reward modeling, RL fine-tuning, and\ndirect optimization."
    },
    {
      "id": "2411.09339v1",
      "title": "Re-Parameterization of Lightweight Transformer for On-Device Speech Emotion Recognition",
      "summary": "With the increasing implementation of machine learning models on edge or\nInternet-of-Things (IoT) devices, deploying advanced models on\nresource-constrained IoT devices remains challenging. Transformer models, a\ncurrently dominant neural architecture, have achieved great success in broad\ndomains but their complexity hinders its deployment on IoT devices with limited\ncomputation capability and storage size. Although many model compression\napproaches have been explored, they often suffer from notorious performance\ndegradation. To address this issue, we introduce a new method, namely\nTransformer Re-parameterization, to boost the performance of lightweight\nTransformer models. It consists of two processes: the High-Rank Factorization\n(HRF) process in the training stage and the deHigh-Rank Factorization (deHRF)\nprocess in the inference stage. In the former process, we insert an additional\nlinear layer before the Feed-Forward Network (FFN) of the lightweight\nTransformer. It is supposed that the inserted HRF layers can enhance the model\nlearning capability. In the later process, the auxiliary HRF layer will be\nmerged together with the following FFN layer into one linear layer and thus\nrecover the original structure of the lightweight model. To examine the\neffectiveness of the proposed method, we evaluate it on three widely used\nTransformer variants, i.e., ConvTransformer, Conformer, and SpeechFormer\nnetworks, in the application of speech emotion recognition on the IEMOCAP, M3ED\nand DAIC-WOZ datasets. Experimental results show that our proposed method\nconsistently improves the performance of lightweight Transformers, even making\nthem comparable to large models. The proposed re-parameterization approach\nenables advanced Transformer models to be deployed on resource-constrained IoT\ndevices."
    },
    {
      "id": "2411.09329v1",
      "title": "Improving hp-Variational Physics-Informed Neural Networks for Steady-State Convection-Dominated Problems",
      "summary": "This paper proposes and studies two extensions of applying hp-variational\nphysics-informed neural networks, more precisely the FastVPINNs framework, to\nconvection-dominated convection-diffusion-reaction problems. First, a term in\nthe spirit of a SUPG stabilization is included in the loss functional and a\nnetwork architecture is proposed that predicts spatially varying stabilization\nparameters. Having observed that the selection of the indicator function in\nhard-constrained Dirichlet boundary conditions has a big impact on the accuracy\nof the computed solutions, the second novelty is the proposal of a network\narchitecture that learns good parameters for a class of indicator functions.\nNumerical studies show that both proposals lead to noticeably more accurate\nresults than approaches that can be found in the literature."
    },
    {
      "id": "2411.09318v1",
      "title": "DriveThru: a Document Extraction Platform and Benchmark Datasets for Indonesian Local Language Archives",
      "summary": "Indonesia is one of the most diverse countries linguistically. However,\ndespite this linguistic diversity, Indonesian languages remain underrepresented\nin Natural Language Processing (NLP) research and technologies. In the past two\nyears, several efforts have been conducted to construct NLP resources for\nIndonesian languages. However, most of these efforts have been focused on\ncreating manual resources thus difficult to scale to more languages. Although\nmany Indonesian languages do not have a web presence, locally there are\nresources that document these languages well in printed forms such as books,\nmagazines, and newspapers. Digitizing these existing resources will enable\nscaling of Indonesian language resource construction to many more languages. In\nthis paper, we propose an alternative method of creating datasets by digitizing\ndocuments, which have not previously been used to build digital language\nresources in Indonesia. DriveThru is a platform for extracting document content\nutilizing Optical Character Recognition (OCR) techniques in its system to\nprovide language resource building with less manual effort and cost. This paper\nalso studies the utility of current state-of-the-art LLM for post-OCR\ncorrection to show the capability of increasing the character accuracy rate\n(CAR) and word accuracy rate (WAR) compared to off-the-shelf OCR."
    },
    {
      "id": "2411.09317v1",
      "title": "Pie: Pooling CPU Memory for LLM Inference",
      "summary": "The rapid growth of LLMs has revolutionized natural language processing and\nAI analysis, but their increasing size and memory demands present significant\nchallenges. A common solution is to spill over to CPU memory; however,\ntraditional GPU-CPU memory swapping often results in higher latency and lower\nthroughput.\n  This paper introduces Pie, an LLM inference framework that addresses these\nchallenges with performance-transparent swapping and adaptive expansion. By\nleveraging predictable memory access patterns and the high bandwidth of modern\nhardware like the NVIDIA GH200 Grace Hopper Superchip, Pie enables concurrent\ndata swapping without affecting foreground computation, expanding effective\nmemory without added latency. Adaptive expansion dynamically adjusts CPU memory\nallocation based on real-time information, optimizing memory usage and\nperformance under varying conditions.\n  Pie maintains low computation latency, high throughput, and high elasticity.\nOur experimental evaluation demonstrates that Pie achieves optimal swapping\npolicy during cache warmup and effectively balances increased memory capacity\nwith negligible impact on computation. With its extended capacity, Pie\noutperforms vLLM by up to 1.9X in throughput and 2X in latency. Additionally,\nPie can reduce GPU memory usage by up to 1.67X while maintaining the same\nperformance. Compared to FlexGen, an offline profiling-based swapping solution,\nPie achieves magnitudes lower latency and 9.4X higher throughput."
    },
    {
      "id": "2411.09312v1",
      "title": "Approximate Probabilistic Inference forTime-Series Data A Robust Latent Gaussian Model With Temporal Awareness",
      "summary": "The development of robust generative models for highly varied non-stationary\ntime series data is a complex yet important problem. Traditional models for\ntime series data prediction, such as Long Short-Term Memory (LSTM), are\ninefficient and generalize poorly as they cannot capture complex temporal\nrelationships. In this paper, we present a probabilistic generative model that\ncan be trained to capture temporal information, and that is robust to data\nerrors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novel\narchitecture is inspired by Deep Latent Gaussian Model (DLGM). Our model is\ntrained to minimize a loss function based on the negative log loss. One\ncontributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness is\nour regularizer, which accounts for data trends. Experiments conducted show\nthat tDLGM is able to reconstruct and generate complex time series data, and\nthat it is robust against to noise and faulty data."
    },
    {
      "id": "2411.09311v1",
      "title": "Compression Method for Solar Polarization Spectra Collected from Hinode SOT/SP Observations",
      "summary": "The complex structure and extensive details of solar spectral data, combined\nwith a recent surge in volume, present significant processing challenges. To\naddress this, we propose a deep learning-based compression technique using deep\nautoencoder (DAE) and 1D-convolutional autoencoder (CAE) models developed with\nHinode SOT/SP data. We focused on compressing Stokes I and V polarization\nspectra from the quiet Sun, as well as from active regions, providing a novel\ninsight into comprehensive spectral analysis by incorporating spectra from\nextreme magnetic fields. The results indicate that the CAE model outperforms\nthe DAE model in reconstructing Stokes profiles, demonstrating greater\nrobustness and achieving reconstruction errors around the observational noise\nlevel. The proposed method has proven effective in compressing Stokes I and V\nspectra from both the quiet Sun and active regions, highlighting its potential\nfor impactful applications in solar spectral analysis, such as detection of\nunusual spectral signals."
    },
    {
      "id": "2411.09302v1",
      "title": "EEG-Based Speech Decoding: A Novel Approach Using Multi-Kernel Ensemble Diffusion Models",
      "summary": "In this study, we propose an ensemble learning framework for\nelectroencephalogram-based overt speech classification, leveraging denoising\ndiffusion probabilistic models with varying convolutional kernel sizes. The\nensemble comprises three models with kernel sizes of 51, 101, and 201,\neffectively capturing multi-scale temporal features inherent in signals. This\napproach improves the robustness and accuracy of speech decoding by\naccommodating the rich temporal complexity of neural signals. The ensemble\nmodels work in conjunction with conditional autoencoders that refine the\nreconstructed signals and maximize the useful information for downstream\nclassification tasks. The results indicate that the proposed ensemble-based\napproach significantly outperforms individual models and existing\nstate-of-the-art techniques. These findings demonstrate the potential of\nensemble methods in advancing brain signal decoding, offering new possibilities\nfor non-verbal communication applications, particularly in brain-computer\ninterface systems aimed at aiding individuals with speech impairments."
    },
    {
      "id": "2411.09297v1",
      "title": "DTELS: Towards Dynamic Granularity of Timeline Summarization",
      "summary": "The rapid proliferation of online news has posed significant challenges in\ntracking the continuous development of news topics. Traditional timeline\nsummarization constructs a chronological summary of the events but often lacks\nthe flexibility to meet the diverse granularity needs. To overcome this\nlimitation, we introduce a new paradigm, Dynamic-granularity TimELine\nSummarization, (DTELS), which aims to construct adaptive timelines based on\nuser instructions or requirements. This paper establishes a comprehensive\nbenchmark for DTLES that includes: (1) an evaluation framework grounded in\njournalistic standards to assess the timeline quality across four dimensions:\nInformativeness, Granular Consistency, Factuality, and Coherence; (2) a\nlarge-scale, multi-source dataset with multiple granularity timeline\nannotations based on a consensus process to facilitate authority; (3) extensive\nexperiments and analysis with two proposed solutions based on Large Language\nModels (LLMs) and existing state-of-the-art TLS methods. The experimental\nresults demonstrate the effectiveness of LLM-based solutions. However, even the\nmost advanced LLMs struggle to consistently generate timelines that are both\ninformative and granularly consistent, highlighting the challenges of the DTELS\ntask."
    },
    {
      "id": "2411.09296v1",
      "title": "Enhancing generalization in high energy physics using white-box adversarial attacks",
      "summary": "Machine learning is becoming increasingly popular in the context of particle\nphysics. Supervised learning, which uses labeled Monte Carlo (MC) simulations,\nremains one of the most widely used methods for discriminating signals beyond\nthe Standard Model. However, this paper suggests that supervised models may\ndepend excessively on artifacts and approximations from Monte Carlo\nsimulations, potentially limiting their ability to generalize well to real\ndata. This study aims to enhance the generalization properties of supervised\nmodels by reducing the sharpness of local minima. It reviews the application of\nfour distinct white-box adversarial attacks in the context of classifying Higgs\nboson decay signals. The attacks are divided into weight space attacks, and\nfeature space attacks. To study and quantify the sharpness of different local\nminima this paper presents two analysis methods: gradient ascent and reduced\nHessian eigenvalue analysis. The results show that white-box adversarial\nattacks significantly improve generalization performance, albeit with increased\ncomputational complexity."
    },
    {
      "id": "2411.09294v1",
      "title": "Learning Hand State Estimation for a Light Exoskeleton",
      "summary": "We propose a machine learning-based estimator of the hand state for\nrehabilitation purposes, using light exoskeletons. These devices are easy to\nuse and useful for delivering domestic and frequent therapies. We build a\nsupervised approach using information from the muscular activity of the forearm\nand the motion of the exoskeleton to reconstruct the hand's opening degree and\ncompliance level. Such information can be used to evaluate the therapy progress\nand develop adaptive control behaviors. Our approach is validated with a real\nlight exoskeleton. The experiments demonstrate good predictive performance of\nour approach when trained on data coming from a single user and tested on the\nsame user, even across different sessions. This generalization capability makes\nour system promising for practical use in real rehabilitation."
    },
    {
      "id": "2411.09289v1",
      "title": "StreamAdapter: Efficient Test Time Adaptation from Contextual Streams",
      "summary": "In-context learning (ICL) allows large language models (LLMs) to adapt to new\ntasks directly from the given demonstrations without requiring gradient\nupdates. While recent advances have expanded context windows to accommodate\nmore demonstrations, this approach increases inference costs without\nnecessarily improving performance. To mitigate these issues, We propose\nStreamAdapter, a novel approach that directly updates model parameters from\ncontext at test time, eliminating the need for explicit in-context\ndemonstrations. StreamAdapter employs context mapping and weight absorption\nmechanisms to dynamically transform ICL demonstrations into parameter updates\nwith minimal additional parameters. By reducing reliance on numerous in-context\nexamples, StreamAdapter significantly reduce inference costs and allows for\nefficient inference with constant time complexity, regardless of demonstration\ncount. Extensive experiments across diverse tasks and model architectures\ndemonstrate that StreamAdapter achieves comparable or superior adaptation\ncapability to ICL while requiring significantly fewer demonstrations. The\nsuperior task adaptation and context encoding capabilities of StreamAdapter on\nboth language understanding and generation tasks provides a new perspective for\nadapting LLMs at test time using context, allowing for more efficient\nadaptation across scenarios and more cost-effective inference"
    },
    {
      "id": "2411.09286v1",
      "title": "A Centralized-Distributed Transfer Model for Cross-Domain Recommendation Based on Multi-Source Heterogeneous Transfer Learning",
      "summary": "Cross-domain recommendation (CDR) methods are proposed to tackle the sparsity\nproblem in click through rate (CTR) estimation. Existing CDR methods directly\ntransfer knowledge from the source domains to the target domain and ignore the\nheterogeneities among domains, including feature dimensional heterogeneity and\nlatent space heterogeneity, which may lead to negative transfer. Besides, most\nof the existing methods are based on single-source transfer, which cannot\nsimultaneously utilize knowledge from multiple source domains to further\nimprove the model performance in the target domain. In this paper, we propose a\ncentralized-distributed transfer model (CDTM) for CDR based on multi-source\nheterogeneous transfer learning. To address the issue of feature dimension\nheterogeneity, we build a dual embedding structure: domain specific embedding\n(DSE) and global shared embedding (GSE) to model the feature representation in\nthe single domain and the commonalities in the global space,separately. To\nsolve the latent space heterogeneity, the transfer matrix and attention\nmechanism are used to map and combine DSE and GSE adaptively. Extensive offline\nand online experiments demonstrate the effectiveness of our model."
    },
    {
      "id": "2411.09273v1",
      "title": "Cross-Modal Consistency in Multimodal Large Language Models",
      "summary": "Recent developments in multimodal methodologies have marked the beginning of\nan exciting era for models adept at processing diverse data types, encompassing\ntext, audio, and visual content. Models like GPT-4V, which merge computer\nvision with advanced language processing, exhibit extraordinary proficiency in\nhandling intricate tasks that require a simultaneous understanding of both\ntextual and visual information. Prior research efforts have meticulously\nevaluated the efficacy of these Vision Large Language Models (VLLMs) in various\ndomains, including object detection, image captioning, and other related\nfields. However, existing analyses have often suffered from limitations,\nprimarily centering on the isolated evaluation of each modality's performance\nwhile neglecting to explore their intricate cross-modal interactions.\nSpecifically, the question of whether these models achieve the same level of\naccuracy when confronted with identical task instances across different\nmodalities remains unanswered. In this study, we take the initiative to delve\ninto the interaction and comparison among these modalities of interest by\nintroducing a novel concept termed cross-modal consistency. Furthermore, we\npropose a quantitative evaluation framework founded on this concept. Our\nexperimental findings, drawn from a curated collection of parallel\nvision-language datasets developed by us, unveil a pronounced inconsistency\nbetween the vision and language modalities within GPT-4V, despite its portrayal\nas a unified multimodal model. Our research yields insights into the\nappropriate utilization of such models and hints at potential avenues for\nenhancing their design."
    },
    {
      "id": "2411.09269v1",
      "title": "Harnessing multiple LLMs for Information Retrieval: A case study on Deep Learning methodologies in Biodiversity publications",
      "summary": "Deep Learning (DL) techniques are increasingly applied in scientific studies\nacross various domains to address complex research questions. However, the\nmethodological details of these DL models are often hidden in the unstructured\ntext. As a result, critical information about how these models are designed,\ntrained, and evaluated is challenging to access and comprehend. To address this\nissue, in this work, we use five different open-source Large Language Models\n(LLMs): Llama-3 70B, Llama-3.1 70B, Mixtral-8x22B-Instruct-v0.1, Mixtral 8x7B,\nand Gemma 2 9B in combination with Retrieval-Augmented Generation (RAG)\napproach to extract and process DL methodological details from scientific\npublications automatically. We built a voting classifier from the outputs of\nfive LLMs to accurately report DL methodological information. We tested our\napproach using biodiversity publications, building upon our previous research.\nTo validate our pipeline, we employed two datasets of DL-related biodiversity\npublications: a curated set of 100 publications from our prior work and a set\nof 364 publications from the Ecological Informatics journal. Our results\ndemonstrate that the multi-LLM, RAG-assisted pipeline enhances the retrieval of\nDL methodological information, achieving an accuracy of 69.5% (417 out of 600\ncomparisons) based solely on textual content from publications. This\nperformance was assessed against human annotators who had access to code,\nfigures, tables, and other supplementary information. Although demonstrated in\nbiodiversity, our methodology is not limited to this field; it can be applied\nacross other scientific domains where detailed methodological reporting is\nessential for advancing knowledge and ensuring reproducibility. This study\npresents a scalable and reliable approach for automating information\nextraction, facilitating better reproducibility and knowledge transfer across\nstudies."
    },
    {
      "id": "2411.09267v1",
      "title": "Towards efficient compression and communication for prototype-based decentralized learning",
      "summary": "In prototype-based federated learning, the exchange of model parameters\nbetween clients and the master server is replaced by transmission of prototypes\nor quantized versions of the data samples to the aggregation server. A fully\ndecentralized deployment of prototype-based learning, without a central\nagregartor of prototypes, is more robust upon network failures and reacts\nfaster to changes in the statistical distribution of the data, suggesting\npotential advantages and quick adaptation in dynamic learning tasks, e.g., when\nthe data sources are IoT devices or when data is non-iid. In this paper, we\nconsider the problem of designing a communication-efficient decentralized\nlearning system based on prototypes. We address the challenge of prototype\nredundancy by leveraging on a twofold data compression technique, i.e., sending\nonly update messages if the prototypes are informationtheoretically useful (via\nthe Jensen-Shannon distance), and using clustering on the prototypes to\ncompress the update messages used in the gossip protocol. We also use parallel\ninstead of sequential gossiping, and present an analysis of its\nage-of-information (AoI). Our experimental results show that, with these\nimprovements, the communications load can be substantially reduced without\ndecreasing the convergence rate of the learning algorithm."
    },
    {
      "id": "2411.09266v1",
      "title": "How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study of ChatGPT, AI Models and Human Perception",
      "summary": "Multimodal deepfakes involving audiovisual manipulations are a growing threat\nbecause they are difficult to detect with the naked eye or using unimodal deep\nlearningbased forgery detection methods. Audiovisual forensic models, while\nmore capable than unimodal models, require large training datasets and are\ncomputationally expensive for training and inference. Furthermore, these models\nlack interpretability and often do not generalize well to unseen manipulations.\nIn this study, we examine the detection capabilities of a large language model\n(LLM) (i.e., ChatGPT) to identify and account for any possible visual and\nauditory artifacts and manipulations in audiovisual deepfake content. Extensive\nexperiments are conducted on videos from a benchmark multimodal deepfake\ndataset to evaluate the detection performance of ChatGPT and compare it with\nthe detection capabilities of state-of-the-art multimodal forensic models and\nhumans. Experimental results demonstrate the importance of domain knowledge and\nprompt engineering for video forgery detection tasks using LLMs. Unlike\napproaches based on end-to-end learning, ChatGPT can account for spatial and\nspatiotemporal artifacts and inconsistencies that may exist within or across\nmodalities. Additionally, we discuss the limitations of ChatGPT for multimedia\nforensic tasks."
    },
    {
      "id": "2411.09263v1",
      "title": "Rethinking Weight-Averaged Model-merging",
      "summary": "Weight-averaged model-merging has emerged as a powerful approach in deep\nlearning, capable of enhancing model performance without fine-tuning or\nretraining. However, the underlying mechanisms that explain its effectiveness\nremain largely unexplored. In this paper, we investigate this technique from\nthree novel perspectives to provide deeper insights into how and why\nweight-averaged model-merging works: (1) we examine the intrinsic patterns\ncaptured by the learning of the model weights, through the visualizations of\ntheir patterns on several datasets, showing that these weights often encode\nstructured and interpretable patterns; (2) we investigate model ensemble\nmerging strategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process."
    },
    {
      "id": "2411.09261v1",
      "title": "Automating Autograding: Large Language Models as Test Suite Generators for Introductory Programming",
      "summary": "Automatically graded programming assignments provide instant feedback to\nstudents and significantly reduce manual grading time for instructors. However,\ncreating comprehensive suites of test cases for programming problems within\nautomatic graders can be time-consuming and complex. The effort needed to\ndefine test suites may deter some instructors from creating additional problems\nor lead to inadequate test coverage, potentially resulting in misleading\nfeedback on student solutions. Such limitations may reduce student access to\nthe well-documented benefits of timely feedback when learning programming.\n  In this work, we evaluate the effectiveness of using Large Language Models\n(LLMs), as part of a larger workflow, to automatically generate test suites for\nCS1-level programming problems. Each problem's statement and reference solution\nare provided to GPT-4 to produce a test suite that can be used by an\nautograder. We evaluate our proposed approach using a sample of 26 problems,\nand more than 25,000 attempted solutions to those problems, submitted by\nstudents in an introductory programming course. We compare the performance of\nthe LLM-generated test suites against the instructor-created test suites for\neach problem. Our findings reveal that LLM-generated test suites can correctly\nidentify most valid solutions, and for most problems are at least as\ncomprehensive as the instructor test suites. Additionally, the LLM-generated\ntest suites exposed ambiguities in some problem statements, underscoring their\npotential to improve both autograding and instructional design."
    },
    {
      "id": "2411.09259v1",
      "title": "Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey",
      "summary": "The rapid evolution of multimodal foundation models has led to significant\nadvancements in cross-modal understanding and generation across diverse\nmodalities, including text, images, audio, and video. However, these models\nremain susceptible to jailbreak attacks, which can bypass built-in safety\nmechanisms and induce the production of potentially harmful content.\nConsequently, understanding the methods of jailbreak attacks and existing\ndefense mechanisms is essential to ensure the safe deployment of multimodal\ngenerative models in real-world scenarios, particularly in security-sensitive\napplications. To provide comprehensive insight into this topic, this survey\nreviews jailbreak and defense in multimodal generative models. First, given the\ngeneralized lifecycle of multimodal jailbreak, we systematically explore\nattacks and corresponding defense strategies across four levels: input,\nencoder, generator, and output. Based on this analysis, we present a detailed\ntaxonomy of attack methods, defense mechanisms, and evaluation frameworks\nspecific to multimodal generative models. Additionally, we cover a wide range\nof input-output configurations, including modalities such as Any-to-Text,\nAny-to-Vision, and Any-to-Any within generative systems. Finally, we highlight\ncurrent research challenges and propose potential directions for future\nresearch.The open-source repository corresponding to this work can be found at\nhttps://github.com/liuxuannan/Awesome-Multimodal-Jailbreak."
    },
    {
      "id": "2411.09255v1",
      "title": "DAHL: Domain-specific Automated Hallucination Evaluation of Long-Form Text through a Benchmark Dataset in Biomedicine",
      "summary": "We introduce DAHL, a benchmark dataset and automated evaluation system\ndesigned to assess hallucination in long-form text generation, specifically\nwithin the biomedical domain. Our benchmark dataset, meticulously curated from\nbiomedical research papers, consists of 8,573 questions across 29 categories.\nDAHL evaluates fact-conflicting hallucinations in Large Language Models (LLMs)\nby deconstructing responses into atomic units, each representing a single piece\nof information. The accuracy of these responses is averaged to produce the DAHL\nScore, offering a more in-depth evaluation of hallucinations compared to\nprevious methods that rely on multiple-choice tasks. We conduct experiments\nwith 8 different models, finding that larger models tend to hallucinate less;\nhowever, beyond a model size of 7 to 8 billion parameters, further scaling does\nnot significantly improve factual accuracy. The DAHL Score holds potential as\nan efficient alternative to human-annotated preference labels, being able to be\nexpanded to other specialized domains. We release the dataset and code in\npublic."
    },
    {
      "id": "2411.09251v1",
      "title": "Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow Forecasting",
      "summary": "Predicting spatio-temporal traffic flow presents significant challenges due\nto complex interactions between spatial and temporal factors. Existing\napproaches often address these dimensions in isolation, neglecting their\ncritical interdependencies. In this paper, we introduce the Spatio-Temporal\nUnitized Model (STUM), a unified framework designed to capture both spatial and\ntemporal dependencies while addressing spatio-temporal heterogeneity through\ntechniques such as distribution alignment and feature fusion. It also ensures\nboth predictive accuracy and computational efficiency. Central to STUM is the\nAdaptive Spatio-temporal Unitized Cell (ASTUC), which utilizes low-rank\nmatrices to seamlessly store, update, and interact with space, time, as well as\ntheir correlations. Our framework is also modular, allowing it to integrate\nwith various spatio-temporal graph neural networks through components such as\nbackbone models, feature extractors, residual fusion blocks, and predictive\nmodules to collectively enhance forecasting outcomes. Experimental results\nacross multiple real-world datasets demonstrate that STUM consistently improves\nprediction performance with minimal computational cost. These findings are\nfurther supported by hyperparameter optimization, pre-training analysis, and\nresult visualization. We provide our source code for reproducibility at\nhttps://anonymous.4open.science/r/STUM-E4F0."
    },
    {
      "id": "2411.09249v1",
      "title": "Enhancing Financial Domain Adaptation of Language Models via Model Augmentation",
      "summary": "The domain adaptation of language models, including large language models\n(LLMs), has become increasingly important as the use of such models continues\nto expand. This study demonstrates the effectiveness of Composition to Augment\nLanguage Models (CALM) in adapting to the financial domain. CALM is a model to\nextend the capabilities of existing models by introducing cross-attention\nbetween two LLMs with different functions. In our experiments, we developed a\nCALM to enhance the financial performance of an LLM with strong response\ncapabilities by leveraging a financial-specialized LLM. Notably, the CALM was\ntrained using a financial dataset different from the one used to train the\nfinancial-specialized LLM, confirming CALM's ability to adapt to various\ndatasets. The models were evaluated through quantitative Japanese financial\nbenchmarks and qualitative response comparisons, demonstrating that CALM\nenables superior responses with higher scores than the original models and\nbaselines. Additionally, comparative experiments on connection points revealed\nthat connecting the middle layers of the models is most effective in\nfacilitating adaptation to the financial domain. These findings confirm that\nCALM is a practical approach for adapting LLMs to the financial domain."
    },
    {
      "id": "2411.09243v1",
      "title": "Towards Unified Neural Decoding of Perceived, Spoken and Imagined Speech from EEG Signals",
      "summary": "Brain signals accompany various information relevant to human actions and\nmental imagery, making them crucial to interpreting and understanding human\nintentions. Brain-computer interface technology leverages this brain activity\nto generate external commands for controlling the environment, offering\ncritical advantages to individuals with paralysis or locked-in syndrome. Within\nthe brain-computer interface domain, brain-to-speech research has gained\nattention, focusing on the direct synthesis of audible speech from brain\nsignals. Most current studies decode speech from brain activity using invasive\ntechniques and emphasize spoken speech data. However, humans express various\nspeech states, and distinguishing these states through non-invasive approaches\nremains a significant yet challenging task. This research investigated the\neffectiveness of deep learning models for non-invasive-based neural signal\ndecoding, with an emphasis on distinguishing between different speech\nparadigms, including perceived, overt, whispered, and imagined speech, across\nmultiple frequency bands. The model utilizing the spatial conventional neural\nnetwork module demonstrated superior performance compared to other models,\nespecially in the gamma band. Additionally, imagined speech in the theta\nfrequency band, where deep learning also showed strong effects, exhibited\nstatistically significant differences compared to the other speech paradigms."
    },
    {
      "id": "2411.09242v1",
      "title": "FluidML: Fast and Memory Efficient Inference Optimization",
      "summary": "Machine learning models deployed on edge devices have enabled numerous\nexciting new applications, such as humanoid robots, AR glasses, and autonomous\nvehicles. However, the computing resources available on these edge devices are\nnot catching up with the ever-growing number of parameters in these models. As\nthe models become bigger and more complicated, the novel yet sophisticated\nstructure challenges the inference runtime optimization. We present FluidML, a\ngeneric runtime memory management and optimization framework that can flexibly\ntransform the model execution blueprint to achieve faster and more\nmemory-efficient inference. Evaluations across different platforms show that\nFluidML can consistently reduce the end-to-end inference latency by up to\n25.38% for popular language models and reduce peak memory usage by up to\n41.47%, compared to state-of-the-art approaches. FluidML is of ~30K line of\ncodes, built for general-purpose usage, and will be released as an open-source\ninference runtime optimization framework to the community."
    },
    {
      "id": "2411.09238v1",
      "title": "Rethinking the \"Heatmap + Monte Carlo Tree Search\" Paradigm for Solving Large Scale TSP",
      "summary": "The Travelling Salesman Problem (TSP) remains a fundamental challenge in\ncombinatorial optimization, inspiring diverse algorithmic strategies. This\npaper revisits the \"heatmap + Monte Carlo Tree Search (MCTS)\" paradigm that has\nrecently gained traction for learning-based TSP solutions. Within this\nframework, heatmaps encode the likelihood of edges forming part of the optimal\ntour, and MCTS refines this probabilistic guidance to discover optimal\nsolutions. Contemporary approaches have predominantly emphasized the refinement\nof heatmap generation through sophisticated learning models, inadvertently\nsidelining the critical role of MCTS. Our extensive empirical analysis reveals\ntwo pivotal insights: 1) The configuration of MCTS strategies profoundly\ninfluences the solution quality, demanding meticulous tuning to leverage their\nfull potential; 2) Our findings demonstrate that a rudimentary and\nparameter-free heatmap, derived from the intrinsic $k$-nearest nature of TSP,\ncan rival or even surpass the performance of complicated heatmaps, with strong\ngeneralizability across various scales. Empirical evaluations across various\nTSP scales underscore the efficacy of our approach, achieving competitive\nresults. These observations challenge the prevailing focus on heatmap\nsophistication, advocating a reevaluation of the paradigm to harness both\ncomponents synergistically. Our code is available at:\nhttps://github.com/LOGO-CUHKSZ/rethink_mcts_tsp."
    },
    {
      "id": "2411.09224v1",
      "title": "Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers",
      "summary": "Our everyday lives now heavily rely on artificial intelligence (AI) powered\nlarge language models (LLMs). Like regular users, programmers are also\nbenefiting from the newest large language models. In response to the critical\nrole that AI models play in modern software development, this study presents a\nthorough evaluation of leading programming assistants, including ChatGPT,\nGemini(Bard AI), AlphaCode, and GitHub Copilot. The evaluation is based on\ntasks like natural language processing and code generation accuracy in\ndifferent programming languages like Java, Python and C++. Based on the\nresults, it has emphasized their strengths and weaknesses and the importance of\nfurther modifications to increase the reliability and accuracy of the latest\npopular models. Although these AI assistants illustrate a high level of\nprogress in language understanding and code generation, along with ethical\nconsiderations and responsible usage, they provoke a necessity for discussion.\nWith time, developing more refined AI technology is essential for achieving\nadvanced solutions in various fields, especially with the knowledge of the\nfeature intricacies of these models and their implications. This study offers a\ncomparison of different LLMs and provides essential feedback on the rapidly\nchanging area of AI models. It also emphasizes the need for ethical\ndevelopmental practices to actualize AI models' full potential."
    },
    {
      "id": "2411.09220v1",
      "title": "Transferable Adversarial Attacks against ASR",
      "summary": "Given the extensive research and real-world applications of automatic speech\nrecognition (ASR), ensuring the robustness of ASR models against minor input\nperturbations becomes a crucial consideration for maintaining their\neffectiveness in real-time scenarios. Previous explorations into ASR model\nrobustness have predominantly revolved around evaluating accuracy on white-box\nsettings with full access to ASR models. Nevertheless, full ASR model details\nare often not available in real-world applications. Therefore, evaluating the\nrobustness of black-box ASR models is essential for a comprehensive\nunderstanding of ASR model resilience. In this regard, we thoroughly study the\nvulnerability of practical black-box attacks in cutting-edge ASR models and\npropose to employ two advanced time-domain-based transferable attacks alongside\nour differentiable feature extractor. We also propose a speech-aware gradient\noptimization approach (SAGO) for ASR, which forces mistranscription with\nminimal impact on human imperceptibility through voice activity detection rule\nand a speech-aware gradient-oriented optimizer. Our comprehensive experimental\nresults reveal performance enhancements compared to baseline approaches across\nfive models on two databases."
    },
    {
      "id": "2411.09214v1",
      "title": "HateGPT: Unleashing GPT-3.5 Turbo to Combat Hate Speech on X",
      "summary": "The widespread use of social media platforms like Twitter and Facebook has\nenabled people of all ages to share their thoughts and experiences, leading to\nan immense accumulation of user-generated content. However, alongside the\nbenefits, these platforms also face the challenge of managing hate speech and\noffensive content, which can undermine rational discourse and threaten\ndemocratic values. As a result, there is a growing need for automated methods\nto detect and mitigate such content, especially given the complexity of\nconversations that may require contextual analysis across multiple languages,\nincluding code-mixed languages like Hinglish, German-English, and Bangla. We\nparticipated in the English task where we have to classify English tweets into\ntwo categories namely Hate and Offensive and Non Hate-Offensive. In this work,\nwe experiment with state-of-the-art large language models like GPT-3.5 Turbo\nvia prompting to classify tweets into Hate and Offensive or Non Hate-Offensive.\nIn this study, we evaluate the performance of a classification model using\nMacro-F1 scores across three distinct runs. The Macro-F1 score, which balances\nprecision and recall across all classes, is used as the primary metric for\nmodel evaluation. The scores obtained are 0.756 for run 1, 0.751 for run 2, and\n0.754 for run 3, indicating a high level of performance with minimal variance\namong the runs. The results suggest that the model consistently performs well\nin terms of precision and recall, with run 1 showing the highest performance.\nThese findings highlight the robustness and reliability of the model across\ndifferent runs."
    },
    {
      "id": "2411.09213v1",
      "title": "Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering",
      "summary": "Retrieval-augmented generation (RAG) has emerged as a promising approach to\nenhance the performance of large language models (LLMs) in knowledge-intensive\ntasks such as those from medical domain. However, the sensitive nature of the\nmedical domain necessitates a completely accurate and trustworthy system. While\nexisting RAG benchmarks primarily focus on the standard retrieve-answer\nsetting, they overlook many practical scenarios that measure crucial aspects of\na reliable medical system. This paper addresses this gap by providing a\ncomprehensive evaluation framework for medical question-answering (QA) systems\nin a RAG setting for these situations, including sufficiency, integration, and\nrobustness. We introduce Medical Retrieval-Augmented Generation Benchmark\n(MedRGB) that provides various supplementary elements to four medical QA\ndatasets for testing LLMs' ability to handle these specific scenarios.\nUtilizing MedRGB, we conduct extensive evaluations of both state-of-the-art\ncommercial LLMs and open-source models across multiple retrieval conditions.\nOur experimental results reveals current models' limited ability to handle\nnoise and misinformation in the retrieved documents. We further analyze the\nLLMs' reasoning processes to provides valuable insights and future directions\nfor developing RAG systems in this critical medical domain."
    },
    {
      "id": "2411.09211v1",
      "title": "Dynamic Neural Communication: Convergence of Computer Vision and Brain-Computer Interface",
      "summary": "Interpreting human neural signals to decode static speech intentions such as\ntext or images and dynamic speech intentions such as audio or video is showing\ngreat potential as an innovative communication tool. Human communication\naccompanies various features, such as articulatory movements, facial\nexpressions, and internal speech, all of which are reflected in neural signals.\nHowever, most studies only generate short or fragmented outputs, while\nproviding informative communication by leveraging various features from neural\nsignals remains challenging. In this study, we introduce a dynamic neural\ncommunication method that leverages current computer vision and brain-computer\ninterface technologies. Our approach captures the user's intentions from neural\nsignals and decodes visemes in short time steps to produce dynamic visual\noutputs. The results demonstrate the potential to rapidly capture and\nreconstruct lip movements during natural speech attempts from human neural\nsignals, enabling dynamic neural communication through the convergence of\ncomputer vision and brain--computer interface."
    },
    {
      "id": "2411.09210v1",
      "title": "Classical Verification of Quantum Learning Advantages with Noises",
      "summary": "Classical verification of quantum learning allows classical clients to\nreliably leverage quantum computing advantages by interacting with untrusted\nquantum servers. Yet, current quantum devices available in practice suffers\nfrom a variety of noises and whether existed classical verification protocols\ncarry over to noisy scenarios remains unclear. Here, we propose an efficient\nclassical error rectification algorithm to reconstruct the noise-free results\ngiven by the quantum Fourier sampling circuit with practical constant-level\nnoises. In particular, we prove that the error rectification algorithm can\nrestore the heavy Fourier coefficients by using a small number of noisy samples\nthat scales logarithmically with the problem size. We apply this algorithm to\nthe agnostic parity learning task with uniform input marginal and prove that\nthis task can be accomplished in an efficient way on noisy quantum devices with\nour algorithm. In addition, we prove that a classical client with access to the\nrandom example oracle can verify the agnostic parity learning results from the\nnoisy quantum prover in an efficient way, under the condition that the Fourier\ncoefficients are sparse. Our results demonstrate the feasibility of classical\nverification of quantum learning advantages with noises, which provide a\nvaluable guide for both theoretical studies and practical applications with\ncurrent noisy intermediate scale quantum devices."
    },
    {
      "id": "2411.09204v1",
      "title": "RibCageImp: A Deep Learning Framework for 3D Ribcage Implant Generation",
      "summary": "The recovery of damaged or resected ribcage structures requires precise,\ncustom-designed implants to restore the integrity and functionality of the\nthoracic cavity. Traditional implant design methods rely mainly on manual\nprocesses, making them time-consuming and susceptible to variability. In this\nwork, we explore the feasibility of automated ribcage implant generation using\ndeep learning. We present a framework based on 3D U-Net architecture that\nprocesses CT scans to generate patient-specific implant designs. To the best of\nour knowledge, this is the first investigation into automated thoracic implant\ngeneration using deep learning approaches. Our preliminary results, while\nmoderate, highlight both the potential and the significant challenges in this\ncomplex domain. These findings establish a foundation for future research in\nautomated ribcage reconstruction and identify key technical challenges that\nneed to be addressed for practical implementation."
    },
    {
      "id": "2411.09199v1",
      "title": "Ghost-Connect Net: A Generalization-Enhanced Guidance For Sparse Deep Networks Under Distribution Shifts",
      "summary": "Sparse deep neural networks (DNNs) excel in real-world applications like\nrobotics and computer vision, by reducing computational demands that hinder\nusability. However, recent studies aim to boost DNN efficiency by trimming\nredundant neurons or filters based on task relevance, but neglect their\nadaptability to distribution shifts. We aim to enhance these existing\ntechniques by introducing a companion network, Ghost Connect-Net (GC-Net), to\nmonitor the connections in the original network with distribution\ngeneralization advantage. GC-Net's weights represent connectivity measurements\nbetween consecutive layers of the original network. After pruning GC-Net, the\npruned locations are mapped back to the original network as pruned connections,\nallowing for the combination of magnitude and connectivity-based pruning\nmethods. Experimental results using common DNN benchmarks, such as CIFAR-10,\nFashion MNIST, and Tiny ImageNet show promising results for hybridizing the\nmethod, and using GC-Net guidance for later layers of a network and direct\npruning on earlier layers. We provide theoretical foundations for GC-Net's\napproach to improving generalization under distribution shifts."
    },
    {
      "id": "2411.09189v1",
      "title": "Improvement and Implementation of a Speech Emotion Recognition Model Based on Dual-Layer LSTM",
      "summary": "This paper builds upon an existing speech emotion recognition model by adding\nan additional LSTM layer to improve the accuracy and processing efficiency of\nemotion recognition from audio data. By capturing the long-term dependencies\nwithin audio sequences through a dual-layer LSTM network, the model can\nrecognize and classify complex emotional patterns more accurately. Experiments\nconducted on the RAVDESS dataset validated this approach, showing that the\nmodified dual layer LSTM model improves accuracy by 2% compared to the\nsingle-layer LSTM while significantly reducing recognition latency, thereby\nenhancing real-time performance. These results indicate that the dual-layer\nLSTM architecture is highly suitable for handling emotional features with\nlong-term dependencies, providing a viable optimization for speech emotion\nrecognition systems. This research provides a reference for practical\napplications in fields like intelligent customer service, sentiment analysis\nand human-computer interaction."
    },
    {
      "id": "2411.09184v1",
      "title": "Dynamic technology impact analysis: A multi-task learning approach to patent citation prediction",
      "summary": "Machine learning (ML) models are valuable tools for analyzing the impact of\ntechnology using patent citation information. However, existing ML-based\nmethods often struggle to account for the dynamic nature of the technology\nimpact over time and the interdependencies of these impacts across different\nperiods. This study proposes a multi-task learning (MTL) approach to enhance\nthe prediction of technology impact across various time frames by leveraging\nknowledge sharing and simultaneously monitoring the evolution of technology\nimpact. First, we quantify the technology impacts and identify patterns through\ncitation analysis over distinct time periods. Next, we develop MTL models to\npredict citation counts using multiple patent indicators over time. Finally, we\nexamine the changes in key input indicators and their patterns over different\nperiods using the SHapley Additive exPlanation method. We also offer guidelines\nfor validating and interpreting the results by employing statistical methods\nand natural language processing techniques. A case study on battery\ntechnologies demonstrates that our approach not only deepens the understanding\nof technology impact, but also improves prediction accuracy, yielding valuable\ninsights for both academia and industry."
    },
    {
      "id": "2411.09181v1",
      "title": "DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation",
      "summary": "Due to the difficulty of acquiring large-scale explicit user feedback,\nimplicit feedback (e.g., clicks or other interactions) is widely applied as an\nalternative source of data, where user-item interactions can be modeled as a\nbipartite graph. Due to the noisy and biased nature of implicit real-world\nuser-item interactions, identifying and rectifying noisy interactions are vital\nto enhance model performance and robustness. Previous works on purifying\nuser-item interactions in collaborative filtering mainly focus on mining the\ncorrelation between user/item embeddings and noisy interactions, neglecting the\nbenefit of temporal patterns in determining noisy interactions. Time\ninformation, while enhancing the model utility, also bears its natural\nadvantage in helping to determine noisy edges, e.g., if someone usually watches\nhorror movies at night and talk shows in the morning, a record of watching a\nhorror movie in the morning is more likely to be noisy interaction. Armed with\nthis observation, we introduce a simple yet effective mechanism for generating\ntime-aware user/item embeddings and propose two strategies for denoising\nbipartite temporal graph in recommender systems (DeBaTeR): the first is through\nreweighting the adjacency matrix (DeBaTeR-A), where a reliability score is\ndefined to reweight the edges through both soft assignment and hard assignment;\nthe second is through reweighting the loss function (DeBaTeR-L), where weights\nare generated to reweight user-item samples in the losses. Extensive\nexperiments have been conducted to demonstrate the efficacy of our methods and\nillustrate how time information indeed helps identifying noisy edges."
    },
    {
      "id": "2411.09180v1",
      "title": "LEAP:D -- A Novel Prompt-based Approach for Domain-Generalized Aerial Object Detection",
      "summary": "Drone-captured images present significant challenges in object detection due\nto varying shooting conditions, which can alter object appearance and shape.\nFactors such as drone altitude, angle, and weather cause these variations,\ninfluencing the performance of object detection algorithms. To tackle these\nchallenges, we introduce an innovative vision-language approach using learnable\nprompts. This shift from conventional manual prompts aims to reduce\ndomain-specific knowledge interference, ultimately improving object detection\ncapabilities. Furthermore, we streamline the training process with a one-step\napproach, updating the learnable prompt concurrently with model training,\nenhancing efficiency without compromising performance. Our study contributes to\ndomain-generalized object detection by leveraging learnable prompts and\noptimizing training processes. This enhances model robustness and adaptability\nacross diverse environments, leading to more effective aerial object detection."
    },
    {
      "id": "2411.09178v1",
      "title": "SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for Responsible AI",
      "summary": "As data-driven and AI-based decision making gains widespread adoption in most\ndisciplines, it is crucial that both data privacy and decision fairness are\nappropriately addressed. While differential privacy (DP) provides a robust\nframework for guaranteeing privacy and several widely accepted methods have\nbeen proposed for improving fairness, the vast majority of existing literature\ntreats the two concerns independently. For methods that do consider privacy and\nfairness simultaneously, they often only apply to a specific machine learning\ntask, limiting their generalizability. In response, we introduce SAFES, a\nSequential PrivAcy and Fairness Enhancing data Synthesis procedure that\nsequentially combines DP data synthesis with a fairness-aware data\ntransformation. SAFES allows full control over the privacy-fairness-utility\ntrade-off via tunable privacy and fairness parameters. We illustrate SAFES by\ncombining AIM, a graphical model-based DP data synthesizer, with a popular\nfairness-aware data pre-processing transformation. Empirical evaluations on the\nAdult and COMPAS datasets demonstrate that for reasonable privacy loss,\nSAFES-generated synthetic data achieve significantly improved fairness metrics\nwith relatively low utility loss."
    },
    {
      "id": "2411.09176v1",
      "title": "Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging",
      "summary": "Imagine searching a collection of coins for quarters ($0.25$), dimes\n($0.10$), nickels ($0.05$), and pennies ($0.01$)-a hybrid foraging task where\nobservers look for multiple instances of multiple target types. In such tasks,\nhow do target values and their prevalence influence foraging and eye movement\nbehaviors (e.g., should you prioritize rare quarters or common nickels)? To\nexplore this, we conducted human psychophysics experiments, revealing that\nhumans are proficient reward foragers. Their eye fixations are drawn to regions\nwith higher average rewards, fixation durations are longer on more valuable\ntargets, and their cumulative rewards exceed chance, approaching the upper\nbound of optimal foragers. To probe these decision-making processes of humans,\nwe developed a transformer-based Visual Forager (VF) model trained via\nreinforcement learning. Our VF model takes a series of targets, their\ncorresponding values, and the search image as inputs, processes the images\nusing foveated vision, and produces a sequence of eye movements along with\ndecisions on whether to collect each fixated item. Our model outperforms all\nbaselines, achieves cumulative rewards comparable to those of humans, and\napproximates human foraging behavior in eye movements and foraging biases\nwithin time-limited environments. Furthermore, stress tests on\nout-of-distribution tasks with novel targets, unseen values, and varying set\nsizes demonstrate the VF model's effective generalization. Our work offers\nvaluable insights into the relationship between eye movements and\ndecision-making, with our model serving as a powerful tool for further\nexploration of this connection. All data, code, and models will be made\npublicly available."
    },
    {
      "id": "2411.09175v1",
      "title": "Hybrid deep additive neural networks",
      "summary": "Traditional neural networks (multi-layer perceptrons) have become an\nimportant tool in data science due to their success across a wide range of\ntasks. However, their performance is sometimes unsatisfactory, and they often\nrequire a large number of parameters, primarily due to their reliance on the\nlinear combination structure. Meanwhile, additive regression has been a popular\nalternative to linear regression in statistics. In this work, we introduce\nnovel deep neural networks that incorporate the idea of additive regression.\nOur neural networks share architectural similarities with Kolmogorov-Arnold\nnetworks but are based on simpler yet flexible activation and basis functions.\nAdditionally, we introduce several hybrid neural networks that combine this\narchitecture with that of traditional neural networks. We derive their\nuniversal approximation properties and demonstrate their effectiveness through\nsimulation studies and a real-data application. The numerical results indicate\nthat our neural networks generally achieve better performance than traditional\nneural networks while using fewer parameters."
    },
    {
      "id": "2411.09174v1",
      "title": "Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance",
      "summary": "Recent advances in image generation, particularly via diffusion models, have\nled to impressive improvements in image synthesis quality. Despite this,\ndiffusion models are still challenged by model-induced artifacts and limited\nstability in image fidelity. In this work, we hypothesize that the primary\ncause of this issue is the improper resampling operation that introduces\naliasing in the diffusion model and a careful alias-free resampling dictated by\nimage processing theory can improve the model's performance in image synthesis.\nWe propose the integration of alias-free resampling layers into the UNet\narchitecture of diffusion models without adding extra trainable parameters,\nthereby maintaining computational efficiency. We then assess whether these\ntheory-driven modifications enhance image quality and rotational equivariance.\nOur experimental results on benchmark datasets, including CIFAR-10, MNIST, and\nMNIST-M, reveal consistent gains in image quality, particularly in terms of FID\nand KID scores. Furthermore, we propose a modified diffusion process that\nenables user-controlled rotation of generated images without requiring\nadditional training. Our findings highlight the potential of theory-driven\nenhancements such as alias-free resampling in generative models to improve\nimage quality while maintaining model efficiency and pioneer future research\ndirections to incorporate them into video-generating diffusion models, enabling\ndeeper exploration of the applications of alias-free resampling in generative\nmodeling."
    },
    {
      "id": "2411.09170v1",
      "title": "Towards Scalable Handwriting Communication via EEG Decoding and Latent Embedding Integration",
      "summary": "In recent years, brain-computer interfaces have made advances in decoding\nvarious motor-related tasks, including gesture recognition and movement\nclassification, utilizing electroencephalogram (EEG) data. These developments\nare fundamental in exploring how neural signals can be interpreted to recognize\nspecific physical actions. This study centers on a written alphabet\nclassification task, where we aim to decode EEG signals associated with\nhandwriting. To achieve this, we incorporate hand kinematics to guide the\nextraction of the consistent embeddings from high-dimensional neural recordings\nusing auxiliary variables (CEBRA). These CEBRA embeddings, along with the EEG,\nare processed by a parallel convolutional neural network model that extracts\nfeatures from both data sources simultaneously. The model classifies nine\ndifferent handwritten characters, including symbols such as exclamation marks\nand commas, within the alphabet. We evaluate the model using a quantitative\nfive-fold cross-validation approach and explore the structure of the embedding\nspace through visualizations. Our approach achieves a classification accuracy\nof 91 % for the nine-class task, demonstrating the feasibility of fine-grained\nhandwriting decoding from EEG."
    },
    {
      "id": "2411.09169v1",
      "title": "Artificial Theory of Mind and Self-Guided Social Organisation",
      "summary": "One of the challenges artificial intelligence (AI) faces is how a collection\nof agents coordinate their behaviour to achieve goals that are not reachable by\nany single agent. In a recent article by Ozmen et al this was framed as one of\nsix grand challenges: That AI needs to respect human cognitive processes at the\nhuman-AI interaction frontier. We suggest that this extends to the AI-AI\nfrontier and that it should also reflect human psychology, as it is the only\nsuccessful framework we have from which to build out. In this extended abstract\nwe first make the case for collective intelligence in a general setting,\ndrawing on recent work from single neuron complexity in neural networks and ant\nnetwork adaptability in ant colonies. From there we introduce how species\nrelate to one another in an ecological network via niche selection, niche\nchoice, and niche conformity with the aim of forming an analogy with human\nsocial network development as new agents join together and coordinate. From\nthere we show how our social structures are influenced by our neuro-physiology,\nour psychology, and our language. This emphasises how individual people within\na social network influence the structure and performance of that network in\ncomplex tasks, and that cognitive faculties such as Theory of Mind play a\ncentral role. We finish by discussing the current state of the art in AI and\nwhere there is potential for further development of a socially embodied\ncollective artificial intelligence that is capable of guiding its own social\nstructures."
    },
    {
      "id": "2411.09168v1",
      "title": "Theory of Mind Enhances Collective Intelligence",
      "summary": "Collective Intelligence plays a central role in a large variety of fields,\nfrom economics and evolutionary theory to neural networks and eusocial insects,\nand it is also core to much of the work on emergence and self-organisation in\ncomplex systems theory. However, in human collective intelligence there is\nstill much more to be understood in the relationship between specific\npsychological processes at the individual level and the emergence of\nself-organised structures at the social level. Previously psychological factors\nhave played a relatively minor role in the study of collective intelligence as\nthe principles are often quite general and applicable to humans just as readily\nas insects or other agents without sophisticated psychologies. In this article\nwe emphasise, with examples from other complex adaptive systems, the broad\napplicability of collective intelligence principles while the mechanisms and\ntime-scales differ significantly between examples. We contend that flexible\ncollective intelligence in human social settings is improved by our use of a\nspecific cognitive tool: our Theory of Mind. We identify several key\ncharacteristics of psychologically mediated collective intelligence and show\nthat the development of a Theory of Mind is a crucial factor distinguishing\nsocial collective intelligence from general collective intelligence. We then\nplace these capabilities in the context of the next steps in artificial\nintelligence embedded in a future that includes an effective human-AI hybrid\nsocial ecology."
    },
    {
      "id": "2411.09166v1",
      "title": "Unstructured Text Enhanced Open-domain Dialogue System: A Systematic Survey",
      "summary": "Incorporating external knowledge into dialogue generation has been proven to\nbenefit the performance of an open-domain Dialogue System (DS), such as\ngenerating informative or stylized responses, controlling conversation topics.\nIn this article, we study the open-domain DS that uses unstructured text as\nexternal knowledge sources (\\textbf{U}nstructured \\textbf{T}ext\n\\textbf{E}nhanced \\textbf{D}ialogue \\textbf{S}ystem, \\textbf{UTEDS}). The\nexistence of unstructured text entails distinctions between UTEDS and\ntraditional data-driven DS and we aim to analyze these differences. We first\ngive the definition of the UTEDS related concepts, then summarize the recently\nreleased datasets and models. We categorize UTEDS into Retrieval and Generative\nmodels and introduce them from the perspective of model components. The\nretrieval models consist of Fusion, Matching, and Ranking modules, while the\ngenerative models comprise Dialogue and Knowledge Encoding, Knowledge\nSelection, and Response Generation modules. We further summarize the evaluation\nmethods utilized in UTEDS and analyze the current models' performance. At last,\nwe discuss the future development trends of UTEDS, hoping to inspire new\nresearch in this field."
    },
    {
      "id": "2411.09160v1",
      "title": "Rationality based Innate-Values-driven Reinforcement Learning",
      "summary": "Innate values describe agents' intrinsic motivations, which reflect their\ninherent interests and preferences to pursue goals and drive them to develop\ndiverse skills satisfying their various needs. The essence of reinforcement\nlearning (RL) is learning from interaction based on reward-driven behaviors,\nmuch like natural agents. It is an excellent model to describe the\ninnate-values-driven (IV) behaviors of AI agents. Especially developing the\nawareness of the AI agent through balancing internal and external utilities\nbased on its needs in different tasks is a crucial problem for individuals\nlearning to support AI agents integrating human society with safety and harmony\nin the long term. This paper proposes a hierarchical compound intrinsic value\nreinforcement learning model -- innate-values-driven reinforcement learning\ntermed IVRL to describe the complex behaviors of AI agents' interaction. We\nformulated the IVRL model and proposed two IVRL models: DQN and A2C. By\ncomparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in the\nRole-Playing Game (RPG) reinforcement learning test platform VIZDoom, we\ndemonstrated that rationally organizing various individual needs can\neffectively achieve better performance."
    },
    {
      "id": "2411.09158v1",
      "title": "The \\emph{Optimist}: Towards Fully Automated Graph Theory Research",
      "summary": "This paper introduces the \\emph{Optimist}, an autonomous system developed to\nadvance automated conjecture generation in graph theory. Leveraging\nmixed-integer programming (MIP) and heuristic methods, the \\emph{Optimist}\ngenerates conjectures that both rediscover established theorems and propose\nnovel inequalities. Through a combination of memory-based computation and\nagent-like adaptability, the \\emph{Optimist} iteratively refines its\nconjectures by integrating new data, enabling a feedback process with minimal\nhuman (\\emph{or machine}) intervention. Initial experiments reveal the\n\\emph{Optimist}'s potential to uncover foundational results in graph theory, as\nwell as to produce conjectures of interest for future exploration. This work\nalso outlines the \\emph{Optimist}'s evolving integration with a counterpart\nagent, the \\emph{Pessimist} (a human \\emph{or machine} agent), to establish a\ndueling system that will drive fully automated graph theory research."
    },
    {
      "id": "2411.09152v1",
      "title": "GRAINRec: Graph and Attention Integrated Approach for Real-Time Session-Based Item Recommendations",
      "summary": "Recent advancements in session-based recommendation models using deep\nlearning techniques have demonstrated significant performance improvements.\nWhile they can enhance model sophistication and improve the relevance of\nrecommendations, they also make it challenging to implement a scalable\nreal-time solution. To addressing this challenge, we propose GRAINRec: a Graph\nand Attention Integrated session-based recommendation model that generates\nrecommendations in real-time. Our scope of work is item recommendations in\nonline retail where a session is defined as an ordered sequence of digital\nguest actions, such as page views or adds to cart. The proposed model generates\nrecommendations by considering the importance of all items in the session\ntogether, letting us predict relevant recommendations dynamically as the\nsession evolves. We also propose a heuristic approach to implement real-time\ninferencing that meets Target platform's service level agreement (SLA). The\nproposed architecture lets us predict relevant recommendations dynamically as\nthe session evolves, rather than relying on pre-computed recommendations for\neach item. Evaluation results of the proposed model show an average improvement\nof 1.5% across all offline evaluation metrics. A/B tests done over a 2 week\nduration showed an increase of 10% in click through rate and 9% increase in\nattributable demand. Extensive ablation studies are also done to understand our\nmodel performance for different parameters."
    },
    {
      "id": "2411.09142v1",
      "title": "Laplace Transform Interpretation of Differential Privacy",
      "summary": "We introduce a set of useful expressions of Differential Privacy (DP) notions\nin terms of the Laplace transform of the privacy loss distribution. Its bare\nform expression appears in several related works on analyzing DP, either as an\nintegral or an expectation. We show that recognizing the expression as a\nLaplace transform unlocks a new way to reason about DP properties by exploiting\nthe duality between time and frequency domains. Leveraging our interpretation,\nwe connect the $(q, \\rho(q))$-R\\'enyi DP curve and the $(\\epsilon,\n\\delta(\\epsilon))$-DP curve as being the Laplace and inverse-Laplace transforms\nof one another. This connection shows that the R\\'enyi divergence is\nwell-defined for complex orders $q = \\gamma + i \\omega$. Using our Laplace\ntransform-based analysis, we also prove an adaptive composition theorem for\n$(\\epsilon, \\delta)$-DP guarantees that is exactly tight (i.e., matches even in\nconstants) for all values of $\\epsilon$. Additionally, we resolve an issue\nregarding symmetry of $f$-DP on subsampling that prevented equivalence across\nall functional DP notions."
    },
    {
      "id": "2411.09134v1",
      "title": "ABCI 3.0: Evolution of the leading AI infrastructure in Japan",
      "summary": "ABCI 3.0 is the latest version of the ABCI, a large-scale open AI\ninfrastructure that AIST has been operating since August 2018 and will be fully\noperational in January 2025. ABCI 3.0 consists of computing servers equipped\nwith 6128 of the NVIDIA H200 GPUs and an all-flash storage system. Its peak\nperformance is 6.22 exaflops in half precision and 3.0 exaflops in single\nprecision, which is 7 to 13 times faster than the previous system, ABCI 2.0. It\nalso more than doubles both storage capacity and theoretical read/write\nperformance. ABCI 3.0 is expected to accelerate research and development,\nevaluation, and workforce development of cutting-edge AI technologies, with a\nparticular focus on generative AI."
    },
    {
      "id": "2411.09127v1",
      "title": "Complexity-Aware Training of Deep Neural Networks for Optimal Structure Discovery",
      "summary": "We propose a novel algorithm for combined unit/filter and layer pruning of\ndeep neural networks that functions during training and without requiring a\npre-trained network to apply. Our algorithm optimally trades-off learning\naccuracy and pruning levels while balancing layer vs. unit/filter pruning and\ncomputational vs. parameter complexity using only three user-defined\nparameters, which are easy to interpret and tune. The optimal network structure\nis found as the solution of a stochastic optimization problem over the network\nweights and the parameters of variational Bernoulli distributions for 0/1\nRandom Variables scaling the units and layers of the network. Pruning occurs\nwhen a variational parameter converges to 0 rendering the corresponding\nstructure permanently inactive, thus saving computations during training and\nprediction. A key contribution of our approach is to define a cost function\nthat combines the objectives of prediction accuracy and network pruning in a\ncomputational/parameter complexity-aware manner and the automatic selection of\nthe many regularization parameters. We show that the solutions of the\noptimization problem to which the algorithm converges are deterministic\nnetworks. We analyze the ODE system that underlies our stochastic optimization\nalgorithm and establish domains of attraction around zero for the dynamics of\nthe network parameters. These results provide theoretical support for safely\npruning units/filters and/or layers during training and lead to practical\npruning conditions. We evaluate our method on the CIFAR-10/100 and ImageNet\ndatasets using ResNet architectures and demonstrate that our method improves\nupon layer only or unit only pruning and favorably competes with combined\nunit/filter and layer pruning algorithms requiring pre-trained networks with\nrespect to pruning ratios and test accuracy."
    },
    {
      "id": "2411.09125v1",
      "title": "DROJ: A Prompt-Driven Attack against Large Language Models",
      "summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various natural language processing tasks. Due to their training on\ninternet-sourced datasets, LLMs can sometimes generate objectionable content,\nnecessitating extensive alignment with human feedback to avoid such outputs.\nDespite massive alignment efforts, LLMs remain susceptible to adversarial\njailbreak attacks, which usually are manipulated prompts designed to circumvent\nsafety mechanisms and elicit harmful responses. Here, we introduce a novel\napproach, Directed Rrepresentation Optimization Jailbreak (DROJ), which\noptimizes jailbreak prompts at the embedding level to shift the hidden\nrepresentations of harmful queries towards directions that are more likely to\nelicit affirmative responses from the model. Our evaluations on LLaMA-2-7b-chat\nmodel show that DROJ achieves a 100\\% keyword-based Attack Success Rate (ASR),\neffectively preventing direct refusals. However, the model occasionally\nproduces repetitive and non-informative responses. To mitigate this, we\nintroduce a helpfulness system prompt that enhances the utility of the model's\nresponses. Our code is available at\nhttps://github.com/Leon-Leyang/LLM-Safeguard."
    },
    {
      "id": "2411.09120v1",
      "title": "Neural Graph Simulator for Complex Systems",
      "summary": "Numerical simulation is a predominant tool for studying the dynamics in\ncomplex systems, but large-scale simulations are often intractable due to\ncomputational limitations. Here, we introduce the Neural Graph Simulator (NGS)\nfor simulating time-invariant autonomous systems on graphs. Utilizing a graph\nneural network, the NGS provides a unified framework to simulate diverse\ndynamical systems with varying topologies and sizes without constraints on\nevaluation times through its non-uniform time step and autoregressive approach.\nThe NGS offers significant advantages over numerical solvers by not requiring\nprior knowledge of governing equations and effectively handling noisy or\nmissing data with a robust training scheme. It demonstrates superior\ncomputational efficiency over conventional methods, improving performance by\nover $10^5$ times in stiff problems. Furthermore, it is applied to real traffic\ndata, forecasting traffic flow with state-of-the-art accuracy. The versatility\nof the NGS extends beyond the presented cases, offering numerous potential\navenues for enhancement."
    },
    {
      "id": "2411.09118v1",
      "title": "FxTS-Net: Fixed-Time Stable Learning Framework for Neural ODEs",
      "summary": "Neural Ordinary Differential Equations (Neural ODEs), as a novel category of\nmodeling big data methods, cleverly link traditional neural networks and\ndynamical systems. However, it is challenging to ensure the dynamics system\nreaches a correctly predicted state within a user-defined fixed time. To\naddress this problem, we propose a new method for training Neural ODEs using\nfixed-time stability (FxTS) Lyapunov conditions. Our framework, called\nFxTS-Net, is based on the novel FxTS loss (FxTS-Loss) designed on Lyapunov\nfunctions, which aims to encourage convergence to accurate predictions in a\nuser-defined fixed time. We also provide an innovative approach for\nconstructing Lyapunov functions to meet various tasks and network architecture\nrequirements, achieved by leveraging supervised information during training. By\ndeveloping a more precise time upper bound estimation for bounded\nnon-vanishingly perturbed systems, we demonstrate that minimizing FxTS-Loss not\nonly guarantees FxTS behavior of the dynamics but also input perturbation\nrobustness. For optimising FxTS-Loss, we also propose a learning algorithm, in\nwhich the simulated perturbation sampling method can capture sample points in\ncritical regions to approximate FxTS-Loss. Experimentally, we find that\nFxTS-Net provides better prediction performance and better robustness under\ninput perturbation."
    },
    {
      "id": "2411.09117v1",
      "title": "Efficiently learning and sampling multimodal distributions with data-based initialization",
      "summary": "We consider the problem of sampling a multimodal distribution with a Markov\nchain given a small number of samples from the stationary measure. Although\nmixing can be arbitrarily slow, we show that if the Markov chain has a $k$th\norder spectral gap, initialization from a set of $\\tilde O(k/\\varepsilon^2)$\nsamples from the stationary distribution will, with high probability over the\nsamples, efficiently generate a sample whose conditional law is\n$\\varepsilon$-close in TV distance to the stationary measure. In particular,\nthis applies to mixtures of $k$ distributions satisfying a Poincar\\'e\ninequality, with faster convergence when they satisfy a log-Sobolev inequality.\nOur bounds are stable to perturbations to the Markov chain, and in particular\nwork for Langevin diffusion over $\\mathbb R^d$ with score estimation error, as\nwell as Glauber dynamics combined with approximation error from\npseudolikelihood estimation. This justifies the success of data-based\ninitialization for score matching methods despite slow mixing for the data\ndistribution, and improves and generalizes the results of Koehler and Vuong\n(2023) to have linear, rather than exponential, dependence on $k$ and apply to\narbitrary semigroups. As a consequence of our results, we show for the first\ntime that a natural class of low-complexity Ising measures can be efficiently\nlearned from samples."
    },
    {
      "id": "2411.09116v1",
      "title": "P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs",
      "summary": "Recent advancements in large language models (LLMs) showcase varied\nmultilingual capabilities across tasks like translation, code generation, and\nreasoning. Previous assessments often limited their scope to fundamental\nnatural language processing (NLP) or isolated capability-specific tasks. To\nalleviate this drawback, we aim to present a comprehensive multilingual\nmultitask benchmark. First, we present a pipeline for selecting available and\nreasonable benchmarks from massive ones, addressing the oversight in previous\nwork regarding the utility of these benchmarks, i.e., their ability to\ndifferentiate between models being evaluated. Leveraging this pipeline, we\nintroduce P-MMEval, a large-scale benchmark covering effective fundamental and\ncapability-specialized datasets. Furthermore, P-MMEval delivers consistent\nlanguage coverage across various datasets and provides parallel samples.\nFinally, we conduct extensive experiments on representative multilingual model\nseries to compare performances across models, analyze dataset effectiveness,\nexamine prompt impacts on model performances, and explore the relationship\nbetween multilingual performances and factors such as tasks, model sizes, and\nlanguages. These insights offer valuable guidance for future research. The\ndataset is available at https://huggingface.co/datasets/Qwen/P-MMEval."
    },
    {
      "id": "2411.09111v1",
      "title": "Reducing Reasoning Costs -- The Path of Optimization for Chain of Thought via Sparse Attention Mechanism",
      "summary": "In order to address the chain of thought in the large language model\ninference cost surge, this research proposes to use a sparse attention\nmechanism that only focuses on a few relevant tokens. The researcher\nconstructed a new attention mechanism and used GiantRabbit trained with custom\nGPTs as an experimental tool. The experiment tested and compared the reasoning\ntime, correctness score and chain of thought length of this model and o1\nPreview in solving the linear algebra test questions of MIT OpenCourseWare. The\nresults show that GiantRabbit's reasoning time and chain of thought length are\nsignificantly lower than o1 Preview, confirming the feasibility of the sparse\nattention mechanism in reducing chain of thought reasoning. Detailed\narchitectural details and experimental process have been uploaded to Github,\nthe link is:https://github.com/brucewang123456789/GeniusTrail.git."
    },
    {
      "id": "2411.09109v1",
      "title": "Personalized Help for Optimizing Low-Skilled Users' Strategy",
      "summary": "AIs can beat humans in game environments; however, how helpful those agents\nare to human remains understudied. We augment CICERO, a natural language agent\nthat demonstrates superhuman performance in Diplomacy, to generate both move\nand message advice based on player intentions. A dozen Diplomacy games with\nnovice and experienced players, with varying advice settings, show that some of\nthe generated advice is beneficial. It helps novices compete with experienced\nplayers and in some instances even surpass them. The mere presence of advice\ncan be advantageous, even if players do not follow it."
    },
    {
      "id": "2411.09105v1",
      "title": "VCBench: A Controllable Benchmark for Symbolic and Abstract Challenges in Video Cognition",
      "summary": "Recent advancements in Large Video-Language Models (LVLMs) have driven the\ndevelopment of benchmarks designed to assess cognitive abilities in video-based\ntasks. However, most existing benchmarks heavily rely on web-collected videos\npaired with human annotations or model-generated questions, which limit control\nover the video content and fall short in evaluating advanced cognitive\nabilities involving symbolic elements and abstract concepts. To address these\nlimitations, we introduce VCBench, a controllable benchmark to assess LVLMs'\ncognitive abilities, involving symbolic and abstract concepts at varying\ndifficulty levels. By generating video data with the Python-based engine,\nVCBench allows for precise control over the video content, creating dynamic,\ntask-oriented videos that feature complex scenes and abstract concepts. Each\ntask pairs with tailored question templates that target specific cognitive\nchallenges, providing a rigorous evaluation test. Our evaluation reveals that\neven state-of-the-art (SOTA) models, such as Qwen2-VL-72B, struggle with simple\nvideo cognition tasks involving abstract concepts, with performance sharply\ndropping by 19% as video complexity rises. These findings reveal the current\nlimitations of LVLMs in advanced cognitive tasks and highlight the critical\nrole of VCBench in driving research toward more robust LVLMs for complex video\ncognition challenges."
    },
    {
      "id": "2411.09102v1",
      "title": "Provocation: Who benefits from \"inclusion\" in Generative AI?",
      "summary": "The demands for accurate and representative generative AI systems means there\nis an increased demand on participatory evaluation structures. While these\nparticipatory structures are paramount to to ensure non-dominant values,\nknowledge and material culture are also reflected in AI models and the media\nthey generate, we argue that dominant structures of community participation in\nAI development and evaluation are not explicit enough about the benefits and\nharms that members of socially marginalized groups may experience as a result\nof their participation. Without explicit interrogation of these benefits by AI\ndevelopers, as a community we may remain blind to the immensity of systemic\nchange that is needed as well. To support this provocation, we present a\nspeculative case study, developed from our own collective experiences as AI\nresearchers. We use this speculative context to itemize the barriers that need\nto be overcome in order for the proposed benefits to marginalized communities\nto be realized, and harms mitigated."
    },
    {
      "id": "2411.09101v1",
      "title": "Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery",
      "summary": "Vision Transformers (ViT) have recently brought a new wave of research in the\nfield of computer vision. These models have done particularly well in the field\nof image classification and segmentation. Research on semantic and instance\nsegmentation has emerged to accelerate with the inception of the new\narchitecture, with over 80\\% of the top 20 benchmarks for the iSAID dataset\nbeing either based on the ViT architecture or the attention mechanism behind\nits success. This paper focuses on the heuristic comparison of three key\nfactors of using (or not using) ViT for semantic segmentation of remote sensing\naerial images on the iSAID. The experimental results observed during the course\nof the research were under the scrutinization of the following objectives: 1.\nUse of weighted fused loss function for the maximum mean Intersection over\nUnion (mIoU) score, Dice score, and minimization or conservation of entropy or\nclass representation, 2. Comparison of transfer learning on Meta's MaskFormer,\na ViT-based semantic segmentation model, against generic UNet Convolutional\nNeural Networks (CNNs) judged over mIoU, Dice scores, training efficiency, and\ninference time, and 3. What do we lose for what we gain? i.e., the comparison\nof the two models against current state-of-art segmentation models. We show the\nuse of the novel combined weighted loss function significantly boosts the CNN\nmodel's performance capacities as compared to transfer learning the ViT. The\ncode for this implementation can be found on\n\\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation}."
    },
    {
      "id": "2411.09089v1",
      "title": "Set-Based Retrograde Analysis: Precomputing the Solution to 24-card Bridge Double Dummy Deals",
      "summary": "Retrograde analysis is used in game-playing programs to solve states at the\nend of a game, working backwards toward the start of the game. The algorithm\niterates through and computes the perfect-play value for as many states as\nresources allow. We introduce setrograde analysis which achieves the same\nresults by operating on sets of states that have the same game value. The\nalgorithm is demonstrated by computing exact solutions for Bridge double dummy\ncard-play. For deals with 24 cards remaining to be played ($10^{27}$ states,\nwhich can be reduced to $10^{15}$ states using preexisting techniques), we\nstrongly solve all deals. The setrograde algorithm performs a factor of $10^3$\nfewer search operations than a standard retrograde algorithm, producing a\ndatabase with a factor of $10^4$ fewer entries. For applicable domains, this\nallows retrograde searching to reach unprecedented search depths."
    },
    {
      "id": "2411.09077v1",
      "title": "Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data",
      "summary": "Drone detection has benefited from improvements in deep neural networks, but\nlike many other applications, suffers from the availability of accurate data\nfor training. Synthetic data provides a potential for low-cost data generation\nand has been shown to improve data availability and quality. However, models\ntrained on synthetic datasets need to prove their ability to perform on\nreal-world data, known as the problem of sim-to-real transferability. Here, we\npresent a drone detection Faster-RCNN model trained on a purely synthetic\ndataset that transfers to real-world data. We found that it achieves an AP_50\nof 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -\ncompared with 97.8% for an equivalent model trained on real-world data. Our\nresults show that using synthetic data for drone detection has the potential to\nreduce data collection costs and improve labelling quality. These findings\ncould be a starting point for more elaborate synthetic drone datasets. For\nexample, realistic recreations of specific scenarios could de-risk the dataset\ngeneration of safety-critical applications such as the detection of drones at\nairports. Further, synthetic data may enable reliable drone detection systems,\nwhich could benefit other areas, such as unmanned traffic management systems.\nThe code is available\nhttps://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the\ndatasets\nhttps://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection."
    },
    {
      "id": "2411.09073v1",
      "title": "Code-mixed LLM: Improve Large Language Models' Capability to Handle Code-Mixing through Reinforcement Learning from AI Feedback",
      "summary": "Code-mixing(CM) or code-switching(CSW) refers to the juxtaposition of\nlinguistic units from two or more languages during the conversation or\nsometimes even a single utterance. Code-mixing introduces unique challenges in\ndaily life, such as syntactic mismatches and semantic blending, that are rarely\nencountered in monolingual settings. Large language models (LLMs) have\nrevolutionized the field of natural language processing (NLP) by offering\nunprecedented capabilities in understanding human languages. However, the\neffectiveness of current state-of-the-art multilingual LLMs has not yet been\nfully explored in the CM scenario. To fill this gap, we first benchmark the\nperformance of multilingual LLMs on various code-mixing NLP tasks. Then we\npropose to improve the multilingual LLMs' ability to understand code-mixing\nthrough reinforcement learning from human feedback (RLHF) and code-mixed\nmachine translation tasks. Given the high-cost and time-consuming preference\nlabeling procedure, we improve this by utilizing LLMs as annotators to perform\nthe reinforcement learning from AI feedback (RLAIF). The experiments show the\neffectiveness of the proposed method."
    },
    {
      "id": "2411.09072v1",
      "title": "Continuous GNN-based Anomaly Detection on Edge using Efficient Adaptive Knowledge Graph Learning",
      "summary": "The increasing demand for robust security solutions across various industries\nhas made Video Anomaly Detection (VAD) a critical task in applications such as\nintelligent surveillance, evidence investigation, and violence detection.\nTraditional approaches to VAD often rely on finetuning large pre-trained\nmodels, which can be computationally expensive and impractical for real-time or\nresource-constrained environments. To address this, MissionGNN introduced a\nmore efficient method by training a graph neural network (GNN) using a fixed\nknowledge graph (KG) derived from large language models (LLMs) like GPT-4.\nWhile this approach demonstrated significant efficiency in computational power\nand memory, it faces limitations in dynamic environments where frequent updates\nto the KG are necessary due to evolving behavior trends and shifting data\npatterns. These updates typically require cloud-based computation, posing\nchallenges for edge computing applications. In this paper, we propose a novel\nframework that facilitates continuous KG adaptation directly on edge devices,\novercoming the limitations of cloud dependency. Our method dynamically modifies\nthe KG through a three-phase process: pruning, alternating, and creating nodes,\nenabling real-time adaptation to changing data trends. This continuous learning\napproach enhances the robustness of anomaly detection models, making them more\nsuitable for deployment in dynamic and resource-constrained environments."
    },
    {
      "id": "2411.09068v1",
      "title": "Liner Shipping Network Design with Reinforcement Learning",
      "summary": "This paper proposes a novel reinforcement learning framework to address the\nLiner Shipping Network Design Problem (LSNDP), a challenging combinatorial\noptimization problem focused on designing cost-efficient maritime shipping\nroutes. Traditional methods for solving the LSNDP typically involve decomposing\nthe problem into sub-problems, such as network design and multi-commodity flow,\nwhich are then tackled using approximate heuristics or large neighborhood\nsearch (LNS) techniques. In contrast, our approach employs a model-free\nreinforcement learning algorithm on the network design, integrated with a\nheuristic-based multi-commodity flow solver, to produce competitive results on\nthe publicly available LINERLIB benchmark. Additionally, our method also\ndemonstrates generalization capabilities by producing competitive solutions on\nthe benchmark instances after training on perturbed instances."
    },
    {
      "id": "2411.09065v1",
      "title": "Language-Model Prior Overcomes Cold-Start Items",
      "summary": "The growth of recommender systems (RecSys) is driven by digitization and the\nneed for personalized content in areas such as e-commerce and video streaming.\nThe content in these systems often changes rapidly and therefore they\nconstantly face the ongoing cold-start problem, where new items lack\ninteraction data and are hard to value. Existing solutions for the cold-start\nproblem, such as content-based recommenders and hybrid methods, leverage item\nmetadata to determine item similarities. The main challenge with these methods\nis their reliance on structured and informative metadata to capture detailed\nitem similarities, which may not always be available. This paper introduces a\nnovel approach for cold-start item recommendation that utilizes the language\nmodel (LM) to estimate item similarities, which are further integrated as a\nBayesian prior with classic recommender systems. This approach is generic and\nable to boost the performance of various recommenders. Specifically, our\nexperiments integrate it with both sequential and collaborative filtering-based\nrecommender and evaluate it on two real-world datasets, demonstrating the\nenhanced performance of the proposed approach."
    },
    {
      "id": "2411.09064v1",
      "title": "Minimax Optimal Two-Sample Testing under Local Differential Privacy",
      "summary": "We explore the trade-off between privacy and statistical utility in private\ntwo-sample testing under local differential privacy (LDP) for both multinomial\nand continuous data. We begin by addressing the multinomial case, where we\nintroduce private permutation tests using practical privacy mechanisms such as\nLaplace, discrete Laplace, and Google's RAPPOR. We then extend our multinomial\napproach to continuous data via binning and study its uniform separation rates\nunder LDP over H\\\"older and Besov smoothness classes. The proposed tests for\nboth discrete and continuous cases rigorously control the type I error for any\nfinite sample size, strictly adhere to LDP constraints, and achieve minimax\nseparation rates under LDP. The attained minimax rates reveal inherent\nprivacy-utility trade-offs that are unavoidable in private testing. To address\nscenarios with unknown smoothness parameters in density testing, we propose an\nadaptive test based on a Bonferroni-type approach that ensures robust\nperformance without prior knowledge of the smoothness parameters. We validate\nour theoretical findings with extensive numerical experiments and demonstrate\nthe practical relevance and effectiveness of our proposed methods."
    },
    {
      "id": "2411.09062v1",
      "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts",
      "summary": "Manufacturing requires reliable object detection methods for precise picking\nand handling of diverse types of manufacturing parts and components.\nTraditional object detection methods utilize either only 2D images from cameras\nor 3D data from lidars or similar 3D sensors. However, each of these sensors\nhave weaknesses and limitations. Cameras do not have depth perception and 3D\nsensors typically do not carry color information. These weaknesses can\nundermine the reliability and robustness of industrial manufacturing systems.\nTo address these challenges, this work proposes a multi-sensor system combining\nan red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are\ncalibrated for precise alignment of the multimodal data captured from the two\nhardware devices. A novel multimodal object detection method is developed to\nprocess both RGB and depth data. This object detector is based on the Faster\nR-CNN baseline that was originally designed to process only camera images. The\nresults show that the multimodal model significantly outperforms the depth-only\nand RGB-only baselines on established object detection metrics. More\nspecifically, the multimodal model improves mAP by 13% and raises Mean\nPrecision by 11.8% in comparison to the RGB-only baseline. Compared to the\ndepth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.\nHence, this method facilitates more reliable and robust object detection in\nservice to smart manufacturing applications."
    },
    {
      "id": "2411.09056v1",
      "title": "Optimisation Strategies for Ensuring Fairness in Machine Learning: With and Without Demographics",
      "summary": "Ensuring fairness has emerged as one of the primary concerns in AI and its\nrelated algorithms. Over time, the field of machine learning fairness has\nevolved to address these issues. This paper provides an extensive overview of\nthis field and introduces two formal frameworks to tackle open questions in\nmachine learning fairness.\n  In one framework, operator-valued optimisation and min-max objectives are\nemployed to address unfairness in time-series problems. This approach showcases\nstate-of-the-art performance on the notorious COMPAS benchmark dataset,\ndemonstrating its effectiveness in real-world scenarios.\n  In the second framework, the challenge of lacking sensitive attributes, such\nas gender and race, in commonly used datasets is addressed. This issue is\nparticularly pressing because existing algorithms in this field predominantly\nrely on the availability or estimations of such attributes to assess and\nmitigate unfairness. Here, a framework for a group-blind bias-repair is\nintroduced, aiming to mitigate bias without relying on sensitive attributes.\nThe efficacy of this approach is showcased through analyses conducted on the\nAdult Census Income dataset.\n  Additionally, detailed algorithmic analyses for both frameworks are provided,\naccompanied by convergence guarantees, ensuring the robustness and reliability\nof the proposed methodologies."
    },
    {
      "id": "2411.09055v1",
      "title": "SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated Machine Learning for Indoor Localization",
      "summary": "Machine learning (ML) based indoor localization solutions are critical for\nmany emerging applications, yet their efficacy is often compromised by\nhardware/software variations across mobile devices (i.e., device heterogeneity)\nand the threat of ML data poisoning attacks. Conventional methods aimed at\ncountering these challenges show limited resilience to the uncertainties\ncreated by these phenomena. In response, in this paper, we introduce SAFELOC, a\nnovel framework that not only minimizes localization errors under these\nchallenging conditions but also ensures model compactness for efficient mobile\ndevice deployment. Our framework targets a distributed and co-operative\nlearning environment that uses federated learning (FL) to preserve user data\nprivacy and assumes heterogeneous mobile devices carried by users (just like in\nmost real-world scenarios). Within this heterogeneous FL context, SAFELOC\nintroduces a novel fused neural network architecture that performs data\npoisoning detection and localization, with a low model footprint. Additionally,\na dynamic saliency map-based aggregation strategy is designed to adapt based on\nthe severity of the detected data poisoning scenario. Experimental evaluations\ndemonstrate that SAFELOC achieves improvements of up to 5.9x in mean\nlocalization error, 7.8x in worst-case localization error, and a 2.1x reduction\nin model inference latency compared to state-of-the-art indoor localization\nframeworks, across diverse building floorplans, mobile devices, and ML data\npoisoning attack scenarios."
    },
    {
      "id": "2411.09052v1",
      "title": "ClevrSkills: Compositional Language and Visual Reasoning in Robotics",
      "summary": "Robotics tasks are highly compositional by nature. For example, to perform a\nhigh-level task like cleaning the table a robot must employ low-level\ncapabilities of moving the effectors to the objects on the table, pick them up\nand then move them off the table one-by-one, while re-evaluating the\nconsequently dynamic scenario in the process. Given that large vision language\nmodels (VLMs) have shown progress on many tasks that require high level,\nhuman-like reasoning, we ask the question: if the models are taught the\nrequisite low-level capabilities, can they compose them in novel ways to\nachieve interesting high-level tasks like cleaning the table without having to\nbe explicitly taught so? To this end, we present ClevrSkills - a benchmark\nsuite for compositional reasoning in robotics. ClevrSkills is an environment\nsuite developed on top of the ManiSkill2 simulator and an accompanying dataset.\nThe dataset contains trajectories generated on a range of robotics tasks with\nlanguage and visual annotations as well as multi-modal prompts as task\nspecification. The suite includes a curriculum of tasks with three levels of\ncompositional understanding, starting with simple tasks requiring basic motor\nskills. We benchmark multiple different VLM baselines on ClevrSkills and show\nthat even after being pre-trained on large numbers of tasks, these models fail\non compositional reasoning in robotics tasks."
    },
    {
      "id": "2411.09050v1",
      "title": "The Systems Engineering Approach in Times of Large Language Models",
      "summary": "Using Large Language Models (LLMs) to address critical societal problems\nrequires adopting this novel technology into socio-technical systems. However,\nthe complexity of such systems and the nature of LLMs challenge such a vision.\nIt is unlikely that the solution to such challenges will come from the\nArtificial Intelligence (AI) community itself. Instead, the Systems Engineering\napproach is better equipped to facilitate the adoption of LLMs by prioritising\nthe problems and their context before any other aspects. This paper introduces\nthe challenges LLMs generate and surveys systems research efforts for\nengineering AI-based systems. We reveal how the systems engineering principles\nhave supported addressing similar issues to the ones LLMs pose and discuss our\nfindings to provide future directions for adopting LLMs."
    },
    {
      "id": "2411.09047v1",
      "title": "Anomaly Detection in Large-Scale Cloud Systems: An Industry Case and Dataset",
      "summary": "As Large-Scale Cloud Systems (LCS) become increasingly complex, effective\nanomaly detection is critical for ensuring system reliability and performance.\nHowever, there is a shortage of large-scale, real-world datasets available for\nbenchmarking anomaly detection methods.\n  To address this gap, we introduce a new high-dimensional dataset from IBM\nCloud, collected over 4.5 months from the IBM Cloud Console. This dataset\ncomprises 39,365 rows and 117,448 columns of telemetry data. Additionally, we\ndemonstrate the application of machine learning models for anomaly detection\nand discuss the key challenges faced in this process.\n  This study and the accompanying dataset provide a resource for researchers\nand practitioners in cloud system monitoring. It facilitates more efficient\ntesting of anomaly detection methods in real-world data, helping to advance the\ndevelopment of robust solutions to maintain the health and performance of\nlarge-scale cloud infrastructures."
    },
    {
      "id": "2411.09027v1",
      "title": "Transformer-based Time-Series Biomarker Discovery for COPD Diagnosis",
      "summary": "Chronic Obstructive Pulmonary Disorder (COPD) is an irreversible and\nprogressive disease which is highly heritable. Clinically, COPD is defined\nusing the summary measures derived from a spirometry test but these are not\nalways adequate. Here we show that using the high-dimensional raw spirogram can\nprovide a richer signal compared to just using the summary measures. We design\na transformer-based deep learning technique to process the raw spirogram values\nalong with demographic information and predict clinically-relevant endpoints\nrelated to COPD. Our method is able to perform better than prior works while\nbeing more computationally efficient. Using the weights learned by the model,\nwe make the framework more interpretable by identifying parts of the spirogram\nthat are important for the model predictions. Pairing up with a board-certified\npulmonologist, we also provide clinical insights into the different aspects of\nthe spirogram and show that the explanations obtained from the model align with\nunderlying medical knowledge."
    },
    {
      "id": "2411.09018v1",
      "title": "Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted Captions",
      "summary": "Recent research increasingly focuses on training vision-language models\n(VLMs) with long, detailed image captions. However, small-scale VLMs often\nstruggle to balance the richness of these captions with the risk of\nhallucinating content during fine-tuning. In this paper, we explore how well\nVLMs adapt to such captions. To quantify caption quality, we propose Decomposed\nNLI (DNLI), an evaluation framework that breaks down generated captions into\nindividual propositions, assessing each in isolation. This fine-grained\nanalysis reveals a critical balance between capturing descriptive details and\npreventing hallucinations. Our findings show that simply reducing caption\ncomplexity or employing standard data curation techniques does not effectively\nresolve this issue. To tackle this challenge, we introduce Knowledge Adapted\n(KnowAda) fine-tuning, a data-centric approach that automatically adapts\ntraining data with the model's existing knowledge and visual understanding.\nKnowAda minimizes hallucinations while preserving high descriptiveness. We\nvalidate this approach across several small-scale VLMs (up to 7B parameters)\nand dense caption datasets, demonstrating that KnowAda effectively balances\nhallucination reduction and descriptiveness. Our results show that KnowAda\noutperforms various baselines in both automatic metrics and human evaluations.\nWe will release our code and models."
    },
    {
      "id": "2411.09009v1",
      "title": "Cut Your Losses in Large-Vocabulary Language Models",
      "summary": "As language models grow ever larger, so do their vocabularies. This has\nshifted the memory footprint of LLMs during training disproportionately to one\nsingle layer: the cross-entropy in the loss computation. Cross-entropy builds\nup a logit matrix with entries for each pair of input tokens and vocabulary\nitems and, for small models, consumes an order of magnitude more memory than\nthe rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that\ncomputes the cross-entropy loss without materializing the logits for all tokens\ninto global memory. Rather, CCE only computes the logit for the correct token\nand evaluates the log-sum-exp over all logits on the fly. We implement a custom\nkernel that performs the matrix multiplications and the log-sum-exp reduction\nover the vocabulary in flash memory, making global memory consumption for the\ncross-entropy computation negligible. This has a dramatic effect. Taking the\nGemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss\ncomputation from 24 GB to 1 MB, and the total training-time memory consumption\nof the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we\nleverage the inherent sparsity of softmax and propose to skip elements of the\ngradient computation that have a negligible (i.e., below numerical precision)\ncontribution to the gradient. Experiments demonstrate that the dramatic\nreduction in memory consumption is accomplished without sacrificing training\nspeed or convergence."
    },
    {
      "id": "2411.09003v1",
      "title": "Refusal in LLMs is an Affine Function",
      "summary": "We propose affine concept editing (ACE) as an approach for steering language\nmodels' behavior by intervening directly in activations. We begin with an\naffine decomposition of model activation vectors and show that prior methods\nfor steering model behavior correspond to subsets of terms of this\ndecomposition. We then provide a derivation of ACE and test it on refusal using\nLlama 3 8B and Hermes Eagle RWKV v5. ACE ultimately combines affine subspace\nprojection and activation addition to reliably control the model's refusal\nresponses across prompt types. We evaluate the results using LLM-based scoring\non a collection of harmful and harmless prompts. Our experiments demonstrate\nthat ACE consistently achieves more precise control over model behavior and\ngeneralizes to models where directional ablation via affine subspace projection\nalone produces incoherent outputs. Code for reproducing our results is\navailable at https://github.com/EleutherAI/steering-llama3 ."
    },
    {
      "id": "2411.09001v1",
      "title": "Virtual teaching assistant for undergraduate students using natural language processing & deep learning",
      "summary": "Online education's popularity has been continuously increasing over the past\nfew years. Many universities were forced to switch to online education as a\nresult of COVID-19. In many cases, even after more than two years of online\ninstruction, colleges were unable to resume their traditional classroom\nprograms. A growing number of institutions are considering blended learning\nwith some parts in-person and the rest of the learning taking place online.\nNevertheless, many online education systems are inefficient, and this results\nin a poor rate of student retention. In this paper, we are offering a primary\ndataset, the initial implementation of a virtual teaching assistant named\nVTA-bot, and its system architecture. Our primary implementation of the\nsuggested system consists of a chatbot that can be queried about the content\nand topics of the fundamental python programming language course. Students in\ntheir first year of university will be benefited from this strategy, which aims\nto increase student participation and involvement in online education."
    },
    {
      "id": "2411.08998v1",
      "title": "Microfoundation Inference for Strategic Prediction",
      "summary": "Often in prediction tasks, the predictive model itself can influence the\ndistribution of the target variable, a phenomenon termed performative\nprediction. Generally, this influence stems from strategic actions taken by\nstakeholders with a vested interest in predictive models. A key challenge that\nhinders the widespread adaptation of performative prediction in machine\nlearning is that practitioners are generally unaware of the social impacts of\ntheir predictions. To address this gap, we propose a methodology for learning\nthe distribution map that encapsulates the long-term impacts of predictive\nmodels on the population. Specifically, we model agents' responses as a\ncost-adjusted utility maximization problem and propose estimates for said cost.\nOur approach leverages optimal transport to align pre-model exposure (ex ante)\nand post-model exposure (ex post) distributions. We provide a rate of\nconvergence for this proposed estimate and assess its quality through empirical\ndemonstrations on a credit-scoring dataset."
    },
    {
      "id": "2411.08993v1",
      "title": "Parameter Inference via Differentiable Diffusion Bridge Importance Sampling",
      "summary": "We introduce a methodology for performing parameter inference in\nhigh-dimensional, non-linear diffusion processes. We illustrate its\napplicability for obtaining insights into the evolution of and relationships\nbetween species, including ancestral state reconstruction. Estimation is\nperformed by utilising score matching to approximate diffusion bridges, which\nare subsequently used in an importance sampler to estimate log-likelihoods. The\nentire setup is differentiable, allowing gradient ascent on approximated\nlog-likelihoods. This allows both parameter inference and diffusion mean\nestimation. This novel, numerically stable, score matching-based parameter\ninference framework is presented and demonstrated on biological two- and\nthree-dimensional morphometry data."
    },
    {
      "id": "2411.08992v1",
      "title": "IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis",
      "summary": "We present a new annotated microscopic cellular image dataset to improve the\neffectiveness of machine learning methods for cellular image analysis. Cell\ncounting is an important step in cell analysis. Typically, domain experts\nmanually count cells in a microscopic image. Automated cell counting can\npotentially eliminate this tedious, time-consuming process. However, a good,\nlabeled dataset is required for training an accurate machine learning model.\nOur dataset includes microscopic images of cells, and for each image, the cell\ncount and the location of individual cells. The data were collected as part of\nan ongoing study investigating the potential of electrical stimulation to\nmodulate stem cell differentiation and possible applications for neural repair.\nCompared to existing publicly available datasets, our dataset has more images\nof cells stained with more variety of antibodies (protein components of immune\nresponses against invaders) typically used for cell analysis. The experimental\nresults on this dataset indicate that none of the five existing models under\nthis study are able to achieve sufficiently accurate count to replace the\nmanual methods. The dataset is available at\nhttps://figshare.com/articles/dataset/Dataset/21970604."
    },
    {
      "id": "2411.08987v1",
      "title": "Non-Euclidean High-Order Smooth Convex Optimization",
      "summary": "We develop algorithms for the optimization of convex objectives that have\nH\\\"older continuous $q$-th derivatives with respect to a $p$-norm by using a\n$q$-th order oracle, for $p, q \\geq 1$. We can also optimize other structured\nfunctions. We do this by developing a non-Euclidean inexact accelerated\nproximal point method that makes use of an inexact uniformly convex\nregularizer. We also provide nearly matching lower bounds for any deterministic\nalgorithm that interacts with the function via a local oracle."
    },
    {
      "id": "2411.08982v1",
      "title": "Lynx: Enabling Efficient MoE Inference through Dynamic Batch-Aware Expert Selection",
      "summary": "Mixture-of-Experts (MoE) architectures have recently gained popularity in\nenabling efficient scaling of large language models. However, we uncover a\nfundamental tension: while MoEs are designed for selective expert activation,\nproduction serving requires request batching, which forces the activation of\nall experts and negates MoE's efficiency benefits during the decode phase. We\npresent Lynx, a system that enables efficient MoE inference through dynamic,\nbatch-aware expert selection. Our key insight is that expert importance varies\nsignificantly across tokens and inference phases, creating opportunities for\nruntime optimization. Lynx leverages this insight through a lightweight\nframework that dynamically reduces active experts while preserving model\naccuracy. Our evaluations show that Lynx achieves up to 1.55x reduction in\ninference latency while maintaining negligible accuracy loss from baseline\nmodel across complex code generation and mathematical reasoning tasks."
    },
    {
      "id": "2411.08981v1",
      "title": "Reliability, Resilience and Human Factors Engineering for Trustworthy AI Systems",
      "summary": "As AI systems become integral to critical operations across industries and\nservices, ensuring their reliability and safety is essential. We offer a\nframework that integrates established reliability and resilience engineering\nprinciples into AI systems. By applying traditional metrics such as failure\nrate and Mean Time Between Failures (MTBF) along with resilience engineering\nand human reliability analysis, we propose an integrate framework to manage AI\nsystem performance, and prevent or efficiently recover from failures. Our work\nadapts classical engineering methods to AI systems and outlines a research\nagenda for future technical studies. We apply our framework to a real-world AI\nsystem, using system status data from platforms such as openAI, to demonstrate\nits practical applicability. This framework aligns with emerging global\nstandards and regulatory frameworks, providing a methodology to enhance the\ntrustworthiness of AI systems. Our aim is to guide policy, regulation, and the\ndevelopment of reliable, safe, and adaptable AI technologies capable of\nconsistent performance in real-world environments."
    },
    {
      "id": "2411.08979v1",
      "title": "CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt",
      "summary": "Text classification is a fundamental task in natural language processing\n(NLP), and large language models (LLMs) have demonstrated their capability to\nperform this task across various domains. However, the performance of LLMs\nheavily depends on the quality of their input prompts. Recent studies have also\nshown that LLMs exhibit remarkable results in code-related tasks. To leverage\nthe capabilities of LLMs in text classification, we propose the Code Completion\nPrompt (CoCoP) method, which transforms the text classification problem into a\ncode completion task. CoCoP significantly improves text classification\nperformance across diverse datasets by utilizing LLMs' code-completion\ncapability. For instance, CoCoP enhances the accuracy of the SST2 dataset by\nmore than 20%. Moreover, when CoCoP integrated with LLMs specifically designed\nfor code-related tasks (code models), such as CodeLLaMA, this method\ndemonstrates better or comparable performance to few-shot learning techniques\nwhile using only one-tenth of the model size. The source code of our proposed\nmethod will be available to the public upon the acceptance of the paper."
    },
    {
      "id": "2411.08977v1",
      "title": "Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness",
      "summary": "Large language models (LLMs) are known to exhibit demographic biases, yet few\nstudies systematically evaluate these biases across multiple datasets or\naccount for confounding factors. In this work, we examine LLM alignment with\nhuman annotations in five offensive language datasets, comprising approximately\n220K annotations. Our findings reveal that while demographic traits,\nparticularly race, influence alignment, these effects are inconsistent across\ndatasets and often entangled with other factors. Confounders -- such as\ndocument difficulty, annotator sensitivity, and within-group agreement --\naccount for more variation in alignment patterns than demographic traits alone.\nSpecifically, alignment increases with higher annotator sensitivity and group\nagreement, while greater document difficulty corresponds to reduced alignment.\nOur results underscore the importance of multi-dataset analyses and\nconfounder-aware methodologies in developing robust measures of demographic\nbias in LLMs."
    },
    {
      "id": "2411.08975v1",
      "title": "Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion",
      "summary": "Though multiple instance learning (MIL) has been a foundational strategy in\ncomputational pathology for processing whole slide images (WSIs), current\napproaches are designed for traditional hematoxylin and eosin (H&E) slides\nrather than emerging multiplexed technologies. Here, we present an MIL\nstrategy, the Fluoroformer module, that is specifically tailored to multiplexed\nWSIs by leveraging scaled dot-product attention (SDPA) to interpretably fuse\ninformation across disparate channels. On a cohort of 434 non-small cell lung\ncancer (NSCLC) samples, we show that the Fluoroformer both obtains strong\nprognostic performance and recapitulates immuno-oncological hallmarks of NSCLC.\nOur technique thereby provides a path for adapting state-of-the-art AI\ntechniques to emerging spatial biology assays."
    },
    {
      "id": "2411.08968v1",
      "title": "Sparse Upcycling: Inference Inefficient Finetuning",
      "summary": "Small, highly trained, open-source large language models are widely used due\nto their inference efficiency, but further improving their quality remains a\nchallenge. Sparse upcycling is a promising approach that transforms a\npretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing\nthe model's parameter count and quality. In this work, we compare the\neffectiveness of sparse upcycling against continued pretraining (CPT) across\ndifferent model sizes, compute budgets, and pretraining durations. Our\nexperiments show that sparse upcycling can achieve better quality, with\nimprovements of over 20% relative to CPT in certain scenarios. However, this\ncomes with a significant inference cost, leading to 40% slowdowns in\nhigh-demand inference settings for larger models. Our findings highlight the\ntrade-off between model quality and inference efficiency, offering insights for\npractitioners seeking to balance model quality and deployment constraints."
    },
    {
      "id": "2411.08954v1",
      "title": "Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples",
      "summary": "Although diffusion models can generate remarkably high-quality samples, they\nare intrinsically bottlenecked by their expensive iterative sampling procedure.\nConsistency models (CMs) have recently emerged as a promising diffusion model\ndistillation method, reducing the cost of sampling by generating high-fidelity\nsamples in just a few iterations. Consistency model distillation aims to solve\nthe probability flow ordinary differential equation (ODE) defined by an\nexisting diffusion model. CMs are not directly trained to minimize error\nagainst an ODE solver, rather they use a more computationally tractable\nobjective. As a way to study how effectively CMs solve the probability flow\nODE, and the effect that any induced error has on the quality of generated\nsamples, we introduce Direct CMs, which \\textit{directly} minimize this error.\nIntriguingly, we find that Direct CMs reduce the ODE solving error compared to\nCMs but also result in significantly worse sample quality, calling into\nquestion why exactly CMs work well in the first place. Full code is available\nat: https://github.com/layer6ai-labs/direct-cms."
    },
    {
      "id": "2411.08879v1",
      "title": "4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization",
      "summary": "Novel view synthesis of dynamic scenes is becoming important in various\napplications, including augmented and virtual reality. We propose a novel 4D\nGaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded\nmonocular videos. To overcome the overfitting problem of existing work for\nthese real-world videos, we introduce an uncertainty-aware regularization that\nidentifies uncertain regions with few observations and selectively imposes\nadditional priors based on diffusion models and depth smoothness on such\nregions. This approach improves both the performance of novel view synthesis\nand the quality of training image reconstruction. We also identify the\ninitialization problem of 4DGS in fast-moving dynamic regions, where the\nStructure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.\nTo initialize Gaussian primitives in such regions, we present a dynamic region\ndensification method using the estimated depth maps and scene flow. Our\nexperiments show that the proposed method improves the performance of 4DGS\nreconstruction from a video captured by a handheld monocular camera and also\nexhibits promising results in few-shot static scene reconstruction."
    },
    {
      "id": "2411.08878v1",
      "title": "A Short Note on Evaluating RepNet for Temporal Repetition Counting in Videos",
      "summary": "We discuss some consistent issues on how RepNet has been evaluated in various\npapers. As a way to mitigate these issues, we report RepNet performance results\non different datasets, and release evaluation code and the RepNet checkpoint to\nobtain these results. Code URL:\nhttps://github.com/google-research/google-research/blob/master/repnet/"
    },
    {
      "id": "2411.08875v1",
      "title": "Causal Explanations for Image Classifiers",
      "summary": "Existing algorithms for explaining the output of image classifiers use\ndifferent definitions of explanations and a variety of techniques to extract\nthem. However, none of the existing tools use a principled approach based on\nformal definitions of causes and explanations for the explanation extraction.\nIn this paper we present a novel black-box approach to computing explanations\ngrounded in the theory of actual causality. We prove relevant theoretical\nresults and present an algorithm for computing approximate explanations based\non these definitions. We prove termination of our algorithm and discuss its\ncomplexity and the amount of approximation compared to the precise definition.\nWe implemented the framework in a tool rex and we present experimental results\nand a comparison with state-of-the-art tools. We demonstrate that rex is the\nmost efficient tool and produces the smallest explanations, in addition to\noutperforming other black-box tools on standard quality measures."
    },
    {
      "id": "2411.08870v1",
      "title": "The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models",
      "summary": "Several recent works seek to develop foundation models specifically for\nmedical applications, adapting general-purpose large language models (LLMs) and\nvision-language models (VLMs) via continued pretraining on publicly available\nbiomedical corpora. These works typically claim that such domain-adaptive\npretraining (DAPT) improves performance on downstream medical tasks, such as\nanswering medical licensing exam questions. In this paper, we compare ten\npublic \"medical\" LLMs and two VLMs against their corresponding base models,\narriving at a different conclusion: all medical VLMs and nearly all medical\nLLMs fail to consistently improve over their base models in the zero-/few-shot\nprompting and supervised fine-tuning regimes for medical question-answering\n(QA). For instance, across all tasks and model pairs we consider in the 3-shot\nsetting, medical LLMs only outperform their base models in 22.7% of cases,\nreach a (statistical) tie in 36.8% of cases, and are significantly worse than\ntheir base models in the remaining 40.5% of cases. Our conclusions are based on\n(i) comparing each medical model head-to-head, directly against the\ncorresponding base model; (ii) optimizing the prompts for each model separately\nin zero-/few-shot prompting; and (iii) accounting for statistical uncertainty\nin comparisons. While these basic practices are not consistently adopted in the\nliterature, our ablations show that they substantially impact conclusions.\nMeanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs\ncan show performance improvements, but the benefits do not carry over to tasks\nbased on clinical notes. Our findings suggest that state-of-the-art\ngeneral-domain models may already exhibit strong medical knowledge and\nreasoning capabilities, and offer recommendations to strengthen the conclusions\nof future studies."
    },
    {
      "id": "2411.08868v1",
      "title": "CamemBERT 2.0: A Smarter French Language Model Aged to Perfection",
      "summary": "French language models, such as CamemBERT, have been widely adopted across\nindustries for natural language processing (NLP) tasks, with models like\nCamemBERT seeing over 4 million downloads per month. However, these models face\nchallenges due to temporal concept drift, where outdated training data leads to\na decline in performance, especially when encountering new topics and\nterminology. This issue emphasizes the need for updated models that reflect\ncurrent linguistic trends. In this paper, we introduce two new versions of the\nCamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these\nchallenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use\nof the Replaced Token Detection (RTD) objective for better contextual\nunderstanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked\nLanguage Modeling (MLM) objective. Both models are trained on a significantly\nlarger and more recent dataset with longer context length and an updated\ntokenizer that enhances tokenization performance for French. We evaluate the\nperformance of these models on both general-domain NLP tasks and\ndomain-specific applications, such as medical field tasks, demonstrating their\nversatility and effectiveness across a range of use cases. Our results show\nthat these updated models vastly outperform their predecessors, making them\nvaluable tools for modern NLP systems. All our new models, as well as\nintermediate checkpoints, are made openly available on Huggingface."
    },
    {
      "id": "2411.08867v1",
      "title": "Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier Profiles",
      "summary": "In machine learning and data mining, outliers are data points that\nsignificantly differ from the dataset and often introduce irrelevant\ninformation that can induce bias in its statistics and models. Therefore,\nunsupervised methods are crucial to detect outliers if there is limited or no\ninformation about them. Global-Local Outlier Scores based on Hierarchies\n(GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a\nstate-of-the-art hierarchical clustering method. GLOSH estimates outlier scores\nfor each data point by comparing its density to the highest density of the\nregion they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to\nHDBSCAN*'s minpts parameter that influences density estimation. With limited\nknowledge about the data, choosing an appropriate minpts value beforehand is\nchallenging as one or some minpts values may better represent the underlying\ncluster structure than others. Additionally, in the process of searching for\n``potential outliers'', one has to define the number of outliers n a dataset\nhas, which may be impractical and is often unknown. In this paper, we propose\nan unsupervised strategy to find the ``best'' minpts value, leveraging the\nrange of GLOSH scores across minpts values to identify the value for which\nGLOSH scores can best identify outliers from the rest of the dataset. Moreover,\nwe propose an unsupervised strategy to estimate a threshold for classifying\npoints into inliers and (potential) outliers without the need to pre-define any\nvalue. Our experiments show that our strategies can automatically find the\nminpts value and threshold that yield the best or near best outlier detection\nresults using GLOSH."
    },
    {
      "id": "2411.08862v1",
      "title": "LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs",
      "summary": "We introduce LLMStinger, a novel approach that leverages Large Language\nModels (LLMs) to automatically generate adversarial suffixes for jailbreak\nattacks. Unlike traditional methods, which require complex prompt engineering\nor white-box access, LLMStinger uses a reinforcement learning (RL) loop to\nfine-tune an attacker LLM, generating new suffixes based on existing attacks\nfor harmful questions from the HarmBench benchmark. Our method significantly\noutperforms existing red-teaming approaches (we compared against 15 of the\nlatest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on\nLLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for\ntheir extensive safety measures. Additionally, we achieved a 94.97% ASR on\nGPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability\nof LLMStinger across open and closed-source models."
    },
    {
      "id": "2411.08861v1",
      "title": "Interaction Testing in Variation Analysis",
      "summary": "Relationships of cause and effect are of prime importance for explaining\nscientific phenomena. Often, rather than just understanding the effects of\ncauses, researchers also wish to understand how a cause $X$ affects an outcome\n$Y$ mechanistically -- i.e., what are the causal pathways that are activated\nbetween $X$ and $Y$. For analyzing such questions, a range of methods has been\ndeveloped over decades under the rubric of causal mediation analysis.\nTraditional mediation analysis focuses on decomposing the average treatment\neffect (ATE) into direct and indirect effects, and therefore focuses on the ATE\nas the central quantity. This corresponds to providing explanations for\nassociations in the interventional regime, such as when the treatment $X$ is\nrandomized. Commonly, however, it is of interest to explain associations in the\nobservational regime, and not just in the interventional regime. In this paper,\nwe introduce \\text{variation analysis}, an extension of mediation analysis that\nfocuses on the total variation (TV) measure between $X$ and $Y$, written as\n$\\mathrm{E}[Y \\mid X=x_1] - \\mathrm{E}[Y \\mid X=x_0]$. The TV measure\nencompasses both causal and confounded effects, as opposed to the ATE which\nonly encompasses causal (direct and mediated) variations. In this way, the TV\nmeasure is suitable for providing explanations in the natural regime and\nanswering questions such as ``why is $X$ associated with $Y$?''. Our focus is\non decomposing the TV measure, in a way that explicitly includes direct,\nindirect, and confounded variations. Furthermore, we also decompose the TV\nmeasure to include interaction terms between these different pathways.\nSubsequently, interaction testing is introduced, involving hypothesis tests to\ndetermine if interaction terms are significantly different from zero. If\ninteractions are not significant, more parsimonious decompositions of the TV\nmeasure can be used."
    },
    {
      "id": "2411.08849v1",
      "title": "Oblique Bayesian additive regression trees",
      "summary": "Current implementations of Bayesian Additive Regression Trees (BART) are\nbased on axis-aligned decision rules that recursively partition the feature\nspace using a single feature at a time. Several authors have demonstrated that\noblique trees, whose decision rules are based on linear combinations of\nfeatures, can sometimes yield better predictions than axis-aligned trees and\nexhibit excellent theoretical properties. We develop an oblique version of BART\nthat leverages a data-adaptive decision rule prior that recursively partitions\nthe feature space along random hyperplanes. Using several synthetic and\nreal-world benchmark datasets, we systematically compared our oblique BART\nimplementation to axis-aligned BART and other tree ensemble methods, finding\nthat oblique BART was competitive with -- and sometimes much better than --\nthose methods."
    },
    {
      "id": "2411.08843v1",
      "title": "Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale",
      "summary": "Accurate surface solar irradiance (SSI) forecasting is essential for\noptimizing renewable energy systems, particularly in the context of long-term\nenergy planning on a global scale. This paper presents a pioneering approach to\nsolar radiation forecasting that leverages recent advancements in numerical\nweather prediction (NWP) and data-driven machine learning weather models. These\nadvances facilitate long, stable rollouts and enable large ensemble forecasts,\nenhancing the reliability of predictions. Our flexible model utilizes variables\nforecast by these NWP and AI weather models to estimate 6-hourly SSI at global\nscale. Developed using NVIDIA Modulus, our model represents the first adaptive\nglobal framework capable of providing long-term SSI forecasts. Furthermore, it\ncan be fine-tuned using satellite data, which significantly enhances its\nperformance in the fine-tuned regions, while maintaining accuracy elsewhere.\nThe improved accuracy of these forecasts has substantial implications for the\nintegration of solar energy into power grids, enabling more efficient energy\nmanagement and contributing to the global transition to renewable energy\nsources."
    },
    {
      "id": "2411.08842v1",
      "title": "AstroM$^3$: A self-supervised multimodal model for astronomy",
      "summary": "While machine-learned models are now routinely employed to facilitate\nastronomical inquiry, model inputs tend to be limited to a primary data source\n(namely images or time series) and, in the more advanced approaches, some\nmetadata. Yet with the growing use of wide-field, multiplexed observational\nresources, individual sources of interest often have a broad range of\nobservational modes available. Here we construct an astronomical multimodal\ndataset and propose AstroM$^3$, a self-supervised pre-training approach that\nenables a model to learn from multiple modalities simultaneously. Specifically,\nwe extend the CLIP (Contrastive Language-Image Pretraining) model to a trimodal\nsetting, allowing the integration of time-series photometry data, spectra, and\nastrophysical metadata. In a fine-tuning supervised setting, our results\ndemonstrate that CLIP pre-training improves classification performance for\ntime-series photometry, where accuracy increases from 84.6% to 91.5%.\nFurthermore, CLIP boosts classification accuracy by up to 12.6% when the\navailability of labeled data is limited, showing the effectiveness of\nleveraging larger corpora of unlabeled data. In addition to fine-tuned\nclassification, we can use the trained model in other downstream tasks that are\nnot explicitly contemplated during the construction of the self-supervised\nmodel. In particular we show the efficacy of using the learned embeddings for\nmisclassifications identification, similarity search, and anomaly detection.\nOne surprising highlight is the \"rediscovery\" of Mira subtypes and two\nRotational variable subclasses using manifold learning and dimension reduction\nalgorithm. To our knowledge this is the first construction of an $n>2$ mode\nmodel in astronomy. Extensions to $n>3$ modes is naturally anticipated with\nthis approach."
    },
    {
      "id": "2411.08832v1",
      "title": "Offline Adaptation of Quadruped Locomotion using Diffusion Models",
      "summary": "We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform."
    },
    {
      "id": "2411.08821v1",
      "title": "Model agnostic local variable importance for locally dependent relationships",
      "summary": "Global variable importance measures are commonly used to interpret machine\nlearning model results. Local variable importance techniques assess how\nvariables contribute to individual observations rather than the entire dataset.\nCurrent methods typically fail to accurately reflect locally dependent\nrelationships between variables and instead focus on marginal importance\nvalues. Additionally, they are not natively adapted for multi-class\nclassification problems. We propose a new model-agnostic method for calculating\nlocal variable importance, CLIQUE, that captures locally dependent\nrelationships, contains improvements over permutation-based methods, and can be\ndirectly applied to multi-class classification problems. Simulated and\nreal-world examples show that CLIQUE emphasizes locally dependent information\nand properly reduces bias in regions where variables do not affect the\nresponse."
    },
    {
      "id": "2411.08814v1",
      "title": "Process-aware Human Activity Recognition",
      "summary": "Humans naturally follow distinct patterns when conducting their daily\nactivities, which are driven by established practices and processes, such as\nproduction workflows, social norms and daily routines. Human activity\nrecognition (HAR) algorithms usually use neural networks or machine learning\ntechniques to analyse inherent relationships within the data. However, these\napproaches often overlook the contextual information in which the data are\ngenerated, potentially limiting their effectiveness. We propose a novel\napproach that incorporates process information from context to enhance the HAR\nperformance. Specifically, we align probabilistic events generated by machine\nlearning models with process models derived from contextual information. This\nalignment adaptively weighs these two sources of information to optimise HAR\naccuracy. Our experiments demonstrate that our approach achieves better\naccuracy and Macro F1-score compared to baseline models."
    },
    {
      "id": "2411.08813v1",
      "title": "Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique",
      "summary": "A key development in the cybersecurity evaluations space is the work carried\nout by Meta, through their CyberSecEval approach. While this work is\nundoubtedly a useful contribution to a nascent field, there are notable\nfeatures that limit its utility. Key drawbacks focus on the insecure code\ndetection part of Meta's methodology. We explore these limitations, and use our\nexploration as a test case for LLM-assisted benchmark analysis."
    },
    {
      "id": "2411.08804v1",
      "title": "FinRobot: AI Agent for Equity Research and Valuation with Large Language Models",
      "summary": "As financial markets grow increasingly complex, there is a rising need for\nautomated tools that can effectively assist human analysts in equity research,\nparticularly within sell-side research. While Generative AI (GenAI) has\nattracted significant attention in this field, existing AI solutions often fall\nshort due to their narrow focus on technical factors and limited capacity for\ndiscretionary judgment. These limitations hinder their ability to adapt to new\ndata in real-time and accurately assess risks, which diminishes their practical\nvalue for investors.\n  This paper presents FinRobot, the first AI agent framework specifically\ndesigned for equity research. FinRobot employs a multi-agent Chain of Thought\n(CoT) system, integrating both quantitative and qualitative analyses to emulate\nthe comprehensive reasoning of a human analyst. The system is structured around\nthree specialized agents: the Data-CoT Agent, which aggregates diverse data\nsources for robust financial integration; the Concept-CoT Agent, which mimics\nan analysts reasoning to generate actionable insights; and the Thesis-CoT\nAgent, which synthesizes these insights into a coherent investment thesis and\nreport. FinRobot provides thorough company analysis supported by precise\nnumerical data, industry-appropriate valuation metrics, and realistic risk\nassessments. Its dynamically updatable data pipeline ensures that research\nremains timely and relevant, adapting seamlessly to new financial information.\nUnlike existing automated research tools, such as CapitalCube and Wright\nReports, FinRobot delivers insights comparable to those produced by major\nbrokerage firms and fundamental research vendors. We open-source FinRobot at\n\\url{https://github. com/AI4Finance-Foundation/FinRobot}."
    },
    {
      "id": "2411.08800v1",
      "title": "Deep Learning Accelerated Quantum Transport Simulations in Nanoelectronics: From Break Junctions to Field-Effect Transistors",
      "summary": "Quantum transport calculations are essential for understanding and designing\nnanoelectronic devices, yet the trade-off between accuracy and computational\nefficiency has long limited their practical applications. We present a general\nframework that combines the deep learning tight-binding Hamiltonian (DeePTB)\napproach with the non-equilibrium Green's Function (NEGF) method, enabling\nefficient quantum transport calculations while maintaining first-principles\naccuracy. We demonstrate the capabilities of the DeePTB-NEGF framework through\ntwo representative applications: comprehensive simulation of break junction\nsystems, where conductance histograms show good agreement with experimental\nmeasurements in both metallic contact and single-molecule junction cases; and\nsimulation of carbon nanotube field effect transistors through self-consistent\nNEGF-Poisson calculations, capturing essential physics including the\nelectrostatic potential and transfer characteristic curves under finite bias\nconditions. This framework bridges the gap between first-principles accuracy\nand computational efficiency, providing a powerful tool for high-throughput\nquantum transport simulations across different scales in nanoelectronics."
    },
    {
      "id": "2411.08798v1",
      "title": "Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity and Directional Convergence",
      "summary": "This work focuses on the gradient flow dynamics of a neural network model\nthat uses correlation loss to approximate a multi-index function on\nhigh-dimensional standard Gaussian data. Specifically, the multi-index function\nwe consider is a sum of neurons $f^*(x) \\!=\\! \\sum_{j=1}^k \\! \\sigma^*(v_j^T\nx)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first\nand second Hermite polynomials in its Hermite expansion. It is known that, for\nthe single-index case ($k\\!=\\!1$), overcoming the search phase requires\npolynomial time complexity. We first generalize this result to multi-index\nfunctions characterized by vectors in arbitrary directions. After the search\nphase, it is not clear whether the network neurons converge to the index\nvectors, or get stuck at a sub-optimal solution. When the index vectors are\northogonal, we give a complete characterization of the fixed points and prove\nthat neurons converge to the nearest index vectors. Therefore, using $n \\!\n\\asymp \\! k \\log k$ neurons ensures finding the full set of index vectors with\ngradient flow with high probability over random initialization. When $ v_i^T\nv_j \\!=\\! \\beta \\! \\geq \\! 0$ for all $i \\neq j$, we prove the existence of a\nsharp threshold $\\beta_c \\!=\\! c/(c+k)$ at which the fixed point that computes\nthe average of the index vectors transitions from a saddle point to a minimum.\nNumerical simulations show that using a correlation loss and a mild\noverparameterization suffices to learn all of the index vectors when they are\nnearly orthogonal, however, the correlation loss fails when the dot product\nbetween the index vectors exceeds a certain threshold."
    },
    {
      "id": "2411.08794v1",
      "title": "Evaluating World Models with LLM for Decision Making",
      "summary": "World model emerges as a key module in decision making, where MuZero and\nDreamer achieve remarkable successes in complex tasks. Recent work leverages\nLarge Language Models (LLMs) as general world simulators to simulate the\ndynamics of the world due to their generalizability. LLMs also serve as the\nworld model for deliberative reasoning in Reasoning via Planning (RAP) and Tree\nof Thought (ToT). However, the world models are either evaluated as a general\nworld simulator, or as a functional module of the agent, i.e., predicting the\ntransitions to assist the planning. In this work, we propose a comprehensive\nevaluation of the world models with LLMs from the decision making perspective.\nSpecifically, we leverage the 31 diverse environments from (Wang et al.,\n2023;2024) and curate the rule-based policy of each environment for the diverse\nevaluation. Then, we design three main tasks, i.e., policy verification, action\nproposal, and policy planning, where the world models can be used for decision\nmaking solely. Finally, we conduct the comprehensive evaluation of the advanced\nLLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main\ntasks under various settings. The key observations include: i) GPT-4o\nsignificantly outperforms GPT-4o-mini on the three main tasks, especially for\nthe tasks which require the domain knowledge, ii) the performance of the world\nmodel with LLM will be decreased for long-term decision-making tasks, and iii)\nthe combination of different functionalities of the world model will brings\nadditional unstabilities of the performance."
    },
    {
      "id": "2411.08791v1",
      "title": "Locally Private Sampling with Public Data",
      "summary": "Local differential privacy (LDP) is increasingly employed in\nprivacy-preserving machine learning to protect user data before sharing it with\nan untrusted aggregator. Most LDP methods assume that users possess only a\nsingle data record, which is a significant limitation since users often gather\nextensive datasets (e.g., images, text, time-series data) and frequently have\naccess to public datasets. To address this limitation, we propose a locally\nprivate sampling framework that leverages both the private and public datasets\nof each user. Specifically, we assume each user has two distributions: $p$ and\n$q$ that represent their private dataset and the public dataset, respectively.\nThe objective is to design a mechanism that generates a private sample\napproximating $p$ while simultaneously preserving $q$. We frame this objective\nas a minimax optimization problem using $f$-divergence as the utility measure.\nWe fully characterize the minimax optimal mechanisms for general\n$f$-divergences provided that $p$ and $q$ are discrete distributions.\nRemarkably, we demonstrate that this optimal mechanism is universal across all\n$f$-divergences. Experiments validate the effectiveness of our minimax optimal\nsampler compared to the state-of-the-art locally private sampler."
    },
    {
      "id": "2411.08790v1",
      "title": "Can sparse autoencoders be used to decompose and interpret steering vectors?",
      "summary": "Steering vectors are a promising approach to control the behaviour of large\nlanguage models. However, their underlying mechanisms remain poorly understood.\nWhile sparse autoencoders (SAEs) may offer a potential method to interpret\nsteering vectors, recent findings show that SAE-reconstructed vectors often\nlack the steering properties of the original vectors. This paper investigates\nwhy directly applying SAEs to steering vectors yields misleading\ndecompositions, identifying two reasons: (1) steering vectors fall outside the\ninput distribution for which SAEs are designed, and (2) steering vectors can\nhave meaningful negative projections in feature directions, which SAEs are not\ndesigned to accommodate. These limitations hinder the direct use of SAEs for\ninterpreting steering vectors."
    },
    {
      "id": "2411.08785v1",
      "title": "Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training",
      "summary": "The majority of previous researches addressing multi-lingual IE are limited\nto zero-shot cross-lingual single-transfer (one-to-one) setting, with\nhigh-resource languages predominantly as source training data. As a result,\nthese works provide little understanding and benefit for the realistic goal of\ndeveloping a multi-lingual IE system that can generalize to as many languages\nas possible. Our study aims to fill this gap by providing a detailed analysis\non Cross-Lingual Multi-Transferability (many-to-many transfer learning), for\nthe recent IE corpora that cover a diverse set of languages. Specifically, we\nfirst determine the correlation between single-transfer performance and a wide\nrange of linguistic-based distances. From the obtained insights, a combined\nlanguage distance metric can be developed that is not only highly correlated\nbut also robust across different tasks and model scales. Next, we investigate\nthe more general zero-shot multi-lingual transfer settings where multiple\nlanguages are involved in the training and evaluation processes. Language\nclustering based on the newly defined distance can provide directions for\nachieving the optimal cost-performance trade-off in data (languages) selection\nproblem. Finally, a relational-transfer setting is proposed to further\nincorporate multi-lingual unlabeled data based on adversarial training using\nthe relation induced from the above linguistic distance."
    },
    {
      "id": "2411.08773v1",
      "title": "Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity",
      "summary": "An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such\nthat, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves\nthe norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor. In\nthis work, we give an oblivious subspace embedding with the optimal dimension\n$m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde\nO(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result\nto nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the\nbest sparsity attainable by an optimal oblivious subspace embedding, improving\non a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et\nal., STOC 2024]. We further extend our approach to the non-oblivious setting,\nproposing a new family of Leverage Score Sparsified embeddings with Independent\nColumns, which yield faster runtimes for matrix approximation and regression\ntasks.\n  In our analysis, we develop a new method which uses a decoupling argument\ntogether with the cumulant method for bounding the edge universality error of\nisotropic random matrices. To achieve near-optimal sparsity, we combine this\ngeneral-purpose approach with new traces inequalities that leverage the\nspecific structure of our subspace embedding construction."
    },
    {
      "id": "2411.08768v1",
      "title": "Sharingan: Extract User Action Sequence from Desktop Recordings",
      "summary": "Video recordings of user activities, particularly desktop recordings, offer a\nrich source of data for understanding user behaviors and automating processes.\nHowever, despite advancements in Vision-Language Models (VLMs) and their\nincreasing use in video analysis, extracting user actions from desktop\nrecordings remains an underexplored area. This paper addresses this gap by\nproposing two novel VLM-based methods for user action extraction: the Direct\nFrame-Based Approach (DF), which inputs sampled frames directly into VLMs, and\nthe Differential Frame-Based Approach (DiffF), which incorporates explicit\nframe differences detected via computer vision techniques. We evaluate these\nmethods using a basic self-curated dataset and an advanced benchmark adapted\nfrom prior work. Our results show that the DF approach achieves an accuracy of\n70% to 80% in identifying user actions, with the extracted action sequences\nbeing re-playable though Robotic Process Automation. We find that while VLMs\nshow potential, incorporating explicit UI changes can degrade performance,\nmaking the DF approach more reliable. This work represents the first\napplication of VLMs for extracting user action sequences from desktop\nrecordings, contributing new methods, benchmarks, and insights for future\nresearch."
    },
    {
      "id": "2411.08767v1",
      "title": "SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate",
      "summary": "Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional\n(3D) wireless channel modeling, driven by advances in graphical rendering.\nCurrent approaches struggle to accurately model beyond 5G (B5G) network\nsignaling, which often operates at higher frequencies and is more susceptible\nto environmental conditions and changes. Existing online learning solutions\nrequire real-time environmental supervision during training, which is both\ncostly and incompatible with GPU-based processing. In response, we propose a\nnovel approach that redefines ray trajectory generation as a sequential\ndecision-making problem, leveraging generative models to jointly learn the\noptical, physical, and signal properties within each designated environment.\nOur work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing\nHierarchy (SANDWICH), an innovative offline, fully differentiable approach that\ncan be trained entirely on GPUs. SANDWICH offers superior performance compared\nto existing online learning methods, outperforms the baseline by 4e^-2 radian\nin RT accuracy, and only fades 0.5 dB away from toplined channel gain\nestimation."
    },
    {
      "id": "2411.08766v1",
      "title": "Mapping Methane -- The Impact of Dairy Farm Practices on Emissions Through Satellite Data and Machine Learning",
      "summary": "This study investigates the correlation between dairy farm characteristics\nand methane concentrations as derived from satellite observations in Eastern\nCanada. Utilizing data from 11 dairy farms collected between January 2020 and\nDecember 2022, we integrated Sentinel-5P satellite methane data with critical\nfarm-level attributes, including herd genetics, feeding practices, and\nmanagement strategies. Initial analyses revealed significant correlations with\nmethane concentrations, leading to the application of Variance Inflation Factor\n(VIF) and Principal Component Analysis (PCA) to address multicollinearity and\nenhance model stability. Subsequently, machine learning models - specifically\nRandom Forest and Neural Networks - were employed to evaluate feature\nimportance and predict methane emissions. Our findings indicate a strong\nnegative correlation between the Estimated Breeding Value (EBV) for protein\npercentage and methane concentrations, suggesting that genetic selection for\nhigher milk protein content could be an effective strategy for emissions\nreduction. The integration of atmospheric transport models with satellite data\nfurther refined our emission estimates, significantly enhancing accuracy and\nspatial resolution. This research underscores the potential of advanced\nsatellite monitoring, machine learning techniques, and atmospheric modeling in\nimproving methane emission assessments within the dairy sector. It emphasizes\nthe critical role of farm-specific characteristics in developing effective\nmitigation strategies. Future investigations should focus on expanding the\ndataset and incorporating inversion modeling for more precise emission\nquantification. Balancing ecological impacts with economic viability will be\nessential for fostering sustainable dairy farming practices."
    },
    {
      "id": "2411.08764v1",
      "title": "Flow reconstruction in time-varying geometries using graph neural networks",
      "summary": "The paper presents a Graph Attention Convolutional Network (GACN) for flow\nreconstruction from very sparse data in time-varying geometries. The model\nincorporates a feature propagation algorithm as a preprocessing step to handle\nextremely sparse inputs, leveraging information from neighboring nodes to\ninitialize missing features. In addition, a binary indicator is introduced as a\nvalidity mask to distinguish between the original and propagated data points,\nenabling more effective learning from sparse inputs. Trained on a unique data\nset of Direct Numerical Simulations (DNS) of a motored engine at a technically\nrelevant operating condition, the GACN shows robust performance across\ndifferent resolutions and domain sizes and can effectively handle unstructured\ndata and variable input sizes. The model is tested on previously unseen DNS\ndata as well as on an experimental data set from Particle Image Velocimetry\n(PIV) measurements that were not considered during training. A comparative\nanalysis shows that the GACN consistently outperforms both a conventional\nConvolutional Neural Network (CNN) and cubic interpolation methods on the DNS\nand PIV test sets by achieving lower reconstruction errors and better capturing\nfine-scale turbulent structures. In particular, the GACN effectively\nreconstructs flow fields from domains up to 14 times larger than those observed\nduring training, with the performance advantage increasing for larger domains."
    },
    {
      "id": "2411.08760v1",
      "title": "Energy Dissipation Preserving Physics Informed Neural Network for Allen-Cahn Equations",
      "summary": "This paper investigates a numerical solution of Allen-Cahn equation with\nconstant and degenerate mobility, with polynomial and logarithmic energy\nfunctionals, with deterministic and random initial functions, and with\nadvective term in one, two, and three spatial dimensions, based on the\nphysics-informed neural network (PINN). To improve the learning capacity of the\nPINN, we incorporate the energy dissipation property of the Allen-Cahn equation\nas a penalty term into the loss function of the network. To facilitate the\nlearning process of random initials, we employ a continuous analogue of the\ninitial random condition by utilizing the Fourier series expansion. Adaptive\nmethods from traditional numerical analysis are also integrated to enhance the\neffectiveness of the proposed PINN. Numerical results indicate a consistent\ndecrease in the discrete energy, while also revealing phenomena such as phase\nseparation and metastability."
    },
    {
      "id": "2411.08758v1",
      "title": "ScaleNet: Scale Invariance Learning in Directed Graphs",
      "summary": "Graph Neural Networks (GNNs) have advanced relational data analysis but lack\ninvariance learning techniques common in image classification. In node\nclassification with GNNs, it is actually the ego-graph of the center node that\nis classified. This research extends the scale invariance concept to node\nclassification by drawing an analogy to image processing: just as scale\ninvariance being used in image classification to capture multi-scale features,\nwe propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalize\ntraditional ego-graphs by replacing undirected single-edges with\n``scaled-edges'', which are ordered sequences of multiple directed edges. We\nempirically assess the performance of the proposed scale invariance in graphs\non seven benchmark datasets, across both homophilic and heterophilic\nstructures. Our scale-invariance-based graph learning outperforms inception\nmodels derived from random walks by being simpler, faster, and more accurate.\nThe scale invariance explains inception models' success on homophilic graphs\nand limitations on heterophilic graphs. To ensure applicability of inception\nmodel to heterophilic graphs as well, we further present ScaleNet, an\narchitecture that leverages multi-scaled features. ScaleNet achieves\nstate-of-the-art results on five out of seven datasets (four homophilic and one\nheterophilic) and matches top performance on the remaining two, demonstrating\nits excellent applicability. This represents a significant advance in graph\nlearning, offering a unified framework that enhances node classification across\nvarious graph types. Our code is available at\nhttps://github.com/Qin87/ScaleNet/tree/July25."
    },
    {
      "id": "2411.08755v1",
      "title": "Weakly-Supervised Anomaly Detection in Surveillance Videos Based on Two-Stream I3D Convolution Network",
      "summary": "The widespread implementation of urban surveillance systems has necessitated\nmore sophisticated techniques for anomaly detection to ensure enhanced public\nsafety. This paper presents a significant advancement in the field of anomaly\ndetection through the application of Two-Stream Inflated 3D (I3D) Convolutional\nNetworks. These networks substantially outperform traditional 3D Convolutional\nNetworks (C3D) by more effectively extracting spatial and temporal features\nfrom surveillance videos, thus improving the precision of anomaly detection.\nOur research advances the field by implementing a weakly supervised learning\nframework based on Multiple Instance Learning (MIL), which uniquely\nconceptualizes surveillance videos as collections of 'bags' that contain\ninstances (video clips). Each instance is innovatively processed through a\nranking mechanism that prioritizes clips based on their potential to display\nanomalies. This novel strategy not only enhances the accuracy and precision of\nanomaly detection but also significantly diminishes the dependency on extensive\nmanual annotations. Moreover, through meticulous optimization of model\nsettings, including the choice of optimizer, our approach not only establishes\nnew benchmarks in the performance of anomaly detection systems but also offers\na scalable and efficient solution for real-world surveillance applications.\nThis paper contributes significantly to the field of computer vision by\ndelivering a more adaptable, efficient, and context-aware anomaly detection\nsystem, which is poised to redefine practices in urban surveillance."
    },
    {
      "id": "2411.08752v1",
      "title": "Multi-Perspective Stance Detection",
      "summary": "Subjective NLP tasks usually rely on human annotations provided by multiple\nannotators, whose judgments may vary due to their diverse backgrounds and life\nexperiences. Traditional methods often aggregate multiple annotations into a\nsingle ground truth, disregarding the diversity in perspectives that arises\nfrom annotator disagreement. In this preliminary study, we examine the effect\nof including multiple annotations on model accuracy in classification. Our\nmethodology investigates the performance of perspective-aware classification\nmodels in stance detection task and further inspects if annotator disagreement\naffects the model confidence. The results show that multi-perspective approach\nyields better classification performance outperforming the baseline which uses\nthe single label. This entails that designing more inclusive perspective-aware\nAI models is not only an essential first step in implementing responsible and\nethical AI, but it can also achieve superior results than using the traditional\napproaches."
    },
    {
      "id": "2411.08750v1",
      "title": "Optimal Transport-Based Displacement Interpolation with Data Augmentation for Reduced Order Modeling of Nonlinear Dynamical Systems",
      "summary": "We present a novel reduced-order Model (ROM) that leverages optimal transport\n(OT) theory and displacement interpolation to enhance the representation of\nnonlinear dynamics in complex systems. While traditional ROM techniques face\nchallenges in this scenario, especially when data (i.e., observational\nsnapshots) is limited, our method addresses these issues by introducing a data\naugmentation strategy based on OT principles. The proposed framework generates\ninterpolated solutions tracing geodesic paths in the space of probability\ndistributions, enriching the training dataset for the ROM. A key feature of our\napproach is its ability to provide a continuous representation of the\nsolution's dynamics by exploiting a virtual-to-real time mapping. This enables\nthe reconstruction of solutions at finer temporal scales than those provided by\nthe original data. To further improve prediction accuracy, we employ Gaussian\nProcess Regression to learn the residual and correct the representation between\nthe interpolated snapshots and the physical solution. We demonstrate the\neffectiveness of our methodology with atmospheric mesoscale benchmarks\ncharacterized by highly nonlinear, advection-dominated dynamics. Our results\nshow improved accuracy and efficiency in predicting complex system behaviors,\nindicating the potential of this approach for a wide range of applications in\ncomputational physics and engineering."
    },
    {
      "id": "2411.08745v1",
      "title": "Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers",
      "summary": "A central question in multilingual language modeling is whether large\nlanguage models (LLMs) develop a universal concept representation, disentangled\nfrom specific languages. In this paper, we address this question by analyzing\nlatent representations (latents) during a word translation task in\ntransformer-based LLMs. We strategically extract latents from a source\ntranslation prompt and insert them into the forward pass on a target\ntranslation prompt. By doing so, we find that the output language is encoded in\nthe latent at an earlier layer than the concept to be translated. Building on\nthis insight, we conduct two key experiments. First, we demonstrate that we can\nchange the concept without changing the language and vice versa through\nactivation patching alone. Second, we show that patching with the mean over\nlatents across different languages does not impair and instead improves the\nmodels' performance in translating the concept. Our results provide evidence\nfor the existence of language-agnostic concept representations within the\ninvestigated models."
    },
    {
      "id": "2411.08742v1",
      "title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models",
      "summary": "With the rise of Speech Large Language Models (Speech LLMs), there has been\ngrowing interest in discrete speech tokens for their ability to integrate with\ntext-based tokens seamlessly. Compared to most studies that focus on continuous\nspeech features, although discrete-token based LLMs have shown promising\nresults on certain tasks, the performance gap between these two paradigms is\nrarely explored. In this paper, we present a fair and thorough comparison\nbetween discrete and continuous features across a variety of semantic-related\ntasks using a light-weight LLM (Qwen1.5-0.5B). Our findings reveal that\ncontinuous features generally outperform discrete tokens, particularly in tasks\nrequiring fine-grained semantic understanding. Moreover, this study goes beyond\nsurface-level comparison by identifying key factors behind the\nunder-performance of discrete tokens, such as limited token granularity and\ninefficient information retention. To enhance the performance of discrete\ntokens, we explore potential aspects based on our analysis. We hope our results\ncan offer new insights into the opportunities for advancing discrete speech\ntokens in Speech LLMs."
    },
    {
      "id": "2411.08739v1",
      "title": "Bayesian Comparisons Between Representations",
      "summary": "Which neural networks are similar is a fundamental question for both machine\nlearning and neuroscience. Our novel method compares representations based on\nBayesian statistics about linear readouts from the representations. Concretely,\nwe suggest to use the total variation distance or Jensen-Shannon distance\nbetween prior predictive distributions to compare representations. The prior\npredictive distribution is a full description of the inductive bias and\ngeneralization of a model in Bayesian statistics, making it a great basis for\ncomparisons. As Jensen-Shannon distance and total variation distance are\nmetrics our dissimilarity measures are pseudo-metrics for representations. For\na linear readout, our metrics just depend on the linear kernel matrix of the\nrepresentations. Thus, our metrics connects linear read-out based comparisons\nto kernel based metrics like centered kernel alignment and representational\nsimilarity analysis. We apply our new metrics to deep neural networks trained\non ImageNet-1k. Our new metrics can be computed efficiently including a\nstochastic gradient without dimensionality reductions of the representations.\nIt broadly agrees with existing metrics, but is more stringent. It varies less\nacross different random image samples, and it measures how well two\nrepresentations could be distinguished based on a linear read out. Thus our\nmetric nicely extends our toolkit for comparing representations."
    },
    {
      "id": "2411.08734v1",
      "title": "Recommender systems and reinforcement learning for building control and occupant interaction: A text-mining driven review of scientific literature",
      "summary": "The indoor environment greatly affects health and well-being; enhancing\nhealth and reducing energy use in these settings is a key research focus. With\nadvancing Information and Communication Technology (ICT), recommendation\nsystems and reinforcement learning have emerged as promising methods to induce\nbehavioral changes that improve indoor environments and building energy\nefficiency. This study employs text-mining and Natural Language Processing\n(NLP) to examine these approaches in building control and occupant interaction.\nAnalyzing approximately 27,000 articles from the ScienceDirect database, we\nfound extensive use of recommendation systems and reinforcement learning for\nspace optimization, location recommendations, and personalized control\nsuggestions. Despite broad applications, their use in optimizing indoor\nenvironments and energy efficiency is limited. Traditional recommendation\nalgorithms are commonly used, but optimizing indoor conditions and energy\nefficiency often requires advanced machine learning techniques like\nreinforcement and deep learning. This review highlights the potential for\nexpanding recommender systems and reinforcement learning applications in\nbuildings and indoor environments. Areas for innovation include predictive\nmaintenance, building-related product recommendations, and optimizing\nenvironments for specific needs like sleep and productivity enhancements based\non user feedback."
    },
    {
      "id": "2411.08733v2",
      "title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models",
      "summary": "Aligning Large Language Models (LLMs) traditionally relies on costly training\nand human preference annotations. Self-alignment seeks to reduce these expenses\nby enabling models to align themselves. To further lower costs and achieve\nalignment without any expensive tuning or annotations, we introduce a new\ntuning-free approach for self-alignment, Dynamic Rewarding with Prompt\nOptimization (DRPO). Our approach leverages a search-based optimization\nframework that allows LLMs to iteratively self-improve and craft the optimal\nalignment instructions, all without additional training or human intervention.\nThe core of DRPO is a dynamic rewarding mechanism, which identifies and\nrectifies model-specific alignment weaknesses, allowing LLMs to adapt\nefficiently to diverse alignment challenges. Empirical evaluations on eight\nrecent LLMs, both open- and closed-sourced, demonstrate that DRPO significantly\nenhances alignment performance, with base models outperforming their\nSFT/RLHF-tuned counterparts. Moreover, the prompts automatically optimized by\nDRPO surpass those curated by human experts, further validating the\neffectiveness of our approach. Our findings highlight the great potential of\ncurrent LLMs to achieve adaptive self-alignment through inference-time\noptimization, complementing tuning-based alignment methods."
    },
    {
      "id": "2411.08728v1",
      "title": "Polymetis:Large Language Modeling for Multiple Material Domains",
      "summary": "As the application of large language models in various fields continues to\nexpand, materials science also ushers in opportunities for AI-driven\ninnovation. The traditional way of relying on manual search for materials\nscience-related information is now using artificial intelligence technology as\nan auxiliary tool to improve the efficiency of materials science research. To\naccelerate researchers' knowledge acquisition and intelligent decision-making\nsupport in materials science research, this paper proposes a large language\nmodel Polymetis model for a variety of materials fields, aiming to provide\nhighly professional knowledge answers in the field of materials, covering\nenergy materials, functional materials, alloy materials, physical chemistry,\nbiology, and other material directions. The model uses a dataset of about 2\nmillion material knowledge instructions, and in the process of building the\ndataset, we developed the Intelligent Extraction Large Model (IELM), which is\nspecially used to extract and form structured knowledge from scientific texts,\navoiding a large number of costs that need to be manually annotated, and\nimproving efficiency. We inject this data into the GLM4-9B model for learning\nto enhance its inference capabilities in a variety of material domains. In\naddition, we have introduced enhanced prompt strategies to ensure that the\nanswers to the model are more organized and comprehensive, providing efficient\nand comprehensive intelligent support for the diverse needs of materials\nscience exploration, and promoting the development of material science."
    },
    {
      "id": "2411.08726v1",
      "title": "Analyst Reports and Stock Performance: Evidence from the Chinese Market",
      "summary": "This article applies natural language processing (NLP) to extract and\nquantify textual information to predict stock performance. Using an extensive\ndataset of Chinese analyst reports and employing a customized BERT deep\nlearning model for Chinese text, this study categorizes the sentiment of the\nreports as positive, neutral, or negative. The findings underscore the\npredictive capacity of this sentiment indicator for stock volatility, excess\nreturns, and trading volume. Specifically, analyst reports with strong positive\nsentiment will increase excess return and intraday volatility, and vice versa,\nreports with strong negative sentiment also increase volatility and trading\nvolume, but decrease future excess return. The magnitude of this effect is\ngreater for positive sentiment reports than for negative sentiment reports.\nThis article contributes to the empirical literature on sentiment analysis and\nthe response of the stock market to news in the Chinese stock market."
    },
    {
      "id": "2411.08708v1",
      "title": "Are Triggers Needed for Document-Level Event Extraction?",
      "summary": "Most existing work on event extraction has focused on sentence-level texts\nand presumes the identification of a trigger-span -- a word or phrase in the\ninput that evokes the occurrence of an event of interest. Event arguments are\nthen extracted with respect to the trigger. Indeed, triggers are treated as\nintegral to, and trigger detection as an essential component of, event\nextraction. In this paper, we provide the first investigation of the role of\ntriggers for the more difficult and much less studied task of document-level\nevent extraction. We analyze their usefulness in multiple end-to-end and\npipelined neural event extraction models for three document-level event\nextraction datasets, measuring performance using triggers of varying quality\n(human-annotated, LLM-generated, keyword-based, and random). Our research shows\nthat trigger effectiveness varies based on the extraction task's\ncharacteristics and data quality, with basic, automatically-generated triggers\nserving as a viable alternative to human-annotated ones. Furthermore, providing\ndetailed event descriptions to the extraction model helps maintain robust\nperformance even when trigger quality degrades. Perhaps surprisingly, we also\nfind that the mere existence of trigger input, even random ones, is important\nfor prompt-based LLM approaches to the task."
    },
    {
      "id": "2411.08706v1",
      "title": "Searching Latent Program Spaces",
      "summary": "Program synthesis methods aim to automatically generate programs restricted\nto a language that can explain a given specification of input-output pairs.\nWhile purely symbolic approaches suffer from a combinatorial search space,\nrecent methods leverage neural networks to learn distributions over program\nstructures to narrow this search space significantly, enabling more efficient\nsearch. However, for challenging problems, it remains difficult to train models\nto perform program synthesis in one shot, making test-time search essential.\nMost neural methods lack structured search mechanisms during inference, relying\ninstead on stochastic sampling or gradient updates, which can be inefficient.\nIn this work, we propose the Latent Program Network (LPN), a general algorithm\nfor program induction that learns a distribution over latent programs in a\ncontinuous space, enabling efficient search and test-time adaptation. We\nexplore how to train these networks to optimize for test-time computation and\ndemonstrate the use of gradient-based search both during training and at test\ntime. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates\nperformance by generalizing programs to new inputs rather than explaining the\nunderlying specification. We show that LPN can generalize beyond its training\ndistribution and adapt to unseen tasks by utilizing test-time computation,\noutperforming algorithms without test-time adaptation mechanisms."
    },
    {
      "id": "2411.08703v1",
      "title": "MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification",
      "summary": "The distinct characteristics of multiomics data, including complex\ninteractions within and across biological layers and disease heterogeneity\n(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop\nnovel designs to address unique challenges in multiomics prediction. In this\npaper, we propose the multi-view knowledge transfer learning (MVKTrans)\nframework, which transfers intra- and inter-omics knowledge in an adaptive\nmanner by reviewing data heterogeneity and suppressing bias transfer, thereby\nenhancing classification performance. Specifically, we design a graph\ncontrastive module that is trained on unlabeled data to effectively learn and\ntransfer the underlying intra-omics patterns to the supervised task. This\nunsupervised pretraining promotes learning general and unbiased representations\nfor each modality, regardless of the downstream tasks. In light of the varying\ndiscriminative capacities of modalities across different diseases and/or\nsamples, we introduce an adaptive and bi-directional cross-omics distillation\nmodule. This module automatically identifies richer modalities and facilitates\ndynamic knowledge transfer from more informative to less informative omics,\nthereby enabling a more robust and generalized integration. Extensive\nexperiments on four real biomedical datasets demonstrate the superior\nperformance and robustness of MVKTrans compared to the state-of-the-art. Code\nand data are available at https://github.com/Yaolab-fantastic/MVKTrans."
    },
    {
      "id": "2411.08701v1",
      "title": "TRACE: Transformer-based Risk Assessment for Clinical Evaluation",
      "summary": "We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),\na novel method for clinical risk assessment based on clinical data, leveraging\nthe self-attention mechanism for enhanced feature interaction and result\ninterpretation. Our approach is able to handle different data modalities,\nincluding continuous, categorical and multiple-choice (checkbox) attributes.\nThe proposed architecture features a shared representation of the clinical data\nobtained by integrating specialized embeddings of each data modality, enabling\nthe detection of high-risk individuals using Transformer encoder layers. To\nassess the effectiveness of the proposed method, a strong baseline based on\nnon-negative multi-layer perceptrons (MLPs) is introduced. The proposed method\noutperforms various baselines widely used in the domain of clinical risk\nassessment, while effectively handling missing values. In terms of\nexplainability, our Transformer-based method offers easily interpretable\nresults via attention weights, further enhancing the clinicians'\ndecision-making process."
    },
    {
      "id": "2411.08700v1",
      "title": "Rethinking negative sampling in content-based news recommendation",
      "summary": "News recommender systems are hindered by the brief lifespan of articles, as\nthey undergo rapid relevance decay. Recent studies have demonstrated the\npotential of content-based neural techniques in tackling this problem. However,\nthese models often involve complex neural architectures and often lack\nconsideration for negative examples. In this study, we posit that the careful\nsampling of negative examples has a big impact on the model's outcome. We\ndevise a negative sampling technique that not only improves the accuracy of the\nmodel but also facilitates the decentralization of the recommendation system.\nThe experimental results obtained using the MIND dataset demonstrate that the\naccuracy of the method under consideration can compete with that of\nState-of-the-Art models. The utilization of the sampling technique is essential\nin reducing model complexity and accelerating the training process, while\nmaintaining a high level of accuracy. Finally, we discuss how decentralized\nmodels can help improve privacy and scalability."
    },
    {
      "id": "2411.08699v1",
      "title": "FedSub: Introducing class-aware Subnetworks Fusion to Enhance Personalized Federated Learning in Ubiquitous Systems",
      "summary": "Personalized Federated Learning is essential in AI-driven ubiquitous systems,\nsupporting the distributed development of models able to adapt to diverse and\nevolving user behaviors while safeguarding privacy. Despite addressing\nheterogeneous user data distributions in collaborative model training, existing\nmethods often face limitations balancing personalization and generalization,\noversimplifying user similarities, or relying heavily on global models. In this\npaper, we propose FedSub, a novel federated approach designed to enhance\npersonalization through the use of class-aware prototypes and model\nsubnetworks. Prototypes serve as compact representations of user data,\nclustered on the server to identify similarities based on specific label\npatterns. Concurrently, subnetworks -- model components necessary to process\neach class -- are extracted locally and fused by the server according to these\nclusters, producing highly tailored model updates for each user. This\nfine-grained, class-specific aggregation of clients' models allows FedSub to\ncapture the unique characteristics of individual user data patterns. The\neffectiveness of FedSub is validated in three real-world scenarios\ncharacterized by high data heterogeneity, derived from human activity\nrecognition and mobile health applications. Experimental evaluations\ndemonstrate FedSub's performance improvements with respect to the\nstate-of-the-art and significant advancements in personalization for ubiquitous\nsystems based on personal mobile and wearable devices."
    },
    {
      "id": "2411.08696v1",
      "title": "Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs",
      "summary": "Several initiatives have been undertaken to conceptually model the domain of\nscholarly data using ontologies and to create respective Knowledge Graphs. Yet,\nthe full potential seems unleashed, as automated means for automatic population\nof said ontologies are lacking, and respective initiatives from the Semantic\nWeb community are not necessarily connected: we propose to make scholarly data\nmore sustainably accessible by leveraging Wikidata's infrastructure and\nautomating its population in a sustainable manner through LLMs by tapping into\nunstructured sources like conference Web sites and proceedings texts as well as\nalready existing structured conference datasets. While an initial analysis\nshows that Semantic Web conferences are only minimally represented in Wikidata,\nwe argue that our methodology can help to populate, evolve and maintain\nscholarly data as a community within Wikidata. Our main contributions include\n(a) an analysis of ontologies for representing scholarly data to identify gaps\nand relevant entities/properties in Wikidata, (b) semi-automated extraction --\nrequiring (minimal) manual validation -- of conference metadata (e.g.,\nacceptance rates, organizer roles, programme committee members, best paper\nawards, keynotes, and sponsors) from websites and proceedings texts using LLMs.\nFinally, we discuss (c) extensions to visualization tools in the Wikidata\ncontext for data exploration of the generated scholarly data. Our study focuses\non data from 105 Semantic Web-related conferences and extends/adds more than\n6000 entities in Wikidata. It is important to note that the method can be more\ngenerally applicable beyond Semantic Web-related conferences for enhancing\nWikidata's utility as a comprehensive scholarly resource.\n  Source Repository: https://github.com/scholarly-wikidata/\n  DOI: https://doi.org/10.5281/zenodo.10989709\n  License: Creative Commons CC0 (Data), MIT (Code)"
    },
    {
      "id": "2411.08687v1",
      "title": "Measuring similarity between embedding spaces using induced neighborhood graphs",
      "summary": "Deep Learning techniques have excelled at generating embedding spaces that\ncapture semantic similarities between items. Often these representations are\npaired, enabling experiments with analogies (pairs within the same domain) and\ncross-modality (pairs across domains). These experiments are based on specific\nassumptions about the geometry of embedding spaces, which allow finding paired\nitems by extrapolating the positional relationships between embedding pairs in\nthe training dataset, allowing for tasks such as finding new analogies, and\nmultimodal zero-shot classification. In this work, we propose a metric to\nevaluate the similarity between paired item representations. Our proposal is\nbuilt from the structural similarity between the nearest-neighbors induced\ngraphs of each representation, and can be configured to compare spaces based on\ndifferent distance metrics and on different neighborhood sizes. We demonstrate\nthat our proposal can be used to identify similar structures at different\nscales, which is hard to achieve with kernel methods such as Centered Kernel\nAlignment (CKA). We further illustrate our method with two case studies: an\nanalogy task using GloVe embeddings, and zero-shot classification in the\nCIFAR-100 dataset using CLIP embeddings. Our results show that accuracy in both\nanalogy and zero-shot classification tasks correlates with the embedding\nsimilarity. These findings can help explain performance differences in these\ntasks, and may lead to improved design of paired-embedding models in the\nfuture."
    },
    {
      "id": "2411.08684v1",
      "title": "Analogical Reasoning Within a Conceptual Hyperspace",
      "summary": "We propose an approach to analogical inference that marries the\nneuro-symbolic computational power of complex-sampled hyperdimensional\ncomputing (HDC) with Conceptual Spaces Theory (CST), a promising theory of\nsemantic meaning. CST sketches, at an abstract level, approaches to analogical\ninference that go beyond the standard predicate-based structure mapping\ntheories. But it does not describe how such an approach can be operationalized.\nWe propose a concrete HDC-based architecture that computes several types of\nanalogy classified by CST. We present preliminary proof-of-concept experimental\nresults within a toy domain and describe how it can perform category-based and\nproperty-based analogical reasoning."
    },
    {
      "id": "2411.08671v1",
      "title": "Theoretical Analysis of Byte-Pair Encoding",
      "summary": "Byte-Pair Encoding (BPE) is a widely used method for subword tokenization,\nwith origins in grammar-based text compression. It is employed in a variety of\nlanguage processing tasks such as machine translation or large language model\n(LLM) pretraining, to create a token dictionary of a prescribed size. Most\nevaluations of BPE to date are empirical, and the reasons for its good\npractical performance are not well understood.\n  In this paper we focus on the optimization problem underlying BPE: finding a\npair encoding that achieves optimal compression utility. We show that this\nproblem is APX-complete, indicating that it is unlikely to admit a\npolynomial-time approximation scheme. This answers, in a stronger form, a\nquestion recently raised by Zouhar et al.\n  On the positive side, we show that BPE approximates the compression utility\nof the optimal pair encoding to a worst-case factor between $0.333$ and\n$0.625$. Our results aim to explain the ongoing success of BPE and are, to our\nknowledge, the first rigorous guarantees on its compression utility that hold\nfor all inputs."
    },
    {
      "id": "2411.08666v1",
      "title": "A Survey on Vision Autoregressive Model",
      "summary": "Autoregressive models have demonstrated great performance in natural language\nprocessing (NLP) with impressive scalability, adaptability and\ngeneralizability. Inspired by their notable success in NLP field,\nautoregressive models have been intensively investigated recently for computer\nvision, which perform next-token predictions by representing visual data as\nvisual tokens and enables autoregressive modelling for a wide range of vision\ntasks, ranging from visual generation and visual understanding to the very\nrecent multimodal generation that unifies visual generation and understanding\nwith a single autoregressive model. This paper provides a systematic review of\nvision autoregressive models, including the development of a taxonomy of\nexisting methods and highlighting their major contributions, strengths, and\nlimitations, covering various vision tasks such as image generation, video\ngeneration, image editing, motion generation, medical image analysis, 3D\ngeneration, robotic manipulation, unified multimodal generation, etc. Besides,\nwe investigate and analyze the latest advancements in autoregressive models,\nincluding thorough benchmarking and discussion of existing methods across\nvarious evaluation datasets. Finally, we outline key challenges and promising\ndirections for future research, offering a roadmap to guide further\nadvancements in vision autoregressive models."
    },
    {
      "id": "2411.08664v1",
      "title": "UniMat: Unifying Materials Embeddings through Multi-modal Learning",
      "summary": "Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery."
    },
    {
      "id": "2411.08652v1",
      "title": "Accelerating Quasi-Static Time Series Simulations with Foundation Models",
      "summary": "Quasi-static time series (QSTS) simulations have great potential for\nevaluating the grid's ability to accommodate the large-scale integration of\ndistributed energy resources. However, as grids expand and operate closer to\ntheir limits, iterative power flow solvers, central to QSTS simulations, become\ncomputationally prohibitive and face increasing convergence issues. Neural\npower flow solvers provide a promising alternative, speeding up power flow\ncomputations by 3 to 4 orders of magnitude, though they are costly to train. In\nthis paper, we envision how recently introduced grid foundation models could\nimprove the economic viability of neural power flow solvers. Conceptually,\nthese models amortize training costs by serving as a foundation for a range of\ngrid operation and planning tasks beyond power flow solving, with only minimal\nfine-tuning required. We call for collaboration between the AI and power grid\ncommunities to develop and open-source these models, enabling all operators,\neven those with limited resources, to benefit from AI without building\nsolutions from scratch."
    },
    {
      "id": "2411.08651v1",
      "title": "Estimating unknown parameters in differential equations with a reinforcement learning based PSO method",
      "summary": "Differential equations offer a foundational yet powerful framework for\nmodeling interactions within complex dynamic systems and are widely applied\nacross numerous scientific fields. One common challenge in this area is\nestimating the unknown parameters of these dynamic relationships. However,\ntraditional numerical optimization methods rely on the selection of initial\nparameter values, making them prone to local optima. Meanwhile, deep learning\nand Bayesian methods require training models on specific differential\nequations, resulting in poor versatility. This paper reformulates the parameter\nestimation problem of differential equations as an optimization problem by\nintroducing the concept of particles from the particle swarm optimization\nalgorithm. Building on reinforcement learning-based particle swarm optimization\n(RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown\nparameters of differential equations. We compared its performance on three\ntypical ordinary differential equations with the state-of-the-art methods,\nincluding the RLLPSO algorithm, traditional numerical methods, deep learning\napproaches, and Bayesian methods. The experimental results demonstrate that our\nDERLPSO consistently outperforms other methods in terms of performance,\nachieving an average Mean Square Error of 1.13e-05, which reduces the error by\napproximately 4 orders of magnitude compared to other methods. Apart from\nordinary differential equations, our DERLPSO also show great promise for\nestimating unknown parameters of partial differential equations. The DERLPSO\nmethod proposed in this paper has high accuracy, is independent of initial\nparameter values, and possesses strong versatility and stability. This work\nprovides new insights into unknown parameter estimation for differential\nequations."
    },
    {
      "id": "2411.08645v1",
      "title": "A System Level Performance Evaluation for Superconducting Digital Systems",
      "summary": "Superconducting Digital (SCD) technology offers significant potential for\nenhancing the performance of next generation large scale compute workloads. By\nleveraging advanced lithography and a 300 mm platform, SCD devices can reduce\nenergy consumption and boost computational power. This paper presents a\ncross-layer modeling approach to evaluate the system-level performance benefits\nof SCD architectures for Large Language Model (LLM) training and inference. Our\nfindings, based on experimental data and Pulse Conserving Logic (PCL) design\nprinciples, demonstrate substantial performance gain in both training and\ninference. We are, thus, able to convincingly show that the SCD technology can\naddress memory and interconnect limitations of present day solutions for\nnext-generation compute systems."
    },
    {
      "id": "2411.08642v1",
      "title": "Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models",
      "summary": "The remarkable progress in neural-network-driven visual data generation,\nespecially with neural rendering techniques like Neural Radiance Fields and 3D\nGaussian splatting, offers a powerful alternative to GANs and diffusion models.\nThese methods can produce high-fidelity images and lifelike avatars,\nhighlighting the need for robust detection methods. In response, an\nunsupervised training technique is proposed that enables the model to extract\ncomprehensive features from the Fourier spectrum magnitude, thereby overcoming\nthe challenges of reconstructing the spectrum due to its centrosymmetric\nproperties. By leveraging the spectral domain and dynamically combining it with\nspatial domain information, we create a robust multimodal detector that\ndemonstrates superior generalization capabilities in identifying challenging\nsynthetic images generated by the latest image synthesis techniques. To address\nthe absence of a 3D neural rendering-based fake image database, we develop a\ncomprehensive database that includes images generated by diverse neural\nrendering techniques, providing a robust foundation for evaluating and\nadvancing detection methods."
    },
    {
      "id": "2411.08641v1",
      "title": "DipMe: Haptic Recognition of Granular Media for Tangible Interactive Applications",
      "summary": "While tangible user interface has shown its power in naturally interacting\nwith rigid or soft objects, users cannot conveniently use different types of\ngranular materials as the interaction media. We introduce DipMe as a smart\ndevice to recognize the types of granular media in real time, which can be used\nto connect the granular materials in the physical world with various virtual\ncontent. Other than vision-based solutions, we propose a dip operation of our\ndevice and exploit the haptic signals to recognize different types of granular\nmaterials. With modern machine learning tools, we find the haptic signals from\ndifferent granular media are distinguishable by DipMe. With the online granular\nobject recognition, we build several tangible interactive applications,\ndemonstrating the effects of DipMe in perceiving granular materials and its\npotential in developing a tangible user interface with granular objects as the\nnew media."
    },
    {
      "id": "2411.08640v1",
      "title": "Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats and Promising Technical Solutions using LLMs",
      "summary": "The evolution of wireless communication systems will be fundamentally\nimpacted by an open radio access network (O-RAN), a new concept defining an\nintelligent architecture with enhanced flexibility, openness, and the ability\nto slice services more efficiently. For all its promises, and like any\ntechnological advancement, O-RAN is not without risks that need to be carefully\nassessed and properly addressed to accelerate its wide adoption in future\nmobile networks. In this paper, we present an in-depth security analysis of the\nO-RAN architecture, discussing the potential threats that may arise in the\ndifferent O-RAN architecture layers and their impact on the Confidentiality,\nIntegrity, and Availability (CIA) triad. We also promote the potential of zero\ntrust, Moving Target Defense (MTD), blockchain, and large language models(LLM)\ntechnologies in fortifying O-RAN's security posture. Furthermore, we\nnumerically demonstrate the effectiveness of MTD in empowering robust deep\nreinforcement learning methods for dynamic network slice admission control in\nthe O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI)\nbased on LLMs in securing the system."
    },
    {
      "id": "2411.08638v1",
      "title": "Gaussian Mixture Models Based Augmentation Enhances GNN Generalization",
      "summary": "Graph Neural Networks (GNNs) have shown great promise in tasks like node and\ngraph classification, but they often struggle to generalize, particularly to\nunseen or out-of-distribution (OOD) data. These challenges are exacerbated when\ntraining data is limited in size or diversity. To address these issues, we\nintroduce a theoretical framework using Rademacher complexity to compute a\nregret bound on the generalization error and then characterize the effect of\ndata augmentation. This framework informs the design of GMM-GDA, an efficient\ngraph data augmentation (GDA) algorithm leveraging the capability of Gaussian\nMixture Models (GMMs) to approximate any distribution. Our approach not only\noutperforms existing augmentation techniques in terms of generalization but\nalso offers improved time complexity, making it highly suitable for real-world\napplications."
    },
    {
      "id": "2411.08637v1",
      "title": "Robot See, Robot Do: Imitation Reward for Noisy Financial Environments",
      "summary": "The sequential nature of decision-making in financial asset trading aligns\nnaturally with the reinforcement learning (RL) framework, making RL a common\napproach in this domain. However, the low signal-to-noise ratio in financial\nmarkets results in noisy estimates of environment components, including the\nreward function, which hinders effective policy learning by RL agents. Given\nthe critical importance of reward function design in RL problems, this paper\nintroduces a novel and more robust reward function by leveraging imitation\nlearning, where a trend labeling algorithm acts as an expert. We integrate\nimitation (expert's) feedback with reinforcement (agent's) feedback in a\nmodel-free RL algorithm, effectively embedding the imitation learning problem\nwithin the RL paradigm to handle the stochasticity of reward signals. Empirical\nresults demonstrate that this novel approach improves financial performance\nmetrics compared to traditional benchmarks and RL agents trained solely using\nreinforcement feedback."
    },
    {
      "id": "2411.08631v1",
      "title": "Deep Generative Demand Learning for Newsvendor and Pricing",
      "summary": "We consider data-driven inventory and pricing decisions in the feature-based\nnewsvendor problem, where demand is influenced by both price and contextual\nfeatures and is modeled without any structural assumptions. The unknown demand\ndistribution results in a challenging conditional stochastic optimization\nproblem, further complicated by decision-dependent uncertainty and the\nintegration of features. Inspired by recent advances in deep generative\nlearning, we propose a novel approach leveraging conditional deep generative\nmodels (cDGMs) to address these challenges. cDGMs learn the demand distribution\nand generate probabilistic demand forecasts conditioned on price and features.\nThis generative approach enables accurate profit estimation and supports the\ndesign of algorithms for two key objectives: (1) optimizing inventory for\narbitrary prices, and (2) jointly determining optimal pricing and inventory\nlevels. We provide theoretical guarantees for our approach, including the\nconsistency of profit estimation and convergence of our decisions to the\noptimal solution. Extensive simulations-ranging from simple to complex\nscenarios, including one involving textual features-and a real-world case study\ndemonstrate the effectiveness of our approach. Our method opens a new paradigm\nin management science and operations research, is adaptable to extensions of\nthe newsvendor and pricing problems, and holds potential for solving other\nconditional stochastic optimization problems."
    },
    {
      "id": "2411.08622v1",
      "title": "Precision-Focused Reinforcement Learning Model for Robotic Object Pushing",
      "summary": "Non-prehensile manipulation, such as pushing objects to a desired target\nposition, is an important skill for robots to assist humans in everyday\nsituations. However, the task is challenging due to the large variety of\nobjects with different and sometimes unknown physical properties, such as\nshape, size, mass, and friction. This can lead to the object overshooting its\ntarget position, requiring fast corrective movements of the robot around the\nobject, especially in cases where objects need to be precisely pushed. In this\npaper, we improve the state-of-the-art by introducing a new memory-based\nvision-proprioception RL model to push objects more precisely to target\npositions using fewer corrective movements."
    },
    {
      "id": "2411.08610v1",
      "title": "Dynamic Subset Tuning: Expanding the Operational Range of Parameter-Efficient Training for Large Language Models",
      "summary": "We propose a novel parameter-efficient training (PET) method for large\nlanguage models that adapts models to downstream tasks by optimizing a small\nsubset of the existing model parameters. Unlike prior methods, this subset is\nnot fixed in location but rather which parameters are modified evolves over the\ncourse of training. This dynamic parameter selection can yield good performance\nwith many fewer parameters than extant methods. Our method enables a seamless\nscaling of the subset size across an arbitrary proportion of the total model\nsize, while popular PET approaches like prompt tuning and LoRA cover only a\nsmall part of this spectrum. We match or outperform prompt tuning and LoRA in\nmost cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given\nparameter budget across different model families and sizes."
    },
    {
      "id": "2411.08605v1",
      "title": "Lo-MARVE: A Low Cost Autonomous Underwater Vehicle for Marine Exploration",
      "summary": "This paper presents Low-cost Marine Autonomous Robotic Vehicle Explorer\n(Lo-MARVE), a novel autonomous underwater vehicle (AUV) designed to provide a\nlow cost solution for underwater exploration and environmental monitoring in\nshallow water environments. Lo-MARVE offers a cost-effective alternative to\nexisting AUVs, featuring a modular design, low-cost sensors, and wireless\ncommunication capabilities. The total cost of Lo-MARVE is approximately EUR\n500. Lo-MARVE is developed using the Raspberry Pi 4B microprocessor, with\ncontrol software written in Python. The proposed AUV was validated through\nfield testing outside of a laboratory setting, in the freshwater environment of\nthe River Corrib in Galway, Ireland. This demonstrates its ability to navigate\nautonomously, collect data, and communicate effectively outside of a controlled\nlaboratory setting. The successful deployment of Lo-MARVE in a real-world\nenvironment validates its proof of concept."
    },
    {
      "id": "2411.08599v1",
      "title": "XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL",
      "summary": "To tackle the challenges of large language model performance in natural\nlanguage to SQL tasks, we introduce XiYan-SQL, an innovative framework that\nemploys a multi-generator ensemble strategy to improve candidate generation. We\nintroduce M-Schema, a semi-structured schema representation method designed to\nenhance the understanding of database structures. To enhance the quality and\ndiversity of generated candidate SQL queries, XiYan-SQL integrates the\nsignificant potential of in-context learning (ICL) with the precise control of\nsupervised fine-tuning. On one hand, we propose a series of training strategies\nto fine-tune models to generate high-quality candidates with diverse\npreferences. On the other hand, we implement the ICL approach with an example\nselection method based on named entity recognition to prevent overemphasis on\nentities. The refiner optimizes each candidate by correcting logical or\nsyntactical errors. To address the challenge of identifying the best candidate,\nwe fine-tune a selection model to distinguish nuances of candidate SQL queries.\nThe experimental results on multiple dialect datasets demonstrate the\nrobustness of XiYan-SQL in addressing challenges across different scenarios.\nOverall, our proposed XiYan-SQL achieves the state-of-the-art execution\naccuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on\nNL2GQL, and a competitive score of 72.23% on the Bird development benchmark.\nThe proposed framework not only enhances the quality and diversity of SQL\nqueries but also outperforms previous methods."
    },
    {
      "id": "2411.08590v1",
      "title": "Hopfield-Fenchel-Young Networks: A Unified Framework for Associative Memory Retrieval",
      "summary": "Associative memory models, such as Hopfield networks and their modern\nvariants, have garnered renewed interest due to advancements in memory capacity\nand connections with self-attention in transformers. In this work, we introduce\na unified framework-Hopfield-Fenchel-Young networks-which generalizes these\nmodels to a broader family of energy functions. Our energies are formulated as\nthe difference between two Fenchel-Young losses: one, parameterized by a\ngeneralized entropy, defines the Hopfield scoring mechanism, while the other\napplies a post-transformation to the Hopfield output. By utilizing Tsallis and\nnorm entropies, we derive end-to-end differentiable update rules that enable\nsparse transformations, uncovering new connections between loss margins,\nsparsity, and exact retrieval of single memory patterns. We further extend this\nframework to structured Hopfield networks using the SparseMAP transformation,\nallowing the retrieval of pattern associations rather than a single pattern.\nOur framework unifies and extends traditional and modern Hopfield networks and\nprovides an energy minimization perspective for widely used\npost-transformations like $\\ell_2$-normalization and layer normalization-all\nthrough suitable choices of Fenchel-Young losses and by using convex analysis\nas a building block. Finally, we validate our Hopfield-Fenchel-Young networks\non diverse memory recall tasks, including free and sequential recall.\nExperiments on simulated data, image retrieval, multiple instance learning, and\ntext rationalization demonstrate the effectiveness of our approach."
    },
    {
      "id": "2411.08587v1",
      "title": "DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods",
      "summary": "Assessing the quality of aleatoric uncertainty estimates from uncertainty\nquantification (UQ) deep learning methods is important in scientific contexts,\nwhere uncertainty is physically meaningful and important to characterize and\ninterpret exactly. We systematically compare aleatoric uncertainty measured by\ntwo UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER).\nOur method focuses on both zero-dimensional (0D) and two-dimensional (2D) data,\nto explore how the UQ methods function for different data dimensionalities. We\ninvestigate uncertainty injected on the input and output variables and include\na method to propagate uncertainty in the case of input uncertainty so that we\ncan compare the predicted aleatoric uncertainty to the known values. We\nexperiment with three levels of noise. The aleatoric uncertainty predicted\nacross all models and experiments scales with the injected noise level.\nHowever, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm\nal})$ with the true uncertainty for half of the DE experiments and almost all\nof the DER experiments. The predicted uncertainty is the least accurate for\nboth UQ methods for the 2D input uncertainty experiment and the high-noise\nlevel. While these results do not apply to more complex data, they highlight\nthat further research on post-facto calibration for these methods would be\nbeneficial, particularly for high-noise and high-dimensional settings."
    },
    {
      "id": "2411.08586v2",
      "title": "Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method",
      "summary": "Summarizing patient clinical notes is vital for reducing documentation\nburdens. Current manual summarization makes medical staff struggle. We propose\nan automatic method using LLMs, but long inputs cause LLMs to lose context,\nreducing output quality especially in small size model. We used a 7B model,\nopen-calm-7b, enhanced with Native Bayes Context Extend and a redesigned\ndecoding mechanism to reference one sentence at a time, keeping inputs within\ncontext windows, 2048 tokens. Our improved model achieved near parity with\nGoogle's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating\nstrong performance using less resources, enhancing automated EMR summarization\nfeasibility."
    },
    {
      "id": "2411.08583v1",
      "title": "An Empirical Examination of the Evaluative AI Framework",
      "summary": "This study empirically examines the \"Evaluative AI\" framework, which aims to\nenhance the decision-making process for AI users by transitioning from a\nrecommendation-based approach to a hypothesis-driven one. Rather than offering\ndirect recommendations, this framework presents users pro and con evidence for\nhypotheses to support more informed decisions. However, findings from the\ncurrent behavioral experiment reveal no significant improvement in\ndecision-making performance and limited user engagement with the evidence\nprovided, resulting in cognitive processes similar to those observed in\ntraditional AI systems. Despite these results, the framework still holds\npromise for further exploration in future research."
    },
    {
      "id": "2411.08582v1",
      "title": "Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors",
      "summary": "The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining state of the art algorithms with a novel unsupervised anomaly\ngeneration methodology that takes into account physics model of the engine.\nThis hybrid approach leverages the strengths of both supervised ML and\nunsupervised signature analysis, achieving superior diagnostic accuracy and\nreliability along with a wide industrial application. Our experimental results\ndemonstrate that this method significantly outperforms existing ML and non-ML\nstate-of-the-art approaches while retaining the practical advantages of an\nunsupervised methodology. The findings highlight the potential of our approach\nto significantly contribute to the field of engine diagnostics, offering a\nrobust and efficient solution for real-world applications."
    },
    {
      "id": "2411.08937v1",
      "title": "Dual-Head Knowledge Distillation: Enhancing Logits Utilization with an Auxiliary Head",
      "summary": "Traditional knowledge distillation focuses on aligning the student's\npredicted probabilities with both ground-truth labels and the teacher's\npredicted probabilities. However, the transition to predicted probabilities\nfrom logits would obscure certain indispensable information. To address this\nissue, it is intuitive to additionally introduce a logit-level loss function as\na supplement to the widely used probability-level loss function, for exploiting\nthe latent information of logits. Unfortunately, we empirically find that the\namalgamation of the newly introduced logit-level loss and the previous\nprobability-level loss will lead to performance degeneration, even trailing\nbehind the performance of employing either loss in isolation. We attribute this\nphenomenon to the collapse of the classification head, which is verified by our\ntheoretical analysis based on the neural collapse theory. Specifically, the\ngradients of the two loss functions exhibit contradictions in the linear\nclassifier yet display no such conflict within the backbone. Drawing from the\ntheoretical analysis, we propose a novel method called dual-head knowledge\ndistillation, which partitions the linear classifier into two classification\nheads responsible for different losses, thereby preserving the beneficial\neffects of both losses on the backbone while eliminating adverse influences on\nthe classification head. Extensive experiments validate that our method can\neffectively exploit the information inside the logits and achieve superior\nperformance against state-of-the-art counterparts."
    },
    {
      "id": "2411.08566v1",
      "title": "Grammarization-Based Grasping with Deep Multi-Autoencoder Latent Space Exploration by Reinforcement Learning Agent",
      "summary": "Grasping by a robot in unstructured environments is deemed a critical\nchallenge because of the requirement for effective adaptation to a wide\nvariation in object geometries, material properties, and other environmental\nfactors. In this paper, we propose a novel framework for robotic grasping based\non the idea of compressing high-dimensional target and gripper features in a\ncommon latent space using a set of autoencoders. Our approach simplifies\ngrasping by using three autoencoders dedicated to the target, the gripper, and\na third one that fuses their latent representations. This allows the RL agent\nto achieve higher learning rates at the initial stages of exploration of a new\nenvironment, as well as at non-zero shot grasp attempts. The agent explores the\nlatent space of the third autoencoder for better quality grasp without explicit\nreconstruction of objects. By implementing the PoWER algorithm into the RL\ntraining process, updates on the agent's policy will be made through the\nperturbation in the reward-weighted latent space. The successful exploration\nefficiently constrains both position and pose integrity for feasible executions\nof grasps. We evaluate our system on a diverse set of objects, demonstrating\nthe high success rate in grasping with minimum computational overhead. We found\nthat approach enhances the adaptation of the RL agent by more than 35 \\% in\nsimulation experiments."
    },
    {
      "id": "2411.08563v1",
      "title": "Leveraging LLMs for Predictive Insights in Food Policy and Behavioral Interventions",
      "summary": "Food consumption and production contribute significantly to global greenhouse\ngas emissions, making them crucial entry points for mitigating climate change\nand maintaining a liveable planet. Over the past two decades, food policy\ninitiatives have explored interventions to reshape production and consumption\npatterns, focusing on reducing food waste and curbing ruminant meat\nconsumption. While the evidence of \"what works\" improves, evaluating which\npolicies are appropriate and effective in specific contexts remains difficult\ndue to external validity challenges. This paper demonstrates that a fine-tuned\nlarge language model (LLM) can accurately predict the direction of outcomes in\napproximately 80\\% of empirical studies measuring dietary-based impacts (e.g.\nfood choices, sales, waste) resulting from behavioral interventions and\npolicies. Approximately 75 prompts were required to achieve optimal results,\nwith performance showing signs of catastrophic loss beyond this point. Our\nfindings indicate that greater input detail enhances predictive accuracy,\nalthough the model still faces challenges with unseen studies, underscoring the\nimportance of a representative training sample. As LLMs continue to improve and\ndiversify, they hold promise for advancing data-driven, evidence-based\npolicymaking."
    },
    {
      "id": "2411.08562v1",
      "title": "Neural Corrective Machine Unranking",
      "summary": "Machine unlearning in neural information retrieval (IR) systems requires\nremoving specific data whilst maintaining model performance. Applying existing\nmachine unlearning methods to IR may compromise retrieval effectiveness or\ninadvertently expose unlearning actions due to the removal of particular items\nfrom the retrieved results presented to users. We formalise corrective\nunranking, which extends machine unlearning in (neural) IR context by\nintegrating substitute documents to preserve ranking integrity, and propose a\nnovel teacher-student framework, Corrective unRanking Distillation (CuRD), for\nthis task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR\nmodel such that its output relevance scores of to-be-forgotten samples mimic\nthose of low-ranking, non-retrievable samples; (2) enables correction by\nfine-tuning the relevance scores for the substitute samples to match those of\ncorresponding to-be-forgotten samples closely; (3) seeks to preserve\nperformance on samples that are not targeted for forgetting. We evaluate CuRD\non four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and\nTREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the\ntraining dataset demonstrate that CuRD outperforms seven state-of-the-art\nbaselines in terms of forgetting and correction while maintaining model\nretention and generalisation capabilities."
    },
    {
      "id": "2411.08561v1",
      "title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
      "summary": "Software systems often record important runtime information in logs to help\nwith troubleshooting. Log-based anomaly detection has become a key research\narea that aims to identify system issues through log data, ultimately enhancing\nthe reliability of software systems. Traditional deep learning methods often\nstruggle to capture the semantic information embedded in log data, which is\ntypically organized in natural language. In this paper, we propose LogLLM, a\nlog-based anomaly detection framework that leverages large language models\n(LLMs). LogLLM employs BERT for extracting semantic vectors from log messages,\nwhile utilizing Llama, a transformer decoder-based model, for classifying log\nsequences. Additionally, we introduce a projector to align the vector\nrepresentation spaces of BERT and Llama, ensuring a cohesive understanding of\nlog semantics. Unlike conventional methods that require log parsers to extract\ntemplates, LogLLM preprocesses log messages with regular expressions,\nstreamlining the entire process. Our framework is trained through a novel\nthree-stage procedure designed to enhance performance and adaptability.\nExperimental results across four public datasets demonstrate that LogLLM\noutperforms state-of-the-art methods. Even when handling unstable logs, it\neffectively captures the semantic meaning of log messages and detects anomalies\naccurately."
    },
    {
      "id": "2411.08557v1",
      "title": "Learning Locally Adaptive Metrics that Enhance Structural Representation with $\\texttt{LAMINAR}$",
      "summary": "We present $\\texttt{LAMINAR}$, a novel unsupervised machine learning pipeline\ndesigned to enhance the representation of structure within data via producing a\nmore-informative distance metric. Analysis methods in the physical sciences\noften rely on standard metrics to define geometric relationships in data, which\nmay fail to capture the underlying structure of complex data sets.\n$\\texttt{LAMINAR}$ addresses this by using a continuous-normalising-flow and\ninverse-transform-sampling to define a Riemannian manifold in the data space\nwithout the need for the user to specify a metric over the data a-priori. The\nresult is a locally-adaptive-metric that produces structurally-informative\ndensity-based distances. We demonstrate the utility of $\\texttt{LAMINAR}$ by\ncomparing its output to the Euclidean metric for structured data sets."
    },
    {
      "id": "2411.08553v1",
      "title": "CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs",
      "summary": "Large language models (LLMs) have demonstrated remarkable performance in\ndiverse tasks using zero-shot and few-shot prompting. Even though their\ncapabilities of data synthesis have been studied well in recent years, the\ngenerated data suffers from a lack of diversity, less adherence to the prompt,\nand potential biases that creep into the data from the generator model. In this\nwork, we tackle the challenge of generating datasets with high diversity, upon\nwhich a student model is trained for downstream tasks. Taking the route of\ndecoding-time guidance-based approaches, we propose CorrSynth, which generates\ndata that is more diverse and faithful to the input prompt using a correlated\nsampling strategy. Further, our method overcomes the complexity drawbacks of\nsome other guidance-based techniques like classifier-based guidance. With\nextensive experiments, we show the effectiveness of our approach and\nsubstantiate our claims. In particular, we perform intrinsic evaluation to show\nthe improvements in diversity. Our experiments show that CorrSynth improves\nboth student metrics and intrinsic metrics upon competitive baselines across\nfour datasets, showing the innate advantage of our method."
    },
    {
      "id": "2411.08552v1",
      "title": "Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with Variational Quantum Circuits",
      "summary": "Quantum Machine Learning (QML) offers tremendous potential but is currently\nlimited by the availability of qubits. We introduce an innovative approach that\nutilizes pre-trained neural networks to enhance Variational Quantum Circuits\n(VQC). This technique effectively separates approximation error from qubit\ncount and removes the need for restrictive conditions, making QML more viable\nfor real-world applications. Our method significantly improves parameter\noptimization for VQC while delivering notable gains in representation and\ngeneralization capabilities, as evidenced by rigorous theoretical analysis and\nextensive empirical testing on quantum dot classification tasks. Moreover, our\nresults extend to applications such as human genome analysis, demonstrating the\nbroad applicability of our approach. By addressing the constraints of current\nquantum hardware, our work paves the way for a new era of advanced QML\napplications, unlocking the full potential of quantum computing in fields such\nas machine learning, materials science, medicine, mimetics, and various\ninterdisciplinary areas."
    },
    {
      "id": "2411.08550v1",
      "title": "Graph Neural Networks in Supply Chain Analytics and Optimization: Concepts, Perspectives, Dataset and Benchmarks",
      "summary": "Graph Neural Networks (GNNs) have recently gained traction in transportation,\nbioinformatics, language and image processing, but research on their\napplication to supply chain management remains limited. Supply chains are\ninherently graph-like, making them ideal for GNN methodologies, which can\noptimize and solve complex problems. The barriers include a lack of proper\nconceptual foundations, familiarity with graph applications in SCM, and\nreal-world benchmark datasets for GNN-based supply chain research. To address\nthis, we discuss and connect supply chains with graph structures for effective\nGNN application, providing detailed formulations, examples, mathematical\ndefinitions, and task guidelines. Additionally, we present a multi-perspective\nreal-world benchmark dataset from a leading FMCG company in Bangladesh,\nfocusing on supply chain planning. We discuss various supply chain tasks using\nGNNs and benchmark several state-of-the-art models on homogeneous and\nheterogeneous graphs across six supply chain analytics tasks. Our analysis\nshows that GNN-based models consistently outperform statistical Machine\nLearning and other Deep Learning models by around 10-30% in regression, 10-30%\nin classification and detection tasks, and 15-40% in anomaly detection tasks on\ndesignated metrics. With this work, we lay the groundwork for solving supply\nchain problems using GNNs, supported by conceptual discussions, methodological\ninsights, and a comprehensive dataset."
    },
    {
      "id": "2411.08544v1",
      "title": "Deeper Insights into Learning Performance of Stochastic Configuration Networks",
      "summary": "Stochastic Configuration Networks (SCNs) are a class of randomized neural\nnetworks that integrate randomized algorithms within an incremental learning\nframework. A defining feature of SCNs is the supervisory mechanism, which\nadaptively adjusts the distribution to generate effective random basis\nfunctions, thereby enabling error-free learning. In this paper, we present a\ncomprehensive analysis of the impact of the supervisory mechanism on the\nlearning performance of SCNs. Our findings reveal that the current SCN\nframework evaluates the effectiveness of each random basis function in reducing\nresidual errors using a lower bound on its error reduction potential, which\nconstrains SCNs' overall learning efficiency. Specifically, SCNs may fail to\nconsistently select the most effective random candidate as the new basis\nfunction during each training iteration. To overcome this problem, we propose a\nnovel method for evaluating the hidden layer's output matrix, supported by a\nnew supervisory mechanism that accurately assesses the error reduction\npotential of random basis functions without requiring the computation of the\nMoore-Penrose inverse of the output matrix. This approach enhances the\nselection of basis functions, reducing computational complexity and improving\nthe overall scalability and learning capabilities of SCNs. We introduce a\nRecursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new\nsupervisory mechanism and demonstrate its effectiveness through simulations\nover some benchmark datasets. Experiments show that RMPI-SCN outperforms the\nconventional SCN in terms of learning capability, underscoring its potential to\nadvance the SCN framework for large-scale data modeling applications."
    },
    {
      "id": "2411.08537v1",
      "title": "MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation",
      "summary": "Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste\nproducts from the human brain. An impairment in their functionality has been\nassociated with aging as well as brain disorders like multiple sclerosis and\nAlzheimer's disease. However, MLVs have only recently been described for the\nfirst time in magnetic resonance imaging (MRI), and their ramified structure\nrenders manual segmentation particularly difficult. Further, as there is no\nconsistent notion of their appearance, human-annotated MLV structures contain a\nhigh inter-rater variability that most automatic segmentation methods cannot\ntake into account. In this work, we propose a new rater-aware training scheme\nfor the popular nnU-Net model, and we explore rater-based ensembling strategies\nfor accurate and consistent segmentation of MLVs. This enables us to boost\nnnU-Net's performance while obtaining explicit predictions in different\nannotation styles and a rater-based uncertainty estimation. Our final model,\nMLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to\nthe human reference standard. The model further matches the human inter-rater\nreliability and replicates age-related associations with MLV volume."
    },
    {
      "id": "2411.08534v1",
      "title": "Neural Topic Modeling with Large Language Models in the Loop",
      "summary": "Topic modeling is a fundamental task in natural language processing, allowing\nthe discovery of latent thematic structures in text corpora. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities in topic\ndiscovery, their direct application to topic modeling suffers from issues such\nas incomplete topic coverage, misalignment of topics, and inefficiency. To\naddress these limitations, we propose LLM-ITL, a novel LLM-in-the-loop\nframework that integrates LLMs with many existing Neural Topic Models (NTMs).\nIn LLM-ITL, global topics and document representations are learned through the\nNTM, while an LLM refines the topics via a confidence-weighted Optimal\nTransport (OT)-based alignment objective. This process enhances the\ninterpretability and coherence of the learned topics, while maintaining the\nefficiency of NTMs. Extensive experiments demonstrate that LLM-ITL can help\nNTMs significantly improve their topic interpretability while maintaining the\nquality of document representation."
    },
    {
      "id": "2411.08533v1",
      "title": "ACROSS: A Deformation-Based Cross-Modal Representation for Robotic Tactile Perception",
      "summary": "Tactile perception is essential for human interaction with the environment\nand is becoming increasingly crucial in robotics. Tactile sensors like the\nBioTac mimic human fingertips and provide detailed interaction data. Despite\nits utility in applications like slip detection and object identification, this\nsensor is now deprecated, making many existing valuable datasets obsolete.\nHowever, recreating similar datasets with newer sensor technologies is both\ntedious and time-consuming. Therefore, it is crucial to adapt these existing\ndatasets for use with new setups and modalities. In response, we introduce\nACROSS, a novel framework for translating data between tactile sensors by\nexploiting sensor deformation information. We demonstrate the approach by\ntranslating BioTac signals into the DIGIT sensor. Our framework consists of\nfirst converting the input signals into 3D deformation meshes. We then\ntransition from the 3D deformation mesh of one sensor to the mesh of another,\nand finally convert the generated 3D deformation mesh into the corresponding\noutput space. We demonstrate our approach to the most challenging problem of\ngoing from a low-dimensional tactile representation to a high-dimensional one.\nIn particular, we transfer the tactile signals of a BioTac sensor to DIGIT\ntactile images. Our approach enables the continued use of valuable datasets and\nthe exchange of data between groups with different setups."
    },
    {
      "id": "2411.08936v1",
      "title": "Clustered Patch Embeddings for Permutation-Invariant Classification of Whole Slide Images",
      "summary": "Whole Slide Imaging (WSI) is a cornerstone of digital pathology, offering\ndetailed insights critical for diagnosis and research. Yet, the gigapixel size\nof WSIs imposes significant computational challenges, limiting their practical\nutility. Our novel approach addresses these challenges by leveraging various\nencoders for intelligent data reduction and employing a different\nclassification model to ensure robust, permutation-invariant representations of\nWSIs. A key innovation of our method is the ability to distill the complex\ninformation of an entire WSI into a single vector, effectively capturing the\nessential features needed for accurate analysis. This approach significantly\nenhances the computational efficiency of WSI analysis, enabling more accurate\npathological assessments without the need for extensive computational\nresources. This breakthrough equips us with the capability to effectively\naddress the challenges posed by large image resolutions in whole-slide imaging,\npaving the way for more scalable and effective utilization of WSIs in medical\ndiagnostics and research, marking a significant advancement in the field."
    },
    {
      "id": "2411.08530v1",
      "title": "Efficient Whole Slide Image Classification through Fisher Vector Representation",
      "summary": "The advancement of digital pathology, particularly through computational\nanalysis of whole slide images (WSI), is poised to significantly enhance\ndiagnostic precision and efficiency. However, the large size and complexity of\nWSIs make it difficult to analyze and classify them using computers. This study\nintroduces a novel method for WSI classification by automating the\nidentification and examination of the most informative patches, thus\neliminating the need to process the entire slide. Our method involves\ntwo-stages: firstly, it extracts only a few patches from the WSIs based on\ntheir pathological significance; and secondly, it employs Fisher vectors (FVs)\nfor representing features extracted from these patches, which is known for its\nrobustness in capturing fine-grained details. This approach not only\naccentuates key pathological features within the WSI representation but also\nsignificantly reduces computational overhead, thus making the process more\nefficient and scalable. We have rigorously evaluated the proposed method across\nmultiple datasets to benchmark its performance against comprehensive WSI\nanalysis and contemporary weakly-supervised learning methodologies. The\nempirical results indicate that our focused analysis of select patches,\ncombined with Fisher vector representation, not only aligns with, but at times\nsurpasses, the classification accuracy of standard practices. Moreover, this\nstrategy notably diminishes computational load and resource expenditure,\nthereby establishing an efficient and precise framework for WSI analysis in the\nrealm of digital pathology."
    },
    {
      "id": "2411.08526v1",
      "title": "Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes in the Patent System",
      "summary": "This study examines gender disparities in patent law by analyzing the textual\ncontent of patent applications. While prior research has primarily focused on\nthe study of metadata (i.e., filing year or technological class), we employ\nmachine learning and natural language processing techniques to derive latent\ninformation from patent texts. In particular, these methods are used to predict\ninventor gender based on textual characteristics. We find that gender can be\nidentified with notable accuracy - even without knowing the inventor's name.\nThis ability to discern gender through text suggests that anonymized patent\nexamination - often proposed as a solution to mitigate disparities in patent\ngrant rate - may not fully address gender-specific outcomes in securing a\npatent. Our analysis additionally identifies gendered differences in textual\nchoices within patent documents and the fields in which inventors choose to\nwork. These findings highlight the complex interaction between textual choices,\ngender, and success in securing a patent. As discussed herein, this raises\ncritical questions about the efficacy of current proposals aimed at achieving\ngender parity and efficiency in the patent system."
    },
    {
      "id": "2411.08521v1",
      "title": "SAD-TIME: a Spatiotemporal-fused network for depression detection with Automated multi-scale Depth-wise and TIME-interval-related common feature extractor",
      "summary": "Background and Objective: Depression is a severe mental disorder, and\naccurate diagnosis is pivotal to the cure and rehabilitation of people with\ndepression. However, the current questionnaire-based diagnostic methods could\nbring subjective biases and may be denied by subjects. In search of a more\nobjective means of diagnosis, researchers have begun to experiment with deep\nlearning-based methods for identifying depressive disorders in recent years.\nMethods: In this study, a novel Spatiotemporal-fused network with Automated\nmulti-scale Depth-wise and TIME-interval-related common feature extractor\n(SAD-TIME) is proposed. SAD-TIME incorporates an automated nodes' common\nfeatures extractor (CFE), a spatial sector (SpS), a modified temporal sector\n(TeS), and a domain adversarial learner (DAL). The CFE includes a multi-scale\ndepth-wise 1D-convolutional neural network and a time-interval embedding\ngenerator, where the unique information of each channel is preserved. The SpS\nfuses the functional connectivity with the distance-based connectivity\ncontaining spatial position of EEG electrodes. A multi-head-attention graph\nconvolutional network is also applied in the SpS to fuse the features from\ndifferent EEG channels. The TeS is based on long short-term memory and graph\ntransformer networks, where the temporal information of different time-windows\nis fused. Moreover, the DAL is used after the SpS to obtain the\ndomain-invariant feature. Results: Experimental results under tenfold\ncross-validation show that the proposed SAD-TIME method achieves 92.00% and\n94.00% depression classification accuracies on two datasets, respectively, in\ncross-subject mode. Conclusion: SAD-TIME is a robust depression detection\nmodel, where the automatedly-generated features, the SpS and the TeS assist the\nclassification performance with the fusion of the innate spatiotemporal\ninformation in the EEG signals."
    },
    {
      "id": "2411.08516v1",
      "title": "Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding",
      "summary": "The ubiquity and value of tables as semi-structured data across various\ndomains necessitate advanced methods for understanding their complexity and\nvast amounts of information. Despite the impressive capabilities of large\nlanguage models (LLMs) in advancing the natural language understanding\nfrontier, their application to large-scale tabular data presents significant\nchallenges, specifically regarding table size and complex intricate\nrelationships. Existing works have shown promise with small-scale tables but\noften flounder when tasked with the complex reasoning required by larger,\ninterconnected tables found in real-world scenarios. To address this gap, we\nintroduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning\ncapabilities over large and complex tables. Our method employs Table\nCondensation and Decomposition to distill and reorganize relevant data into a\nmanageable format, followed by the construction of a hierarchical Table-Tree\nthat facilitates tree-structured reasoning. Through a meticulous Table-Tree\nExecution process, we systematically unravel the tree-structured reasoning\nchain to derive the solutions. Experiments across diverse datasets, including\nWikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new\nbenchmark with superior performance, showcasing remarkable efficiency and\ngeneralization capabilities in large-scale table reasoning."
    },
    {
      "id": "2411.08935v1",
      "title": "Classification of Keratitis from Eye Corneal Photographs using Deep Learning",
      "summary": "Keratitis is an inflammatory corneal condition responsible for 10% of visual\nimpairment in low- and middle-income countries (LMICs), with bacteria, fungi,\nor amoeba as the most common infection etiologies. While an accurate and timely\ndiagnosis is crucial for the selected treatment and the patients' sight\noutcomes, due to the high cost and limited availability of laboratory\ndiagnostics in LMICs, diagnosis is often made by clinical observation alone,\ndespite its lower accuracy. In this study, we investigate and compare different\ndeep learning approaches to diagnose the source of infection: 1) three separate\nbinary models for infection type predictions; 2) a multitask model with a\nshared backbone and three parallel classification layers (Multitask V1); and,\n3) a multitask model with a shared backbone and a multi-head classification\nlayer (Multitask V2). We used a private Brazilian cornea dataset to conduct the\nempirical evaluation. We achieved the best results with Multitask V2, with an\narea under the receiver operating characteristic curve (AUROC) confidence\nintervals of 0.7413-0.7740 (bacteria), 0.8395-0.8725 (fungi), and 0.9448-0.9616\n(amoeba). A statistical analysis of the impact of patient features on models'\nperformance revealed that sex significantly affects amoeba infection\nprediction, and age seems to affect fungi and bacteria predictions."
    },
    {
      "id": "2411.08514v1",
      "title": "Explainers' Mental Representations of Explainees' Needs in Everyday Explanations",
      "summary": "In explanations, explainers have mental representations of explainees'\ndeveloping knowledge and shifting interests regarding the explanandum. These\nmental representations are dynamic in nature and develop over time, thereby\nenabling explainers to react to explainees' needs by adapting and customizing\nthe explanation. XAI should be able to react to explainees' needs in a similar\nmanner. Therefore, a component that incorporates aspects of explainers' mental\nrepresentations of explainees is required. In this study, we took first steps\nby investigating explainers' mental representations in everyday explanations of\ntechnological artifacts. According to the dual nature theory, technological\nartifacts require explanations with two distinct perspectives, namely\nobservable and measurable features addressing \"Architecture\" or interpretable\naspects addressing \"Relevance\". We conducted extended semi structured pre-,\npost- and video recall-interviews with explainers (N=9) in the context of an\nexplanation. The transcribed interviews were analyzed utilizing qualitative\ncontent analysis. The explainers' answers regarding the explainees' knowledge\nand interests with regard to the technological artifact emphasized the\nvagueness of early assumptions of explainers toward strong beliefs in the\ncourse of explanations. The assumed knowledge of explainees in the beginning is\ncentered around Architecture and develops toward knowledge with regard to both\nArchitecture and Relevance. In contrast, explainers assumed higher interests in\nRelevance in the beginning to interests regarding both Architecture and\nRelevance in the further course of explanations. Further, explainers often\nfinished the explanation despite their perception that explainees still had\ngaps in knowledge. These findings are transferred into practical implications\nrelevant for user models for adaptive explainable systems."
    },
    {
      "id": "2411.08506v1",
      "title": "An Information Theoretic Approach to Operationalize Right to Data Protection",
      "summary": "The widespread practice of indiscriminate data scraping to fine-tune language\nmodels (LMs) raises significant legal and ethical concerns, particularly\nregarding compliance with data protection laws such as the General Data\nProtection Regulation (GDPR). This practice often results in the unauthorized\nuse of personal information, prompting growing debate within the academic and\nregulatory communities. Recent works have introduced the concept of generating\nunlearnable datasets (by adding imperceptible noise to the clean data), such\nthat the underlying model achieves lower loss during training but fails to\ngeneralize to the unseen test setting. Though somewhat effective, these\napproaches are predominantly designed for images and are limited by several\npractical constraints like requiring knowledge of the target model. To this\nend, we introduce RegText, a framework that injects imperceptible spurious\ncorrelations into natural language datasets, effectively rendering them\nunlearnable without affecting semantic content. We demonstrate RegText's\nutility through rigorous empirical analysis of small and large LMs. Notably,\nRegText can restrict newer models like GPT-4o and Llama from learning on our\ngenerated data, resulting in a drop in their test accuracy compared to their\nzero-shot performance and paving the way for generating unlearnable text to\nprotect public data."
    },
    {
      "id": "2411.08504v2",
      "title": "Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks",
      "summary": "How objective and unbiased are we while making decisions? This work\ninvestigates cognitive bias identification in high-stake decision making\nprocess by human experts, questioning its effectiveness in real-world settings,\nsuch as candidates assessments for university admission. We begin with a\nstatistical analysis assessing correlations among different decision points\namong in the current process, which discovers discrepancies that imply\ncognitive bias and inconsistency in decisions. This motivates our exploration\nof bias-aware AI-augmented workflow that surpass human judgment. We propose\nBGM-HAN, an enhanced Hierarchical Attention Network with Byte-Pair Encoding,\nGated Residual Connections and Multi-Head Attention. Using it as a backbone\nmodel, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow,\nwhich simulate real-world decision-making. In our experiments, both the\nproposed model and the agentic workflow significantly improves on both human\njudgment and alternative models, validated with real-world data."
    },
    {
      "id": "2411.08482v1",
      "title": "Methodology for a Statistical Analysis of Influencing Factors on 3D Object Detection Performance",
      "summary": "In autonomous driving, object detection is an essential task to perceive the\nenvironment by localizing and classifying objects. Most object detection\nalgorithms rely on deep learning for their superior performance. However, their\nblack box nature makes it challenging to ensure safety. In this paper, we\npropose a first-of-its-kind methodology for statistical analysis of the\ninfluence of various factors related to the objects to detect or the\nenvironment on the detection performance of both LiDAR- and camera-based 3D\nobject detectors. We perform a univariate analysis between each of the factors\nand the detection error in order to compare the strength of influence. To\nbetter identify potential sources of detection errors, we also analyze the\nperformance in dependency of the influencing factors and examine the\ninterdependencies between the different influencing factors. Recognizing the\nfactors that influence detection performance helps identify robustness issues\nin the trained object detector and supports the safety approval of object\ndetection systems."
    },
    {
      "id": "2411.08478v1",
      "title": "Learning Model Agnostic Explanations via Constraint Programming",
      "summary": "Interpretable Machine Learning faces a recurring challenge of explaining the\npredictions made by opaque classifiers such as ensemble models, kernel methods,\nor neural networks in terms that are understandable to humans. When the model\nis viewed as a black box, the objective is to identify a small set of features\nthat jointly determine the black box response with minimal error. However,\nfinding such model-agnostic explanations is computationally demanding, as the\nproblem is intractable even for binary classifiers. In this paper, the task is\nframed as a Constraint Optimization Problem, where the constraint solver seeks\nan explanation of minimum error and bounded size for an input data instance and\na set of samples generated by the black box. From a theoretical perspective,\nthis constraint programming approach offers PAC-style guarantees for the output\nexplanation. We evaluate the approach empirically on various datasets and show\nthat it statistically outperforms the state-of-the-art heuristic Anchors\nmethod."
    },
    {
      "id": "2411.08934v1",
      "title": "Predicting household socioeconomic position in Mozambique using satellite and household imagery",
      "summary": "Many studies have predicted SocioEconomic Position (SEP) for aggregated\nspatial units such as villages using satellite data, but SEP prediction at the\nhousehold level and other sources of imagery have not been yet explored. We\nassembled a dataset of 975 households in a semi-rural district in southern\nMozambique, consisting of self-reported asset, expenditure, and income SEP\ndata, as well as multimodal imagery including satellite images and a\nground-based photograph survey of 11 household elements. We fine-tuned a\nconvolutional neural network to extract feature vectors from the images, which\nwe then used in regression analyzes to model household SEP using different sets\nof image types. The best prediction performance was found when modeling\nasset-based SEP using random forest models with all image types, while the\nperformance for expenditure- and income-based SEP was lower. Using SHAP, we\nobserved clear differences between the images with the largest positive and\nnegative effects, as well as identified the most relevant household elements in\nthe predictions. Finally, we fitted an additional reduced model using only the\nidentified relevant household elements, which had an only slightly lower\nperformance compared to models using all images. Our results show how\nground-based household photographs allow to zoom in from an area-level to an\nindividual household prediction while minimizing the data collection effort by\nusing explainable machine learning. The developed workflow can be potentially\nintegrated into routine household surveys, where the collected household\nimagery could be used for other purposes, such as refined asset\ncharacterization and environmental exposure assessment."
    },
    {
      "id": "2411.08469v1",
      "title": "Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)",
      "summary": "Growing concerns over the lack of transparency in AI, particularly in\nhigh-stakes fields like healthcare and finance, drive the need for explainable\nand trustworthy systems. While Large Language Models (LLMs) perform\nexceptionally well in generating accurate outputs, their \"black box\" nature\nposes significant challenges to transparency and trust. To address this, the\npaper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs.\nBy leveraging domain expert knowledge, retrieval-augmented generation (RAG),\nand formal reasoning frameworks like Answer Set Programming (ASP), TranspNet\nenhances LLM outputs with structured reasoning and verification. This approach\nensures that AI systems deliver not only accurate but also explainable and\ntrustworthy results, meeting regulatory demands for transparency and\naccountability. TranspNet provides a comprehensive solution for developing AI\nsystems that are reliable and interpretable, making it suitable for real-world\napplications where trust is critical."
    },
    {
      "id": "2411.08464v1",
      "title": "Crystal Structure Generation Based On Material Properties",
      "summary": "The discovery of new materials is very important to the field of materials\nscience. When researchers explore new materials, they often have expected\nperformance requirements for their crystal structure. In recent years,\ndata-driven methods have made great progress in the direction plane of crystal\nstructure generation, but there is still a lack of methods that can effectively\nmap material properties to crystal structure. In this paper, we propose a\nCrystal DiT model to generate the crystal structure from the expected material\nproperties by embedding the material properties and combining the symmetry\ninformation predicted by the large language model. Experimental verification\nshows that our proposed method has good performance."
    },
    {
      "id": "2411.08463v1",
      "title": "Symbolic-AI-Fusion Deep Learning (SAIF-DL): Encoding Knowledge into Training with Answer Set Programming Loss Penalties by a Novel Loss Function Approach",
      "summary": "This paper presents a hybrid methodology that enhances the training process\nof deep learning (DL) models by embedding domain expert knowledge using\nontologies and answer set programming (ASP). By integrating these symbolic AI\nmethods, we encode domain-specific constraints, rules, and logical reasoning\ndirectly into the model's learning process, thereby improving both performance\nand trustworthiness. The proposed approach is flexible and applicable to both\nregression and classification tasks, demonstrating generalizability across\nvarious fields such as healthcare, autonomous systems, engineering, and battery\nmanufacturing applications. Unlike other state-of-the-art methods, the strength\nof our approach lies in its scalability across different domains. The design\nallows for the automation of the loss function by simply updating the ASP\nrules, making the system highly scalable and user-friendly. This facilitates\nseamless adaptation to new domains without significant redesign, offering a\npractical solution for integrating expert knowledge into DL models in\nindustrial settings such as battery manufacturing."
    },
    {
      "id": "2411.08460v1",
      "title": "Trap-MID: Trapdoor-based Defense against Model Inversion Attacks",
      "summary": "Model Inversion (MI) attacks pose a significant threat to the privacy of Deep\nNeural Networks by recovering training data distribution from well-trained\nmodels. While existing defenses often rely on regularization techniques to\nreduce information leakage, they remain vulnerable to recent attacks. In this\npaper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to\nmislead MI attacks. A trapdoor is integrated into the model to predict a\nspecific label when the input is injected with the corresponding trigger.\nConsequently, this trapdoor information serves as the \"shortcut\" for MI\nattacks, leading them to extract trapdoor triggers rather than private data. We\nprovide theoretical insights into the impacts of trapdoor's effectiveness and\nnaturalness on deceiving MI attacks. In addition, empirical experiments\ndemonstrate the state-of-the-art defense performance of Trap-MID against\nvarious MI attacks without the requirements for extra data or large\ncomputational overhead. Our source code is publicly available at\nhttps://github.com/ntuaislab/Trap-MID."
    },
    {
      "id": "2411.08933v1",
      "title": "Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness",
      "summary": "The remarkable advances in deep learning have led to the emergence of many\noff-the-shelf classifiers, e.g., large pre-trained models. However, since they\nare typically trained on clean data, they remain vulnerable to adversarial\nattacks. Despite this vulnerability, their superior performance and\ntransferability make off-the-shelf classifiers still valuable in practice,\ndemanding further work to provide adversarial robustness for them in a post-hoc\nmanner. A recently proposed method, denoised smoothing, leverages a denoiser\nmodel in front of the classifier to obtain provable robustness without\nadditional training. However, the denoiser often creates hallucination, i.e.,\nimages that have lost the semantics of their originally assigned class, leading\nto a drop in robustness. Furthermore, its noise-and-denoise procedure\nintroduces a significant distribution shift from the original distribution,\ncausing the denoised smoothing framework to achieve sub-optimal robustness. In\nthis paper, we introduce Fine-Tuning with Confidence-Aware Denoised Image\nSelection (FT-CADIS), a novel fine-tuning scheme to enhance the certified\nrobustness of off-the-shelf classifiers. FT-CADIS is inspired by the\nobservation that the confidence of off-the-shelf classifiers can effectively\nidentify hallucinated images during denoised smoothing. Based on this, we\ndevelop a confidence-aware training objective to handle such hallucinated\nimages and improve the stability of fine-tuning from denoised images. In this\nway, the classifier can be fine-tuned using only images that are beneficial for\nadversarial robustness. We also find that such a fine-tuning can be done by\nupdating a small fraction of parameters of the classifier. Extensive\nexperiments demonstrate that FT-CADIS has established the state-of-the-art\ncertified robustness among denoised smoothing methods across all\n$\\ell_2$-adversary radius in various benchmarks."
    },
    {
      "id": "2411.08449v1",
      "title": "Towards Evaluating Large Language Models for Graph Query Generation",
      "summary": "Large Language Models (LLMs) are revolutionizing the landscape of Generative\nArtificial Intelligence (GenAI), with innovative LLM-backed solutions emerging\nrapidly. However, when applied to database technologies, specifically query\ngeneration for graph databases and Knowledge Graphs (KGs), LLMs still face\nsignificant challenges. While research on LLM-driven query generation for\nStructured Query Language (SQL) exists, similar systems for graph databases\nremain underdeveloped. This paper presents a comparative study addressing the\nchallenge of generating Cypher queries a powerful language for interacting with\ngraph databases using open-access LLMs. We rigorously evaluate several LLM\nagents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a\nlocally deployed Llama 3.1 8B) using a designed few-shot learning prompt and\nRetrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)\nreasoning. Our empirical analysis of query generation accuracy reveals that\nClaude Sonnet 3.5 outperforms its counterparts in this specific domain.\nFurther, we highlight promising future research directions to address the\nidentified limitations and advance LLM-driven query generation for graph\ndatabases."
    },
    {
      "id": "2411.08447v1",
      "title": "Learning Dynamic Cognitive Map with Autonomous Navigation",
      "summary": "Inspired by animal navigation strategies, we introduce a novel computational\nmodel to navigate and map a space rooted in biologically inspired principles.\nAnimals exhibit extraordinary navigation prowess, harnessing memory,\nimagination, and strategic decision-making to traverse complex and aliased\nenvironments adeptly. Our model aims to replicate these capabilities by\nincorporating a dynamically expanding cognitive map over predicted poses within\nan Active Inference framework, enhancing our agent's generative model\nplasticity to novelty and environmental changes. Through structure learning and\nactive inference navigation, our model demonstrates efficient exploration and\nexploitation, dynamically expanding its model capacity in response to\nanticipated novel un-visited locations and updating the map given new evidence\ncontradicting previous beliefs. Comparative analyses in mini-grid environments\nwith the Clone-Structured Cognitive Graph model (CSCG), which shares similar\nobjectives, highlight our model's ability to rapidly learn environmental\nstructures within a single episode, with minimal navigation overlap. Our model\nachieves this without prior knowledge of observation and world dimensions,\nunderscoring its robustness and efficacy in navigating intricate environments."
    },
    {
      "id": "2411.08443v1",
      "title": "Machine Unlearning on Pre-trained Models by Residual Feature Alignment Using LoRA",
      "summary": "Machine unlearning is new emerged technology that removes a subset of the\ntraining data from a trained model without affecting the model performance on\nthe remaining data. This topic is becoming increasingly important in protecting\nuser privacy and eliminating harmful or outdated data. The key challenge lies\nin effectively and efficiently unlearning specific information without\ncompromising the model's utility on the retained data. For the pre-trained\nmodels, fine-tuning is an important way to achieve the unlearning target.\nPrevious work typically fine-tuned the entire model's parameters, which incurs\nsignificant computation costs. In addition, the fine-tuning process may cause\nshifts in the intermediate layer features, affecting the model's overall\nutility. In this work, we propose a novel and efficient machine unlearning\nmethod on pre-trained models. We term the method as Residual Feature Alignment\nUnlearning. Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose\nthe model's intermediate features into pre-trained features and residual\nfeatures. By adjusting the residual features, we align the unlearned model with\nthe pre-trained model at the intermediate feature level to achieve both\nunlearning and remaining targets. The method aims to learn the zero residuals\non the retained set and shifted residuals on the unlearning set. Extensive\nexperiments on numerous datasets validate the effectiveness of our approach."
    },
    {
      "id": "2411.08438v1",
      "title": "Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data",
      "summary": "Given the growing trend of many organizations integrating Retrieval Augmented\nGeneration (RAG) into their operations, we assess RAG on domain-specific data\nand test state-of-the-art models across various optimization techniques. We\nincorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble\nRetriever, and In-Context-Learning, to enhance the functionality and\nperformance in the academic domain. We focus on data retrieval, specifically\ntargeting various study programs at a large technical university. We\nadditionally introduce a novel evaluation approach, the RAG Confusion Matrix\ndesigned to assess the effectiveness of various configurations within the RAG\nframework. By exploring the integration of both open-source (e.g., Llama2,\nMistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer\nvaluable insights into the application and optimization of RAG frameworks in\ndomain-specific contexts. Our experiments show a significant performance\nincrease when including multi-query in the retrieval phase."
    },
    {
      "id": "2411.08433v1",
      "title": "3D Multi-Object Tracking with Semi-Supervised GRU-Kalman Filter",
      "summary": "3D Multi-Object Tracking (MOT), a fundamental component of environmental\nperception, is essential for intelligent systems like autonomous driving and\nrobotic sensing. Although Tracking-by-Detection frameworks have demonstrated\nexcellent performance in recent years, their application in real-world\nscenarios faces significant challenges. Object movement in complex environments\nis often highly nonlinear, while existing methods typically rely on linear\napproximations of motion. Furthermore, system noise is frequently modeled as a\nGaussian distribution, which fails to capture the true complexity of the noise\ndynamics. These oversimplified modeling assumptions can lead to significant\nreductions in tracking precision. To address this, we propose a GRU-based MOT\nmethod, which introduces a learnable Kalman filter into the motion module. This\napproach is able to learn object motion characteristics through data-driven\nlearning, thereby avoiding the need for manual model design and model error. At\nthe same time, to avoid abnormal supervision caused by the wrong association\nbetween annotations and trajectories, we design a semi-supervised learning\nstrategy to accelerate the convergence speed and improve the robustness of the\nmodel. Evaluation experiment on the nuScenes and Argoverse2 datasets\ndemonstrates that our system exhibits superior performance and significant\npotential compared to traditional TBD methods."
    },
    {
      "id": "2411.08432v1",
      "title": "One STEP at a time: Language Agents are Stepwise Planners",
      "summary": "Language agents have shown promising adaptability in dynamic environments to\nperform complex tasks. However, despite the versatile knowledge embedded in\nlarge language models, these agents still fall short when it comes to tasks\nthat require planning. We introduce STEP, a novel framework designed to\nefficiently learn from previous experiences to enhance the planning\ncapabilities of language agents in future steps. Concretely, STEP functions\nthrough four interconnected components. First, the Planner takes on the task,\nbreaks it down into subtasks and provides relevant insights. Then the Executor\ngenerates action candidates, while the Evaluator ensures the actions align with\nlearned rules from previous experiences. Lastly, Memory stores experiences to\ninform future decisions. In the ScienceWorld benchmark, our results show that\nSTEP consistently outperforms state-of-the-art models, achieving an overall\nscore of 67.4 and successfully completing 12 out of 18 tasks. These findings\nhighlight STEP's potential as a framework for enhancing planning capabilities\nin language agents, paving the way for more sophisticated task-solving in\ndynamic environments."
    },
    {
      "id": "2411.08425v1",
      "title": "Properties of fairness measures in the context of varying class imbalance and protected group ratios",
      "summary": "Society is increasingly relying on predictive models in fields like criminal\njustice, credit risk management, or hiring. To prevent such automated systems\nfrom discriminating against people belonging to certain groups, fairness\nmeasures have become a crucial component in socially relevant applications of\nmachine learning. However, existing fairness measures have been designed to\nassess the bias between predictions for protected groups without considering\nthe imbalance in the classes of the target variable. Current research on the\npotential effect of class imbalance on fairness focuses on practical\napplications rather than dataset-independent measure properties. In this paper,\nwe study the general properties of fairness measures for changing class and\nprotected group proportions. For this purpose, we analyze the probability mass\nfunctions of six of the most popular group fairness measures. We also measure\nhow the probability of achieving perfect fairness changes for varying class\nimbalance ratios. Moreover, we relate the dataset-independent properties of\nfairness measures described in this paper to classifier fairness in real-life\ntasks. Our results show that measures such as Equal Opportunity and Positive\nPredictive Parity are more sensitive to changes in class imbalance than\nAccuracy Equality. These findings can help guide researchers and practitioners\nin choosing the most appropriate fairness measures for their classification\nproblems."
    },
    {
      "id": "2411.08424v1",
      "title": "A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis",
      "summary": "Brain connectivity alternations associated with brain disorders have been\nwidely reported in resting-state functional imaging (rs-fMRI) and diffusion\ntensor imaging (DTI). While many dual-modal fusion methods based on graph\nneural networks (GNNs) have been proposed, they generally follow homogenous\nfusion ways ignoring rich heterogeneity of dual-modal information. To address\nthis issue, we propose a novel method that integrates functional and structural\nconnectivity based on heterogeneous graph neural networks (HGNNs) to better\nleverage the rich heterogeneity in dual-modal images. We firstly use blood\noxygen level dependency and whiter matter structure information provided by\nrs-fMRI and DTI to establish homo-meta-path, capturing node relationships\nwithin the same modality. At the same time, we propose to establish\nhetero-meta-path based on structure-function coupling and brain community\nsearching to capture relations among cross-modal nodes. Secondly, we further\nintroduce a heterogeneous graph pooling strategy that automatically balances\nhomo- and hetero-meta-path, effectively leveraging heterogeneous information\nand preventing feature confusion after pooling. Thirdly, based on the\nflexibility of heterogeneous graphs, we propose a heterogeneous graph data\naugmentation approach that can conveniently address the sample imbalance issue\ncommonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset\nfor mild cognitive impairment (MCI) diagnosis. Experimental results indicate\nthe proposed method is effective and superior to other algorithms, with a mean\nclassification accuracy of 93.3%."
    },
    {
      "id": "2411.08418v1",
      "title": "Enhanced Classroom Dialogue Sequences Analysis with a Hybrid AI Agent: Merging Expert Rule-Base with Large Language Models",
      "summary": "Classroom dialogue plays a crucial role in fostering student engagement and\ndeeper learning. However, analysing dialogue sequences has traditionally relied\non either theoretical frameworks or empirical descriptions of practice, with\nlimited integration between the two. This study addresses this gap by\ndeveloping a comprehensive rule base of dialogue sequences and an Artificial\nIntelligence (AI) agent that combines expert-informed rule-based systems with a\nlarge language model (LLM). The agent applies expert knowledge while adapting\nto the complexities of natural language, enabling accurate and flexible\ncategorisation of classroom dialogue sequences. By synthesising findings from\nover 30 studies, we established a comprehensive framework for dialogue\nanalysis. The agent was validated against human expert coding, achieving high\nlevels of precision and reliability. The results demonstrate that the agent\nprovides theory-grounded and adaptive functions, tremendously enhancing the\nefficiency and scalability of classroom dialogue analysis, offering significant\npotential in improving classroom teaching practices and supporting teacher\nprofessional development."
    },
    {
      "id": "2411.08414v1",
      "title": "Material Property Prediction with Element Attribute Knowledge Graphs and Multimodal Representation Learning",
      "summary": "Machine learning has become a crucial tool for predicting the properties of\ncrystalline materials. However, existing methods primarily represent material\ninformation by constructing multi-edge graphs of crystal structures, often\noverlooking the chemical and physical properties of elements (such as atomic\nradius, electronegativity, melting point, and ionization energy), which have a\nsignificant impact on material performance. To address this limitation, we\nfirst constructed an element property knowledge graph and utilized an embedding\nmodel to encode the element attributes within the knowledge graph. Furthermore,\nwe propose a multimodal fusion framework, ESNet, which integrates element\nproperty features with crystal structure features to generate joint multimodal\nrepresentations. This provides a more comprehensive perspective for predicting\nthe performance of crystalline materials, enabling the model to consider both\nmicrostructural composition and chemical characteristics of the materials. We\nconducted experiments on the Materials Project benchmark dataset, which showed\nleading performance in the bandgap prediction task and achieved results on a\npar with existing benchmarks in the formation energy prediction task."
    },
    {
      "id": "2411.08409v1",
      "title": "DiVR: incorporating context from diverse VR scenes for human trajectory prediction",
      "summary": "Virtual environments provide a rich and controlled setting for collecting\ndetailed data on human behavior, offering unique opportunities for predicting\nhuman trajectories in dynamic scenes. However, most existing approaches have\noverlooked the potential of these environments, focusing instead on static\ncontexts without considering userspecific factors. Employing the CREATTIVE3D\ndataset, our work models trajectories recorded in virtual reality (VR) scenes\nfor diverse situations including road-crossing tasks with user interactions and\nsimulated visual impairments. We propose Diverse Context VR Human Motion\nPrediction (DiVR), a cross-modal transformer based on the Perceiver\narchitecture that integrates both static and dynamic scene context using a\nheterogeneous graph convolution network. We conduct extensive experiments\ncomparing DiVR against existing architectures including MLP, LSTM, and\ntransformers with gaze and point cloud context. Additionally, we also stress\ntest our model's generalizability across different users, tasks, and scenes.\nResults show that DiVR achieves higher accuracy and adaptability compared to\nother models and to static graphs. This work highlights the advantages of using\nVR datasets for context-aware human trajectory modeling, with potential\napplications in enhancing user experiences in the metaverse. Our source code is\npublicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model."
    },
    {
      "id": "2411.08404v1",
      "title": "Quantifying Qualitative Insights: Leveraging LLMs to Market Predict",
      "summary": "Recent advancements in Large Language Models (LLMs) have the potential to\ntransform financial analytics by integrating numerical and textual data.\nHowever, challenges such as insufficient context when fusing multimodal\ninformation and the difficulty in measuring the utility of qualitative outputs,\nwhich LLMs generate as text, have limited their effectiveness in tasks such as\nfinancial forecasting. This study addresses these challenges by leveraging\ndaily reports from securities firms to create high-quality contextual\ninformation. The reports are segmented into text-based key factors and combined\nwith numerical data, such as price information, to form context sets. By\ndynamically updating few-shot examples based on the query time, the sets\nincorporate the latest information, forming a highly relevant set closely\naligned with the query point. Additionally, a crafted prompt is designed to\nassign scores to the key factors, converting qualitative insights into\nquantitative results. The derived scores undergo a scaling process,\ntransforming them into real-world values that are used for prediction. Our\nexperiments demonstrate that LLMs outperform time-series models in market\nforecasting, though challenges such as imperfect reproducibility and limited\nexplainability remain."
    },
    {
      "id": "2411.08400v1",
      "title": "BAMAX: Backtrack Assisted Multi-Agent Exploration using Reinforcement Learning",
      "summary": "Autonomous robots collaboratively exploring an unknown environment is still\nan open problem. The problem has its roots in coordination among non-stationary\nagents, each with only a partial view of information. The problem is compounded\nwhen the multiple robots must completely explore the environment. In this\npaper, we introduce Backtrack Assisted Multi-Agent Exploration using\nReinforcement Learning (BAMAX), a method for collaborative exploration in\nmulti-agent systems which attempts to explore an entire virtual environment. As\nin the name, BAMAX leverages backtrack assistance to enhance the performance of\nagents in exploration tasks. To evaluate BAMAX against traditional approaches,\nwe present the results of experiments conducted across multiple hexagonal\nshaped grids sizes, ranging from 10x10 to 60x60. The results demonstrate that\nBAMAX outperforms other methods in terms of faster coverage and less\nbacktracking across these environments."
    },
    {
      "id": "2411.08397v1",
      "title": "CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision",
      "summary": "This paper proposes a foundation model called \"CLaSP\" that can search time\nseries signals using natural language that describes the characteristics of the\nsignals as queries. Previous efforts to represent time series signal data in\nnatural language have had challenges in designing a conventional class of time\nseries signal characteristics, formulating their quantification, and creating a\ndictionary of synonyms. To overcome these limitations, the proposed method\nintroduces a neural network based on contrastive learning. This network is\nfirst trained using the datasets TRUCE and SUSHI, which consist of time series\nsignals and their corresponding natural language descriptions. Previous studies\nhave proposed vocabularies that data analysts use to describe signal\ncharacteristics, and SUSHI was designed to cover these terms. We believe that a\nneural network trained on these datasets will enable data analysts to search\nusing natural language vocabulary. Furthermore, our method does not require a\ndictionary of predefined synonyms, and it leverages common sense knowledge\nembedded in a large-scale language model (LLM). Experimental results\ndemonstrate that CLaSP enables natural language search of time series signal\ndata and can accurately learn the points at which signal data changes."
    },
    {
      "id": "2411.08392v1",
      "title": "RLInspect: An Interactive Visual Approach to Assess Reinforcement Learning Algorithm",
      "summary": "Reinforcement Learning (RL) is a rapidly growing area of machine learning\nthat finds its application in a broad range of domains, from finance and\nhealthcare to robotics and gaming. Compared to other machine learning\ntechniques, RL agents learn from their own experiences using trial and error,\nand improve their performance over time. However, assessing RL models can be\nchallenging, which makes it difficult to interpret their behaviour. While\nreward is a widely used metric to evaluate RL models, it may not always provide\nan accurate measure of training performance. In some cases, the reward may seem\nincreasing while the model's performance is actually decreasing, leading to\nmisleading conclusions about the effectiveness of the training. To overcome\nthis limitation, we have developed RLInspect - an interactive visual analytic\ntool, that takes into account different components of the RL model - state,\naction, agent architecture and reward, and provides a more comprehensive view\nof the RL training. By using RLInspect, users can gain insights into the\nmodel's behaviour, identify issues during training, and potentially correct\nthem effectively, leading to a more robust and reliable RL system."
    },
    {
      "id": "2411.08384v1",
      "title": "Interpretable Syntactic Representations Enable Hierarchical Word Vectors",
      "summary": "The distributed representations currently used are dense and uninterpretable,\nleading to interpretations that themselves are relative, overcomplete, and hard\nto interpret. We propose a method that transforms these word vectors into\nreduced syntactic representations. The resulting representations are compact\nand interpretable allowing better visualization and comparison of the word\nvectors and we successively demonstrate that the drawn interpretations are in\nline with human judgment. The syntactic representations are then used to create\nhierarchical word vectors using an incremental learning approach similar to the\nhierarchical aspect of human learning. As these representations are drawn from\npre-trained vectors, the generation process and learning approach are\ncomputationally efficient. Most importantly, we find out that syntactic\nrepresentations provide a plausible interpretation of the vectors and\nsubsequent hierarchical vectors outperform the original vectors in benchmark\ntests."
    },
    {
      "id": "2411.08378v1",
      "title": "Physics Informed Distillation for Diffusion Models",
      "summary": "Diffusion models have recently emerged as a potent tool in generative\nmodeling. However, their inherent iterative nature often results in sluggish\nimage generation due to the requirement for multiple model evaluations. Recent\nprogress has unveiled the intrinsic link between diffusion models and\nProbability Flow Ordinary Differential Equations (ODEs), thus enabling us to\nconceptualize diffusion models as ODE systems. Simultaneously, Physics Informed\nNeural Networks (PINNs) have substantiated their effectiveness in solving\nintricate differential equations through implicit modeling of their solutions.\nBuilding upon these foundational insights, we introduce Physics Informed\nDistillation (PID), which employs a student model to represent the solution of\nthe ODE system corresponding to the teacher diffusion model, akin to the\nprinciples employed in PINNs. Through experiments on CIFAR 10 and ImageNet\n64x64, we observe that PID achieves performance comparable to recent\ndistillation methods. Notably, it demonstrates predictable trends concerning\nmethod-specific hyperparameters and eliminates the need for synthetic dataset\ngeneration during the distillation process. Both of which contribute to its\neasy-to-use nature as a distillation approach for Diffusion Models. Our code\nand pre-trained checkpoint are publicly available at:\nhttps://github.com/pantheon5100/pid_diffusion.git."
    },
    {
      "id": "2411.08375v1",
      "title": "Developing an Effective Training Dataset to Enhance the Performance of AI-based Speaker Separation Systems",
      "summary": "This paper addresses the challenge of speaker separation, which remains an\nactive research topic despite the promising results achieved in recent years.\nThese results, however, often degrade in real recording conditions due to the\npresence of noise, echo, and other interferences. This is because neural models\nare typically trained on synthetic datasets consisting of mixed audio signals\nand their corresponding ground truths, which are generated using computer\nsoftware and do not fully represent the complexities of real-world recording\nscenarios. The lack of realistic training sets for speaker separation remains a\nmajor hurdle, as obtaining individual sounds from mixed audio signals is a\nnontrivial task. To address this issue, we propose a novel method for\nconstructing a realistic training set that includes mixture signals and\ncorresponding ground truths for each speaker. We evaluate this dataset on a\ndeep learning model and compare it to a synthetic dataset. We got a 1.65 dB\nimprovement in Scale Invariant Signal to Distortion Ratio (SI-SDR) for speaker\nseparation accuracy in realistic mixing. Our findings highlight the potential\nof realistic training sets for enhancing the performance of speaker separation\nmodels in real-world scenarios."
    },
    {
      "id": "2411.08374v1",
      "title": "Federated Graph Learning with Graphless Clients",
      "summary": "Federated Graph Learning (FGL) is tasked with training machine learning\nmodels, such as Graph Neural Networks (GNNs), for multiple clients, each with\nits own graph data. Existing methods usually assume that each client has both\nnode features and graph structure of its graph data. In real-world scenarios,\nhowever, there exist federated systems where only a part of the clients have\nsuch data while other clients (i.e. graphless clients) may only have node\nfeatures. This naturally leads to a novel problem in FGL: how to jointly train\na model over distributed graph data with graphless clients? In this paper, we\npropose a novel framework FedGLS to tackle the problem in FGL with graphless\nclients. In FedGLS, we devise a local graph learner on each graphless client\nwhich learns the local graph structure with the structure knowledge transferred\nfrom other clients. To enable structure knowledge transfer, we design a GNN\nmodel and a feature encoder on each client. During local training, the feature\nencoder retains the local graph structure knowledge together with the GNN model\nvia knowledge distillation, and the structure knowledge is transferred among\nclients in global update. Our extensive experiments demonstrate the superiority\nof the proposed FedGLS over five baselines."
    },
    {
      "id": "2411.08370v1",
      "title": "A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants",
      "summary": "Early fault detection and timely maintenance scheduling can significantly\nmitigate operational risks in NPPs and enhance the reliability of operator\ndecision-making. Therefore, it is necessary to develop an efficient Prognostics\nand Health Management (PHM) multi-step prediction model for predicting of\nsystem health status and prompt execution of maintenance operations. In this\nstudy, we propose a novel predictive model that integrates reinforcement\nlearning with Long Short-Term Memory (LSTM) neural networks and the Expert\nFuzzy Evaluation Method. The model is validated using parameter data for 20\ndifferent breach sizes in the Main Steam Line Break (MSLB) accident condition\nof the CPR1000 pressurized water reactor simulation model and it demonstrates a\nremarkable capability in accurately forecasting NPP parameter changes up to 128\nsteps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds),\nthereby satisfying the temporal advance requirement for fault prognostics in\nNPPs. Furthermore, this method provides an effective reference solution for PHM\napplications such as anomaly detection and remaining useful life prediction."
    },
    {
      "id": "2411.08367v1",
      "title": "Surprisingly Popular Voting for Concentric Rank-Order Models",
      "summary": "An important problem on social information sites is the recovery of ground\ntruth from individual reports when the experts are in the minority. The wisdom\nof the crowd, i.e. the collective opinion of a group of individuals fails in\nsuch a scenario. However, the surprisingly popular (SP)\nalgorithm~\\cite{prelec2017solution} can recover the ground truth even when the\nexperts are in the minority, by asking the individuals to report additional\nprediction reports--their beliefs about the reports of others. Several recent\nworks have extended the surprisingly popular algorithm to an equivalent voting\nrule (SP-voting) to recover the ground truth ranking over a set of $m$\nalternatives. However, we are yet to fully understand when SP-voting can\nrecover the ground truth ranking, and if so, how many samples (votes and\npredictions) it needs. We answer this question by proposing two rank-order\nmodels and analyzing the sample complexity of SP-voting under these models. In\nparticular, we propose concentric mixtures of Mallows and Plackett-Luce models\nwith $G (\\ge 2)$ groups. Our models generalize previously proposed concentric\nmixtures of Mallows models with $2$ groups, and we highlight the importance of\n$G > 2$ groups by identifying three distinct groups (expert, intermediate, and\nnon-expert) from existing datasets. Next, we provide conditions on the\nparameters of the underlying models so that SP-voting can recover ground-truth\nrankings with high probability, and also derive sample complexities under the\nsame. We complement the theoretical results by evaluating SP-voting on\nsimulated and real datasets."
    },
    {
      "id": "2411.08360v1",
      "title": "Coverage Analysis for Digital Cousin Selection -- Improving Multi-Environment Q-Learning",
      "summary": "Q-learning is widely employed for optimizing various large-dimensional\nnetworks with unknown system dynamics. Recent advancements include\nmulti-environment mixed Q-learning (MEMQ) algorithms, which utilize multiple\nindependent Q-learning algorithms across multiple, structurally related but\ndistinct environments and outperform several state-of-the-art Q-learning\nalgorithms in terms of accuracy, complexity, and robustness. We herein conduct\na comprehensive probabilistic coverage analysis to ensure optimal data coverage\nconditions for MEMQ algorithms. First, we derive upper and lower bounds on the\nexpectation and variance of different coverage coefficients (CC) for MEMQ\nalgorithms. Leveraging these bounds, we develop a simple way of comparing the\nutilities of multiple environments in MEMQ algorithms. This approach appears to\nbe near optimal versus our previously proposed partial ordering approach. We\nalso present a novel CC-based MEMQ algorithm to improve the accuracy and\ncomplexity of existing MEMQ algorithms. Numerical experiments are conducted\nusing random network graphs with four different graph properties. Our algorithm\ncan reduce the average policy error (APE) by 65% compared to partial ordering\nand is 95% faster than the exhaustive search. It also achieves 60% less APE\nthan several state-of-the-art reinforcement learning and prior MEMQ algorithms.\nAdditionally, we numerically verify the theoretical results and show their\nscalability with the action-space size."
    },
    {
      "id": "2411.08355v1",
      "title": "Communication Efficient Decentralization for Smoothed Online Convex Optimization",
      "summary": "We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem,\nwhere $N$ agents interact through a communication graph. In each round, each\nagent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online\nfashion and selects an action $x^i_t \\in \\mathbb{R}^d$. The objective is to\nminimize the global cumulative cost, which includes the sum of individual\nhitting costs $f^i_t(x^i_t)$, a temporal \"switching cost\" for changing\ndecisions, and a spatial \"dissimilarity cost\" that penalizes deviations in\ndecisions among neighboring agents. We propose the first decentralized\nalgorithm for multi-agent SOCO and prove its asymptotic optimality. Our\napproach allows each agent to operate using only local information from its\nimmediate neighbors in the graph. For finite-time performance, we establish\nthat the optimality gap in competitive ratio decreases with the time horizon\n$T$ and can be conveniently tuned based on the per-round computation available\nto each agent. Moreover, our results hold even when the communication graph\nchanges arbitrarily and adaptively over time. Finally, we establish that the\ncomputational complexity per round depends only logarithmically on the number\nof agents and almost linearly on their degree within the graph, ensuring\nscalability for large-system implementations."
    },
    {
      "id": "2411.08348v1",
      "title": "Refining Translations with LLMs: A Constraint-Aware Iterative Prompting Approach",
      "summary": "Large language models (LLMs) have demonstrated remarkable proficiency in\nmachine translation (MT), even without specific training on the languages in\nquestion. However, translating rare words in low-resource or domain-specific\ncontexts remains challenging for LLMs. To address this issue, we propose a\nmulti-step prompt chain that enhances translation faithfulness by prioritizing\nkey terms crucial for semantic accuracy. Our method first identifies these\nkeywords and retrieves their translations from a bilingual dictionary,\nintegrating them into the LLM's context using Retrieval-Augmented Generation\n(RAG). We further mitigate potential output hallucinations caused by long\nprompts through an iterative self-checking mechanism, where the LLM refines its\ntranslations based on lexical and semantic constraints. Experiments using Llama\nand Qwen as base models on the FLORES-200 and WMT datasets demonstrate\nsignificant improvements over baselines, highlighting the effectiveness of our\napproach in enhancing translation faithfulness and robustness, particularly in\nlow-resource scenarios."
    },
    {
      "id": "2411.08347v1",
      "title": "A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users",
      "summary": "Emotion and personality are central elements in understanding human\npsychological states. Emotions reflect an individual subjective experiences,\nwhile personality reveals relatively stable behavioral and cognitive patterns.\nExisting affective computing datasets often annotate emotion and personality\ntraits separately, lacking fine-grained labeling of micro-emotions and emotion\nintensity in both single-label and multi-label classifications. Chinese emotion\ndatasets are extremely scarce, and datasets capturing Chinese user personality\ntraits are even more limited. To address these gaps, this study collected data\nfrom the major social media platform Weibo, screening 11,338 valid users from\nover 50,000 individuals with diverse MBTI personality labels and acquiring\n566,900 posts along with the user MBTI personality tags. Using the EQN method,\nwe compiled a multi-label Chinese affective computing dataset that integrates\nthe same user's personality traits with six emotions and micro-emotions, each\nannotated with intensity levels. Validation results across multiple NLP\nclassification models demonstrate the dataset strong utility. This dataset is\ndesigned to advance machine recognition of complex human emotions and provide\ndata support for research in psychology, education, marketing, finance, and\npolitics."
    },
    {
      "id": "2411.08344v1",
      "title": "Bangla Grammatical Error Detection Leveraging Transformer-based Token Classification",
      "summary": "Bangla is the seventh most spoken language by a total number of speakers in\nthe world, and yet the development of an automated grammar checker in this\nlanguage is an understudied problem. Bangla grammatical error detection is a\ntask of detecting sub-strings of a Bangla text that contain grammatical,\npunctuation, or spelling errors, which is crucial for developing an automated\nBangla typing assistant. Our approach involves breaking down the task as a\ntoken classification problem and utilizing state-of-the-art transformer-based\nmodels. Finally, we combine the output of these models and apply rule-based\npost-processing to generate a more reliable and comprehensive result. Our\nsystem is evaluated on a dataset consisting of over 25,000 texts from various\nsources. Our best model achieves a Levenshtein distance score of 1.04. Finally,\nwe provide a detailed analysis of different components of our system."
    },
    {
      "id": "2411.08341v1",
      "title": "Generative AI for Data Augmentation in Wireless Networks: Analysis, Applications, and Case Study",
      "summary": "Data augmentation is a powerful technique to mitigate data scarcity. However,\nowing to fundamental differences in wireless data structures, traditional data\naugmentation techniques may not be suitable for wireless data. Fortunately,\nGenerative Artificial Intelligence (GenAI) can be an effective alternative to\nwireless data augmentation due to its excellent data generation capability.\nThis article systemically explores the potential and effectiveness of\nGenAI-driven data augmentation in wireless networks. We first briefly review\ndata augmentation techniques, discuss their limitations in wireless networks,\nand introduce generative data augmentation, including reviewing GenAI models\nand their applications in data augmentation. We then explore the application\nprospects of GenAI-driven data augmentation in wireless networks from the\nphysical, network, and application layers, which provides a GenAI-driven data\naugmentation architecture for each application. Subsequently, we propose a\ngeneral generative diffusion model-based data augmentation framework for Wi-Fi\ngesture recognition, which uses transformer-based diffusion models to generate\nhigh-quality channel state information data. Furthermore, we develop residual\nneural network models for Wi-Fi gesture recognition to evaluate the role of\naugmented data and conduct a case study based on a real dataset. Simulation\nresults demonstrate the effectiveness of the proposed framework. Finally, we\ndiscuss research directions for generative data augmentation."
    },
    {
      "id": "2411.08335v1",
      "title": "DEEGITS: Deep Learning based Framework for Measuring Heterogenous Traffic State in Challenging Traffic Scenarios",
      "summary": "This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic State\nMeasurement), a comprehensive framework that leverages state-of-the-art\nconvolutional neural network (CNN) techniques to accurately and rapidly detect\nvehicles and pedestrians, as well as to measure traffic states in challenging\nscenarios (i.e., congestion, occlusion). In this study, we enhance the training\ndataset through data fusion, enabling simultaneous detection of vehicles and\npedestrians. Image preprocessing and augmentation are subsequently performed to\nimprove the quality and quantity of the dataset. Transfer learning is applied\non the YOLOv8 pretrained model to increase the model's capability to identify a\ndiverse array of vehicles. Optimal hyperparameters are obtained using the Grid\nSearch algorithm, with the Stochastic Gradient Descent (SGD) optimizer\noutperforming other optimizers under these settings. Extensive experimentation\nand evaluation demonstrate substantial accuracy within the detection framework,\nwith the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5\non the test set, surpassing previous benchmarks on similar datasets. The\nDeepSORT multi-object tracking algorithm is incorporated to track detected\nvehicles and pedestrians in this study. Finally, the framework is tested to\nmeasure heterogeneous traffic states in mixed traffic conditions. Two locations\nwith differing traffic compositions and congestion levels are selected: one\nmotorized-dominant location with moderate density and one\nnon-motorized-dominant location with higher density. Errors are statistically\ninsignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91\nto 0.97 for heterogeneous traffic flow and speed measurements, respectively."
    },
    {
      "id": "2411.08334v1",
      "title": "Enhancing Multimodal Query Representation via Visual Dialogues for End-to-End Knowledge Retrieval",
      "summary": "Existing multimodal retrieval systems often rely on disjointed models for\nimage comprehension, such as object detectors and caption generators, leading\nto cumbersome implementations and training processes. To overcome this\nlimitation, we propose an end-to-end retrieval system, Ret-XKnow, to endow a\ntext retriever with the ability to understand multimodal queries via dynamic\nmodality interaction. Ret-XKnow leverages a partial convolution mechanism to\nfocus on visual information relevant to the given textual query, thereby\nenhancing multimodal query representations. To effectively learn multimodal\ninteraction, we also introduce the Visual Dialogue-to-Retrieval (ViD2R) dataset\nautomatically constructed from visual dialogue datasets. Our dataset\nconstruction process ensures that the dialogues are transformed into suitable\ninformation retrieval tasks using a text retriever. We demonstrate that our\napproach not only significantly improves retrieval performance in zero-shot\nsettings but also achieves substantial improvements in fine-tuning scenarios.\nOur code is publicly available: https://github.com/yeongjoonJu/Ret_XKnow."
    },
    {
      "id": "2411.08332v1",
      "title": "Learning-Augmented Algorithms for Online Concave Packing and Convex Covering Problems",
      "summary": "Learning-augmented algorithms have been extensively studied across the\ncomputer science community in the recent years, driven by advances in machine\nlearning predictors, which can provide additional information to augment\nclassical algorithms. Such predictions are especially powerful in the context\nof online problems, where decisions have to be made without knowledge of the\nfuture, and which traditionally exhibits impossibility results bounding the\nperformance of any online algorithm. The study of learning-augmented algorithms\nthus aims to use external advice prudently, to overcome classical impossibility\nresults when the advice is accurate, and still perform comparably to the\nstate-of-the-art online algorithms even when the advice is inaccurate.\n  In this paper, we present learning-augmented algorithmic frameworks for two\nfundamental optimizations settings, extending and generalizing prior works. For\nonline packing with concave objectives, we present a simple but overarching\nstrategy that switches between the advice and the state-of-the-art online\nalgorithm. For online covering with convex objectives, we greatly extend\nprimal-dual methods for online convex covering programs by Azar et al. (FOCS\n2016) and previous learning-augmented framework for online covering linear\nprograms from the literature, to many new applications. We show that our\nalgorithms break impossibility results when the advice is accurate, while\nmaintaining comparable performance with state-of-the-art classical online\nalgorithms even when the advice is erroneous."
    },
    {
      "id": "2411.08326v1",
      "title": "Neural Conjugate Flows: Physics-informed architectures with flow structure",
      "summary": "We introduce Neural Conjugate Flows (NCF), a class of neural network\narchitectures equipped with exact flow structure. By leveraging topological\nconjugation, we prove that these networks are not only naturally isomorphic to\na continuous group, but are also universal approximators for flows of ordinary\ndifferential equation (ODEs). Furthermore, topological properties of these\nflows can be enforced by the architecture in an interpretable manner. We\ndemonstrate in numerical experiments how this topological group structure leads\nto concrete computational gains over other physics informed neural networks in\nestimating and extrapolating latent dynamics of ODEs, while training up to five\ntimes faster than other flow-based architectures."
    },
    {
      "id": "2411.08324v1",
      "title": "Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle",
      "summary": "Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of static questions without a temporal dimension. To address\nthese limitations, we propose using future event prediction as a continuous\nevaluation method to assess LLMs' temporal generalization and forecasting\nabilities. Our benchmark, Daily Oracle, automatically generates question-answer\n(QA) pairs from daily news, challenging LLMs to predict \"future\" event\noutcomes. Our findings reveal that as pre-training data becomes outdated, LLM\nperformance degrades over time. While Retrieval Augmented Generation (RAG) has\nthe potential to enhance prediction accuracy, the performance degradation\npattern persists, highlighting the need for continuous model updates."
    },
    {
      "id": "2411.08320v1",
      "title": "Responsible AI in Construction Safety: Systematic Evaluation of Large Language Models and Prompt Engineering",
      "summary": "Construction remains one of the most hazardous sectors. Recent advancements\nin AI, particularly Large Language Models (LLMs), offer promising opportunities\nfor enhancing workplace safety. However, responsible integration of LLMs\nrequires systematic evaluation, as deploying them without understanding their\ncapabilities and limitations risks generating inaccurate information, fostering\nmisplaced confidence, and compromising worker safety. This study evaluates the\nperformance of two widely used LLMs, GPT-3.5 and GPT-4o, across three\nstandardized exams administered by the Board of Certified Safety Professionals\n(BCSP). Using 385 questions spanning seven safety knowledge areas, the study\nanalyzes the models' accuracy, consistency, and reliability. Results show that\nboth models consistently exceed the BCSP benchmark, with GPT-4o achieving an\naccuracy rate of 84.6% and GPT-3.5 reaching 73.8%. Both models demonstrate\nstrengths in safety management systems and hazard identification and control,\nbut exhibit weaknesses in science, mathematics, emergency response, and fire\nprevention. An error analysis identifies four primary limitations affecting LLM\nperformance: lack of knowledge, reasoning flaws, memory issues, and calculation\nerrors. Our study also highlights the impact of prompt engineering strategies,\nwith variations in accuracy reaching 13.5% for GPT-3.5 and 7.9% for GPT-4o.\nHowever, no single prompt configuration proves universally effective. This\nresearch advances knowledge in three ways: by identifying areas where LLMs can\nsupport safety practices and where human oversight remains essential, by\noffering practical insights into improving LLM implementation through prompt\nengineering, and by providing evidence-based direction for future research and\ndevelopment. These contributions support the responsible integration of AI in\nconstruction safety management toward achieving zero injuries."
    },
    {
      "id": "2411.08314v1",
      "title": "Conditional Variable Flow Matching: Transforming Conditional Densities with Amortized Conditional Optimal Transport",
      "summary": "Forecasting stochastic nonlinear dynamical systems under the influence of\nconditioning variables is a fundamental challenge repeatedly encountered across\nthe biological and physical sciences. While flow-based models can impressively\npredict the temporal evolution of probability distributions representing\npossible outcomes of a specific process, existing frameworks cannot\nsatisfactorily account for the impact of conditioning variables on these\ndynamics. Amongst several limitations, existing methods require training data\nwith paired conditions and are developed for discrete conditioning variables.\nWe propose Conditional Variable Flow Matching (CVFM), a framework for learning\nflows transforming conditional distributions with amortization across\ncontinuous conditioning variables - permitting predictions across the\nconditional density manifold. This is accomplished through several novel\nadvances, in particular, simultaneous sample conditioned flows over the main\nand conditioning variables, alongside a conditional Wasserstein distance and\nkernel facilitating conditional optimal transport. Collectively, these advances\nallow for learning system dynamics provided measurement data whose states and\nconditioning variables are not in correspondence. We demonstrate CVFM on a\nsuite of increasingly challenging problems, including discrete and continuous\nconditional mapping benchmarks, image-to-image domain transfer, and modeling\nthe temporal evolution of materials internal structure during manufacturing\nprocesses. We observe that CVFM results in improved performance and convergence\ncharacteristics over alternative conditional variants."
    },
    {
      "id": "2411.08932v1",
      "title": "PyGen: A Collaborative Human-AI Approach to Python Package Creation",
      "summary": "The principles of automation and innovation serve as foundational elements\nfor advancement in contemporary science and technology. Here, we introduce\nPygen, an automation platform designed to empower researchers, technologists,\nand hobbyists to bring abstract ideas to life as core, usable software tools\nwritten in Python. Pygen leverages the immense power of autoregressive large\nlanguage models to augment human creativity during the ideation, iteration, and\ninnovation process. By combining state-of-the-art language models with\nopen-source code generation technologies, Pygen has significantly reduced the\nmanual overhead of tool development. From a user prompt, Pygen automatically\ngenerates Python packages for a complete workflow from concept to package\ngeneration and documentation. The findings of our work show that Pygen\nconsiderably enhances the researcher's productivity by enabling the creation of\nresilient, modular, and well-documented packages for various specialized\npurposes. We employ a prompt enhancement approach to distill the user's package\ndescription into increasingly specific and actionable. While being inherently\nan open-ended task, we have evaluated the generated packages and the\ndocumentation using Human Evaluation, LLM-based evaluation, and CodeBLEU, with\ndetailed results in the results section. Furthermore, we documented our\nresults, analyzed the limitations, and suggested strategies to alleviate them.\nPygen is our vision of ethical automation, a framework that promotes\ninclusivity, accessibility, and collaborative development. This project marks\nthe beginning of a large-scale effort towards creating tools where intelligent\nagents collaborate with humans to improve scientific and technological\ndevelopment substantially.\n  Our code and generated examples are open-sourced at\n[https://github.com/GitsSaikat/Pygen]"
    },
    {
      "id": "2411.08307v1",
      "title": "PerceiverS: A Multi-Scale Perceiver with Effective Segmentation for Long-Term Expressive Symbolic Music Generation",
      "summary": "Music generation has progressed significantly, especially in the domain of\naudio generation. However, generating symbolic music that is both\nlong-structured and expressive remains a significant challenge. In this paper,\nwe propose PerceiverS (Segmentation and Scale), a novel architecture designed\nto address this issue by leveraging both Effective Segmentation and Multi-Scale\nattention mechanisms. Our approach enhances symbolic music generation by\nsimultaneously learning long-term structural dependencies and short-term\nexpressive details. By combining cross-attention and self-attention in a\nMulti-Scale setting, PerceiverS captures long-range musical structure while\npreserving performance nuances. The proposed model, evaluated on datasets like\nMaestro, demonstrates improvements in generating coherent and diverse music\nwith both structural consistency and expressive variation. The project demos\nand the generated music samples can be accessed through the link:\nhttps://perceivers.github.io."
    },
    {
      "id": "2411.08306v1",
      "title": "SDDBench: A Benchmark for Synthesizable Drug Design",
      "summary": "A significant challenge in wet lab experiments with current drug design\ngenerative models is the trade-off between pharmacological properties and\nsynthesizability. Molecules predicted to have highly desirable properties are\noften difficult to synthesize, while those that are easily synthesizable tend\nto exhibit less favorable properties. As a result, evaluating the\nsynthesizability of molecules in general drug design scenarios remains a\nsignificant challenge in the field of drug discovery. The commonly used\nsynthetic accessibility (SA) score aims to evaluate the ease of synthesizing\ngenerated molecules, but it falls short of guaranteeing that synthetic routes\ncan actually be found. Inspired by recent advances in top-down synthetic route\ngeneration, we propose a new, data-driven metric to evaluate molecule\nsynthesizability. Our approach directly assesses the feasibility of synthetic\nroutes for a given molecule through our proposed round-trip score. This novel\nmetric leverages the synergistic duality between retrosynthetic planners and\nreaction predictors, both of which are trained on extensive reaction datasets.\nTo demonstrate the efficacy of our method, we conduct a comprehensive\nevaluation of round-trip scores alongside search success rate across a range of\nrepresentative molecule generative models. Code is available at\nhttps://github.com/SongtaoLiu0823/SDDBench."
    },
    {
      "id": "2411.08302v1",
      "title": "R3HF: Reward Redistribution for Enhancing Reinforcement Learning from Human Feedback",
      "summary": "Reinforcement learning from human feedback (RLHF) provides a paradigm for\naligning large language models (LLMs) with human preferences. This involves the\ninitial training of a reward model based on pairwise human feedback. The reward\nmodel is subsequently utilized in reinforcement learning to assess the scores\nof each generated sentence as a whole, further guiding the optimization of\nLLMs. However, current approaches have a significant shortcoming: \\emph{They\nallocate a single, sparse, and delayed reward to an entire sequence of output}.\nThis may overlook some significant individual contributions of each token\ntowards the desired outcome. To overcome this limitation, our paper proposes a\nnovel reward redistribution method called R3HF, which facilitates a more\nfine-grained, token-level reward allocation. Specifically, our method treats\nthe reward prediction task of the reward model as a regression problem. As a\nresult, the redistributed rewards are computed by evaluating the specific\ncontribution of each token to the reward model's output. This detailed approach\nimproves the model's understanding of language nuances, leading to more precise\nenhancements in its performance. Our method is crafted to integrate seamlessly\nwith most current techniques while incurring minimal computational costs.\nThrough comprehensive experiments across diverse datasets and tasks, we have\nverified the effectiveness and superiority of our approach."
    },
    {
      "id": "2411.08299v1",
      "title": "DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multi-Agent Reinforcement Learning Approach",
      "summary": "Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment\ncapabilities, prompting the development of UAVs for various application\nscenarios within the Internet of Things (IoT). The unique capabilities of UAVs\ngive rise to increasingly critical and complex tasks in uncertain and\npotentially harsh environments. The substantial amount of data generated from\nthese applications necessitates processing and analysis through deep neural\nnetworks (DNNs). However, UAVs encounter challenges due to their limited\ncomputing resources when managing DNN models. This paper presents a joint\napproach that combines multiple-agent reinforcement learning (MARL) and\ngenerative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed\nat reducing latency from task capture to result output. To address these\nchallenges, we first consider the task size of the target area to be inspected\nand the shortest flying path as optimization constraints, employing a greedy\nalgorithm to resolve the subproblem with a focus on minimizing the UAV's flying\npath and the overall system cost. In the second stage, we introduce a novel DNN\ntask assignment algorithm, termed GDM-MADDPG, which utilizes the reverse\ndenoising process of GDM to replace the actor network in multi-agent deep\ndeterministic policy gradient (MADDPG). This approach generates specific DNN\ntask assignment actions based on agents' observations in a dynamic environment.\nSimulation results indicate that our algorithm performs favorably compared to\nbenchmarks in terms of path planning, Age of Information (AoI), energy\nconsumption, and task load balancing."
    },
    {
      "id": "2411.08297v1",
      "title": "TowerDebias: A Novel Debiasing Method based on the Tower Property",
      "summary": "Decision-making processes have increasingly come to rely on sophisticated\nmachine learning tools, raising concerns about the fairness of their\npredictions with respect to any sensitive groups. The widespread use of\ncommercial black-box machine learning models necessitates careful consideration\nof their legal and ethical implications on consumers. In situations where users\nhave access to these \"black-box\" models, a key question emerges: how can we\nmitigate or eliminate the influence of sensitive attributes, such as race or\ngender? We propose towerDebias (tDB), a novel approach designed to reduce the\ninfluence of sensitive variables in predictions made by black-box models. Using\nthe Tower Property from probability theory, tDB aims to improve prediction\nfairness during the post-processing stage in a manner amenable to the\nFairness-Utility Tradeoff. This method is highly flexible, requiring no prior\nknowledge of the original model's internal structure, and can be extended to a\nrange of different applications. We provide a formal improvement theorem for\ntDB and demonstrate its effectiveness in both regression and classification\ntasks, underscoring its impact on the fairness-utility tradeoff."
    },
    {
      "id": "2411.08290v1",
      "title": "RESOLVE: Relational Reasoning with Symbolic and Object-Level Features Using Vector Symbolic Processing",
      "summary": "Modern transformer-based encoder-decoder architectures struggle with\nreasoning tasks due to their inability to effectively extract relational\ninformation between input objects (data/tokens). Recent work introduced the\nAbstractor module, embedded between transformer layers, to address this gap.\nHowever, the Abstractor layer while excelling at capturing relational\ninformation (pure relational reasoning), faces challenges in tasks that require\nboth object and relational-level reasoning (partial relational reasoning). To\naddress this, we propose RESOLVE, a neuro-vector symbolic architecture that\ncombines object-level features with relational representations in\nhigh-dimensional spaces, using fast and efficient operations such as bundling\n(summation) and binding (Hadamard product) allowing both object-level features\nand relational representations to coexist within the same structure without\ninterfering with one another. RESOLVE is driven by a novel attention mechanism\nthat operates in a bipolar high dimensional space, allowing fast attention\nscore computation compared to the state-of-the-art. By leveraging this design,\nthe model achieves both low compute latency and memory efficiency. RESOLVE also\noffers better generalizability while achieving higher accuracy in purely\nrelational reasoning tasks such as sorting as well as partial relational\nreasoning tasks such as math problem-solving compared to state-of-the-art\nmethods."
    },
    {
      "id": "2411.08286v1",
      "title": "Hashing for Protein Structure Similarity Search",
      "summary": "Protein structure similarity search (PSSS), which tries to search proteins\nwith similar structures, plays a crucial role across diverse domains from drug\ndesign to protein function prediction and molecular evolution. Traditional\nalignment-based PSSS methods, which directly calculate alignment on the protein\nstructures, are highly time-consuming with high memory cost. Recently,\nalignment-free methods, which represent protein structures as fixed-length\nreal-valued vectors, are proposed for PSSS. Although these methods have lower\ntime and memory cost than alignment-based methods, their time and memory cost\nis still too high for large-scale PSSS, and their accuracy is unsatisfactory.\nIn this paper, we propose a novel method, called\n$\\underline{\\text{p}}$r$\\underline{\\text{o}}$tein\n$\\underline{\\text{s}}$tructure $\\underline{\\text{h}}$ashing (POSH), for PSSS.\nPOSH learns a binary vector representation for each protein structure, which\ncan dramatically reduce the time and memory cost for PSSS compared with\nreal-valued vector representation based methods. Furthermore, in POSH we also\npropose expressive hand-crafted features and a structure encoder to well model\nboth node and edge interactions in proteins. Experimental results on real\ndatasets show that POSH can outperform other methods to achieve\nstate-of-the-art accuracy. Furthermore, POSH achieves a memory saving of more\nthan six times and speed improvement of more than four times, compared with\nother methods."
    },
    {
      "id": "2411.08278v2",
      "title": "Knowledge Bases in Support of Large Language Models for Processing Web News",
      "summary": "Large Language Models (LLMs) have received considerable interest in wide\napplications lately. During pre-training via massive datasets, such a model\nimplicitly memorizes the factual knowledge of trained datasets in its hidden\nparameters. However, knowledge held implicitly in parameters often makes its\nuse by downstream applications ineffective due to the lack of common-sense\nreasoning. In this article, we introduce a general framework that permits to\nbuild knowledge bases with an aid of LLMs, tailored for processing Web news.\nThe framework applies a rule-based News Information Extractor (NewsIE) to news\nitems for extracting their relational tuples, referred to as knowledge bases,\nwhich are then graph-convoluted with the implicit knowledge facts of news items\nobtained by LLMs, for their classification. It involves two lightweight\ncomponents: 1) NewsIE: for extracting the structural information of every news\nitem, in the form of relational tuples; 2) BERTGraph: for graph convoluting the\nimplicit knowledge facts with relational tuples extracted by NewsIE. We have\nevaluated our framework under different news-related datasets for news category\nclassification, with promising experimental results."
    },
    {
      "id": "2411.08275v1",
      "title": "A Large-Scale Study of Relevance Assessments with Large Language Models: An Initial Look",
      "summary": "The application of large language models to provide relevance assessments\npresents exciting opportunities to advance information retrieval, natural\nlanguage processing, and beyond, but to date many unknowns remain. This paper\nreports on the results of a large-scale evaluation (the TREC 2024 RAG Track)\nwhere four different relevance assessment approaches were deployed in situ: the\n\"standard\" fully manual process that NIST has implemented for decades and three\ndifferent alternatives that take advantage of LLMs to different extents using\nthe open-source UMBRELA tool. This setup allows us to correlate system rankings\ninduced by the different approaches to characterize tradeoffs between cost and\nquality. We find that in terms of nDCG@20, nDCG@100, and Recall@100, system\nrankings induced by automatically generated relevance assessments from UMBRELA\ncorrelate highly with those induced by fully manual assessments across a\ndiverse set of 77 runs from 19 teams. Our results suggest that automatically\ngenerated UMBRELA judgments can replace fully manual judgments to accurately\ncapture run-level effectiveness. Surprisingly, we find that LLM assistance does\nnot appear to increase correlation with fully manual assessments, suggesting\nthat costs associated with human-in-the-loop processes do not bring obvious\ntangible benefits. Overall, human assessors appear to be stricter than UMBRELA\nin applying relevance criteria. Our work validates the use of LLMs in academic\nTREC-style evaluations and provides the foundation for future studies."
    },
    {
      "id": "2411.08267v1",
      "title": "Least Squares Training of Quadratic Convolutional Neural Networks with Applications to System Theory",
      "summary": "This paper provides a least squares formulation for the training of a 2-layer\nconvolutional neural network using quadratic activation functions, a 2-norm\nloss function, and no regularization term. Using this method, an analytic\nexpression for the globally optimal weights is obtained alongside a quadratic\ninput-output equation for the network. These properties make the network a\nviable tool in system theory by enabling further analysis, such as the\nsensitivity of the output to perturbations in the input, which is crucial for\nsafety-critical systems such as aircraft or autonomous vehicles.The least\nsquares method is compared to previously proposed strategies for training\nquadratic networks and to a back-propagation-trained ReLU network. The proposed\nmethod is applied to a system identification problem and a GPS position\nestimation problem. The least squares network is shown to have a significantly\nreduced training time with minimal compromises on prediction accuracy alongside\nthe advantages of having an analytic input-output equation. Although these\nresults only apply to 2-layer networks, this paper motivates the exploration of\ndeeper quadratic networks in the context of system theory."
    },
    {
      "id": "2411.08257v1",
      "title": "GPTree: Towards Explainable Decision-Making via LLM-powered Decision Trees",
      "summary": "Traditional decision tree algorithms are explainable but struggle with\nnon-linear, high-dimensional data, limiting its applicability in complex\ndecision-making. Neural networks excel at capturing complex patterns but\nsacrifice explainability in the process. In this work, we present GPTree, a\nnovel framework combining explainability of decision trees with the advanced\nreasoning capabilities of LLMs. GPTree eliminates the need for feature\nengineering and prompt chaining, requiring only a task-specific prompt and\nleveraging a tree-based structure to dynamically split samples. We also\nintroduce an expert-in-the-loop feedback mechanism to further enhance\nperformance by enabling human intervention to refine and rebuild decision\npaths, emphasizing the harmony between human expertise and machine\nintelligence. Our decision tree achieved a 7.8% precision rate for identifying\n\"unicorn\" startups at the inception stage of a startup, surpassing gpt-4o with\nfew-shot learning as well as the best human decision-makers (3.1% to 5.6%)."
    },
    {
      "id": "2411.08254v1",
      "title": "VALTEST: Automated Validation of Language Model Generated Test Cases",
      "summary": "Large Language Models (LLMs) have demonstrated significant potential in\nautomating software testing, specifically in generating unit test cases.\nHowever, the validation of LLM-generated test cases remains a challenge,\nparticularly when the ground truth is unavailable. This paper introduces\nVALTEST, a novel framework designed to automatically validate test cases\ngenerated by LLMs by leveraging token probabilities. We evaluate VALTEST using\nnine test suites generated from three datasets (HumanEval, MBPP, and LeetCode)\nacross three LLMs (GPT-4o, GPT-3.5-turbo, and LLama3.1 8b). By extracting\nstatistical features from token probabilities, we train a machine learning\nmodel to predict test case validity. VALTEST increases the validity rate of\ntest cases by 6.2% to 24%, depending on the dataset and LLM. Our results\nsuggest that token probabilities are reliable indicators for distinguishing\nbetween valid and invalid test cases, which provides a robust solution for\nimproving the correctness of LLM-generated test cases in software testing. In\naddition, we found that replacing the identified invalid test cases by VALTEST,\nusing a Chain-of-Thought prompting results in a more effective test suite while\nkeeping the high validity rates."
    },
    {
      "id": "2411.08249v1",
      "title": "Retrieval Augmented Time Series Forecasting",
      "summary": "Retrieval-augmented generation (RAG) is a central component of modern LLM\nsystems, particularly in scenarios where up-to-date information is crucial for\naccurately responding to user queries or when queries exceed the scope of the\ntraining data. The advent of time-series foundation models (TSFM), such as\nChronos, and the need for effective zero-shot forecasting performance across\nvarious time-series domains motivates the question: Do benefits of RAG\nsimilarly carry over to time series forecasting? In this paper, we advocate\nthat the dynamic and event-driven nature of time-series data makes RAG a\ncrucial component of TSFMs and introduce a principled RAG framework for\ntime-series forecasting, called Retrieval Augmented Forecasting (RAF). Within\nRAF, we develop efficient strategies for retrieving related time-series\nexamples and incorporating them into forecast. Through experiments and\nmechanistic studies, we demonstrate that RAF indeed improves the forecasting\naccuracy across diverse time series domains and the improvement is more\nsignificant for larger TSFM sizes."
    },
    {
      "id": "2411.08248v1",
      "title": "Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial Approach",
      "summary": "Deep learning underpins most of the currently advanced natural language\nprocessing (NLP) tasks such as textual classification, neural machine\ntranslation (NMT), abstractive summarization and question-answering (QA).\nHowever, the robustness of the models, particularly QA models, against\nadversarial attacks is a critical concern that remains insufficiently explored.\nThis paper introduces QA-Attack (Question Answering Attack), a novel word-level\nadversarial strategy that fools QA models. Our attention-based attack exploits\nthe customized attention mechanism and deletion ranking strategy to identify\nand target specific words within contextual passages. It creates deceptive\ninputs by carefully choosing and substituting synonyms, preserving grammatical\nintegrity while misleading the model to produce incorrect responses. Our\napproach demonstrates versatility across various question types, particularly\nwhen dealing with extensive long textual inputs. Extensive experiments on\nmultiple benchmark datasets demonstrate that QA-Attack successfully deceives\nbaseline QA models and surpasses existing adversarial techniques regarding\nsuccess rate, semantics changes, BLEU score, fluency and grammar error rate."
    },
    {
      "id": "2411.08243v1",
      "title": "Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset",
      "summary": "In an effort to mitigate the harms of large language models (LLMs), learning\nfrom human feedback (LHF) has been used to steer LLMs towards outputs that are\nintended to be both less harmful and more helpful. Despite the widespread\nadoption of LHF in practice, the quality of this feedback and its effectiveness\nas a safety mitigation technique remain unclear. This study addresses these\nissues by auditing the widely-used Helpful and Harmless (HH) dataset by\nAnthropic. Our work includes: (1) a thorough investigation of the dataset's\ncontent through both manual and automated evaluation; (2) experiments\ndemonstrating the dataset's impact on models' safety; and (3) an analysis of\nthe 100 most influential papers citing this dataset. Through our audit, we\nshowcase how conceptualization failures and quality issues identified in the HH\ndataset can create additional harms by leading to disparate safety behaviors\nacross demographic groups. Our findings highlight the need for more nuanced,\ncontext-sensitive approaches to safety mitigation in LLMs."
    },
    {
      "id": "2411.08244v1",
      "title": "NVCiM-PT: An NVCiM-assisted Prompt Tuning Framework for Edge LLMs",
      "summary": "Large Language Models (LLMs) deployed on edge devices, known as edge LLMs,\nneed to continuously fine-tune their model parameters from user-generated data\nunder limited resource constraints. However, most existing learning methods are\nnot applicable for edge LLMs because of their reliance on high resources and\nlow learning capacity. Prompt tuning (PT) has recently emerged as an effective\nfine-tuning method for edge LLMs by only modifying a small portion of LLM\nparameters, but it suffers from user domain shifts, resulting in repetitive\ntraining and losing resource efficiency. Conventional techniques to address\ndomain shift issues often involve complex neural networks and sophisticated\ntraining, which are incompatible for PT for edge LLMs. Therefore, an open\nresearch question is how to address domain shift issues for edge LLMs with\nlimited resources. In this paper, we propose a prompt tuning framework for edge\nLLMs, exploiting the benefits offered by non-volatile computing-in-memory\n(NVCiM) architectures. We introduce a novel NVCiM-assisted PT framework, where\nwe narrow down the core operations to matrix-matrix multiplication, which can\nthen be accelerated by performing in-situ computation on NVCiM. To the best of\nour knowledge, this is the first work employing NVCiM to improve the edge LLM\nPT performance."
    },
    {
      "id": "2411.08241v1",
      "title": "A Social Outcomes and Priorities centered (SOP) Framework for AI policy",
      "summary": "Rapid developments in AI and its adoption across various domains have\nnecessitated a need to build robust guardrails and risk containment plans while\nensuring equitable benefits for the betterment of society. The current\ntechnology-centered approach has resulted in a fragmented, reactive, and\nineffective policy apparatus. This paper highlights the immediate and urgent\nneed to pivot to a society-centered approach to develop comprehensive,\ncoherent, forward-looking AI policy. To this end, we present a Social Outcomes\nand Priorities centered (SOP) framework for AI policy along with proposals on\nimplementation of its various components. While the SOP framework is presented\nfrom a US-centric view, the takeaways are general and applicable globally."
    },
    {
      "id": "2411.09434v1",
      "title": "Mediffusion: Joint Diffusion for Self-Explainable Semi-Supervised Classification and Medical Image Generation",
      "summary": "We introduce Mediffusion -- a new method for semi-supervised learning with\nexplainable classification based on a joint diffusion model. The medical\nimaging domain faces unique challenges due to scarce data labelling --\ninsufficient for standard training, and critical nature of the applications\nthat require high performance, confidence, and explainability of the models. In\nthis work, we propose to tackle those challenges with a single model that\ncombines standard classification with a diffusion-based generative task in a\nsingle shared parametrisation. By sharing representations, our model\neffectively learns from both labeled and unlabeled data while at the same time\nproviding accurate explanations through counterfactual examples. In our\nexperiments, we show that our Mediffusion achieves results comparable to recent\nsemi-supervised methods while providing more reliable and precise explanations."
    },
    {
      "id": "2411.08232v1",
      "title": "Imitation Learning from Observations: An Autoregressive Mixture of Experts Approach",
      "summary": "This paper presents a novel approach to imitation learning from observations,\nwhere an autoregressive mixture of experts model is deployed to fit the\nunderlying policy. The parameters of the model are learned via a two-stage\nframework. By leveraging the existing dynamics knowledge, the first stage of\nthe framework estimates the control input sequences and hence reduces the\nproblem complexity. At the second stage, the policy is learned by solving a\nregularized maximum-likelihood estimation problem using the estimated control\ninput sequences. We further extend the learning procedure by incorporating a\nLyapunov stability constraint to ensure asymptotic stability of the identified\nmodel, for accurate multi-step predictions. The effectiveness of the proposed\nframework is validated using two autonomous driving datasets collected from\nhuman demonstrations, demonstrating its practical applicability in modelling\ncomplex nonlinear dynamics."
    },
    {
      "id": "2411.08227v1",
      "title": "DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection",
      "summary": "Out-of-distribution (OOD) detection is essential for ensuring the robustness\nof machine learning models by identifying samples that deviate from the\ntraining distribution. While traditional OOD detection has primarily focused on\nsingle-modality inputs, such as images, recent advances in multimodal models\nhave demonstrated the potential of leveraging multiple modalities (e.g., video,\noptical flow, audio) to enhance detection performance. However, existing\nmethods often overlook intra-class variability within in-distribution (ID)\ndata, assuming that samples of the same class are perfectly cohesive and\nconsistent. This assumption can lead to performance degradation, especially\nwhen prediction discrepancies are uniformly amplified across all samples. To\naddress this issue, we propose Dynamic Prototype Updating (DPU), a novel\nplug-and-play framework for multimodal OOD detection that accounts for\nintra-class variations. Our method dynamically updates class center\nrepresentations for each class by measuring the variance of similar samples\nwithin each batch, enabling adaptive adjustments. This approach allows us to\namplify prediction discrepancies based on the updated class centers, thereby\nimproving the model's robustness and generalization across different\nmodalities. Extensive experiments on two tasks, five datasets, and nine base\nOOD algorithms demonstrate that DPU significantly improves OOD detection\nperformance, setting a new state-of-the-art in multimodal OOD detection, with\nimprovements of up to 80 percent in Far-OOD detection. To facilitate\naccessibility and reproducibility, our code is publicly available on GitHub."
    },
    {
      "id": "2411.08224v1",
      "title": "Joint Diffusion models in Continual Learning",
      "summary": "In this work, we introduce JDCL - a new method for continual learning with\ngenerative rehearsal based on joint diffusion models. Neural networks suffer\nfrom catastrophic forgetting defined as abrupt loss in the model's performance\nwhen retrained with additional data coming from a different distribution.\nGenerative-replay-based continual learning methods try to mitigate this issue\nby retraining a model with a combination of new and rehearsal data sampled from\na generative model. In this work, we propose to extend this idea by combining a\ncontinually trained classifier with a diffusion-based generative model into a\nsingle - jointly optimized neural network. We show that such shared\nparametrization, combined with the knowledge distillation technique allows for\nstable adaptation to new tasks without catastrophic forgetting. We evaluate our\napproach on several benchmarks, where it outperforms recent state-of-the-art\ngenerative replay techniques. Additionally, we extend our method to the\nsemi-supervised continual learning setup, where it outperforms competing\nbuffer-based replay techniques, and evaluate, in a self-supervised manner, the\nquality of trained representations."
    },
    {
      "id": "2411.08221v1",
      "title": "SynapsNet: Enhancing Neuronal Population Dynamics Modeling via Learning Functional Connectivity",
      "summary": "The availability of large-scale neuronal population datasets necessitates new\nmethods to model population dynamics and extract interpretable, scientifically\ntranslatable insights. Existing deep learning methods often overlook the\nbiological mechanisms underlying population activity and thus exhibit\nsuboptimal performance with neuronal data and provide little to no\ninterpretable information about neurons and their interactions. In response, we\nintroduce SynapsNet, a novel deep-learning framework that effectively models\npopulation dynamics and functional interactions between neurons. Within this\nbiologically realistic framework, each neuron, characterized by a latent\nembedding, sends and receives currents through directed connections. A shared\ndecoder uses the input current, previous neuronal activity, neuron embedding,\nand behavioral data to predict the population activity in the next time step.\nUnlike common sequential models that treat population activity as a\nmultichannel time series, SynapsNet applies its decoder to each neuron\n(channel) individually, with the learnable functional connectivity serving as\nthe sole pathway for information flow between neurons. Our experiments,\nconducted on mouse cortical activity from publicly available datasets and\nrecorded using the two most common population recording modalities (Ca imaging\nand Neuropixels) across three distinct tasks, demonstrate that SynapsNet\nconsistently outperforms existing models in forecasting population activity.\nAdditionally, our experiments on both real and synthetic data showed that\nSynapsNet accurately learns functional connectivity that reveals predictive\ninteractions between neurons."
    },
    {
      "id": "2411.08212v1",
      "title": "PERFT: Parameter-Efficient Routed Fine-Tuning for Mixture-of-Expert Model",
      "summary": "The Mixture-of-Experts (MoE) paradigm has emerged as a powerful approach for\nscaling transformers with improved resource utilization. However, efficiently\nfine-tuning MoE models remains largely underexplored. Inspired by recent works\non Parameter-Efficient Fine-Tuning (PEFT), we present a unified framework for\nintegrating PEFT modules directly into the MoE mechanism. Aligning with the\ncore principles and architecture of MoE, our framework encompasses a set of\ndesign dimensions including various functional and composition strategies. By\ncombining design choices within our framework, we introduce Parameter-Efficient\nRouted Fine-Tuning (PERFT) as a flexible and scalable family of PEFT strategies\ntailored for MoE models. Extensive experiments on adapting OLMoE-1B-7B and\nMixtral-8$\\times$7B for commonsense and arithmetic reasoning tasks demonstrate\nthe effectiveness, scalability, and intriguing dynamics of PERFT. Additionally,\nwe provide empirical findings for each specific design choice to facilitate\nbetter application of MoE and PEFT."
    },
    {
      "id": "2411.08197v1",
      "title": "What Representational Similarity Measures Imply about Decodable Information",
      "summary": "Neural responses encode information that is useful for a variety of\ndownstream tasks. A common approach to understand these systems is to build\nregression models or ``decoders'' that reconstruct features of the stimulus\nfrom neural responses. Popular neural network similarity measures like centered\nkernel alignment (CKA), canonical correlation analysis (CCA), and Procrustes\nshape distance, do not explicitly leverage this perspective and instead\nhighlight geometric invariances to orthogonal or affine transformations when\ncomparing representations. Here, we show that many of these measures can, in\nfact, be equivalently motivated from a decoding perspective. Specifically,\nmeasures like CKA and CCA quantify the average alignment between optimal linear\nreadouts across a distribution of decoding tasks. We also show that the\nProcrustes shape distance upper bounds the distance between optimal linear\nreadouts and that the converse holds for representations with low participation\nratio. Overall, our work demonstrates a tight link between the geometry of\nneural representations and the ability to linearly decode information. This\nperspective suggests new ways of measuring similarity between neural systems\nand also provides novel, unifying interpretations of existing measures."
    },
    {
      "id": "2411.08195v1",
      "title": "An Explainable Machine Learning Approach for Age and Gender Estimation in Living Individuals Using Dental Biometrics",
      "summary": "Objectives: Age and gender estimation is crucial for various applications,\nincluding forensic investigations and anthropological studies. This research\naims to develop a predictive system for age and gender estimation in living\nindividuals, leveraging dental measurements such as Coronal Height (CH),\nCoronal Pulp Cavity Height (CPCH), and Tooth Coronal Index (TCI). Methods:\nMachine learning models were employed in our study, including Cat Boost\nClassifier (Catboost), Gradient Boosting Machine (GBM), Ada Boost Classifier\n(AdaBoost), Random Forest (RF), eXtreme Gradient Boosting (XGB), Light Gradient\nBoosting Machine (LGB), and Extra Trees Classifier (ETC), to analyze dental\ndata from 862 living individuals (459 males and 403 females). Specifically,\nperiapical radiographs from six teeth per individual were utilized, including\npremolars and molars from both maxillary and mandibular. A novel ensemble\nlearning technique was developed, which uses multiple models each tailored to\ndistinct dental metrics, to estimate age and gender accurately. Furthermore, an\nexplainable AI model has been created utilizing SHAP, enabling dental experts\nto make judicious decisions based on comprehensible insight. Results: The RF\nand XGB models were particularly effective, yielding the highest F1 score for\nage and gender estimation. Notably, the XGB model showed a slightly better\nperformance in age estimation, achieving an F1 score of 73.26%. A similar trend\nfor the RF model was also observed in gender estimation, achieving a F1 score\nof 77.53%. Conclusions: This study marks a significant advancement in dental\nforensic methods, showcasing the potential of machine learning to automate age\nand gender estimation processes with improved accuracy."
    },
    {
      "id": "2411.08187v1",
      "title": "TractoEmbed: Modular Multi-level Embedding framework for white matter tract segmentation",
      "summary": "White matter tract segmentation is crucial for studying brain structural\nconnectivity and neurosurgical planning. However, segmentation remains\nchallenging due to issues like class imbalance between major and minor tracts,\nstructural similarity, subject variability, symmetric streamlines between\nhemispheres etc. To address these challenges, we propose TractoEmbed, a modular\nmulti-level embedding framework, that encodes localized representations through\nlearning tasks in respective encoders. In this paper, TractoEmbed introduces a\nnovel hierarchical streamline data representation that captures maximum spatial\ninformation at each level i.e. individual streamlines, clusters, and patches.\nExperiments show that TractoEmbed outperforms state-of-the-art methods in white\nmatter tract segmentation across different datasets, and spanning various age\ngroups. The modular framework directly allows the integration of additional\nembeddings in future works."
    },
    {
      "id": "2411.08182v1",
      "title": "SCORE: Syntactic Code Representations for Static Script Malware Detection",
      "summary": "As businesses increasingly adopt cloud technologies, they also need to be\naware of new security challenges, such as server-side script attacks, to ensure\nthe integrity of their systems and data. These scripts can steal data,\ncompromise credentials, and disrupt operations. Unlike executables with\nstandardized formats (e.g., ELF, PE), scripts are plaintext files with diverse\nsyntax, making them harder to detect using traditional methods. As a result,\nmore sophisticated approaches are needed to protect cloud infrastructures from\nthese evolving threats. In this paper, we propose novel feature extraction and\ndeep learning (DL)-based approaches for static script malware detection,\ntargeting server-side threats. We extract features from plain-text code using\ntwo techniques: syntactic code highlighting (SCH) and abstract syntax tree\n(AST) construction. SCH leverages complex regexes to parse syntactic elements\nof code, such as keywords, variable names, etc. ASTs generate a hierarchical\nrepresentation of a program's syntactic structure. We then propose a sequential\nand a graph-based model that exploits these feature representations to detect\nscript malware. We evaluate our approach on more than 400K server-side scripts\nin Bash, Python and Perl. We use a balanced dataset of 90K scripts for\ntraining, validation, and testing, with the remaining from 400K reserved for\nfurther analysis. Experiments show that our method achieves a true positive\nrate (TPR) up to 81% higher than leading signature-based antivirus solutions,\nwhile maintaining a low false positive rate (FPR) of 0.17%. Moreover, our\napproach outperforms various neural network-based detectors, demonstrating its\neffectiveness in learning code maliciousness for accurate detection of script\nmalware."
    },
    {
      "id": "2411.08181v1",
      "title": "Challenges in Guardrailing Large Language Models for Science",
      "summary": "The rapid development in large language models (LLMs) has transformed the\nlandscape of natural language processing and understanding (NLP/NLU), offering\nsignificant benefits across various domains. However, when applied to\nscientific research, these powerful models exhibit critical failure modes\nrelated to scientific integrity and trustworthiness. Existing general-purpose\nLLM guardrails are insufficient to address these unique challenges in the\nscientific domain. We provide comprehensive guidelines for deploying LLM\nguardrails in the scientific domain. We identify specific challenges --\nincluding time sensitivity, knowledge contextualization, conflict resolution,\nand intellectual property concerns -- and propose a guideline framework for the\nguardrails that can align with scientific needs. These guardrail dimensions\ninclude trustworthiness, ethics & bias, safety, and legal aspects. We also\noutline in detail the implementation strategies that employ white-box,\nblack-box, and gray-box methodologies that can be enforced within scientific\ncontexts."
    },
    {
      "id": "2411.08172v1",
      "title": "Fault Localization in Deep Learning-based Software: A System-level Approach",
      "summary": "Over the past decade, Deep Learning (DL) has become an integral part of our\ndaily lives. This surge in DL usage has heightened the need for developing\nreliable DL software systems. Given that fault localization is a critical task\nin reliability assessment, researchers have proposed several fault localization\ntechniques for DL-based software, primarily focusing on faults within the DL\nmodel. While the DL model is central to DL components, there are other elements\nthat significantly impact the performance of DL components. As a result, fault\nlocalization methods that concentrate solely on the DL model overlook a large\nportion of the system. To address this, we introduce FL4Deep, a system-level\nfault localization approach considering the entire DL development pipeline to\neffectively localize faults across the DL-based systems. In an evaluation using\n100 faulty DL scripts, FL4Deep outperformed four previous approaches in terms\nof accuracy for three out of six DL-related faults, including issues related to\ndata (84%), mismatched libraries between training and deployment (100%), and\nloss function (69%). Additionally, FL4Deep demonstrated superior precision and\nrecall in fault localization for five categories of faults including three\nmentioned fault types in terms of accuracy, plus insufficient training\niteration and activation function."
    },
    {
      "id": "2411.08171v1",
      "title": "Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection",
      "summary": "Contemporary Artificial Intelligence (AI) and Machine Learning (ML) research\nplaces a significant emphasis on transfer learning, showcasing its\ntransformative potential in enhancing model performance across diverse domains.\nThis paper examines the efficiency and effectiveness of transfer learning in\nthe context of wildfire detection. Three purpose-built models -- Visual\nGeometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-Support\nVector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrained\nmodels -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101. We\ntrained and evaluated these models using a dataset that captures the\ncomplexities of wildfires, incorporating variables such as varying lighting\nconditions, time of day, and diverse terrains. The objective is to discern how\ntransfer learning performs against models trained from scratch in addressing\nthe intricacies of the wildfire detection problem. By assessing the performance\nmetrics, including accuracy, precision, recall, and F1 score, a comprehensive\nunderstanding of the advantages and disadvantages of transfer learning in this\nspecific domain is obtained. This study contributes valuable insights to the\nongoing discourse, guiding future directions in AI and ML research. Keywords:\nWildfire prediction, deep learning, machine learning fire, detection"
    },
    {
      "id": "2411.08167v1",
      "title": "Multi-Agent Stochastic Bandits Robust to Adversarial Corruptions",
      "summary": "We study the problem of multi-agent multi-armed bandits with adversarial\ncorruption in a heterogeneous setting, where each agent accesses a subset of\narms. The adversary can corrupt the reward observations for all agents. Agents\nshare these corrupted rewards with each other, and the objective is to maximize\nthe cumulative total reward of all agents (and not be misled by the adversary).\nWe propose a multi-agent cooperative learning algorithm that is robust to\nadversarial corruptions. For this newly devised algorithm, we demonstrate that\nan adversary with an unknown corruption budget $C$ only incurs an additive\n$O((L / L_{\\min}) C)$ term to the standard regret of the model in\nnon-corruption settings, where $L$ is the total number of agents, and\n$L_{\\min}$ is the minimum number of agents with mutual access to an arm. As a\nside-product, our algorithm also improves the state-of-the-art regret bounds\nwhen reducing to both the single-agent and homogeneous multi-agent scenarios,\ntightening multiplicative $K$ (the number of arms) and $L$ (the number of\nagents) factors, respectively."
    },
    {
      "id": "2411.08166v1",
      "title": "Tackling Polysemanticity with Neuron Embeddings",
      "summary": "We present neuron embeddings, a representation that can be used to tackle\npolysemanticity by identifying the distinct semantic behaviours in a neuron's\ncharacteristic dataset examples, making downstream manual or automatic\ninterpretation much easier. We apply our method to GPT2-small, and provide a UI\nfor exploring the results. Neuron embeddings are computed using a model's\ninternal representations and weights, making them domain and architecture\nagnostic and removing the risk of introducing external structure which may not\nreflect a model's actual computation. We describe how neuron embeddings can be\nused to measure neuron polysemanticity, which could be applied to better\nevaluate the efficacy of Sparse Auto-Encoders (SAEs)."
    },
    {
      "id": "2411.08165v1",
      "title": "Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion",
      "summary": "The Knowledge Graph Completion~(KGC) task aims to infer the missing entity\nfrom an incomplete triple. Existing embedding-based methods rely solely on\ntriples in the KG, which is vulnerable to specious relation patterns and\nlong-tail entities. On the other hand, text-based methods struggle with the\nsemantic gap between KG triples and natural language. Apart from triples,\nentity contexts (e.g., labels, descriptions, aliases) also play a significant\nrole in augmenting KGs. To address these limitations, we propose KGR3, a\ncontext-enriched framework for KGC. KGR3 is composed of three modules. Firstly,\nthe Retrieval module gathers supporting triples from the KG, collects plausible\ncandidate answers from a base embedding model, and retrieves context for each\nrelated entity. Then, the Reasoning module employs a large language model to\ngenerate potential answers for each query triple. Finally, the Re-ranking\nmodule combines candidate answers from the two modules mentioned above, and\nfine-tunes an LLM to provide the best answer. Extensive experiments on widely\nused datasets demonstrate that KGR3 consistently improves various KGC methods.\nSpecifically, the best variant of KGR3 achieves absolute Hits@1 improvements of\n12.3% and 5.6% on the FB15k237 and WN18RR datasets."
    },
    {
      "id": "2411.08164v1",
      "title": "EAPCR: A Universal Feature Extractor for Scientific Data without Explicit Feature Relation Patterns",
      "summary": "Conventional methods, including Decision Tree (DT)-based methods, have been\neffective in scientific tasks, such as non-image medical diagnostics, system\nanomaly detection, and inorganic catalysis efficiency prediction. However, most\ndeep-learning techniques have struggled to surpass or even match this level of\nsuccess as traditional machine-learning methods. The primary reason is that\nthese applications involve multi-source, heterogeneous data where features lack\nexplicit relationships. This contrasts with image data, where pixels exhibit\nspatial relationships; textual data, where words have sequential dependencies;\nand graph data, where nodes are connected through established associations. The\nabsence of explicit Feature Relation Patterns (FRPs) presents a significant\nchallenge for deep learning techniques in scientific applications that are not\nimage, text, and graph-based. In this paper, we introduce EAPCR, a universal\nfeature extractor designed for data without explicit FRPs. Tested across\nvarious scientific tasks, EAPCR consistently outperforms traditional methods\nand bridges the gap where deep learning models fall short. To further\ndemonstrate its robustness, we synthesize a dataset without explicit FRPs.\nWhile Kolmogorov-Arnold Network (KAN) and feature extractors like Convolutional\nNeural Networks (CNNs), Graph Convolutional Networks (GCNs), and Transformers\nstruggle, EAPCR excels, demonstrating its robustness and superior performance\nin scientific tasks without FRPs."
    },
    {
      "id": "2411.08148v1",
      "title": "Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization",
      "summary": "Pioneering advancements in artificial intelligence, especially in genAI, have\nenabled significant possibilities for content creation, but also led to\nwidespread misinformation and false content. The growing sophistication and\nrealism of deepfakes is raising concerns about privacy invasion, identity\ntheft, and has societal, business impacts, including reputational damage and\nfinancial loss. Many deepfake detectors have been developed to tackle this\nproblem. Nevertheless, as for every AI model, the deepfake detectors face the\nwrath of lack of considerable generalization to unseen scenarios and\ncross-domain deepfakes. Besides, adversarial robustness is another critical\nchallenge, as detectors drastically underperform to the slightest imperceptible\nchange. Most state-of-the-art detectors are trained on static datasets and lack\nthe ability to adapt to emerging deepfake attack trends. These three crucial\nchallenges though hold paramount importance for reliability in practise,\nparticularly in the deepfake domain, are also the problems with any other AI\napplication. This paper proposes an adversarial meta-learning algorithm using\ntask-specific adaptive sample synthesis and consistency regularization, in a\nrefinement phase. By focussing on the classifier's strengths and weaknesses, it\nboosts both robustness and generalization of the model. Additionally, the paper\nintroduces a hierarchical multi-agent retrieval-augmented generation workflow\nwith a sample synthesis module to dynamically adapt the model to new data\ntrends by generating custom deepfake samples. The paper further presents a\nframework integrating the meta-learning algorithm with the hierarchical\nmulti-agent workflow, offering a holistic solution for enhancing\ngeneralization, robustness, and adaptability. Experimental results demonstrate\nthe model's consistent performance across various datasets, outperforming the\nmodels in comparison."
    },
    {
      "id": "2411.08147v1",
      "title": "Large Language Models Can Self-Improve in Long-context Reasoning",
      "summary": "Large language models (LLMs) have achieved substantial progress in processing\nlong contexts but still struggle with long-context reasoning. Existing\napproaches typically involve fine-tuning LLMs with synthetic data, which\ndepends on annotations from human experts or advanced models like GPT-4, thus\nrestricting further advancements. To address this issue, we investigate the\npotential for LLMs to self-improve in long-context reasoning and propose \\ours,\nan approach specifically designed for this purpose. This approach is\nstraightforward: we sample multiple outputs for each question, score them with\nMinimum Bayes Risk, and then apply supervised fine-tuning or preference\noptimization based on these outputs. Extensive experiments on several leading\nLLMs demonstrate the effectiveness of \\ours, with an absolute improvement of\n$4.2$ points for Llama-3.1-8B-Instruct. Furthermore, \\ours achieves superior\nperformance compared to prior approaches that depend on data produced by human\nexperts or advanced models. We anticipate that this work will open new avenues\nfor self-improvement techniques in long-context scenarios, which are essential\nfor the continual advancement of LLMs."
    },
    {
      "id": "2411.08138v1",
      "title": "Emergent field theories from neural networks",
      "summary": "We establish a duality relation between Hamiltonian systems and neural\nnetwork-based learning systems. We show that the Hamilton-Jacobi equations for\nposition and momentum variables correspond to the equations governing the\nactivation dynamics of non-trainable variables and the learning dynamics of\ntrainable variables. The duality is then applied to model various field\ntheories using the activation and learning dynamics of neural networks. For\nKlein-Gordon fields, the corresponding weight tensor is symmetric, while for\nDirac fields, the weight tensor must contain an anti-symmetric tensor factor.\nThe dynamical components of the weight and bias tensors correspond,\nrespectively, to the temporal and spatial components of the gauge field."
    },
    {
      "id": "2411.08135v1",
      "title": "On the Role of Speech Data in Reducing Toxicity Detection Bias",
      "summary": "Text toxicity detection systems exhibit significant biases, producing\ndisproportionate rates of false positives on samples mentioning demographic\ngroups. But what about toxicity detection in speech? To investigate the extent\nto which text-based biases are mitigated by speech-based systems, we produce a\nset of high-quality group annotations for the multilingual MuTox dataset, and\nthen leverage these annotations to systematically compare speech- and\ntext-based toxicity classifiers. Our findings indicate that access to speech\ndata during inference supports reduced bias against group mentions,\nparticularly for ambiguous and disagreement-inducing samples. Our results also\nsuggest that improving classifiers, rather than transcription pipelines, is\nmore helpful for reducing group bias. We publicly release our annotations and\nprovide recommendations for future toxicity dataset construction."
    },
    {
      "id": "2411.08133v1",
      "title": "Impactful Bit-Flip Search on Full-precision Models",
      "summary": "Neural networks have shown remarkable performance in various tasks, yet they\nremain susceptible to subtle changes in their input or model parameters. One\nparticularly impactful vulnerability arises through the Bit-Flip Attack (BFA),\nwhere flipping a small number of critical bits in a model's parameters can\nseverely degrade its performance. A common technique for inducing bit flips in\nDRAM is the Row-Hammer attack, which exploits frequent uncached memory accesses\nto alter data. Identifying susceptible bits can be achieved through exhaustive\nsearch or progressive layer-by-layer analysis, especially in quantized\nnetworks. In this work, we introduce Impactful Bit-Flip Search (IBS), a novel\nmethod for efficiently pinpointing and flipping critical bits in full-precision\nnetworks. Additionally, we propose a Weight-Stealth technique that\nstrategically modifies the model's parameters in a way that maintains the float\nvalues within the original distribution, thereby bypassing simple range checks\noften used in tamper detection."
    },
    {
      "id": "2411.08126v1",
      "title": "A Tale of Two Cities: Pessimism and Opportunism in Offline Dynamic Pricing",
      "summary": "This paper studies offline dynamic pricing without data coverage assumption,\nthereby allowing for any price including the optimal one not being observed in\nthe offline data. Previous approaches that rely on the various coverage\nassumptions such as that the optimal prices are observable, would lead to\nsuboptimal decisions and consequently, reduced profits. We address this\nchallenge by framing the problem to a partial identification framework.\nSpecifically, we establish a partial identification bound for the demand\nparameter whose associated price is unobserved by leveraging the inherent\nmonotonicity property in the pricing problem. We further incorporate\npessimistic and opportunistic strategies within the proposed partial\nidentification framework to derive the estimated policy. Theoretically, we\nestablish rate-optimal finite-sample regret guarantees for both strategies.\nEmpirically, we demonstrate the superior performance of the newly proposed\nmethods via a synthetic environment. This research provides practitioners with\nvaluable insights into offline pricing strategies in the challenging\nno-coverage setting, ultimately fostering sustainable growth and profitability\nof the company."
    },
    {
      "id": "2411.08034v2",
      "title": "Scaling Properties of Diffusion Models for Perceptual Tasks",
      "summary": "In this paper, we argue that iterative computation with diffusion models\noffers a powerful paradigm for not only generation but also visual perception\ntasks. We unify tasks such as depth estimation, optical flow, and amodal\nsegmentation under the framework of image-to-image translation, and show how\ndiffusion models benefit from scaling training and test-time compute for these\nperceptual tasks. Through a careful analysis of these scaling properties, we\nformulate compute-optimal training and inference recipes to scale diffusion\nmodels for visual perception tasks. Our models achieve competitive performance\nto state-of-the-art methods using significantly less data and compute. To\naccess our code and models, see https://scaling-diffusion-perception.github.io ."
    },
    {
      "id": "2411.08033v1",
      "title": "GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation",
      "summary": "While 3D content generation has advanced significantly, existing methods\nstill face challenges with input formats, latent space design, and output\nrepresentations. This paper introduces a novel 3D generation framework that\naddresses these challenges, offering scalable, high-quality 3D generation with\nan interactive Point Cloud-structured Latent space. Our framework employs a\nVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)\nrenderings as input, using a unique latent space design that preserves 3D shape\ninformation, and incorporates a cascaded latent diffusion model for improved\nshape-texture disentanglement. The proposed method, GaussianAnything, supports\nmulti-modal conditional 3D generation, allowing for point cloud, caption, and\nsingle/multi-view image inputs. Notably, the newly proposed latent space\nnaturally enables geometry-texture disentanglement, thus allowing 3D-aware\nediting. Experimental results demonstrate the effectiveness of our approach on\nmultiple datasets, outperforming existing methods in both text- and\nimage-conditioned 3D generation."
    },
    {
      "id": "2411.08028v1",
      "title": "Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data",
      "summary": "In real-world NLP applications, Large Language Models (LLMs) offer promising\nsolutions due to their extensive training on vast datasets. However, the large\nsize and high computation demands of LLMs limit their practicality in many\napplications, especially when further fine-tuning is required. To address these\nlimitations, smaller models are typically preferred for deployment. However,\ntheir training is hindered by the scarcity of labeled data. In contrast,\nunlabeled data is often readily which can be leveraged by using LLMs to\ngenerate pseudo-labels for training smaller models. This enables the smaller\nmodels (student) to acquire knowledge from LLMs(teacher) while reducing\ncomputational costs. This process introduces challenges, such as potential\nnoisy pseudo-labels. Selecting high-quality and informative data is therefore\ncritical to enhance model performance while improving the efficiency of data\nutilization. To address this, we propose LLKD that enables Learning with Less\ncomputational resources and less data for Knowledge Distillation from LLMs.\nLLKD is an adaptive sample selection method that incorporates signals from both\nthe teacher and student. Specifically, it prioritizes samples where the teacher\ndemonstrates high confidence in its labeling, indicating reliable labels, and\nwhere the student exhibits a high information need, identifying challenging\nsamples that require further learning. Our comprehensive experiments show that\nLLKD achieves superior performance across various datasets with higher data\nefficiency."
    },
    {
      "id": "2411.08027v1",
      "title": "LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models",
      "summary": "Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters."
    },
    {
      "id": "2411.08024v1",
      "title": "Leonardo vindicated: Pythagorean trees for minimal reconstruction of the natural branching structures",
      "summary": "Trees continue to fascinate with their natural beauty and as engineering\nmasterpieces optimal with respect to several independent criteria. Pythagorean\ntree is a well-known fractal design that realistically mimics the natural tree\nbranching structures. We study various types of Pythagorean-like fractal trees\nwith different shapes of the base, branching angles and relaxed scales in an\nattempt to identify and explain which variants are the closest match to the\nbranching structures commonly observed in the natural world. Pursuing\nsimultaneously the realism and minimalism of the fractal tree model, we have\ndeveloped a flexibly parameterised and fast algorithm to grow and visually\nexamine deep Pythagorean-inspired fractal trees with the capability to orderly\nover- or underestimate the Leonardo da Vinci's tree branching rule as well as\ncontrol various imbalances and branching angles. We tested the realism of the\ngenerated fractal tree images by means of the classification accuracy of\ndetecting natural tree with the transfer-trained deep Convolutional Neural\nNetworks (CNNs). Having empirically established the parameters of the fractal\ntrees that maximize the CNN's natural tree class classification accuracy we\nhave translated them back to the scales and angles of branches and came to the\ninteresting conclusions that support the da Vinci branching rule and golden\nratio based scaling for both the shape of the branch and imbalance between the\nchild branches, and claim the flexibly parameterized fractal trees can be used\nto generate artificial examples to train robust detectors of different species\nof trees."
    },
    {
      "id": "2411.08019v1",
      "title": "Language Models as Causal Effect Generators",
      "summary": "We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure."
    },
    {
      "id": "2411.08017v1",
      "title": "Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings",
      "summary": "Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities."
    },
    {
      "id": "2411.08013v2",
      "title": "Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech",
      "summary": "Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts."
    },
    {
      "id": "2411.08010v1",
      "title": "ExpressivityArena: Can LLMs Express Information Implicitly?",
      "summary": "While Large Language Models (LLMs) have demonstrated remarkable performance\nin certain dimensions, their ability to express implicit language cues that\nhuman use for effective communication remains unclear. This paper presents\nExpressivityArena, a Python library for measuring the implicit communication\nabilities of LLMs. We provide a comprehensive framework to evaluate\nexpressivity of arbitrary LLMs and explore its practical implications. To this\nend, we refine the definition and measurements of ``expressivity,'' and use our\nframework in a set of small experiments. These experiments test LLMs in\ncreative and logical tasks such as poetry, coding, and emotion-based responses.\nThey are then evaluated by an automated grader, through ExpressivityArena,\nwhich we verify to be the most pragmatic for testing expressivity. Building on\nthese experiments, we deepen our understanding of the expressivity of LLMs by\nassessing their ability to remain expressive in conversations. Our findings\nindicate that LLMs are capable of generating and understanding expressive\ncontent, however, with some limitations. These insights will inform the future\ndevelopment and deployment of expressive LLMs. We provide the code for\nExpressivityArena alongside our paper."
    },
    {
      "id": "2411.08003v1",
      "title": "Can adversarial attacks by large language models be attributed?",
      "summary": "Attributing outputs from Large Language Models (LLMs) in adversarial\nsettings-such as cyberattacks and disinformation-presents significant\nchallenges that are likely to grow in importance. We investigate this\nattribution problem using formal language theory, specifically language\nidentification in the limit as introduced by Gold and extended by Angluin. By\nmodeling LLM outputs as formal languages, we analyze whether finite text\nsamples can uniquely pinpoint the originating model. Our results show that due\nto the non-identifiability of certain language classes, under some mild\nassumptions about overlapping outputs from fine-tuned models it is\ntheoretically impossible to attribute outputs to specific LLMs with certainty.\nThis holds also when accounting for expressivity limitations of Transformer\narchitectures. Even with direct model access or comprehensive monitoring,\nsignificant computational hurdles impede attribution efforts. These findings\nhighlight an urgent need for proactive measures to mitigate risks posed by\nadversarial LLM use as their influence continues to expand."
    },
    {
      "id": "2411.07990v1",
      "title": "Derivational Morphology Reveals Analogical Generalization in Large Language Models",
      "summary": "What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought."
    },
    {
      "id": "2411.07983v1",
      "title": "Gini Coefficient as a Unified Metric for Evaluating Many-versus-Many Similarity in Vector Spaces",
      "summary": "We demonstrate that Gini coefficients can be used as unified metrics to\nevaluate many-versus-many (all-to-all) similarity in vector spaces. Our\nanalysis of various image datasets shows that images with the highest Gini\ncoefficients tend to be the most similar to one another, while images with the\nlowest Gini coefficients are the least similar. We also show that this\nrelationship holds true for vectorized text embeddings from various corpuses,\nhighlighting the consistency of our method and its broad applicability across\ndifferent types of data. Additionally, we demonstrate that selecting machine\nlearning training samples that closely match the distribution of the testing\ndataset is far more important than ensuring data diversity. Selection of\nexemplary and iconic training samples with higher Gini coefficients leads to\nsignificantly better model performance compared to simply having a diverse\ntraining set with lower Gini coefficients. Thus, Gini coefficients can serve as\neffective criteria for selecting machine learning training samples, with our\nselection method outperforming random sampling methods in very sparse\ninformation settings."
    },
    {
      "id": "2411.07979v2",
      "title": "Exact, Tractable Gauss-Newton Optimization in Deep Reversible Architectures Reveal Poor Generalization",
      "summary": "Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers. However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization."
    },
    {
      "id": "2411.07978v1",
      "title": "Doubly Robust Regression Discontinuity Designs",
      "summary": "This study introduces a doubly robust (DR) estimator for regression\ndiscontinuity (RD) designs. In RD designs, treatment effects are estimated in a\nquasi-experimental setting where treatment assignment depends on whether a\nrunning variable surpasses a predefined cutoff. A common approach in RD\nestimation is to apply nonparametric regression methods, such as local linear\nregression. In such an approach, the validity relies heavily on the consistency\nof nonparametric estimators and is limited by the nonparametric convergence\nrate, thereby preventing $\\sqrt{n}$-consistency. To address these issues, we\npropose the DR-RD estimator, which combines two distinct estimators for the\nconditional expected outcomes. If either of these estimators is consistent, the\ntreatment effect estimator remains consistent. Furthermore, due to the\ndebiasing effect, our proposed estimator achieves $\\sqrt{n}$-consistency if\nboth regression estimators satisfy certain mild conditions, which also\nsimplifies statistical inference."
    },
    {
      "id": "2411.07976v2",
      "title": "DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring",
      "summary": "Coronary artery disease (CAD), one of the most common cause of mortality in\nthe world. Coronary artery calcium (CAC) scoring using computed tomography (CT)\nis key for risk assessment to prevent coronary disease. Previous studies on\nrisk assessment and calcification detection in CT scans primarily use\napproaches based on UNET architecture, frequently implemented on pre-built\nmodels. However, these models are limited by the availability of annotated CT\nscans containing CAC and suffering from imbalanced dataset, decreasing\nperformance of CAC segmentation and scoring. In this study, we extend this\napproach by incorporating the self-supervised learning (SSL) technique of DINO\n(self-distillation with no labels) to eliminate limitations of scarce annotated\ndata in CT scans. The DINO model's ability to train without requiring CAC area\nannotations enhances its robustness in generating distinct features. The DINO\nmodel is trained on to focus specifically on calcified areas by using labels,\naiming to generate features that effectively capture and highlight key\ncharacteristics. The label-guided DINO (DINO-LG) enhances classification by\ndistinguishing CT slices that contain calcification from those that do not,\nperforming 57% better than the standard DINO model in this task. CAC scoring\nand segmentation tasks are performed by a basic U-NET architecture, fed\nspecifically with CT slices containing calcified areas as identified by the\nDINO-LG model. This targeted identification performed by DINO-LG model improves\nCAC segmentation performance by approximately 10% and significant increase in\nCAC scoring accuracy."
    },
    {
      "id": "2411.07975v1",
      "title": "JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation",
      "summary": "We present JanusFlow, a powerful framework that unifies image understanding\nand generation in a single model. JanusFlow introduces a minimalist\narchitecture that integrates autoregressive language models with rectified\nflow, a state-of-the-art method in generative modeling. Our key finding\ndemonstrates that rectified flow can be straightforwardly trained within the\nlarge language model framework, eliminating the need for complex architectural\nmodifications. To further improve the performance of our unified model, we\nadopt two key strategies: (i) decoupling the understanding and generation\nencoders, and (ii) aligning their representations during unified training.\nExtensive experiments show that JanusFlow achieves comparable or superior\nperformance to specialized models in their respective domains, while\nsignificantly outperforming existing unified approaches across standard\nbenchmarks. This work represents a step toward more efficient and versatile\nvision-language models."
    },
    {
      "id": "2411.07971v1",
      "title": "Optimal Control of Mechanical Ventilators with Learned Respiratory Dynamics",
      "summary": "Deciding on appropriate mechanical ventilator management strategies\nsignificantly impacts the health outcomes for patients with respiratory\ndiseases. Acute Respiratory Distress Syndrome (ARDS) is one such disease that\nrequires careful ventilator operation to be effectively treated. In this work,\nwe frame the management of ventilators for patients with ARDS as a sequential\ndecision making problem using the Markov decision process framework. We\nimplement and compare controllers based on clinical guidelines contained in the\nARDSnet protocol, optimal control theory, and learned latent dynamics\nrepresented as neural networks. The Pulse Physiology Engine's respiratory\ndynamics simulator is used to establish a repeatable benchmark, gather\nsimulated data, and quantitatively compare these controllers. We score\nperformance in terms of measured improvement in established ARDS health markers\n(pertaining to improved respiratory rate, oxygenation, and vital signs). Our\nresults demonstrate that techniques leveraging neural networks and optimal\ncontrol can automatically discover effective ventilation management strategies\nwithout access to explicit ventilator management procedures or guidelines (such\nas those defined in the ARDSnet protocol)."
    },
    {
      "id": "2411.07964v1",
      "title": "Sleep Staging from Airflow Signals Using Fourier Approximations of Persistence Curves",
      "summary": "Sleep staging is a challenging task, typically manually performed by sleep\ntechnologists based on electroencephalogram and other biosignals of patients\ntaken during overnight sleep studies. Recent work aims to leverage automated\nalgorithms to perform sleep staging not based on electroencephalogram signals,\nbut rather based on the airflow signals of subjects. Prior work uses ideas from\ntopological data analysis (TDA), specifically Hermite function expansions of\npersistence curves (HEPC) to featurize airflow signals. However, finite order\nHEPC captures only partial information. In this work, we propose Fourier\napproximations of persistence curves (FAPC), and use this technique to perform\nsleep staging based on airflow signals. We analyze performance using an XGBoost\nmodel on 1155 pediatric sleep studies taken from the Nationwide Children's\nHospital Sleep DataBank (NCHSDB), and find that FAPC methods provide\ncomplimentary information to HEPC methods alone, leading to a 4.9% increase in\nperformance over baseline methods."
    },
    {
      "id": "2411.07965v1",
      "title": "From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents",
      "summary": "The advanced role-playing capabilities of Large Language Models (LLMs) have\npaved the way for developing Role-Playing Agents (RPAs). However, existing\nbenchmarks, such as HPD, which incorporates manually scored character\nrelationships into the context for LLMs to sort coherence, and SocialBench,\nwhich uses specific profiles generated by LLMs in the context of\nmultiple-choice tasks to assess character preferences, face limitations like\npoor generalizability, implicit and inaccurate judgments, and excessive context\nlength. To address the above issues, we propose an automatic, scalable, and\ngeneralizable paradigm. Specifically, we construct a benchmark by extracting\nrelations from a general knowledge graph and leverage RPA's inherent\nhallucination properties to prompt it to interact across roles, employing\nChatGPT for stance detection and defining relationship hallucination along with\nthree related metrics. Extensive experiments validate the effectiveness and\nstability of our metrics. Our findings further explore factors influencing\nthese metrics and discuss the trade-off between relationship hallucination and\nfactuality."
    },
    {
      "id": "2411.07959v1",
      "title": "On the Convergence of Continual Federated Learning Using Incrementally Aggregated Gradients",
      "summary": "The holy grail of machine learning is to enable Continual Federated Learning\n(CFL) to enhance the efficiency, privacy, and scalability of AI systems while\nlearning from streaming data. The primary challenge of a CFL system is to\novercome global catastrophic forgetting, wherein the accuracy of the global\nmodel trained on new tasks declines on the old tasks. In this work, we propose\nContinual Federated Learning with Aggregated Gradients (C-FLAG), a novel\nreplay-memory based federated strategy consisting of edge-based gradient\nupdates on memory and aggregated gradients on the current data. We provide\nconvergence analysis of the C-FLAG approach which addresses forgetting and bias\nwhile converging at a rate of $O(1/\\sqrt{T})$ over $T$ communication rounds. We\nformulate an optimization sub-problem that minimizes catastrophic forgetting,\ntranslating CFL into an iterative algorithm with adaptive learning rates that\nensure seamless learning across tasks. We empirically show that C-FLAG\noutperforms several state-of-the-art baselines on both task and\nclass-incremental settings with respect to metrics such as accuracy and\nforgetting."
    },
    {
      "id": "2411.07957v1",
      "title": "Tukey g-and-h neural network regression for non-Gaussian data",
      "summary": "This paper addresses non-Gaussian regression with neural networks via the use\nof the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexible\nparametric transform with two parameters $g$ and $h$ which, when applied to a\nstandard normal random variable, introduces both skewness and kurtosis,\nresulting in a distribution commonly called the Tukey g-and-h distribution.\nSpecific values of $g$ and $h$ produce good approximations to other families of\ndistributions, such as the Cauchy and student-t distributions. The flexibility\nof the Tukey g-and-h distribution has driven its popularity in the statistical\ncommunity, in applied sciences and finance. In this work we consider the\ntraining of a neural network to predict the parameters of a Tukey g-and-h\ndistribution in a regression framework via the minimization of the\ncorresponding negative log-likelihood, despite the latter having no closed-form\nexpression. We demonstrate the efficiency of our procedure in simulated\nexamples and apply our method to a real-world dataset of global crop yield for\nseveral types of crops. Finally, we show how we can carry out a goodness-of-fit\nanalysis between the predicted distributions and the test data. A Pytorch\nimplementation is made available on Github and as a Pypi package."
    },
    {
      "id": "2411.07955v1",
      "title": "How To Discover Short, Shorter, and the Shortest Proofs of Unsatisfiability: A Branch-and-Bound Approach for Resolution Proof Length Minimization",
      "summary": "Modern software for propositional satisfiability problems gives a powerful\nautomated reasoning toolkit, capable of outputting not only a\nsatisfiable/unsatisfiable signal but also a justification of unsatisfiability\nin the form of resolution proof (or a more expressive proof), which is commonly\nused for verification purposes. Empirically, modern SAT solvers produce\nrelatively short proofs, however, there are no inherent guarantees that these\nproofs cannot be significantly reduced. This paper proposes a novel\nbranch-and-bound algorithm for finding the shortest resolution proofs; to this\nend, we introduce a layer list representation of proofs that groups clauses by\ntheir level of indirection. As we show, this representation breaks all\npermutational symmetries, thereby improving upon the state-of-the-art\nsymmetry-breaking and informing the design of a novel workflow for proof\nminimization. In addition to that, we design pruning procedures that reason on\nproof length lower bound, clause subsumption, and dominance. Our experiments\nsuggest that the proofs from state-of-the-art solvers could be shortened by\n30-60% on the instances from SAT Competition 2002 and by 25-50% on small\nsynthetic formulas. When treated as an algorithm for finding the shortest\nproof, our approach solves twice as many instances as the previous work based\non SAT solving and reduces the time to optimality by orders of magnitude for\nthe instances solved by both approaches."
    },
    {
      "id": "2411.07954v2",
      "title": "Learning Memory Mechanisms for Decision Making through Demonstrations",
      "summary": "In Partially Observable Markov Decision Processes, integrating an agent's\nhistory into memory poses a significant challenge for decision-making.\nTraditional imitation learning, relying on observation-action pairs for expert\ndemonstrations, fails to capture the expert's memory mechanisms used in\ndecision-making. To capture memory processes as demonstrations, we introduce\nthe concept of memory dependency pairs $(p, q)$ indicating that events at time\n$p$ are recalled for decision-making at time $q$. We introduce AttentionTuner\nto leverage memory dependency pairs in Transformers and find significant\nimprovements across several tasks compared to standard Transformers when\nevaluated on Memory Gym and the Long-term Memory Benchmark. Code is available\nat https://github.com/WilliamYue37/AttentionTuner."
    },
    {
      "id": "2411.07942v1",
      "title": "Towards Low-bit Communication for Tensor Parallel LLM Inference",
      "summary": "Tensor parallelism provides an effective way to increase server large\nlanguage model (LLM) inference efficiency despite adding an additional\ncommunication cost. However, as server LLMs continue to scale in size, they\nwill need to be distributed across more devices, magnifying the communication\ncost. One way to approach this problem is with quantization, but current\nmethods for LLMs tend to avoid quantizing the features that tensor parallelism\nneeds to communicate. Taking advantage of consistent outliers in communicated\nfeatures, we introduce a quantization method that reduces communicated values\non average from 16 bits to 4.2 bits while preserving nearly all of the original\nperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma\n2 27B's and Llama 2 13B's original performance, respectively, averaged across\nall tasks we evaluated on."
    },
    {
      "id": "2411.07941v1",
      "title": "DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks",
      "summary": "Computed tomography (CT) provides highly detailed three-dimensional (3D)\nmedical images but is costly, time-consuming, and often inaccessible in\nintraoperative settings (Organization et al. 2011). Recent advancements have\nexplored reconstructing 3D chest volumes from sparse 2D X-rays, such as\nsingle-view or orthogonal double-view images. However, current models tend to\nprocess 2D images in a planar manner, prioritizing visual realism over\nstructural accuracy. In this work, we introduce DuoLift Generative Adversarial\nNetworks (DuoLift-GAN), a novel architecture with dual branches that\nindependently elevate 2D images and their features into 3D representations.\nThese 3D outputs are merged into a unified 3D feature map and decoded into a\ncomplete 3D chest volume, enabling richer 3D information capture. We also\npresent a masked loss function that directs reconstruction towards critical\nanatomical regions, improving structural accuracy and visual quality. This\npaper demonstrates that DuoLift-GAN significantly enhances reconstruction\naccuracy while achieving superior visual realism compared to existing methods."
    },
    {
      "id": "2411.07940v2",
      "title": "Automatic dataset shift identification to support root cause analysis of AI performance drift",
      "summary": "Shifts in data distribution can substantially harm the performance of\nclinical AI models. Hence, various methods have been developed to detect the\npresence of such shifts at deployment time. However, root causes of dataset\nshifts are varied, and the choice of shift mitigation strategies is highly\ndependent on the precise type of shift encountered at test time. As such,\ndetecting test-time dataset shift is not sufficient: precisely identifying\nwhich type of shift has occurred is critical. In this work, we propose the\nfirst unsupervised dataset shift identification framework, effectively\ndistinguishing between prevalence shift (caused by a change in the label\ndistribution), covariate shift (caused by a change in input characteristics)\nand mixed shifts (simultaneous prevalence and covariate shifts). We discuss the\nimportance of self-supervised encoders for detecting subtle covariate shifts\nand propose a novel shift detector leveraging both self-supervised encoders and\ntask model outputs for improved shift detection. We report promising results\nfor the proposed shift identification framework across three different imaging\nmodalities (chest radiography, digital mammography, and retinal fundus images)\non five types of real-world dataset shifts, using four large publicly available\ndatasets."
    },
    {
      "id": "2411.07934v2",
      "title": "Doubly Mild Generalization for Offline Reinforcement Learning",
      "summary": "Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance."
    },
    {
      "id": "2411.07933v1",
      "title": "Prediction of Acoustic Communication Performance for AUVs using Gaussian Process Classification",
      "summary": "Cooperating autonomous underwater vehicles (AUVs) often rely on acoustic\ncommunication to coordinate their actions effectively. However, the reliability\nof underwater acoustic communication decreases as the communication range\nbetween vehicles increases. Consequently, teams of cooperating AUVs typically\nmake conservative assumptions about the maximum range at which they can\ncommunicate reliably. To address this limitation, we propose a novel approach\nthat involves learning a map representing the probability of successful\ncommunication based on the locations of the transmitting and receiving\nvehicles. This probabilistic communication map accounts for factors such as the\nrange between vehicles, environmental noise, and multi-path effects at a given\nlocation. In pursuit of this goal, we investigate the application of Gaussian\nprocess binary classification to generate the desired communication map. We\nspecialize existing results to this specific binary classification problem and\nexplore methods to incorporate uncertainty in vehicle location into the mapping\nprocess. Furthermore, we compare the prediction performance of the probability\ncommunication map generated using binary classification with that of a\nsignal-to-noise ratio (SNR) communication map generated using Gaussian process\nregression. Our approach is experimentally validated using communication and\nnavigation data collected during trials with a pair of Virginia Tech 690 AUVs."
    },
    {
      "id": "2411.08085v1",
      "title": "Deep Learning 2.0: Artificial Neurons That Matter -- Reject Correlation, Embrace Orthogonality",
      "summary": "We introduce a yat-product-powered neural network, the Neural Matter Network\n(NMN), a breakthrough in deep learning that achieves non-linear pattern\nrecognition without activation functions. Our key innovation relies on the\nyat-product and yat-product, which naturally induces non-linearity by\nprojecting inputs into a pseudo-metric space, eliminating the need for\ntraditional activation functions while maintaining only a softmax layer for\nfinal class probability distribution. This approach simplifies network\narchitecture and provides unprecedented transparency into the network's\ndecision-making process. Our comprehensive empirical evaluation across\ndifferent datasets demonstrates that NMN consistently outperforms traditional\nMLPs. The results challenge the assumption that separate activation functions\nare necessary for effective deep-learning models. The implications of this work\nextend beyond immediate architectural benefits, by eliminating intermediate\nactivation functions while preserving non-linear capabilities, yat-MLP\nestablishes a new paradigm for neural network design that combines simplicity\nwith effectiveness. Most importantly, our approach provides unprecedented\ninsights into the traditionally opaque \"black-box\" nature of neural networks,\noffering a clearer understanding of how these models process and classify\ninformation."
    },
    {
      "id": "2411.07917v1",
      "title": "CryptoLLM: Unleashing the Power of Prompted LLMs for SmartQnA and Classification of Crypto Posts",
      "summary": "The rapid growth of social media has resulted in an large volume of\nuser-generated content, particularly in niche domains such as cryptocurrency.\nThis task focuses on developing robust classification models to accurately\ncategorize cryptocurrency-related social media posts into predefined classes,\nincluding but not limited to objective, positive, negative, etc. Additionally,\nthe task requires participants to identify the most relevant answers from a set\nof posts in response to specific questions. By leveraging advanced LLMs, this\nresearch aims to enhance the understanding and filtering of cryptocurrency\ndiscourse, thereby facilitating more informed decision-making in this volatile\nsector. We have used a prompt-based technique to solve the classification task\nfor reddit posts and twitter posts. Also, we have used 64-shot technique along\nwith prompts on GPT-4-Turbo model to determine whether a answer is relevant to\na question or not."
    },
    {
      "id": "2411.07892v1",
      "title": "Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus",
      "summary": "Podcasts provide highly diverse content to a massive listener base through a\nunique on-demand modality. However, limited data has prevented large-scale\ncomputational analysis of the podcast ecosystem. To fill this gap, we introduce\na massive dataset of over 1.1M podcast transcripts that is largely\ncomprehensive of all English language podcasts available through public RSS\nfeeds from May and June of 2020. This data is not limited to text, but rather\nincludes audio features and speaker turns for a subset of 370K episodes, and\nspeaker role inferences and other metadata for all 1.1M episodes. Using this\ndata, we also conduct a foundational investigation into the content, structure,\nand responsiveness of this ecosystem. Together, our data and analyses open the\ndoor to continued computational research of this popular and impactful medium."
    },
    {
      "id": "2411.07889v1",
      "title": "A Stochastic Optimization Framework for Private and Fair Learning From Decentralized Data",
      "summary": "Machine learning models are often trained on sensitive data (e.g., medical\nrecords and race/gender) that is distributed across different \"silos\" (e.g.,\nhospitals). These federated learning models may then be used to make\nconsequential decisions, such as allocating healthcare resources. Two key\nchallenges emerge in this setting: (i) maintaining the privacy of each person's\ndata, even if other silos or an adversary with access to the central server\ntries to infer this data; (ii) ensuring that decisions are fair to different\ndemographic groups (e.g., race/gender). In this paper, we develop a novel\nalgorithm for private and fair federated learning (FL). Our algorithm satisfies\ninter-silo record-level differential privacy (ISRL-DP), a strong notion of\nprivate FL requiring that silo i's sent messages satisfy record-level\ndifferential privacy for all i. Our framework can be used to promote different\nfairness notions, including demographic parity and equalized odds. We prove\nthat our algorithm converges under mild smoothness assumptions on the loss\nfunction, whereas prior work required strong convexity for convergence. As a\nbyproduct of our analysis, we obtain the first convergence guarantee for\nISRL-DP nonconvex-strongly concave min-max FL. Experiments demonstrate the\nstate-of-the-art fairness-accuracy tradeoffs of our algorithm across different\nprivacy levels."
    },
    {
      "id": "2411.07885v1",
      "title": "INTRABENCH: Interactive Radiological Benchmark",
      "summary": "Current interactive segmentation approaches, inspired by the success of\nMETA's Segment Anything model, have achieved notable advancements, however,\nthey come with substantial limitations that hinder their practical application\nin real clinical scenarios. These include unrealistic human interaction\nrequirements, such as slice-by-slice operations for 2D models on 3D data, a\nlack of iterative refinement, and insufficient evaluation experiments. These\nshortcomings prevent accurate assessment of model performance and lead to\ninconsistent outcomes across studies. IntRaBench overcomes these challenges by\noffering a comprehensive and reproducible framework for evaluating interactive\nsegmentation methods in realistic, clinically relevant scenarios. It includes\ndiverse datasets, target structures, and segmentation models, and provides a\nflexible codebase that allows seamless integration of new models and prompting\nstrategies. Additionally, we introduce advanced techniques to minimize\nclinician interaction, ensuring fair comparisons between 2D and 3D models. By\nopen-sourcing IntRaBench, we invite the research community to integrate their\nmodels and prompting techniques, ensuring continuous and transparent evaluation\nof interactive segmentation models in 3D medical imaging."
    },
    {
      "id": "2411.07873v1",
      "title": "Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules",
      "summary": "Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning."
    },
    {
      "id": "2411.07871v1",
      "title": "Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease",
      "summary": "The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports."
    },
    {
      "id": "2411.07870v2",
      "title": "Trustful LLMs: Customizing and Grounding Text Generation with Knowledge Bases and Dual Decoders",
      "summary": "Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process."
    },
    {
      "id": "2411.07863v1",
      "title": "CDXFormer: Boosting Remote Sensing Change Detection with Extended Long Short-Term Memory",
      "summary": "In complex scenes and varied conditions, effectively integrating\nspatial-temporal context is crucial for accurately identifying changes.\nHowever, current RS-CD methods lack a balanced consideration of performance and\nefficiency. CNNs lack global context, Transformers have quadratic computational\ncomplexity, and Mambas are restricted by CUDA acceleration. In this paper, we\npropose CDXFormer, with a core component that is a powerful XLSTM-based feature\nenhancement layer, integrating the advantages of linear computational\ncomplexity, global context perception, and strong interpret-ability.\nSpecifically, we introduce a scale-specific Feature Enhancer layer,\nincorporating a Cross-Temporal Global Perceptron customized for\nsemantic-accurate deep features, and a Cross-Temporal Spatial Refiner\ncustomized for detail-rich shallow features. Additionally, we propose a\nCross-Scale Interactive Fusion module to progressively interact global change\nrepresentations with spatial responses. Extensive experimental results\ndemonstrate that CDXFormer achieves state-of-the-art performance across three\nbenchmark datasets, offering a compelling balance between efficiency and\naccuracy. Code is available at https://github.com/xwmaxwma/rschange."
    },
    {
      "id": "2411.07858v1",
      "title": "Verbosity $\\neq$ Veracity: Demystify Verbosity Compensation Behavior of Large Language Models",
      "summary": "When unsure about an answer, humans often respond with more words than\nnecessary, hoping that part of the response will be correct. We observe a\nsimilar behavior in large language models (LLMs), which we term \"Verbosity\nCompensation\" (VC). VC is harmful because it confuses the user understanding,\nleading to low efficiency, and influences the LLM services by increasing the\nlatency and cost of generating useless tokens. In this paper, we present the\nfirst work that defines and analyzes Verbosity Compensation, explores its\ncauses, and proposes a simple mitigating approach. We define Verbosity\nCompensation as the behavior of generating responses that can be compressed\nwithout information loss when prompted to write concisely. Our experiments,\nconducted on five datasets of knowledge and reasoning-based QA tasks with 14\nnewly developed LLMs, reveal three conclusions. 1) We reveal a pervasive\npresence of verbosity compensation across all models and all datasets. Notably,\nGPT-4 exhibits a VC frequency of 50.40%. 2) We reveal the large performance gap\nbetween verbose and concise responses, with a notable difference of 27.61% on\nthe Qasper dataset. We also demonstrate that this difference does not naturally\ndiminish as LLM capability increases. Both 1) and 2) highlight the urgent need\nto mitigate the frequency of VC behavior and disentangle verbosity with\nveracity. We propose a simple yet effective cascade algorithm that replaces the\nverbose responses with the other model-generated responses. The results show\nthat our approach effectively alleviates the VC of the Mistral model from\n63.81% to 16.16% on the Qasper dataset. 3) We also find that verbose responses\nexhibit higher uncertainty across all five datasets, suggesting a strong\nconnection between verbosity and model uncertainty. Our dataset and code are\navailable at https://github.com/psunlpgroup/VerbosityLLM."
    },
    {
      "id": "2411.07854v1",
      "title": "Tucano: Advancing Neural Text Generation for Portuguese",
      "summary": "Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/"
    },
    {
      "id": "2411.07853v1",
      "title": "Evidential time-to-event prediction model with well-calibrated uncertainty estimation",
      "summary": "Time-to-event analysis, or Survival analysis, provides valuable insights into\nclinical prognosis and treatment recommendations. However, this task is\ntypically more challenging than other regression tasks due to the censored\nobservations. Moreover, concerns regarding the reliability of predictions\npersist among clinicians, mainly attributed to the absence of confidence\nassessment, robustness, and calibration of prediction. To address those\nchallenges, we introduce an evidential regression model designed especially for\ntime-to-event prediction tasks, with which the most plausible event time, is\ndirectly quantified by aggregated Gaussian random fuzzy numbers (GRFNs). The\nGRFNs are a newly introduced family of random fuzzy subsets of the real line\nthat generalizes both Gaussian random variables and Gaussian possibility\ndistributions. Different from conventional methods that construct models based\non strict data distribution, e.g., proportional hazard function, our model only\nassumes the event time is encoded in a real line GFRN without any strict\ndistribution assumption, therefore offering more flexibility in complex data\nscenarios. Furthermore, the epistemic and aleatory uncertainty regarding the\nevent time is quantified within the aggregated GRFN as well. Our model can,\ntherefore, provide more detailed clinical decision-making guidance with two\nmore degrees of information. The model is fit by minimizing a generalized\nnegative log-likelihood function that accounts for data censoring based on\nuncertainty evidence reasoning. Experimental results on simulated datasets with\nvarying data distributions and censoring scenarios, as well as on real-world\ndatasets across diverse clinical settings and tasks, demonstrate that our model\nachieves both accurate and reliable performance, outperforming state-of-the-art\nmethods."
    },
    {
      "id": "2411.07850v1",
      "title": "IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems",
      "summary": "Adversarial examples, which are inputs deliberately perturbed with\nimperceptible changes to induce model errors, have raised serious concerns for\nthe reliability and security of deep neural networks (DNNs). While adversarial\nattacks have been extensively studied in continuous data domains such as\nimages, the discrete nature of text presents unique challenges. In this paper,\nwe propose Irony-based Adversarial Examples (IAE), a method that transforms\nstraightforward sentences into ironic ones to create adversarial text. This\napproach exploits the rhetorical device of irony, where the intended meaning is\nopposite to the literal interpretation, requiring a deeper understanding of\ncontext to detect. The IAE method is particularly challenging due to the need\nto accurately locate evaluation words, substitute them with appropriate\ncollocations, and expand the text with suitable ironic elements while\nmaintaining semantic coherence. Our research makes the following key\ncontributions: (1) We introduce IAE, a strategy for generating textual\nadversarial examples using irony. This method does not rely on pre-existing\nirony corpora, making it a versatile tool for creating adversarial text in\nvarious NLP tasks. (2) We demonstrate that the performance of several\nstate-of-the-art deep learning models on sentiment analysis tasks significantly\ndeteriorates when subjected to IAE attacks. This finding underscores the\nsusceptibility of current NLP systems to adversarial manipulation through\nirony. (3) We compare the impact of IAE on human judgment versus NLP systems,\nrevealing that humans are less susceptible to the effects of irony in text."
    },
    {
      "id": "2411.07845v1",
      "title": "Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements",
      "summary": "What ethical concerns, if any, do LLM researchers have? We introduce EthiCon,\na corpus of 1,580 ethical concern statements extracted from scientific papers\npublished in the ACL Anthology. We extract ethical concern keywords from the\nstatements and show promising results in automating the concern identification\nprocess. Through a survey, we compare the ethical concerns of the corpus to the\nconcerns listed by the general public and professionals in the field. Finally,\nwe compare our retrieved ethical concerns with existing taxonomies pointing to\ngaps and future research directions."
    },
    {
      "id": "2411.07843v1",
      "title": "Chain Association-based Attacking and Shielding Natural Language Processing Systems",
      "summary": "Association as a gift enables people do not have to mention something in\ncompletely straightforward words and allows others to understand what they\nintend to refer to. In this paper, we propose a chain association-based\nadversarial attack against natural language processing systems, utilizing the\ncomprehension gap between humans and machines. We first generate a chain\nassociation graph for Chinese characters based on the association paradigm for\nbuilding search space of potential adversarial examples. Then, we introduce an\ndiscrete particle swarm optimization algorithm to search for the optimal\nadversarial examples. We conduct comprehensive experiments and show that\nadvanced natural language processing models and applications, including large\nlanguage models, are vulnerable to our attack, while humans appear good at\nunderstanding the perturbed text. We also explore two methods, including\nadversarial training and associative graph-based recovery, to shield systems\nfrom chain association-based attack. Since a few examples that use some\nderogatory terms, this paper contains materials that may be offensive or\nupsetting to some people."
    },
    {
      "id": "2411.07841v1",
      "title": "Federated Learning for Discrete Optimal Transport with Large Population under Incomplete Information",
      "summary": "Optimal transport is a powerful framework for the efficient allocation of\nresources between sources and targets. However, traditional models often\nstruggle to scale effectively in the presence of large and heterogeneous\npopulations. In this work, we introduce a discrete optimal transport framework\ndesigned to handle large-scale, heterogeneous target populations, characterized\nby type distributions. We address two scenarios: one where the type\ndistribution of targets is known, and one where it is unknown. For the known\ndistribution, we propose a fully distributed algorithm to achieve optimal\nresource allocation. In the case of unknown distribution, we develop a\nfederated learning-based approach that enables efficient computation of the\noptimal transport scheme while preserving privacy. Case studies are provided to\nevaluate the performance of our learning algorithm."
    },
    {
      "id": "2411.07837v1",
      "title": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training",
      "summary": "With the increase in the number of parameters in large language models, the\nprocess of pre-training and fine-tuning increasingly demands larger volumes of\nGPU memory. A significant portion of this memory is typically consumed by the\noptimizer state. To overcome this challenge, recent approaches such as low-rank\nadaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao\net al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been\nproposed. However, in all these algorithms, the $\\textit{effective rank of the\nweight updates remains low-rank}$, which can lead to a substantial loss of\ninformation from the gradient. This loss can be critically important,\nespecially during the pre-training stage. In this paper, we introduce\n$\\texttt{FRUGAL}$ ($\\textbf{F}$ull-$\\textbf{R}$ank $\\textbf{U}$pdates with\n$\\textbf{G}$r$\\textbf{A}$dient sp$\\textbf{L}$itting), a new memory-efficient\noptimization framework. $\\texttt{FRUGAL}$ leverages gradient splitting to\nperform low-dimensional updates using advanced algorithms (such as Adam), while\nupdates along the remaining directions are executed via state-free methods like\nSGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with\nvarious low-rank update selection techniques, including GaLore and BAdam. We\nprovide theoretical convergence guarantees for our framework when using SGDM\nfor low-dimensional updates and SGD for state-free updates. Additionally, our\nmethod consistently outperforms concurrent approaches across various fixed\nmemory budgets, achieving state-of-the-art results in pre-training and\nfine-tuning tasks while balancing memory efficiency and performance metrics."
    },
    {
      "id": "2411.07832v1",
      "title": "Dynamical-VAE-based Hindsight to Learn the Causal Dynamics of Factored-POMDPs",
      "summary": "Learning representations of underlying environmental dynamics from partial\nobservations is a critical challenge in machine learning. In the context of\nPartially Observable Markov Decision Processes (POMDPs), state representations\nare often inferred from the history of past observations and actions. We\ndemonstrate that incorporating future information is essential to accurately\ncapture causal dynamics and enhance state representations. To address this, we\nintroduce a Dynamical Variational Auto-Encoder (DVAE) designed to learn causal\nMarkovian dynamics from offline trajectories in a POMDP. Our method employs an\nextended hindsight framework that integrates past, current, and multi-step\nfuture information within a factored-POMDP setting. Empirical results reveal\nthat this approach uncovers the causal graph governing hidden state transitions\nmore effectively than history-based and typical hindsight-based models."
    },
    {
      "id": "2411.07828v1",
      "title": "Suite-IN: Aggregating Motion Features from Apple Suite for Robust Inertial Navigation",
      "summary": "With the rapid development of wearable technology, devices like smartphones,\nsmartwatches, and headphones equipped with IMUs have become essential for\napplications such as pedestrian positioning. However, traditional pedestrian\ndead reckoning (PDR) methods struggle with diverse motion patterns, while\nrecent data-driven approaches, though improving accuracy, often lack robustness\ndue to reliance on a single device.In our work, we attempt to enhance the\npositioning performance using the low-cost commodity IMUs embedded in the\nwearable devices. We propose a multi-device deep learning framework named\nSuite-IN, aggregating motion data from Apple Suite for inertial navigation.\nMotion data captured by sensors on different body parts contains both local and\nglobal motion information, making it essential to reduce the negative effects\nof localized movements and extract global motion representations from multiple\ndevices."
    },
    {
      "id": "2411.07826v1",
      "title": "Efficient Federated Finetuning of Tiny Transformers with Resource-Constrained Devices",
      "summary": "In recent years, Large Language Models (LLMs) through Transformer structures\nhave dominated many machine learning tasks, especially text processing.\nHowever, these models require massive amounts of data for training and induce\nhigh resource requirements, particularly in terms of the large number of\nFloating Point Operations (FLOPs) and the high amounts of memory needed. To\nfine-tune such a model in a parameter-efficient way, techniques like Adapter or\nLoRA have been developed. However, we observe that the application of LoRA,\nwhen used in federated learning (FL), while still being parameter-efficient, is\nmemory and FLOP inefficient. Based on that observation, we develop a novel\nlayer finetuning scheme that allows devices in cross-device FL to make use of\npretrained neural networks (NNs) while adhering to given resource constraints.\nWe show that our presented scheme outperforms the current state of the art when\ndealing with homogeneous or heterogeneous computation and memory constraints\nand is on par with LoRA regarding limited communication, thereby achieving\nsignificantly higher accuracies in FL training."
    },
    {
      "id": "2411.07820v2",
      "title": "Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models",
      "summary": "We introduce the Extract-Refine-Retrieve-Read (ERRR) framework, a novel\napproach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems."
    },
    {
      "id": "2411.07816v1",
      "title": "Dual-Criterion Model Aggregation in Federated Learning: Balancing Data Quantity and Quality",
      "summary": "Federated learning (FL) has become one of the key methods for\nprivacy-preserving collaborative learning, as it enables the transfer of models\nwithout requiring local data exchange. Within the FL framework, an aggregation\nalgorithm is recognized as one of the most crucial components for ensuring the\nefficacy and security of the system. Existing average aggregation algorithms\ntypically assume that all client-trained data holds equal value or that weights\nare based solely on the quantity of data contributed by each client. In\ncontrast, alternative approaches involve training the model locally after\naggregation to enhance adaptability. However, these approaches fundamentally\nignore the inherent heterogeneity between different clients' data and the\ncomplexity of variations in data at the aggregation stage, which may lead to a\nsuboptimal global model.\n  To address these issues, this study proposes a novel dual-criterion weighted\naggregation algorithm involving the quantity and quality of data from the\nclient node. Specifically, we quantify the data used for training and perform\nmultiple rounds of local model inference accuracy evaluation on a specialized\ndataset to assess the data quality of each client. These two factors are\nutilized as weights within the aggregation process, applied through a\ndynamically weighted summation of these two factors. This approach allows the\nalgorithm to adaptively adjust the weights, ensuring that every client can\ncontribute to the global model, regardless of their data's size or initial\nquality. Our experiments show that the proposed algorithm outperforms several\nexisting state-of-the-art aggregation approaches on both a general-purpose\nopen-source dataset, CIFAR-10, and a dataset specific to visual obstacle\navoidance."
    },
    {
      "id": "2411.07806v1",
      "title": "Federated Low-Rank Adaptation with Differential Privacy over Wireless Networks",
      "summary": "Fine-tuning large pre-trained foundation models (FMs) on distributed edge\ndevices presents considerable computational and privacy challenges. Federated\nfine-tuning (FedFT) mitigates some privacy issues by facilitating collaborative\nmodel training without the need to share raw data. To lessen the computational\nburden on resource-limited devices, combining low-rank adaptation (LoRA) with\nfederated learning enables parameter-efficient fine-tuning. Additionally, the\nsplit FedFT architecture partitions an FM between edge devices and a central\nserver, reducing the necessity for complete model deployment on individual\ndevices. However, the risk of privacy eavesdropping attacks in FedFT remains a\nconcern, particularly in sensitive areas such as healthcare and finance. In\nthis paper, we propose a split FedFT framework with differential privacy (DP)\nover wireless networks, where the inherent wireless channel noise in the uplink\ntransmission is utilized to achieve DP guarantees without adding an extra\nartificial noise. We shall investigate the impact of the wireless noise on\nconvergence performance of the proposed framework. We will also show that by\nupdating only one of the low-rank matrices in the split FedFT with DP, the\nproposed method can mitigate the noise amplification effect. Simulation results\nwill demonstrate that the proposed framework achieves higher accuracy under\nstrict privacy budgets compared to baseline methods."
    },
    {
      "id": "2411.07800v1",
      "title": "Kernel-based retrieval models for hyperspectral image data optimized with Kernel Flows",
      "summary": "Kernel-based statistical methods are efficient, but their performance depends\nheavily on the selection of kernel parameters. In literature, the optimization\nstudies on kernel-based chemometric methods is limited and often reduced to\ngrid searching. Previously, the authors introduced Kernel Flows (KF) to learn\nkernel parameters for Kernel Partial Least-Squares (K-PLS) regression. KF is\neasy to implement and helps minimize overfitting. In cases of high collinearity\nbetween spectra and biogeophysical quantities in spectroscopy, simpler methods\nlike Principal Component Regression (PCR) may be more suitable. In this study,\nwe propose a new KF-type approach to optimize Kernel Principal Component\nRegression (K-PCR) and test it alongside KF-PLS. Both methods are benchmarked\nagainst non-linear regression techniques using two hyperspectral remote sensing\ndatasets."
    },
    {
      "id": "2411.07796v1",
      "title": "PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring",
      "summary": "Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but\ntraditional methods like the Dawes-Redman system are often limited by high\ninter-observer variability, leading to inconsistent interpretations and\npotential misdiagnoses. This paper introduces PatchCTG, a transformer-based\nmodel specifically designed for CTG analysis, employing patch-based\ntokenisation, instance normalisation and channel-independent processing to\ncapture essential local and global temporal dependencies within CTG signals.\nPatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over\n20,000 CTG traces across diverse clinical outcomes after applying the inclusion\nand exclusion criteria. With extensive hyperparameter optimisation, PatchCTG\nachieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at\nYouden's index threshold, demonstrating adaptability to various clinical needs.\nTesting across varying temporal thresholds showed robust predictive\nperformance, particularly with finetuning on data closer to delivery, achieving\na sensitivity of 52% and specificity of 88% for near-delivery cases. These\nfindings suggest the potential of PatchCTG to enhance clinical decision-making\nin antepartum care by providing a reliable, objective tool for fetal health\nassessment. The source code is available at\nhttps://github.com/jaleedkhan/PatchCTG."
    },
    {
      "id": "2411.07784v1",
      "title": "Interaction Asymmetry: A General Principle for Learning Composable Abstractions",
      "summary": "Learning disentangled representations of concepts and re-composing them in\nunseen ways is crucial for generalizing to out-of-domain situations. However,\nthe underlying properties of concepts that enable such disentanglement and\ncompositional generalization remain poorly understood. In this work, we propose\nthe principle of interaction asymmetry which states: \"Parts of the same concept\nhave more complex interactions than parts of different concepts\". We formalize\nthis via block diagonality conditions on the $(n+1)$th order derivatives of the\ngenerator mapping concepts to observed data, where different orders of\n\"complexity\" correspond to different $n$. Using this formalism, we prove that\ninteraction asymmetry enables both disentanglement and compositional\ngeneralization. Our results unify recent theoretical results for learning\nconcepts of objects, which we show are recovered as special cases with\n$n\\!=\\!0$ or $1$. We provide results for up to $n\\!=\\!2$, thus extending these\nprior works to more flexible generator functions, and conjecture that the same\nproof strategies generalize to larger $n$. Practically, our theory suggests\nthat, to disentangle concepts, an autoencoder should penalize its latent\ncapacity and the interactions between concepts during decoding. We propose an\nimplementation of these criteria using a flexible Transformer-based VAE, with a\nnovel regularizer on the attention weights of the decoder. On synthetic image\ndatasets consisting of objects, we provide evidence that this model can achieve\ncomparable object disentanglement to existing models that use more explicit\nobject-centric priors."
    },
    {
      "id": "2411.07781v1",
      "title": "RedCode: Risky Code Execution and Generation Benchmark for Code Agents",
      "summary": "With the rapidly increasing capabilities and adoption of code agents for\nAI-assisted coding, safety concerns, such as generating or executing risky\ncode, have become significant barriers to the real-world deployment of these\nagents. To provide comprehensive and practical evaluations on the safety of\ncode agents, we propose RedCode, a benchmark for risky code execution and\ngeneration: (1) RedCode-Exec provides challenging prompts that could lead to\nrisky code execution, aiming to evaluate code agents' ability to recognize and\nhandle unsafe code. We provide a total of 4,050 risky test cases in Python and\nBash tasks with diverse input formats including code snippets and natural text.\nThey covers 25 types of critical vulnerabilities spanning 8 domains (e.g.,\nwebsites, file systems). We provide Docker environments and design\ncorresponding evaluation metrics to assess their execution results. (2)\nRedCode-Gen provides 160 prompts with function signatures and docstrings as\ninput to assess whether code agents will follow instructions to generate\nharmful code or software. Our empirical findings, derived from evaluating three\nagent frameworks based on 19 LLMs, provide insights into code agents'\nvulnerabilities. For instance, evaluations on RedCode-Exec show that agents are\nmore likely to reject executing risky operations on the operating system, but\nare less likely to reject executing technically buggy code, indicating high\nrisks. Risky operations described in natural text lead to a lower rejection\nrate than those in code format. Additionally, evaluations on RedCode-Gen show\nthat more capable base models and agents with stronger overall coding\nabilities, such as GPT4, tend to produce more sophisticated and effective\nharmful software. Our findings highlight the need for stringent safety\nevaluations for diverse code agents. Our dataset and code are available at\nhttps://github.com/AI-secure/RedCode."
    },
    {
      "id": "2411.07773v1",
      "title": "Likelihood as a Performance Gauge for Retrieval-Augmented Generation",
      "summary": "Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization."
    },
    {
      "id": "2411.07772v1",
      "title": "Automatic Album Sequencing",
      "summary": "Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing"
    },
    {
      "id": "2411.08925v1",
      "title": "Retrieval of sun-induced plant fluorescence in the O$_2$-A absorption band from DESIS imagery",
      "summary": "We provide the first method allowing to retrieve spaceborne SIF maps at 30 m\nground resolution with a strong correlation ($r^2=0.6$) to high-quality\nairborne estimates of sun-induced fluorescence (SIF). SIF estimates can provide\nexplanatory information for many tasks related to agricultural management and\nphysiological studies. While SIF products from airborne platforms are accurate\nand spatially well resolved, the data acquisition of such products remains\nscience-oriented and limited to temporally constrained campaigns. Spaceborne\nSIF products on the other hand are available globally with often sufficient\nrevisit times. However, the spatial resolution of spaceborne SIF products is\ntoo small for agricultural applications. In view of ESA's upcoming FLEX mission\nwe develop a method for SIF retrieval in the O$_2$-A band of hyperspectral\nDESIS imagery to provide first insights for spaceborne SIF retrieval at high\nspatial resolution. To this end, we train a simulation-based self-supervised\nnetwork with a novel perturbation based regularizer and test performance\nimprovements under additional supervised regularization of atmospheric variable\nprediction. In a validation study with corresponding HyPlant derived SIF\nestimates at 740 nm we find that our model reaches a mean absolute difference\nof 0.78 mW / nm / sr / m$^2$."
    },
    {
      "id": "2411.07763v1",
      "title": "Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows",
      "summary": "Real-world enterprise text-to-SQL workflows often involve complex cloud or\nlocal data across various database systems, multiple SQL queries in various\ndialects, and diverse operations from data transformation to analytics. We\nintroduce Spider 2.0, an evaluation framework comprising 632 real-world\ntext-to-SQL workflow problems derived from enterprise-level database use cases.\nThe databases in Spider 2.0 are sourced from real data applications, often\ncontaining over 1,000 columns and stored in local or cloud database systems\nsuch as BigQuery and Snowflake. We show that solving problems in Spider 2.0\nfrequently requires understanding and searching through database metadata,\ndialect documentation, and even project-level codebases. This challenge calls\nfor models to interact with complex SQL workflow environments, process\nextremely long contexts, perform intricate reasoning, and generate multiple SQL\nqueries with diverse operations, often exceeding 100 lines, which goes far\nbeyond traditional text-to-SQL challenges. Our evaluations indicate that based\non o1-preview, our code agent framework successfully solves only 17.0% of the\ntasks, compared with 91.2% on Spider 1.0 and 73.0% on BIRD. Our results on\nSpider 2.0 show that while language models have demonstrated remarkable\nperformance in code generation -- especially in prior text-to-SQL benchmarks --\nthey require significant improvement in order to achieve adequate performance\nfor real-world enterprise usage. Progress on Spider 2.0 represents crucial\nsteps towards developing intelligent, autonomous, code agents for real-world\nenterprise settings. Our code, baseline models, and data are available at\nhttps://spider2-sql.github.io."
    },
    {
      "id": "2411.07762v1",
      "title": "ASER: Activation Smoothing and Error Reconstruction for Large Language Model Quantization",
      "summary": "Quantization stands as a pivotal technique for large language model (LLM)\nserving, yet it poses significant challenges particularly in achieving\neffective low-bit quantization. The limited numerical mapping makes the\nquantized model produce a non-trivial error, bringing out intolerable\nperformance degration. This paper is anchored in the basic idea of model\ncompression objectives, and delves into the layer-wise error distribution of\nLLMs during post-training quantization. Subsequently, we introduce ASER, an\nalgorithm consisting of (1) Error Reconstruction: low-rank compensation for\nquantization error with LoRA-style matrices constructed by whitening SVD; (2)\nActivation Smoothing: outlier extraction to gain smooth activation and better\nerror compensation. ASER is capable of quantizing typical LLMs to low-bit ones,\nparticularly preserving accuracy even in W4A8 per-channel setup. Experimental\nresults show that ASER is competitive among the state-of-the-art quantization\nalgorithms, showing potential to activation quantization, with minor overhead."
    },
    {
      "id": "2411.07760v1",
      "title": "Navigation with QPHIL: Quantizing Planner for Hierarchical Implicit Q-Learning",
      "summary": "Offline Reinforcement Learning (RL) has emerged as a powerful alternative to\nimitation learning for behavior modeling in various domains, particularly in\ncomplex navigation tasks. An existing challenge with Offline RL is the\nsignal-to-noise ratio, i.e. how to mitigate incorrect policy updates due to\nerrors in value estimates. Towards this, multiple works have demonstrated the\nadvantage of hierarchical offline RL methods, which decouples high-level path\nplanning from low-level path following. In this work, we present a novel\nhierarchical transformer-based approach leveraging a learned quantizer of the\nspace. This quantization enables the training of a simpler zone-conditioned\nlow-level policy and simplifies planning, which is reduced to discrete\nautoregressive prediction. Among other benefits, zone-level reasoning in\nplanning enables explicit trajectory stitching rather than implicit stitching\nbased on noisy value function estimates. By combining this transformer-based\nplanner with recent advancements in offline RL, our proposed approach achieves\nstate-of-the-art results in complex long-distance navigation environments."
    },
    {
      "id": "2411.07759v1",
      "title": "Optimizing Traffic Signal Control using High-Dimensional State Representation and Efficient Deep Reinforcement Learning",
      "summary": "In reinforcement learning-based (RL-based) traffic signal control (TSC),\ndecisions on the signal timing are made based on the available information on\nvehicles at a road intersection. This forms the state representation for the RL\nenvironment which can either be high-dimensional containing several variables\nor a low-dimensional vector. Current studies suggest that using high\ndimensional state representations does not lead to improved performance on TSC.\nHowever, we argue, with experimental results, that the use of high dimensional\nstate representations can, in fact, lead to improved TSC performance with\nimprovements up to 17.9% of the average waiting time. This high-dimensional\nrepresentation is obtainable using the cost-effective vehicle-to-infrastructure\n(V2I) communication, encouraging its adoption for TSC. Additionally, given the\nlarge size of the state, we identified the need to have computational efficient\nmodels and explored model compression via pruning."
    },
    {
      "id": "2411.07753v1",
      "title": "Spatially Regularized Graph Attention Autoencoder Framework for Detecting Rainfall Extremes",
      "summary": "We introduce a novel Graph Attention Autoencoder (GAE) with spatial\nregularization to address the challenge of scalable anomaly detection in\nspatiotemporal rainfall data across India from 1990 to 2015. Our model\nleverages a Graph Attention Network (GAT) to capture spatial dependencies and\ntemporal dynamics in the data, further enhanced by a spatial regularization\nterm ensuring geographic coherence. We construct two graph datasets employing\nrainfall, pressure, and temperature attributes from the Indian Meteorological\nDepartment and ERA5 Reanalysis on Single Levels, respectively. Our network\noperates on graph representations of the data, where nodes represent geographic\nlocations, and edges, inferred through event synchronization, denote\nsignificant co-occurrences of rainfall events. Through extensive experiments,\nwe demonstrate that our GAE effectively identifies anomalous rainfall patterns\nacross the Indian landscape. Our work paves the way for sophisticated\nspatiotemporal anomaly detection methodologies in climate science, contributing\nto better climate change preparedness and response strategies."
    },
    {
      "id": "2411.07751v1",
      "title": "SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model",
      "summary": "Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/"
    },
    {
      "id": "2411.07739v1",
      "title": "Unlocking Legal Knowledge with Multi-Layered Embedding-Based Retrieval",
      "summary": "This work addresses the challenge of capturing the complexities of legal\nknowledge by proposing a multi-layered embedding-based retrieval method for\nlegal and legislative texts. Creating embeddings not only for individual\narticles but also for their components (paragraphs, clauses) and structural\ngroupings (books, titles, chapters, etc), we seek to capture the subtleties of\nlegal information through the use of dense vectors of embeddings, representing\nit at varying levels of granularity. Our method meets various information needs\nby allowing the Retrieval Augmented Generation system to provide accurate\nresponses, whether for specific segments or entire sections, tailored to the\nuser's query. We explore the concepts of aboutness, semantic chunking, and\ninherent hierarchy within legal texts, arguing that this method enhances the\nlegal information retrieval. Despite the focus being on Brazil's legislative\nmethods and the Brazilian Constitution, which follow a civil law tradition, our\nfindings should in principle be applicable across different legal systems,\nincluding those adhering to common law traditions. Furthermore, the principles\nof the proposed method extend beyond the legal domain, offering valuable\ninsights for organizing and retrieving information in any field characterized\nby information encoded in hierarchical text."
    },
    {
      "id": "2411.07729v1",
      "title": "Exploring the loss landscape of regularized neural networks via convex duality",
      "summary": "We discuss several aspects of the loss landscape of regularized neural\nnetworks: the structure of stationary points, connectivity of optimal\nsolutions, path with nonincreasing loss to arbitrary global optimum, and the\nnonuniqueness of optimal solutions, by casting the problem into an equivalent\nconvex problem and considering its dual. Starting from two-layer neural\nnetworks with scalar output, we first characterize the solution set of the\nconvex problem using its dual and further characterize all stationary points.\nWith the characterization, we show that the topology of the global optima goes\nthrough a phase transition as the width of the network changes, and construct\ncounterexamples where the problem may have a continuum of optimal solutions.\nFinally, we show that the solution set characterization and connectivity\nresults can be extended to different architectures, including two-layer\nvector-valued neural networks and parallel three-layer neural networks."
    },
    {
      "id": "2411.07728v1",
      "title": "No-Reference Point Cloud Quality Assessment via Graph Convolutional Network",
      "summary": "Three-dimensional (3D) point cloud, as an emerging visual media format, is\nincreasingly favored by consumers as it can provide more realistic visual\ninformation than two-dimensional (2D) data. Similar to 2D plane images and\nvideos, point clouds inevitably suffer from quality degradation and information\nloss through multimedia communication systems. Therefore, automatic point cloud\nquality assessment (PCQA) is of critical importance. In this work, we propose a\nnovel no-reference PCQA method by using a graph convolutional network (GCN) to\ncharacterize the mutual dependencies of multi-view 2D projected image contents.\nThe proposed GCN-based PCQA (GC-PCQA) method contains three modules, i.e.,\nmulti-view projection, graph construction, and GCN-based quality prediction.\nFirst, multi-view projection is performed on the test point cloud to obtain a\nset of horizontally and vertically projected images. Then, a\nperception-consistent graph is constructed based on the spatial relations among\ndifferent projected images. Finally, reasoning on the constructed graph is\nperformed by GCN to characterize the mutual dependencies and interactions\nbetween different projected images, and aggregate feature information of\nmulti-view projected images for final quality prediction. Experimental results\non two publicly available benchmark databases show that our proposed GC-PCQA\ncan achieve superior performance than state-of-the-art quality assessment\nmetrics. The code will be available at: https://github.com/chenwuwq/GC-PCQA."
    },
    {
      "id": "2411.07724v1",
      "title": "Convergence Rate Analysis of LION",
      "summary": "The LION (evoLved sIgn mOmeNtum) optimizer for deep neural network training\nwas found by Google via program search, with the simple sign update yet showing\nimpressive performance in training large scale networks. Although previous\nstudies have investigated its convergence properties, a comprehensive analysis,\nespecially the convergence rate, is still desirable. Recognizing that LION can\nbe regarded as solving a specific constrained problem, this paper focuses on\ndemonstrating its convergence to the Karush-Kuhn-Tucker (KKT) point at the rate\nof $\\cal O(\\sqrt{d}K^{-1/4})$ measured by gradient $\\ell_1$ norm, where $d$ is\nthe problem dimension and $K$ is the number of iteration steps. Step further,\nwe remove the constraint and establish that LION converges to the critical\npoint of the general unconstrained problem at the same rate. This rate not only\ndelivers the currently optimal dependence on the problem dimension $d$ but also\ntightly matches the theoretical lower bound for nonconvex stochastic\noptimization algorithms, which is typically measured using the gradient\n$\\ell_2$ norm, with respect to the number of iterations $K$. Through extensive\nexperiments, we not only demonstrate that LION achieves lower loss and higher\nperformance compared to standard SGD, but also empirically confirm that the\ngradient $\\ell_1/\\ell_2$ norm ratio aligns with $\\Theta(\\sqrt{d})$, thus\nproving that our convergence rate matches the theoretical lower bound with\nrespect to $d$ in the empirical sense."
    },
    {
      "id": "2411.07722v1",
      "title": "Is Cognition consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding",
      "summary": "Multimodal large language models (MLLMs) have shown impressive capabilities\nin document understanding, a rapidly growing research area with significant\nindustrial demand in recent years. As a multimodal task, document understanding\nrequires models to possess both perceptual and cognitive abilities. However,\ncurrent MLLMs often face conflicts between perception and cognition. Taking a\ndocument VQA task (cognition) as an example, an MLLM might generate answers\nthat do not match the corresponding visual content identified by its OCR\n(perception). This conflict suggests that the MLLM might struggle to establish\nan intrinsic connection between the information it \"sees\" and what it\n\"understands.\" Such conflicts challenge the intuitive notion that cognition is\nconsistent with perception, hindering the performance and explainability of\nMLLMs. In this paper, we define the conflicts between cognition and perception\nas Cognition and Perception (C&P) knowledge conflicts, a form of multimodal\nknowledge conflicts, and systematically assess them with a focus on document\nunderstanding. Our analysis reveals that even GPT-4o, a leading MLLM, achieves\nonly 68.6% C&P consistency. To mitigate the C&P knowledge conflicts, we propose\na novel method called Multimodal Knowledge Consistency Fine-tuning. This method\nfirst ensures task-specific consistency and then connects the cognitive and\nperceptual knowledge. Our method significantly reduces C&P knowledge conflicts\nacross all tested MLLMs and enhances their performance in both cognitive and\nperceptual tasks in most scenarios."
    },
    {
      "id": "2411.08082v1",
      "title": "Explainable Deep Learning Framework for SERS Bio-quantification",
      "summary": "Surface-enhanced Raman spectroscopy (SERS) is a potential fast and\ninexpensive method of analyte quantification, which can be combined with deep\nlearning to discover biomarker-disease relationships. This study aims to\naddress present challenges of SERS through a novel SERS bio-quantification\nframework, including spectral processing, analyte quantification, and model\nexplainability. To this end,serotonin quantification in urine media was\nassessed as a model task with 682 SERS spectra measured in a micromolar range\nusing cucurbit[8]uril chemical spacers. A denoising autoencoder was utilized\nfor spectral enhancement, and convolutional neural networks (CNN) and vision\ntransformers were utilized for biomarker quantification. Lastly, a novel\ncontext representative interpretable model explanations (CRIME) method was\ndeveloped to suit the current needs of SERS mixture analysis explainability.\nSerotonin quantification was most efficient in denoised spectra analysed using\na convolutional neural network with a three-parameter logistic output layer\n(mean absolute error = 0.15 {\\mu}M, mean percentage error = 4.67%).\nSubsequently, the CRIME method revealed the CNN model to present six prediction\ncontexts, of which three were associated with serotonin. The proposed framework\ncould unlock a novel, untargeted hypothesis generating method of biomarker\ndiscovery considering the rapid and inexpensive nature of SERS measurements,\nand the potential to identify biomarkers from CRIME contexts."
    },
    {
      "id": "2411.07719v1",
      "title": "EMPERROR: A Flexible Generative Perception Error Model for Probing Self-Driving Planners",
      "summary": "To handle the complexities of real-world traffic, learning planners for\nself-driving from data is a promising direction. While recent approaches have\nshown great progress, they typically assume a setting in which the ground-truth\nworld state is available as input. However, when deployed, planning needs to be\nrobust to the long-tail of errors incurred by a noisy perception system, which\nis often neglected in evaluation. To address this, previous work has proposed\ndrawing adversarial samples from a perception error model (PEM) mimicking the\nnoise characteristics of a target object detector. However, these methods use\nsimple PEMs that fail to accurately capture all failure modes of detection. In\nthis paper, we present EMPERROR, a novel transformer-based generative PEM,\napply it to stress-test an imitation learning (IL)-based planner and show that\nit imitates modern detectors more faithfully than previous work. Furthermore,\nit is able to produce realistic noisy inputs that increase the planner's\ncollision rate by up to 85%, demonstrating its utility as a valuable tool for a\nmore complete evaluation of self-driving planners."
    },
    {
      "id": "2411.07715v1",
      "title": "Training Data for Large Language Model",
      "summary": "In 2022, with the release of ChatGPT, large-scale language models gained\nwidespread attention. ChatGPT not only surpassed previous models in terms of\nparameters and the scale of its pretraining corpus but also achieved\nrevolutionary performance improvements through fine-tuning on a vast amount of\nhigh-quality, human-annotated data. This progress has led enterprises and\nresearch institutions to recognize that building smarter and more powerful\nmodels relies on rich and high-quality datasets. Consequently, the construction\nand optimization of datasets have become a critical focus in the field of\nartificial intelligence. This paper summarizes the current state of pretraining\nand fine-tuning data for training large-scale language models, covering aspects\nsuch as data scale, collection methods, data types and characteristics,\nprocessing workflows, and provides an overview of available open-source\ndatasets."
    },
    {
      "id": "2411.07711v1",
      "title": "OWLed: Outlier-weighed Layerwise Pruning for Efficient Autonomous Driving Framework",
      "summary": "The integration of Large Language Models (LLMs) into autonomous driving\nsystems offers promising enhancements in environmental understanding and\ndecision-making. However, the substantial computational demands of deploying\nLLMs locally on vehicles render this approach unfeasible for real-world\nautomotive applications. To address this challenge, we introduce OWLed, the\nOutlier-Weighed Layerwise Pruning for Efficient Autonomous Driving Framework\nthat leverages outlier-weighted layerwise sparsity for model compression. Our\nmethod assigns non-uniform sparsity ratios to different layers based on the\ndistribution of outlier features, significantly reducing the model size without\nthe need for fine-tuning. To ensure the compressed model adapts well to\nautonomous driving tasks, we incorporate driving environment data into both the\ncalibration and pruning processes. Our empirical studies reveal that the\nencoder component is more sensitive to pruning than the LLM, highlighting its\ncritical role in the system. Experimental results demonstrate that OWLed\noutperforms existing methods in perception, action prediction, and language\nunderstanding while substantially lowering computational requirements. These\nfindings underscore the potential of combining advanced pruning techniques with\nLLMs to develop efficient and robust autonomous driving systems capable of\nhandling complex scenarios. Code will be made publicly available."
    },
    {
      "id": "2411.07700v1",
      "title": "Test Where Decisions Matter: Importance-driven Testing for Deep Reinforcement Learning",
      "summary": "In many Deep Reinforcement Learning (RL) problems, decisions in a trained\npolicy vary in significance for the expected safety and performance of the\npolicy. Since RL policies are very complex, testing efforts should concentrate\non states in which the agent's decisions have the highest impact on the\nexpected outcome. In this paper, we propose a novel model-based method to\nrigorously compute a ranking of state importance across the entire state space.\nWe then focus our testing efforts on the highest-ranked states. In this paper,\nwe focus on testing for safety. However, the proposed methods can be easily\nadapted to test for performance. In each iteration, our testing framework\ncomputes optimistic and pessimistic safety estimates. These estimates provide\nlower and upper bounds on the expected outcomes of the policy execution across\nall modeled states in the state space. Our approach divides the state space\ninto safe and unsafe regions upon convergence, providing clear insights into\nthe policy's weaknesses. Two important properties characterize our approach.\n(1) Optimal Test-Case Selection: At any time in the testing process, our\napproach evaluates the policy in the states that are most critical for safety.\n(2) Guaranteed Safety: Our approach can provide formal verification guarantees\nover the entire state space by sampling only a fraction of the policy. Any\nsafety properties assured by the pessimistic estimate are formally proven to\nhold for the policy. We provide a detailed evaluation of our framework on\nseveral examples, showing that our method discovers unsafe policy behavior with\nlow testing effort."
    },
    {
      "id": "2411.07691v1",
      "title": "New Emerged Security and Privacy of Pre-trained Model: a Survey and Outlook",
      "summary": "Thanks to the explosive growth of data and the development of computational\nresources, it is possible to build pre-trained models that can achieve\noutstanding performance on various tasks, such as neural language processing,\ncomputer vision, and more. Despite their powerful capabilities, pre-trained\nmodels have also sparked attention to the emerging security challenges\nassociated with their real-world applications. Security and privacy issues,\nsuch as leaking privacy information and generating harmful responses, have\nseriously undermined users' confidence in these powerful models. Concerns are\ngrowing as model performance improves dramatically. Researchers are eager to\nexplore the unique security and privacy issues that have emerged, their\ndistinguishing factors, and how to defend against them. However, the current\nliterature lacks a clear taxonomy of emerging attacks and defenses for\npre-trained models, which hinders a high-level and comprehensive understanding\nof these questions. To fill the gap, we conduct a systematical survey on the\nsecurity risks of pre-trained models, proposing a taxonomy of attack and\ndefense methods based on the accessibility of pre-trained models' input and\nweights in various security test scenarios. This taxonomy categorizes attacks\nand defenses into No-Change, Input-Change, and Model-Change approaches. With\nthe taxonomy analysis, we capture the unique security and privacy issues of\npre-trained models, categorizing and summarizing existing security issues based\non their characteristics. In addition, we offer a timely and comprehensive\nreview of each category's strengths and limitations. Our survey concludes by\nhighlighting potential new research opportunities in the security and privacy\nof pre-trained models."
    },
    {
      "id": "2411.07690v1",
      "title": "World Models: The Safety Perspective",
      "summary": "With the proliferation of the Large Language Model (LLM), the concept of\nWorld Models (WM) has recently attracted a great deal of attention in the AI\nresearch community, especially in the context of AI agents. It is arguably\nevolving into an essential foundation for building AI agent systems. A WM is\nintended to help the agent predict the future evolution of environmental states\nor help the agent fill in missing information so that it can plan its actions\nand behave safely. The safety property of WM plays a key role in their\neffective use in critical applications. In this work, we review and analyze the\nimpacts of the current state-of-the-art in WM technology from the point of view\nof trustworthiness and safety based on a comprehensive survey and the fields of\napplication envisaged. We provide an in-depth analysis of state-of-the-art WMs\nand derive technical research challenges and their impact in order to call on\nthe research community to collaborate on improving the safety and\ntrustworthiness of WM."
    },
    {
      "id": "2411.07688v1",
      "title": "Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG",
      "summary": "Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000\n$\\times$ 100,000 pixels or more) poses a significant challenge for current\nRemote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize\nthe UHR image to standard input image size, the extensive spatial and\ncontextual information that UHR images contain will be neglected. Otherwise,\nthe original size of these images often exceeds the token limits of standard\nRSMLLMs, making it difficult to process the entire image and capture long-range\ndependencies to answer the query based on the abundant visual context. In this\npaper, we introduce ImageRAG for RS, a training-free framework to address the\ncomplexities of analyzing UHR remote sensing imagery. By transforming UHR\nremote sensing image analysis task to image's long context selection task, we\ndesign an innovative image contextual retrieval mechanism based on the\nRetrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's\ncore innovation lies in its ability to selectively retrieve and focus on the\nmost relevant portions of the UHR image as visual contexts that pertain to a\ngiven query. Fast path and slow path are proposed in this framework to handle\nthis task efficiently and effectively. ImageRAG allows RSMLLMs to manage\nextensive context and spatial information from UHR RSI, ensuring the analysis\nis both accurate and efficient."
    },
    {
      "id": "2411.07686v1",
      "title": "Data-Driven Graph Switching for Cyber-Resilient Control in Microgrids",
      "summary": "Distributed microgrids are conventionally dependent on communication networks\nto achieve secondary control objectives. This dependence makes them vulnerable\nto stealth data integrity attacks (DIAs) where adversaries may perform\nmanipulations via infected transmitters and repeaters to jeopardize stability.\nThis paper presents a physics-guided, supervised Artificial Neural Network\n(ANN)-based framework that identifies communication-level cyberattacks in\nmicrogrids by analyzing whether incoming measurements will cause abnormal\nbehavior of the secondary control layer. If abnormalities are detected, an\niteration through possible spanning tree graph topologies that can be used to\nfulfill secondary control objectives is done. Then, a communication network\ntopology that would not create secondary control abnormalities is identified\nand enforced for maximum stability. By altering the communication graph\ntopology, the framework eliminates the dependence of the secondary control\nlayer on inputs from compromised cyber devices helping it achieve resilience\nwithout instability. Several case studies are provided showcasing the\nrobustness of the framework against False Data Injections and repeater-level\nMan-in-the-Middle attacks. To understand practical feasibility, robustness is\nalso verified against larger microgrid sizes and in the presence of varying\nnoise levels. Our findings indicate that performance can be affected when\nattempting scalability in the presence of noise. However, the framework\noperates robustly in low-noise settings."
    },
    {
      "id": "2411.07685v1",
      "title": "Fast Disentangled Slim Tensor Learning for Multi-view Clustering",
      "summary": "Tensor-based multi-view clustering has recently received significant\nattention due to its exceptional ability to explore cross-view high-order\ncorrelations. However, most existing methods still encounter some limitations.\n(1) Most of them explore the correlations among different affinity matrices,\nmaking them unscalable to large-scale data. (2) Although some methods address\nit by introducing bipartite graphs, they may result in sub-optimal solutions\ncaused by an unstable anchor selection process. (3) They generally ignore the\nnegative impact of latent semantic-unrelated information in each view. To\ntackle these issues, we propose a new approach termed fast Disentangled Slim\nTensor Learning (DSTL) for multi-view clustering . Instead of focusing on the\nmulti-view graph structures, DSTL directly explores the high-order correlations\namong multi-view latent semantic representations based on matrix factorization.\nTo alleviate the negative influence of feature redundancy, inspired by robust\nPCA, DSTL disentangles the latent low-dimensional representation into a\nsemantic-unrelated part and a semantic-related part for each view.\nSubsequently, two slim tensors are constructed with tensor-based\nregularization. To further enhance the quality of feature disentanglement, the\nsemantic-related representations are aligned across views through a consensus\nalignment indicator. Our proposed model is computationally efficient and can be\nsolved effectively. Extensive experiments demonstrate the superiority and\nefficiency of DSTL over state-of-the-art approaches. The code of DSTL is\navailable at https://github.com/dengxu-nju/DSTL."
    },
    {
      "id": "2411.07684v1",
      "title": "AI enhanced diagnosis of Peyronies disease a novel approach using Computer Vision",
      "summary": "This study presents an innovative AI-driven tool for diagnosing Peyronie's\nDisease (PD), a condition that affects between 0.3% and 13.1% of men worldwide.\nOur method uses key point detection on both images and videos to measure penile\ncurvature angles, utilizing advanced computer vision techniques. This tool has\ndemonstrated high accuracy in identifying anatomical landmarks, validated\nagainst conventional goniometer measurements. Traditional PD diagnosis often\ninvolves subjective and invasive methods, which can lead to patient discomfort\nand inaccuracies. Our approach offers a precise, reliable, and non-invasive\ndiagnostic tool to address these drawbacks. The model distinguishes between PD\nand normal anatomical changes with a sensitivity of 96.7% and a specificity of\n100%. This advancement represents a significant improvement in urological\ndiagnostics, greatly enhancing the efficacy and convenience of PD assessment\nfor healthcare providers and patients."
    },
    {
      "id": "2411.07681v1",
      "title": "What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?",
      "summary": "Despite the remarkable capabilities of modern large language models (LLMs),\nthe mechanisms behind their problem-solving abilities remain elusive. In this\nwork, we aim to better understand how the learning dynamics of LLM finetuning\nshapes downstream generalization. Our analysis focuses on reasoning tasks,\nwhose problem structure allows us to distinguish between memorization (the\nexact replication of reasoning steps from the training data) and performance\n(the correctness of the final solution). We find that a model's generalization\nbehavior can be effectively characterized by a training metric we call\npre-memorization train accuracy: the accuracy of model samples on training\nqueries before they begin to copy the exact reasoning steps from the training\nset. On the dataset level, this metric is able to reliably predict test\naccuracy, achieving $R^2$ of around or exceeding 0.9 across various models\n(Llama3 8, Gemma2 9B), datasets (GSM8k, MATH), and training configurations. On\na per-example level, this metric is also indicative of whether individual model\npredictions are robust to perturbations in the training query. By connecting a\nmodel's learning behavior to its generalization, pre-memorization train\naccuracy can guide targeted improvements to training strategies. We focus on\ndata curation as an example, and show that prioritizing examples with low\npre-memorization accuracy leads to 1.5-2x improvements in data efficiency\ncompared to i.i.d. data scaling, and outperforms other standard data curation\ntechniques."
    },
    {
      "id": "2411.07679v1",
      "title": "Safe Exploitative Play with Untrusted Type Beliefs",
      "summary": "The combination of the Bayesian game and learning has a rich history, with\nthe idea of controlling a single agent in a system composed of multiple agents\nwith unknown behaviors given a set of types, each specifying a possible\nbehavior for the other agents. The idea is to plan an agent's own actions with\nrespect to those types which it believes are most likely to maximize the\npayoff. However, the type beliefs are often learned from past actions and\nlikely to be incorrect. With this perspective in mind, we consider an agent in\na game with type predictions of other components, and investigate the impact of\nincorrect beliefs to the agent's payoff. In particular, we formally define a\ntradeoff between risk and opportunity by comparing the payoff obtained against\nthe optimal payoff, which is represented by a gap caused by trusting or\ndistrusting the learned beliefs. Our main results characterize the tradeoff by\nestablishing upper and lower bounds on the Pareto front for both normal-form\nand stochastic Bayesian games, with numerical results provided."
    },
    {
      "id": "2411.07672v1",
      "title": "Rethinking Structure Learning For Graph Neural Networks",
      "summary": "To improve the performance of Graph Neural Networks (GNNs), Graph Structure\nLearning (GSL) has been extensively applied to reconstruct or refine original\ngraph structures, effectively addressing issues like heterophily,\nover-squashing, and noisy structures. While GSL is generally thought to improve\nGNN performance, it often leads to longer training times and more\nhyperparameter tuning. Besides, the distinctions among current GSL methods\nremain ambiguous from the perspective of GNN training, and there is a lack of\ntheoretical analysis to quantify their effectiveness. Recent studies further\nsuggest that, under fair comparisons with the same hyperparameter tuning, GSL\ndoes not consistently outperform baseline GNNs. This motivates us to ask a\ncritical question: is GSL really useful for GNNs? To address this question,\nthis paper makes two key contributions. First, we propose a new GSL framework,\nwhich includes three steps: GSL base (the representation used for GSL)\nconstruction, new structure construction, and view fusion, to better understand\nthe effectiveness of GSL in GNNs. Second, after graph convolution, we analyze\nthe differences in mutual information (MI) between node representations derived\nfrom the original topology and those from the newly constructed topology.\nSurprisingly, our empirical observations and theoretical analysis show that no\nmatter which type of graph structure construction methods are used, after\nfeeding the same GSL bases to the newly constructed graph, there is no MI gain\ncompared to the original GSL bases. To fairly reassess the effectiveness of\nGSL, we conduct ablation experiments and find that it is the pretrained GSL\nbases that enhance GNN performance, and in most cases, GSL cannot improve GNN\nperformance. This finding encourages us to rethink the essential components in\nGNNs, such as self-training and structural encoding, in GNN design rather than\nGSL."
    },
    {
      "id": "2411.07663v1",
      "title": "Is Graph Convolution Always Beneficial For Every Feature?",
      "summary": "Graph Neural Networks (GNNs) have demonstrated strong capabilities in\nprocessing structured data. While traditional GNNs typically treat each feature\ndimension equally during graph convolution, we raise an important question: Is\nthe graph convolution operation equally beneficial for each feature? If not,\nthe convolution operation on certain feature dimensions can possibly lead to\nharmful effects, even worse than the convolution-free models. In prior studies,\nto assess the impacts of graph convolution on features, people proposed metrics\nbased on feature homophily to measure feature consistency with the graph\ntopology. However, these metrics have shown unsatisfactory alignment with GNN\nperformance and have not been effectively employed to guide feature selection\nin GNNs. To address these limitations, we introduce a novel metric, Topological\nFeature Informativeness (TFI), to distinguish between GNN-favored and\nGNN-disfavored features, where its effectiveness is validated through both\ntheoretical analysis and empirical observations. Based on TFI, we propose a\nsimple yet effective Graph Feature Selection (GFS) method, which processes\nGNN-favored and GNN-disfavored features separately, using GNNs and non-GNN\nmodels. Compared to original GNNs, GFS significantly improves the extraction of\nuseful topological information from each feature with comparable computational\ncosts. Extensive experiments show that after applying GFS to 8 baseline and\nstate-of-the-art (SOTA) GNN architectures across 10 datasets, 83.75% of the\nGFS-augmented cases show significant performance boosts. Furthermore, our\nproposed TFI metric outperforms other feature selection methods. These results\nvalidate the effectiveness of both GFS and TFI. Additionally, we demonstrate\nthat GFS's improvements are robust to hyperparameter tuning, highlighting its\npotential as a universal method for enhancing various GNN architectures."
    },
    {
      "id": "2411.07656v1",
      "title": "Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach",
      "summary": "Large Language Models (LLMs) often perpetuate biases in pronoun usage,\nleading to misrepresentation or exclusion of queer individuals. This paper\naddresses the specific problem of biased pronoun usage in LLM outputs,\nparticularly the inappropriate use of traditionally gendered pronouns (\"he,\"\n\"she\") when inclusive language is needed to accurately represent all\nidentities. We introduce a collaborative agent pipeline designed to mitigate\nthese biases by analyzing and optimizing pronoun usage for inclusivity. Our\nmulti-agent framework includes specialized agents for both bias detection and\ncorrection. Experimental evaluations using the Tango dataset-a benchmark\nfocused on gender pronoun usage-demonstrate that our approach significantly\nimproves inclusive pronoun classification, achieving a 32.6 percentage point\nincrease over GPT-4o in correctly disagreeing with inappropriate traditionally\ngendered pronouns $(\\chi^2 = 38.57, p < 0.0001)$. These results accentuate the\npotential of agent-driven frameworks in enhancing fairness and inclusivity in\nAI-generated content, demonstrating their efficacy in reducing biases and\npromoting socially responsible AI."
    },
    {
      "id": "2411.07654v1",
      "title": "Spike Talk in Power Electronic Grids -- Leveraging Post Moore's Computing Laws",
      "summary": "Emerging distributed generation demands highly reliable and resilient\ncoordinating control in microgrids. To improve on these aspects, spiking neural\nnetwork is leveraged, as a grid-edge intelligence tool to establish a talkative\ninfrastructure, Spike Talk, expediting coordination in next-generation\nmicrogrids without the need of communication at all. This paper unravels the\nphysics behind Spike Talk from the perspective of its distributed\ninfrastructure, which aims to address the Von Neumann Bottleneck. Relying on\ninferring information via power flows in tie lines, Spike Talk allows adaptive\nand flexible control and coordination itself, and features in synaptic\nplasticity facilitating online and local training functionality. Preliminary\ncase studies are demonstrated with results, while more extensive validations\nare to be included as future scopes of work."
    },
    {
      "id": "2411.07650v1",
      "title": "Understanding Audiovisual Deepfake Detection: Techniques, Challenges, Human Factors and Perceptual Insights",
      "summary": "Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity."
    },
    {
      "id": "2411.07643v1",
      "title": "xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell Lung Cancer",
      "summary": "Understanding how deep learning models predict oncology patient risk can\nprovide critical insights into disease progression, support clinical\ndecision-making, and pave the way for trustworthy and data-driven precision\nmedicine. Building on recent advances in the spatial modeling of the tumor\nmicroenvironment using graph neural networks, we present an explainable cell\ngraph (xCG) approach for survival prediction. We validate our model on a public\ncohort of imaging mass cytometry (IMC) data for 416 cases of lung\nadenocarcinoma. We explain survival predictions in terms of known phenotypes on\nthe cell level by computing risk attributions over cell graphs, for which we\npropose an efficient grid-based layer-wise relevance propagation (LRP) method.\nOur ablation studies highlight the importance of incorporating the cancer stage\nand model ensembling to improve the quality of risk estimates. Our xCG method,\ntogether with the IMC data, is made publicly available to support further\nresearch."
    },
    {
      "id": "2411.07641v1",
      "title": "Top-$n\u03c3$: Not All Logits Are You Need",
      "summary": "Large language models (LLMs) typically employ greedy decoding or\nlow-temperature sampling for reasoning tasks, reflecting a perceived trade-off\nbetween diversity and accuracy. We challenge this convention by introducing\ntop-$n\\sigma$, a novel sampling method that operates directly on pre-softmax\nlogits by leveraging a statistical threshold. Our key insight is that logits\nnaturally separate into a Gaussian-distributed noisy region and a distinct\ninformative region, enabling efficient token filtering without complex\nprobability manipulations. Unlike existing methods (e.g., top-$p$, min-$p$)\nthat inadvertently include more noise tokens at higher temperatures,\ntop-$n\\sigma$ maintains a stable sampling space regardless of temperature\nscaling. We also provide a theoretical analysis of top-$n\\sigma$ to better\nunderstand its behavior. The extensive experimental results across four\nreasoning-focused datasets demonstrate that our method not only outperforms\nexisting sampling approaches but also surpasses greedy decoding, while\nmaintaining consistent performance even at high temperatures."
    },
    {
      "id": "2411.07634v1",
      "title": "Exploring Multi-Agent Reinforcement Learning for Unrelated Parallel Machine Scheduling",
      "summary": "Scheduling problems pose significant challenges in resource, industry, and\noperational management. This paper addresses the Unrelated Parallel Machine\nScheduling Problem (UPMS) with setup times and resources using a Multi-Agent\nReinforcement Learning (MARL) approach. The study introduces the Reinforcement\nLearning environment and conducts empirical analyses, comparing MARL with\nSingle-Agent algorithms. The experiments employ various deep neural network\npolicies for single- and Multi-Agent approaches. Results demonstrate the\nefficacy of the Maskable extension of the Proximal Policy Optimization (PPO)\nalgorithm in Single-Agent scenarios and the Multi-Agent PPO algorithm in\nMulti-Agent setups. While Single-Agent algorithms perform adequately in reduced\nscenarios, Multi-Agent approaches reveal challenges in cooperative learning but\na scalable capacity. This research contributes insights into applying MARL\ntechniques to scheduling optimization, emphasizing the need for algorithmic\nsophistication balanced with scalability for intelligent scheduling solutions."
    },
    {
      "id": "2411.08923v1",
      "title": "Aligning Visual Contrastive learning models via Preference Optimization",
      "summary": "Contrastive learning models have demonstrated impressive abilities to capture\nsemantic similarities by aligning representations in the embedding space.\nHowever, their performance can be limited by the quality of the training data\nand its inherent biases. While Reinforcement Learning from Human Feedback\n(RLHF) and Direct Preference Optimization (DPO) have been applied to generative\nmodels to align them with human preferences, their use in contrastive learning\nhas yet to be explored. This paper introduces a novel method for training\ncontrastive learning models using Preference Optimization (PO) to break down\ncomplex concepts. Our method systematically aligns model behavior with desired\npreferences, enhancing performance on the targeted task. In particular, we\nfocus on enhancing model robustness against typographic attacks, commonly seen\nin contrastive models like CLIP. We further apply our method to disentangle\ngender understanding and mitigate gender biases, offering a more nuanced\ncontrol over these sensitive attributes. Our experiments demonstrate that\nmodels trained using PO outperform standard contrastive learning techniques\nwhile retaining their ability to handle adversarial challenges and maintain\naccuracy on other downstream tasks. This makes our method well-suited for tasks\nrequiring fairness, robustness, and alignment with specific preferences. We\nevaluate our method on several vision-language tasks, tackling challenges such\nas typographic attacks. Additionally, we explore the model's ability to\ndisentangle gender concepts and mitigate gender bias, showcasing the\nversatility of our approach."
    },
    {
      "id": "2411.07623v1",
      "title": "Annotating Constructions with UD: the experience of the Italian Constructicon",
      "summary": "The paper descirbes a first attempt of linking the Italian constructicon to\nUD resources"
    },
    {
      "id": "2411.07618v1",
      "title": "Direct Preference Optimization Using Sparse Feature-Level Constraints",
      "summary": "The alignment of large language models (LLMs) with human preferences remains\na key challenge. While post-training techniques like Reinforcement Learning\nfrom Human Feedback (RLHF) and Direct Preference Optimization (DPO) have\nachieved notable success, they often introduce computational inefficiencies and\ntraining instability. In this paper, we propose Feature-level constrained\nPreference Optimization (FPO), a novel method designed to simplify the\nalignment process while ensuring stability. FPO leverages pre-trained Sparse\nAutoencoders (SAEs) and introduces feature-level constraints, allowing for\nefficient, sparsity-enforced alignment. Our approach enjoys efficiency by using\nsparse features activated in a well-trained sparse autoencoder and the quality\nof sequential KL divergence by using the feature-level offline reference.\nExperimental results on benchmark datasets demonstrate that FPO achieves a\n5.08% absolute improvement in win rate with much lower computational cost\ncompared to state-of-the-art baselines, making it a promising solution for\nefficient and controllable LLM alignments."
    },
    {
      "id": "2411.07611v1",
      "title": "Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation",
      "summary": "Clinical rationales play a pivotal role in accurate disease diagnosis;\nhowever, many models predominantly use discriminative methods and overlook the\nimportance of generating supportive rationales. Rationale distillation is a\nprocess that transfers knowledge from large language models (LLMs) to smaller\nlanguage models (SLMs), thereby enhancing the latter's ability to break down\ncomplex tasks. Despite its benefits, rationale distillation alone is inadequate\nfor addressing domain knowledge limitations in tasks requiring specialized\nexpertise, such as disease diagnosis. Effectively embedding domain knowledge in\nSLMs poses a significant challenge. While current LLMs are primarily geared\ntoward processing textual data, multimodal LLMs that incorporate time series\ndata, especially electronic health records (EHRs), are still evolving. To\ntackle these limitations, we introduce ClinRaGen, an SLM optimized for\nmultimodal rationale generation in disease diagnosis. ClinRaGen incorporates a\nunique knowledge-augmented attention mechanism to merge domain knowledge with\ntime series EHR data, utilizing a stepwise rationale distillation strategy to\nproduce both textual and time series-based clinical rationales. Our evaluations\nshow that ClinRaGen markedly improves the SLM's capability to interpret\nmultimodal EHR data and generate accurate clinical rationales, supporting more\nreliable disease diagnosis, advancing LLM applications in healthcare, and\nnarrowing the performance divide between LLMs and SLMs."
    },
    {
      "id": "2411.07607v1",
      "title": "CJST: CTC Compressor based Joint Speech and Text Training for Decoder-Only ASR",
      "summary": "CTC compressor can be an effective approach to integrate audio encoders to\ndecoder-only models, which has gained growing interest for different speech\napplications. In this work, we propose a novel CTC compressor based joint\nspeech and text training (CJST) framework for decoder-only ASR. CJST matches\nspeech and text modalities from both directions by exploring a simple modality\nadaptor and several features of the CTC compressor, including sequence\ncompression, on-the-fly forced peaky alignment and CTC class embeddings.\nExperimental results on the Librispeech and TED-LIUM2 corpora show that the\nproposed CJST achieves an effective text injection without the need of duration\nhandling, leading to the best performance for both in-domain and cross-domain\nscenarios. We also provide a comprehensive study on CTC compressor, covering\nvarious compression modes, edge case handling and behavior under both clean and\nnoisy data conditions, which reveals the most robust setting to use CTC\ncompressor for decoder-only models."
    },
    {
      "id": "2411.07606v1",
      "title": "Optimizing Service Function Chain Mapping in Network Function Virtualization through Simultaneous NF Decomposition and VNF Placement",
      "summary": "Network function virtualization enables network operators to implement new\nservices through a process called service function chain mapping. The concept\nof Service Function Chain (SFC) is introduced to provide complex services,\nwhich is an ordered set of Network Functions (NF). The network functions of an\nSFC can be decomposed in several ways into some Virtual Network Functions\n(VNF). Additionally, the decomposed NFs can be placed (mapped) as VNFs on\ndifferent machines on the underlying physical infrastructure. Selecting good\ndecompositions and good placements among the possible options greatly affects\nboth costs and service quality metrics. Previous research has addressed NF\ndecomposition and VNF placement as separate problems. However, in this paper,\nwe address both NF decomposition and VNF placement simultaneously as a single\nproblem. Since finding an optimal solution is NP-hard, we have employed\nheuristic algorithms to solve the problem. Specifically, we have introduced a\nmultiobjective decomposition and mapping VNFs (MODMVNF) method based on the\nnon-dominated sorting genetic multi-objective algorithm (NSGAII) to solve the\nproblem. The goal is to find near-optimal decomposition and mapping on the\nphysical network at the same time to minimize the mapping cost and\ncommunication latency of SFC. The comparison of the results of the proposed\nmethod with the results obtained by solving ILP formulation of the problem as\nwell as the results obtained from the multi-objective particle swarm algorithm\nshows the efficiency and effectiveness of the proposed method in terms of cost\nand communication latency."
    },
    {
      "id": "2411.07602v1",
      "title": "Circuit Complexity Bounds for RoPE-based Transformer Architecture",
      "summary": "Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ntighter circuit complexity bound for Transformers with $\\mathsf{RoPE}$\nattention. Our key contribution is that we show that unless $\\mathsf{TC}^0 =\n\\mathsf{NC}^1$, a $\\mathsf{RoPE}$-based Transformer with\n$\\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \\leq O(n)$\ncannot solve the arithmetic problem or the Boolean formula value problem. This\nresult significantly demonstrates the fundamental limitation of the\nexpressivity of the $\\mathsf{RoPE}$-based Transformer architecture, although it\nachieves giant empirical success. Our theoretical framework not only\nestablishes tighter complexity bounds but also may instruct further work on the\n$\\mathsf{RoPE}$-based Transformer."
    },
    {
      "id": "2411.07601v1",
      "title": "SegQC: a segmentation network-based framework for multi-metric segmentation quality control and segmentation error detection in volumetric medical images",
      "summary": "Quality control of structures segmentation in volumetric medical images is\nimportant for identifying segmentation errors in clinical practice and for\nfacilitating model development. This paper introduces SegQC, a novel framework\nfor segmentation quality estimation and segmentation error detection. SegQC\ncomputes an estimate measure of the quality of a segmentation in volumetric\nscans and in their individual slices and identifies possible segmentation error\nregions within a slice. The key components include: 1. SegQC-Net, a deep\nnetwork that inputs a scan and its segmentation mask and outputs segmentation\nerror probabilities for each voxel in the scan; 2. three new segmentation\nquality metrics, two overlap metrics and a structure size metric, computed from\nthe segmentation error probabilities; 3. a new method for detecting possible\nsegmentation errors in scan slices computed from the segmentation error\nprobabilities. We introduce a new evaluation scheme to measure segmentation\nerror discrepancies based on an expert radiologist corrections of automatically\nproduced segmentations that yields smaller observer variability and is closer\nto actual segmentation errors. We demonstrate SegQC on three fetal structures\nin 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the\nbenefits of SegQC, we compare it to the unsupervised Test Time Augmentation\n(TTA)-based quality estimation. Our studies indicate that SegQC outperforms\nTTA-based quality estimation in terms of Pearson correlation and MAE for fetal\nbody and fetal brain structures segmentation. Our segmentation error detection\nmethod achieved recall and precision rates of 0.77 and 0.48 for fetal body, and\n0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC\nenhances segmentation metrics estimation for whole scans and individual slices,\nas well as provides error regions detection."
    },
    {
      "id": "2411.07600v1",
      "title": "Decision Feedback In-Context Symbol Detection over Block-Fading Channels",
      "summary": "Pre-trained Transformers, through in-context learning (ICL), have\ndemonstrated exceptional capabilities to adapt to new tasks using example\nprompts \\textit{without model update}. Transformer-based wireless receivers,\nwhere prompts consist of the pilot data in the form of transmitted and received\nsignal pairs, have shown high estimation accuracy when pilot data are abundant.\nHowever, pilot information is often costly and limited in practice. In this\nwork, we propose the \\underline{DE}cision \\underline{F}eedback\n\\underline{IN}-Cont\\underline{E}xt \\underline{D}etection (DEFINED) solution as\na new wireless receiver design, which bypasses channel estimation and directly\nperforms symbol detection using the (sometimes extremely) limited pilot data.\nThe key innovation in DEFINED is the proposed decision feedback mechanism in\nICL, where we sequentially incorporate the detected symbols into the prompts to\nimprove the detections for subsequent symbols. Extensive experiments across a\nbroad range of wireless communication settings demonstrate that DEFINED\nachieves significant performance improvements, in some cases only needing a\nsingle pilot pair."
    },
    {
      "id": "2411.07598v1",
      "title": "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations",
      "summary": "Many open-ended conversations (e.g., tutoring lessons or business meetings)\nrevolve around pre-defined reference materials, like worksheets or meeting\nbullets. To provide a framework for studying such conversation structure, we\nintroduce Problem-Oriented Segmentation & Retrieval (POSR), the task of jointly\nbreaking down conversations into segments and linking each segment to the\nrelevant reference item. As a case study, we apply POSR to education where\neffectively structuring lessons around problems is critical yet difficult. We\npresent LessonLink, the first dataset of real-world tutoring lessons, featuring\n3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT\nmath problems. We define and evaluate several joint and independent approaches\nfor POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT),\nand large language models (LLMs) methods. Our results highlight that modeling\nPOSR as one joint task is essential: POSR methods outperform independent\nsegmentation and retrieval pipelines by up to +76% on joint metrics and surpass\ntraditional segmentation methods by up to +78% on segmentation metrics. We\ndemonstrate POSR's practical impact on downstream education applications,\nderiving new insights on the language and time use in real-world lesson\nstructures."
    },
    {
      "id": "2411.07595v1",
      "title": "Entropy Controllable Direct Preference Optimization",
      "summary": "In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs."
    },
    {
      "id": "2411.07591v1",
      "title": "Overcoming the Curse of Dimensionality in Reinforcement Learning Through Approximate Factorization",
      "summary": "Reinforcement Learning (RL) algorithms are known to suffer from the curse of\ndimensionality, which refers to the fact that large-scale problems often lead\nto exponentially high sample complexity. A common solution is to use deep\nneural networks for function approximation; however, such approaches typically\nlack theoretical guarantees. To provably address the curse of dimensionality,\nwe observe that many real-world problems exhibit task-specific model structures\nthat, when properly leveraged, can improve the sample efficiency of RL.\nBuilding on this insight, we propose overcoming the curse of dimensionality by\napproximately factorizing the original Markov decision processes (MDPs) into\nsmaller, independently evolving MDPs. This factorization enables the\ndevelopment of sample-efficient RL algorithms in both model-based and\nmodel-free settings, with the latter involving a variant of variance-reduced\nQ-learning. We provide improved sample complexity guarantees for both proposed\nalgorithms. Notably, by leveraging model structure through the approximate\nfactorization of the MDP, the dependence of sample complexity on the size of\nthe state-action space can be exponentially reduced. Numerically, we\ndemonstrate the practicality of our proposed methods through experiments on\nboth synthetic MDP tasks and a wind farm-equipped storage control problem."
    },
    {
      "id": "2411.07589v1",
      "title": "Overhead-free User-side Recommender Systems",
      "summary": "Traditionally, recommendation algorithms have been designed for service\ndevelopers. But recently, a new paradigm called user-side recommender systems\nhas been proposed. User-side recommender systems are built and used by end\nusers, in sharp contrast to traditional provider-side recommender systems. Even\nif the official recommender system offered by the provider is not fair, end\nusers can create and enjoy their own user-side recommender systems by\nthemselves. Although the concept of user-side recommender systems is\nattractive, the problem is they require tremendous communication costs between\nthe user and the official system. Even the most efficient user-side recommender\nsystems require about 5 times more costs than provider-side recommender\nsystems. Such high costs hinder the adoption of user-side recommender systems.\nIn this paper, we propose overhead-free user-side recommender systems,\nRecCycle, which realizes user-side recommender systems without any\ncommunication overhead. The main idea of RecCycle is to recycle past\nrecommendation results offered by the provider's recommender systems. The\ningredients of RecCycle can be retrieved ``for free,'' and it greatly reduces\nthe cost of user-side recommendations. In the experiments, we confirm that\nRecCycle performs as well as state-of-the-art user-side recommendation\nalgorithms while RecCycle reduces costs significantly."
    },
    {
      "id": "2411.07586v1",
      "title": "A Comprehensive Survey of AI-Driven Advancements and Techniques in Automated Program Repair and Code Generation",
      "summary": "Bug fixing and code generation have been core research topics in software\ndevelopment for many years. The recent explosive growth in Large Language\nModels has completely transformed these spaces, putting in reach incredibly\npowerful tools for both. In this survey, 27 recent papers have been reviewed\nand split into two groups: one dedicated to Automated Program Repair (APR) and\nLLM integration and the other to code generation using LLMs. The first group\nconsists of new methods for bug detection and repair, which include locating\nsemantic errors, security vulnerabilities, and runtime failure bugs. The place\nof LLMs in reducing manual debugging efforts is emphasized in this work by APR\ntoward context-aware fixes, with innovations that boost accuracy and efficiency\nin automatic debugging. The second group dwells on code generation, providing\nan overview of both general-purpose LLMs fine-tuned for programming and\ntask-specific models. It also presents methods to improve code generation, such\nas identifier-aware training, fine-tuning at the instruction level, and\nincorporating semantic code structures. This survey work contrasts the\nmethodologies in APR and code generation to identify trends such as using LLMs,\nfeedback loops to enable iterative code improvement and open-source models. It\nalso discusses the challenges of achieving functional correctness and security\nand outlines future directions for research in LLM-based software development."
    },
    {
      "id": "2411.07585v1",
      "title": "Reinforcement Learning Framework for Quantitative Trading",
      "summary": "The inherent volatility and dynamic fluctuations within the financial stock\nmarket underscore the necessity for investors to employ a comprehensive and\nreliable approach that integrates risk management strategies, market trends,\nand the movement trends of individual securities. By evaluating specific data,\ninvestors can make more informed decisions. However, the current body of\nliterature lacks substantial evidence supporting the practical efficacy of\nreinforcement learning (RL) agents, as many models have only demonstrated\nsuccess in back testing using historical data. This highlights the urgent need\nfor a more advanced methodology capable of addressing these challenges. There\nis a significant disconnect in the effective utilization of financial\nindicators to better understand the potential market trends of individual\nsecurities. The disclosure of successful trading strategies is often restricted\nwithin financial markets, resulting in a scarcity of widely documented and\npublished strategies leveraging RL. Furthermore, current research frequently\noverlooks the identification of financial indicators correlated with various\nmarket trends and their potential advantages.\n  This research endeavors to address these complexities by enhancing the\nability of RL agents to effectively differentiate between positive and negative\nbuy/sell actions using financial indicators. While we do not address all\nconcerns, this paper provides deeper insights and commentary on the utilization\nof technical indicators and their benefits within reinforcement learning. This\nwork establishes a foundational framework for further exploration and\ninvestigation of more complex scenarios."
    },
    {
      "id": "2411.07574v1",
      "title": "Disentangling Tabular Data towards Better One-Class Anomaly Detection",
      "summary": "Tabular anomaly detection under the one-class classification setting poses a\nsignificant challenge, as it involves accurately conceptualizing \"normal\"\nderived exclusively from a single category to discern anomalies from normal\ndata variations. Capturing the intrinsic correlation among attributes within\nnormal samples presents one promising method for learning the concept. To do\nso, the most recent effort relies on a learnable mask strategy with a\nreconstruction task. However, this wisdom may suffer from the risk of producing\nuniform masks, i.e., essentially nothing is masked, leading to less effective\ncorrelation learning. To address this issue, we presume that attributes related\nto others in normal samples can be divided into two non-overlapping and\ncorrelated subsets, defined as CorrSets, to capture the intrinsic correlation\neffectively. Accordingly, we introduce an innovative method that disentangles\nCorrSets from normal tabular data. To our knowledge, this is a pioneering\neffort to apply the concept of disentanglement for one-class anomaly detection\non tabular data. Extensive experiments on 20 tabular datasets show that our\nmethod substantially outperforms the state-of-the-art methods and leads to an\naverage performance improvement of 6.1% on AUC-PR and 2.1% on AUC-ROC."
    },
    {
      "id": "2411.07567v1",
      "title": "Uncertainty-Aware Test-Time Adaptation for Inverse Consistent Diffeomorphic Lung Image Registration",
      "summary": "Diffeomorphic deformable image registration ensures smooth invertible\ntransformations across inspiratory and expiratory chest CT scans. Yet, in\npractice, deep learning-based diffeomorphic methods struggle to capture large\ndeformations between inspiratory and expiratory volumes, and therefore lack\ninverse consistency. Existing methods also fail to account for model\nuncertainty, which can be useful for improving performance. We propose an\nuncertainty-aware test-time adaptation framework for inverse consistent\ndiffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to\nestimate spatial uncertainty that is used to improve model performance. We\ntrain and evaluate our method for inspiratory-to-expiratory CT registration on\na large cohort of 675 subjects from the COPDGene study, achieving a higher Dice\nsimilarity coefficient (DSC) between the lung boundaries (0.966) compared to\nboth VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates\nconsistent improvements in the inverse registration direction as well with an\noverall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).\nPaired t-tests indicate statistically significant improvements."
    },
    {
      "id": "2411.07563v1",
      "title": "Improving Grapheme-to-Phoneme Conversion through In-Context Knowledge Retrieval with Large Language Models",
      "summary": "Grapheme-to-phoneme (G2P) conversion is a crucial step in Text-to-Speech\n(TTS) systems, responsible for mapping grapheme to corresponding phonetic\nrepresentations. However, it faces ambiguities problems where the same grapheme\ncan represent multiple phonemes depending on contexts, posing a challenge for\nG2P conversion. Inspired by the remarkable success of Large Language Models\n(LLMs) in handling context-aware scenarios, contextual G2P conversion systems\nwith LLMs' in-context knowledge retrieval (ICKR) capabilities are proposed to\npromote disambiguation capability. The efficacy of incorporating ICKR into G2P\nconversion systems is demonstrated thoroughly on the Librig2p dataset. In\nparticular, the best contextual G2P conversion system using ICKR outperforms\nthe baseline with weighted average phoneme error rate (PER) reductions of 2.0%\nabsolute (28.9% relative). Using GPT-4 in the ICKR system can increase of 3.5%\nabsolute (3.8% relative) on the Librig2p dataset."
    },
    {
      "id": "2411.07560v1",
      "title": "EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods",
      "summary": "This study introduces a novel approach for EUR/USD exchange rate forecasting\nthat integrates deep learning, textual analysis, and particle swarm\noptimization (PSO). By incorporating online news and analysis texts as\nqualitative data, the proposed PSO-LSTM model demonstrates superior performance\ncompared to traditional econometric and machine learning models. The research\nemploys advanced text mining techniques, including sentiment analysis using the\nRoBERTa-Large model and topic modeling with LDA. Empirical findings underscore\nthe significant advantage of incorporating textual data, with the PSO-LSTM\nmodel outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH.\nAblation experiments reveal the contribution of each textual data category to\nthe overall forecasting performance. The study highlights the transformative\npotential of artificial intelligence in finance and paves the way for future\nresearch in real-time forecasting and the integration of alternative data\nsources."
    },
    {
      "id": "2411.07559v1",
      "title": "Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models",
      "summary": "Jailbreaking methods, which induce Multi-modal Large Language Models (MLLMs)\nto output harmful responses, raise significant safety concerns. Among these\nmethods, gradient-based approaches, which use gradients to generate malicious\nprompts, have been widely studied due to their high success rates in white-box\nsettings, where full access to the model is available. However, these methods\nhave notable limitations: they require white-box access, which is not always\nfeasible, and involve high memory usage. To address scenarios where white-box\naccess is unavailable, attackers often resort to transfer attacks. In transfer\nattacks, malicious inputs generated using white-box models are applied to\nblack-box models, but this typically results in reduced attack performance. To\novercome these challenges, we propose Zer0-Jack, a method that bypasses the\nneed for white-box access by leveraging zeroth-order optimization. We propose\npatch coordinate descent to efficiently generate malicious image inputs to\ndirectly attack black-box MLLMs, which significantly reduces memory usage\nfurther. Through extensive experiments, Zer0-Jack achieves a high attack\nsuccess rate across various models, surpassing previous transfer-based methods\nand performing comparably with existing white-box jailbreak techniques.\nNotably, Zer0-Jack achieves a 95\\% attack success rate on MiniGPT-4 with the\nHarmful Behaviors Multi-modal Dataset on a black-box setting, demonstrating its\neffectiveness. Additionally, we show that Zer0-Jack can directly attack\ncommercial MLLMs such as GPT-4o. Codes are provided in the supplement."
    },
    {
      "id": "2411.07554v1",
      "title": "Exogenous Randomness Empowering Random Forests",
      "summary": "We offer theoretical and empirical insights into the impact of exogenous\nrandomness on the effectiveness of random forests with tree-building rules\nindependent of training data. We formally introduce the concept of exogenous\nrandomness and identify two types of commonly existing randomness: Type I from\nfeature subsampling, and Type II from tie-breaking in tree-building processes.\nWe develop non-asymptotic expansions for the mean squared error (MSE) for both\nindividual trees and forests and establish sufficient and necessary conditions\nfor their consistency. In the special example of the linear regression model\nwith independent features, our MSE expansions are more explicit, providing more\nunderstanding of the random forests' mechanisms. It also allows us to derive an\nupper bound on the MSE with explicit consistency rates for trees and forests.\nGuided by our theoretical findings, we conduct simulations to further explore\nhow exogenous randomness enhances random forest performance. Our findings\nunveil that feature subsampling reduces both the bias and variance of random\nforests compared to individual trees, serving as an adaptive mechanism to\nbalance bias and variance. Furthermore, our results reveal an intriguing\nphenomenon: the presence of noise features can act as a \"blessing\" in enhancing\nthe performance of random forests thanks to feature subsampling."
    },
    {
      "id": "2411.07546v1",
      "title": "Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection",
      "summary": "A pre-trained visual-language model, contrastive language-image pre-training\n(CLIP), successfully accomplishes various downstream tasks with text prompts,\nsuch as finding images or localizing regions within the image. Despite CLIP's\nstrong multi-modal data capabilities, it remains limited in specialized\nenvironments, such as medical applications. For this purpose, many CLIP\nvariants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives\nrelated to normal regions persist. Thus, we aim to present a simple yet\nimportant goal of reducing false positives in medical anomaly detection. We\nintroduce a Contrastive LAnguage Prompting (CLAP) method that leverages both\npositive and negative text prompts. This straightforward approach identifies\npotential lesion regions by visual attention to the positive prompts in the\ngiven image. To reduce false positives, we attenuate attention on normal\nregions using negative prompts. Extensive experiments with the BMAD dataset,\nincluding six biomedical benchmarks, demonstrate that CLAP method enhances\nanomaly detection performance. Our future plans include developing an automated\nfine prompting method for more practical usage."
    },
    {
      "id": "2411.07538v1",
      "title": "Unraveling the Gradient Descent Dynamics of Transformers",
      "summary": "While the Transformer architecture has achieved remarkable success across\nvarious domains, a thorough theoretical foundation explaining its optimization\ndynamics is yet to be fully developed. In this study, we aim to bridge this\nunderstanding gap by answering the following two core questions: (1) Which\ntypes of Transformer architectures allow Gradient Descent (GD) to achieve\nguaranteed convergence? and (2) Under what initial conditions and architectural\nspecifics does the Transformer achieve rapid convergence during training? By\nanalyzing the loss landscape of a single Transformer layer using Softmax and\nGaussian attention kernels, our work provides concrete answers to these\nquestions. Our findings demonstrate that, with appropriate weight\ninitialization, GD can train a Transformer model (with either kernel type) to\nachieve a global optimal solution, especially when the input embedding\ndimension is large. Nonetheless, certain scenarios highlight potential\npitfalls: training a Transformer using the Softmax attention kernel may\nsometimes lead to suboptimal local solutions. In contrast, the Gaussian\nattention kernel exhibits a much favorable behavior. Our empirical study\nfurther validate the theoretical findings."
    },
    {
      "id": "2411.07537v1",
      "title": "Accident Impact Prediction based on a deep convolutional and recurrent neural network model",
      "summary": "Traffic accidents pose a significant threat to public safety, resulting in\nnumerous fatalities, injuries, and a substantial economic burden each year. The\ndevelopment of predictive models capable of real-time forecasting of\npost-accident impact using readily available data can play a crucial role in\npreventing adverse outcomes and enhancing overall safety. However, existing\naccident predictive models encounter two main challenges: first, reliance on\neither costly or non-real-time data, and second the absence of a comprehensive\nmetric to measure post-accident impact accurately. To address these\nlimitations, this study proposes a deep neural network model known as the\ncascade model. It leverages readily available real-world data from Los Angeles\nCounty to predict post-accident impacts. The model consists of two components:\nLong Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). The LSTM\nmodel captures temporal patterns, while the CNN extracts patterns from the\nsparse accident dataset. Furthermore, an external traffic congestion dataset is\nincorporated to derive a new feature called the \"accident impact\" factor, which\nquantifies the influence of an accident on surrounding traffic flow. Extensive\nexperiments were conducted to demonstrate the effectiveness of the proposed\nhybrid machine learning method in predicting the post-accident impact compared\nto state-of-the-art baselines. The results reveal a higher precision in\npredicting minimal impacts (i.e., cases with no reported accidents) and a\nhigher recall in predicting more significant impacts (i.e., cases with reported\naccidents)."
    },
    {
      "id": "2411.07536v1",
      "title": "Model Stealing for Any Low-Rank Language Model",
      "summary": "Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance."
    },
    {
      "id": "2411.07534v1",
      "title": "Effective Virtual Reality Teleoperation of an Upper-body Humanoid with Modified Task Jacobians and Relaxed Barrier Functions for Self-Collision Avoidance",
      "summary": "We present an approach for retartgeting off-the-shelf Virtual Reality (VR)\ntrackers to effectively teleoperate an upper-body humanoid while ensuring\nself-collision-free motions. Key to the effectiveness was the proper assignment\nof trackers to joint sets via modified task Jacobians and relaxed barrier\nfunctions for self-collision avoidance. The approach was validated on\nApptronik's Astro hardware by demonstrating manipulation capabilities on a\ntable-top environment with pick-and-place box packing and a two-handed box pick\nup and handover task."
    },
    {
      "id": "2411.07533v1",
      "title": "Large Language Models as Neurolinguistic Subjects: Identifying Internal Representations for Form and Meaning",
      "summary": "This study investigates the linguistic understanding of Large Language Models\n(LLMs) regarding signifier (form) and signified (meaning) by distinguishing two\nLLM evaluation paradigms: psycholinguistic and neurolinguistic. Traditional\npsycholinguistic evaluations often reflect statistical biases that may\nmisrepresent LLMs' true linguistic capabilities. We introduce a neurolinguistic\napproach, utilizing a novel method that combines minimal pair and diagnostic\nprobing to analyze activation patterns across model layers. This method allows\nfor a detailed examination of how LLMs represent form and meaning, and whether\nthese representations are consistent across languages. Our contributions are\nthree-fold: (1) We compare neurolinguistic and psycholinguistic methods,\nrevealing distinct patterns in LLM assessment; (2) We demonstrate that LLMs\nexhibit higher competence in form compared to meaning, with the latter largely\ncorrelated to the former; (3) We present new conceptual minimal pair datasets\nfor Chinese (COMPS-ZH) and German (COMPS-DE), complementing existing English\ndatasets."
    },
    {
      "id": "2411.07529v1",
      "title": "Evaluating ChatGPT-3.5 Efficiency in Solving Coding Problems of Different Complexity Levels: An Empirical Analysis",
      "summary": "ChatGPT and other large language models (LLMs) promise to revolutionize\nsoftware development by automatically generating code from program\nspecifications. We assess the performance of ChatGPT's GPT-3.5-turbo model on\nLeetCode, a popular platform with algorithmic coding challenges for technical\ninterview practice, across three difficulty levels: easy, medium, and hard. We\ntest three main hypotheses. First, ChatGPT solves fewer problems as difficulty\nrises (Hypothesis 1). Second, prompt engineering improves ChatGPT's\nperformance, with greater gains on easier problems and diminishing returns on\nharder ones (Hypothesis 2). Third, ChatGPT performs better in popular languages\nlike Python, Java, and C++ than in less common ones like Elixir, Erlang, and\nRacket (Hypothesis 3). To investigate these hypotheses, we conduct automated\nexperiments using Python scripts to generate prompts that instruct ChatGPT to\ncreate Python solutions. These solutions are stored and manually submitted on\nLeetCode to check their correctness. For Hypothesis 1, results show the\nGPT-3.5-turbo model successfully solves 92% of easy, 79% of medium, and 51% of\nhard problems. For Hypothesis 2, prompt engineering yields improvements: 14-29%\nfor Chain of Thought Prompting, 38-60% by providing failed test cases in a\nsecond feedback prompt, and 33-58% by switching to GPT-4. From a random subset\nof problems ChatGPT solved in Python, it also solved 78% in Java, 50% in C++,\nand none in Elixir, Erlang, or Racket. These findings generally validate all\nthree hypotheses."
    },
    {
      "id": "2411.07528v1",
      "title": "SecEncoder: Logs are All You Need in Security",
      "summary": "Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications."
    },
    {
      "id": "2411.07527v1",
      "title": "Prompt-enhanced Network for Hateful Meme Classification",
      "summary": "The dynamic expansion of social media has led to an inundation of hateful\nmemes on media platforms, accentuating the growing need for efficient\nidentification and removal. Acknowledging the constraints of conventional\nmultimodal hateful meme classification, which heavily depends on external\nknowledge and poses the risk of including irrelevant or redundant content, we\ndeveloped Pen -- a prompt-enhanced network framework based on the prompt\nlearning approach. Specifically, after constructing the sequence through the\nprompt method and encoding it with a language model, we performed region\ninformation global extraction on the encoded sequence for multi-view\nperception. By capturing global information about inference instances and\ndemonstrations, Pen facilitates category selection by fully leveraging sequence\ninformation. This approach significantly improves model classification\naccuracy. Additionally, to bolster the model's reasoning capabilities in the\nfeature space, we introduced prompt-aware contrastive learning into the\nframework to improve the quality of sample feature distributions. Through\nextensive ablation experiments on two public datasets, we evaluate the\neffectiveness of the Pen framework, concurrently comparing it with\nstate-of-the-art model baselines. Our research findings highlight that Pen\nsurpasses manual prompt methods, showcasing superior generalization and\nclassification accuracy in hateful meme classification tasks. Our code is\navailable at https://github.com/juszzi/Pen."
    },
    {
      "id": "2411.07523v1",
      "title": "Collaborative and Federated Black-box Optimization: A Bayesian Optimization Perspective",
      "summary": "We focus on collaborative and federated black-box optimization (BBOpt), where\nagents optimize their heterogeneous black-box functions through collaborative\nsequential experimentation. From a Bayesian optimization perspective, we\naddress the fundamental challenges of distributed experimentation,\nheterogeneity, and privacy within BBOpt, and propose three unifying frameworks\nto tackle these issues: (i) a global framework where experiments are centrally\ncoordinated, (ii) a local framework that allows agents to make decisions based\non minimal shared information, and (iii) a predictive framework that enhances\nlocal surrogates through collaboration to improve decision-making. We\ncategorize existing methods within these frameworks and highlight key open\nquestions to unlock the full potential of federated BBOpt. Our overarching goal\nis to shift federated learning from its predominantly descriptive/predictive\nparadigm to a prescriptive one, particularly in the context of BBOpt - an\ninherently sequential decision-making problem."
    },
    {
      "id": "2411.07521v2",
      "title": "Fair Summarization: Bridging Quality and Diversity in Extractive Summaries",
      "summary": "Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. This\nwork highlights the importance of fairness in summarization and sets a\nbenchmark for future research in fairness-aware NLP models."
    },
    {
      "id": "2411.07519v1",
      "title": "TIPS: Threat Actor Informed Prioritization of Applications using SecEncoder",
      "summary": "This paper introduces TIPS: Threat Actor Informed Prioritization using\nSecEncoder, a specialized language model for security. TIPS combines the\nstrengths of both encoder and decoder language models to detect and prioritize\ncompromised applications. By integrating threat actor intelligence, TIPS\nenhances the accuracy and relevance of its detections. Extensive experiments\nwith a real-world benchmark dataset of applications demonstrate TIPS's high\nefficacy, achieving an F-1 score of 0.90 in identifying malicious applications.\nAdditionally, in real-world scenarios, TIPS significantly reduces the backlog\nof investigations for security analysts by 87%, thereby streamlining the threat\nresponse process and improving overall security posture."
    },
    {
      "id": "2411.07518v1",
      "title": "LLM App Squatting and Cloning",
      "summary": "Impersonation tactics, such as app squatting and app cloning, have posed\nlongstanding challenges in mobile app stores, where malicious actors exploit\nthe names and reputations of popular apps to deceive users. With the rapid\ngrowth of Large Language Model (LLM) stores like GPT Store and FlowGPT, these\nissues have similarly surfaced, threatening the integrity of the LLM app\necosystem. In this study, we present the first large-scale analysis of LLM app\nsquatting and cloning using our custom-built tool, LLMappCrazy. LLMappCrazy\ncovers 14 squatting generation techniques and integrates Levenshtein distance\nand BERT-based semantic analysis to detect cloning by analyzing app functional\nsimilarities. Using this tool, we generated variations of the top 1000 app\nnames and found over 5,000 squatting apps in the dataset. Additionally, we\nobserved 3,509 squatting apps and 9,575 cloning cases across six major\nplatforms. After sampling, we find that 18.7% of the squatting apps and 4.9% of\nthe cloning apps exhibited malicious behavior, including phishing, malware\ndistribution, fake content dissemination, and aggressive ad injection."
    },
    {
      "id": "2411.07516v1",
      "title": "SparrowVQE: Visual Question Explanation for Course Content Understanding",
      "summary": "Visual Question Answering (VQA) research seeks to create AI systems to answer\nnatural language questions in images, yet VQA methods often yield overly\nsimplistic and short answers. This paper aims to advance the field by\nintroducing Visual Question Explanation (VQE), which enhances the ability of\nVQA to provide detailed explanations rather than brief responses and address\nthe need for more complex interaction with visual content. We first created an\nMLVQE dataset from a 14-week streamed video machine learning course, including\n885 slide images, 110,407 words of transcripts, and 9,416 designed\nquestion-answer (QA) pairs. Next, we proposed a novel SparrowVQE, a small 3\nbillion parameters multimodal model. We trained our model with a three-stage\ntraining mechanism consisting of multimodal pre-training (slide images and\ntranscripts feature alignment), instruction tuning (tuning the pre-trained\nmodel with transcripts and QA pairs), and domain fine-tuning (fine-tuning slide\nimage and QA pairs). Eventually, our SparrowVQE can understand and connect\nvisual information using the SigLIP model with transcripts using the Phi-2\nlanguage model with an MLP adapter. Experimental results demonstrate that our\nSparrowVQE achieves better performance in our developed MLVQE dataset and\noutperforms state-of-the-art methods in the other five benchmark VQA datasets.\nThe source code is available at\n\\url{https://github.com/YoushanZhang/SparrowVQE}."
    },
    {
      "id": "2411.07515v1",
      "title": "Bayesian Deep Learning Approach for Real-time Lane-based Arrival Curve Reconstruction at Intersection using License Plate Recognition Data",
      "summary": "The acquisition of real-time and accurate traffic arrival information is of\nvital importance for proactive traffic control systems, especially in partially\nconnected vehicle environments. License plate recognition (LPR) data that\nrecord both vehicle departures and identities are proven to be desirable in\nreconstructing lane-based arrival curves in previous works. Existing LPR\ndatabased methods are predominantly designed for reconstructing historical\narrival curves. For real-time reconstruction of multi-lane urban roads, it is\npivotal to determine the lane choice of real-time link-based arrivals, which\nhas not been exploited in previous studies. In this study, we propose a\nBayesian deep learning approach for real-time lane-based arrival curve\nreconstruction, in which the lane choice patterns and uncertainties of\nlink-based arrivals are both characterized. Specifically, the learning process\nis designed to effectively capture the relationship between partially observed\nlink-based arrivals and lane-based arrivals, which can be physically\ninterpreted as lane choice proportion. Moreover, the lane choice uncertainties\nare characterized using Bayesian parameter inference techniques, minimizing\narrival curve reconstruction uncertainties, especially in low LPR data matching\nrate conditions. Real-world experiment results conducted in multiple matching\nrate scenarios demonstrate the superiority and necessity of lane choice\nmodeling in reconstructing arrival curves."
    },
    {
      "id": "2411.07514v1",
      "title": "Robust Offline Reinforcement Learning for Non-Markovian Decision Processes",
      "summary": "Distributionally robust offline reinforcement learning (RL) aims to find a\npolicy that performs the best under the worst environment within an uncertainty\nset using an offline dataset collected from a nominal model. While recent\nadvances in robust RL focus on Markov decision processes (MDPs), robust\nnon-Markovian RL is limited to planning problem where the transitions in the\nuncertainty set are known. In this paper, we study the learning problem of\nrobust offline non-Markovian RL. Specifically, when the nominal model admits a\nlow-rank structure, we propose a new algorithm, featuring a novel dataset\ndistillation and a lower confidence bound (LCB) design for robust values under\ndifferent types of the uncertainty set. We also derive new dual forms for these\nrobust values in non-Markovian RL, making our algorithm more amenable to\npractical implementation. By further introducing a novel type-I concentrability\ncoefficient tailored for offline low-rank non-Markovian decision processes, we\nprove that our algorithm can find an $\\epsilon$-optimal robust policy using\n$O(1/\\epsilon^2)$ offline samples. Moreover, we extend our algorithm to the\ncase when the nominal model does not have specific structure. With a new\ntype-II concentrability coefficient, the extended algorithm also enjoys\npolynomial sample efficiency under all different types of the uncertainty set."
    },
    {
      "id": "2411.07510v1",
      "title": "An Attack Traffic Identification Method Based on Temporal Spectrum",
      "summary": "To address the issues of insufficient robustness, unstable features, and data\nnoise interference in existing network attack detection and identification\nmodels, this paper proposes an attack traffic detection and identification\nmethod based on temporal spectrum. First, traffic data is segmented by a\nsliding window to construct a feature sequence and a corresponding label\nsequence for network traffic. Next, the proposed spectral label generation\nmethods, SSPE and COAP, are applied to transform the label sequence into\nspectral labels and the feature sequence into temporal features. Spectral\nlabels and temporal features are used to capture and represent behavioral\npatterns of attacks. Finally, the constructed temporal features and spectral\nlabels are used to train models, which subsequently detects and identifies\nnetwork attack behaviors. Experimental results demonstrate that compared to\ntraditional methods, models trained with the SSPE or COAP method improve\nidentification accuracy by 10%, and exhibit strong robustness, particularly in\nnoisy environments."
    },
    {
      "id": "2411.07506v1",
      "title": "FM-TS: Flow Matching for Time Series Generation",
      "summary": "Time series generation has emerged as an essential tool for analyzing\ntemporal data across numerous fields. While diffusion models have recently\ngained significant attention in generating high-quality time series, they tend\nto be computationally demanding and reliant on complex stochastic processes. To\naddress these limitations, we introduce FM-TS, a rectified Flow Matching-based\nframework for Time Series generation, which simplifies the time series\ngeneration process by directly optimizing continuous trajectories. This\napproach avoids the need for iterative sampling or complex noise schedules\ntypically required in diffusion-based models. FM-TS is more efficient in terms\nof training and inference. Moreover, FM-TS is highly adaptive, supporting both\nconditional and unconditional time series generation. Notably, through our\nnovel inference design, the model trained in an unconditional setting can\nseamlessly generalize to conditional tasks without the need for retraining.\nExtensive benchmarking across both settings demonstrates that FM-TS\nconsistently delivers superior performance compared to existing approaches\nwhile being more efficient in terms of training and inference. For instance, in\nterms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005,\n0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRI\nunconditional time series datasets, respectively, significantly outperforming\nthe second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and\n0.167 on the same datasets. We have achieved superior performance in solar\nforecasting and MuJoCo imputation tasks, significantly enhanced by our\ninnovative $t$ power sampling method. The code is available at\nhttps://github.com/UNITES-Lab/FMTS."
    },
    {
      "id": "2411.07504v1",
      "title": "AdaS&S: a One-Shot Supernet Approach for Automatic Embedding Size Search in Deep Recommender System",
      "summary": "Deep Learning Recommendation Model(DLRM)s utilize the embedding layer to\nrepresent various categorical features. Traditional DLRMs adopt unified\nembedding size for all features, leading to suboptimal performance and\nredundant parameters. Thus, lots of Automatic Embedding size Search (AES) works\nfocus on obtaining mixed embedding sizes with strong model performance.\nHowever, previous AES works can hardly address several challenges together: (1)\nThe search results of embedding sizes are unstable; (2) Recommendation effect\nwith AES results is unsatisfactory; (3) Memory cost of embeddings is\nuncontrollable. To address these challenges, we propose a novel one-shot AES\nframework called AdaS&S, in which a supernet encompassing various candidate\nembeddings is built and AES is performed as searching network architectures\nwithin it. Our framework contains two main stages: In the first stage, we\ndecouple training parameters from searching embedding sizes, and propose the\nAdaptive Sampling method to yield a well-trained supernet, which further helps\nto produce stable AES results. In the second stage, to obtain embedding sizes\nthat benefits the model effect, we design a reinforcement learning search\nprocess which utilizes the supernet trained previously. Meanwhile, to adapt\nsearching to specific resource constraint, we introduce the resource\ncompetition penalty to balance the model effectiveness and memory cost of\nembeddings. We conduct extensive experiments on public datasets to show the\nsuperiority of AdaS&S. Our method could improve AUC by about 0.3% while saving\nabout 20% of model parameters. Empirical analysis also shows that the stability\nof searching results in AdaS&S significantly exceeds other methods."
    },
    {
      "id": "2411.07503v1",
      "title": "A Novel Automatic Real-time Motion Tracking Method for Magnetic Resonance Imaging-guided Radiotherapy: Leveraging the Enhanced Tracking-Learning-Detection Framework with Automatic Segmentation",
      "summary": "Objective: Ensuring the precision in motion tracking for MRI-guided\nRadiotherapy (MRIgRT) is crucial for the delivery of effective treatments. This\nstudy refined the motion tracking accuracy in MRIgRT through the innovation of\nan automatic real-time tracking method, leveraging an enhanced\nTracking-Learning-Detection (ETLD) framework coupled with automatic\nsegmentation. Methods: We developed a novel MRIgRT motion tracking method by\nintegrating two primary methods: the ETLD framework and an improved Chan-Vese\nmodel (ICV), named ETLD+ICV. The TLD framework was upgraded to suit real-time\ncine MRI, including advanced image preprocessing, no-reference image quality\nassessment, an enhanced median-flow tracker, and a refined detector with\ndynamic search region adjustments. Additionally, ICV was combined for precise\ncoverage of the target volume, which refined the segmented region frame by\nframe using tracking results, with key parameters optimized. Tested on 3.5D MRI\nscans from 10 patients with liver metastases, our method ensures precise\ntracking and accurate segmentation vital for MRIgRT. Results: An evaluation of\n106,000 frames across 77 treatment fractions revealed sub-millimeter tracking\nerrors of less than 0.8mm, with over 99% precision and 98% recall for all\nsubjects, underscoring the robustness and efficacy of the ETLD. Moreover, the\nETLD+ICV yielded a dice global score of more than 82% for all subjects,\ndemonstrating the proposed method's extensibility and precise target volume\ncoverage. Conclusions: This study successfully developed an automatic real-time\nmotion tracking method for MRIgRT that markedly surpasses current methods. The\nnovel method not only delivers exceptional precision in tracking and\nsegmentation but also demonstrates enhanced adaptability to clinical demands,\npositioning it as an indispensable asset in the quest to augment the efficacy\nof radiotherapy treatments."
    },
    {
      "id": "2411.07501v2",
      "title": "LAuReL: Learned Augmented Residual Layer",
      "summary": "One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters."
    },
    {
      "id": "2411.07496v1",
      "title": "ADMM for Structured Fractional Minimization",
      "summary": "We consider a class of structured fractional minimization problems, where the\nnumerator includes a differentiable function, a simple nonconvex nonsmooth\nfunction, a concave nonsmooth function, and a convex nonsmooth function\ncomposed with a linear operator, while the denominator is a continuous function\nthat is either weakly convex or has a weakly convex square root. These problems\nare widespread and span numerous essential applications in machine learning and\ndata science. Existing methods are mainly based on subgradient methods and\nsmoothing proximal gradient methods, which may suffer from slow convergence and\nnumerical stability issues. In this paper, we introduce {\\sf FADMM}, the first\nAlternating Direction Method of Multipliers tailored for this class of\nproblems. {\\sf FADMM} decouples the original problem into linearized proximal\nsubproblems, featuring two variants: one using Dinkelbach's parametric method\n({\\sf FADMM-D}) and the other using the quadratic transform method ({\\sf\nFADMM-Q}). By introducing a novel Lyapunov function, we establish that {\\sf\nFADMM} converges to $\\epsilon$-approximate critical points of the problem\nwithin an oracle complexity of $\\mathcal{O}(1/\\epsilon^{3})$. Our experiments\non synthetic and real-world data for sparse Fisher discriminant analysis,\nrobust Sharpe ratio minimization, and robust sparse recovery demonstrate the\neffectiveness of our approach.\n  Keywords: Fractional Minimization, Nonconvex Optimization, Proximal\nLinearized ADMM, Nonsmooth Optimization, Convergence Analysis"
    },
    {
      "id": "2411.07494v1",
      "title": "Rapid Response: Mitigating LLM Jailbreaks with a Few Examples",
      "summary": "As large language models (LLMs) grow more powerful, ensuring their safety\nagainst misuse becomes crucial. While researchers have focused on developing\nrobust defenses, no method has yet achieved complete invulnerability to\nattacks. We propose an alternative approach: instead of seeking perfect\nadversarial robustness, we develop rapid response techniques to look to block\nwhole classes of jailbreaks after observing only a handful of attacks. To study\nthis setting, we develop RapidResponseBench, a benchmark that measures a\ndefense's robustness against various jailbreak strategies after adapting to a\nfew observed examples. We evaluate five rapid response methods, all of which\nuse jailbreak proliferation, where we automatically generate additional\njailbreaks similar to the examples observed. Our strongest method, which\nfine-tunes an input classifier to block proliferated jailbreaks, reduces attack\nsuccess rate by a factor greater than 240 on an in-distribution set of\njailbreaks and a factor greater than 15 on an out-of-distribution set, having\nobserved just one example of each jailbreaking strategy. Moreover, further\nstudies suggest that the quality of proliferation model and number of\nproliferated examples play an key role in the effectiveness of this defense.\nOverall, our results highlight the potential of responding rapidly to novel\njailbreaks to limit LLM misuse."
    },
    {
      "id": "2411.07483v1",
      "title": "Quantifying Knowledge Distillation Using Partial Information Decomposition",
      "summary": "Knowledge distillation provides an effective method for deploying complex\nmachine learning models in resource-constrained environments. It typically\ninvolves training a smaller student model to emulate either the probabilistic\noutputs or the internal feature representations of a larger teacher model. By\ndoing so, the student model often achieves substantially better performance on\na downstream task compared to when it is trained independently. Nevertheless,\nthe teacher's internal representations can also encode noise or additional\ninformation that may not be relevant to the downstream task. This observation\nmotivates our primary question: What are the information-theoretic limits of\nknowledge transfer? To this end, we leverage a body of work in information\ntheory called Partial Information Decomposition (PID) to quantify the\ndistillable and distilled knowledge of a teacher's representation corresponding\nto a given student and a downstream task. Moreover, we demonstrate that this\nmetric can be practically used in distillation to address challenges caused by\nthe complexity gap between the teacher and the student representations."
    },
    {
      "id": "2411.07482v1",
      "title": "Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling",
      "summary": "Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning."
    },
    {
      "id": "2411.07474v1",
      "title": "Controlled Evaluation of Syntactic Knowledge in Multilingual Language Models",
      "summary": "Language models (LMs) are capable of acquiring elements of human-like\nsyntactic knowledge. Targeted syntactic evaluation tests have been employed to\nmeasure how well they form generalizations about syntactic phenomena in\nhigh-resource languages such as English. However, we still lack a thorough\nunderstanding of LMs' capacity for syntactic generalizations in low-resource\nlanguages, which are responsible for much of the diversity of syntactic\npatterns worldwide. In this study, we develop targeted syntactic evaluation\ntests for three low-resource languages (Basque, Hindi, and Swahili) and use\nthem to evaluate five families of open-access multilingual Transformer LMs. We\nfind that some syntactic tasks prove relatively easy for LMs while others\n(agreement in sentences containing indirect objects in Basque, agreement across\na prepositional phrase in Swahili) are challenging. We additionally uncover\nissues with publicly available Transformers, including a bias toward the\nhabitual aspect in Hindi in multilingual BERT and underperformance compared to\nsimilar-sized models in XGLM-4.5B."
    },
    {
      "id": "2411.07468v2",
      "title": "Privacy-Preserving Verifiable Neural Network Inference Service",
      "summary": "Machine learning has revolutionized data analysis and pattern recognition,\nbut its resource-intensive training has limited accessibility. Machine Learning\nas a Service (MLaaS) simplifies this by enabling users to delegate their data\nsamples to an MLaaS provider and obtain the inference result using a\npre-trained model. Despite its convenience, leveraging MLaaS poses significant\nprivacy and reliability concerns to the client. Specifically, sensitive\ninformation from the client inquiry data can be leaked to an adversarial MLaaS\nprovider. Meanwhile, the lack of a verifiability guarantee can potentially\nresult in biased inference results or even unfair payment issues. While\nexisting trustworthy machine learning techniques, such as those relying on\nverifiable computation or secure computation, offer solutions to privacy and\nreliability concerns, they fall short of simultaneously protecting the privacy\nof client data and providing provable inference verifiability.\n  In this paper, we propose vPIN, a privacy-preserving and verifiable CNN\ninference scheme that preserves privacy for client data samples while ensuring\nverifiability for the inference. vPIN makes use of partial homomorphic\nencryption and commit-and-prove succinct non-interactive argument of knowledge\ntechniques to achieve desirable security properties. In vPIN, we develop\nvarious optimization techniques to minimize the proving circuit for homomorphic\ninference evaluation thereby, improving the efficiency and performance of our\ntechnique. We fully implemented and evaluated our vPIN scheme on standard\ndatasets (e.g., MNIST, CIFAR-10). Our experimental results show that vPIN\nachieves high efficiency in terms of proving time, verification time, and proof\nsize, while providing client data privacy guarantees and provable\nverifiability."
    },
    {
      "id": "2411.07467v1",
      "title": "Machines and Mathematical Mutations: Using GNNs to Characterize Quiver Mutation Classes",
      "summary": "Machine learning is becoming an increasingly valuable tool in mathematics,\nenabling one to identify subtle patterns across collections of examples so vast\nthat they would be impossible for a single researcher to feasibly review and\nanalyze. In this work, we use graph neural networks to investigate quiver\nmutation -- an operation that transforms one quiver (or directed multigraph)\ninto another -- which is central to the theory of cluster algebras with deep\nconnections to geometry, topology, and physics. In the study of cluster\nalgebras, the question of mutation equivalence is of fundamental concern: given\ntwo quivers, can one efficiently determine if one quiver can be transformed\ninto the other through a sequence of mutations? Currently, this question has\nonly been resolved in specific cases. In this paper, we use graph neural\nnetworks and AI explainability techniques to discover mutation equivalence\ncriteria for the previously unknown case of quivers of type $\\tilde{D}_n$.\nAlong the way, we also show that even without explicit training to do so, our\nmodel captures structure within its hidden representation that allows us to\nreconstruct known criteria from type $D_n$, adding to the growing evidence that\nmodern machine learning models are capable of learning abstract and general\nrules from mathematical data."
    },
    {
      "id": "2411.07466v1",
      "title": "IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark",
      "summary": "Recent evaluations of LLMs on coreference resolution have revealed that\ntraditional output formats and evaluation metrics do not fully capture the\nmodels' referential understanding. To address this, we introduce IdentifyMe, a\nnew benchmark for mention resolution presented in a multiple-choice question\n(MCQ) format, commonly used for evaluating LLMs. IdentifyMe features long\nnarratives and employs heuristics to exclude easily identifiable mentions,\ncreating a more challenging task. The benchmark also consists of a curated\nmixture of different mention types and corresponding entities, allowing for a\nfine-grained analysis of model performance. We evaluate both closed- and open\nsource LLMs on IdentifyMe and observe a significant performance gap (20-30%)\nbetween the state-of-the-art sub-10B open models vs. closed ones. We observe\nthat pronominal mentions, which have limited surface information, are typically\nmuch harder for models to resolve than nominal mentions. Additionally, we find\nthat LLMs often confuse entities when their mentions overlap in nested\nstructures. The highest-scoring model, GPT-4o, achieves 81.9% accuracy,\nhighlighting the strong referential capabilities of state-of-the-art LLMs while\nalso indicating room for further improvement."
    },
    {
      "id": "2411.07464v1",
      "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks",
      "summary": "Large Language Models (LLMs) excel in diverse applications including\ngeneration of code snippets, but often struggle with generating code for\ncomplex Machine Learning (ML) tasks. Although existing LLM single-agent based\nsystems give varying performance depending on the task complexity, they purely\nrely on larger and expensive models such as GPT-4. Our investigation reveals\nthat no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama\nperform far worse than GPT-4 in a single-agent setting. With the motivation of\ndeveloping a cost-efficient LLM based solution for solving ML tasks, we propose\nan LLM Multi-Agent based system which leverages combination of experts using\nprofiling, efficient retrieval of past observations, LLM cascades, and\nask-the-expert calls. Through empirical analysis on ML engineering tasks in the\nMLAgentBench benchmark, we demonstrate the effectiveness of our system, using\nno-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and\nexpert to serve occasional ask-the-expert calls for planning. With 94.2\\%\nreduction in the cost (from \\$0.931 per run cost averaged over all tasks for\nGPT-4 single agent system to \\$0.054), our system is able to yield better\naverage success rate of 32.95\\% as compared to GPT-4 single-agent system\nyielding 22.72\\% success rate averaged over all the tasks of MLAgentBench."
    },
    {
      "id": "2411.07463v2",
      "title": "MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation Models, Convolutional Neural Networks, and Uncertainty Quantification for High-Speed Video Phase Detection Data",
      "summary": "Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital in\nnuclear reactors, chemical processing, and electronics cooling for detecting\nvapor, liquid, and microlayer phases. Traditional segmentation models face\npixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQ\nintroduces VideoSAM, a hybrid framework leveraging convolutional neural\nnetworks (CNNs) and transformer-based vision models to enhance segmentation\naccuracy and generalizability across complex multimodal PD tasks. Methods:\nVideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advanced\nfeature extraction and segmentation across diverse HSV PD modalities, spanning\nfluids like water, FC-72, nitrogen, and argon under varied heat flux\nconditions. The framework also incorporates uncertainty quantification (UQ) to\nassess pixel-based discretization errors, delivering reliable metrics such as\ncontact line density and dry area fraction under experimental conditions.\nResults: VideoSAM outperforms SAM and modality-specific CNN models in\nsegmentation accuracy, excelling in environments with complex phase boundaries,\noverlapping bubbles, and dynamic liquid-vapor interactions. Its hybrid\narchitecture supports cross-dataset generalization, adapting effectively to\nvarying modalities. The UQ module provides accurate error estimates, enhancing\nthe reliability of segmentation outputs for advanced HSV PD research.\nConclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PD\nsegmentation, addressing previous limitations with advanced deep learning and\nUQ techniques. The open-source datasets and tools introduced enable scalable,\nprecise, and adaptable segmentation for multimodal PD datasets, supporting\nadvancements in HSV analysis and autonomous experimentation. The codes and data\nused for this paper are publicly available at:\n\\url{https://github.com/chikap421/mseg_vcuq}"
    },
    {
      "id": "2411.07461v1",
      "title": "BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions",
      "summary": "We introduce BLIP3-KALE, a dataset of 218 million image-text pairs that\nbridges the gap between descriptive synthetic captions and factual web-scale\nalt-text. KALE augments synthetic dense image captions with web-scale alt-text\nto generate factually grounded image captions. Our two-stage approach leverages\nlarge vision-language models and language models to create knowledge-augmented\ncaptions, which are then used to train a specialized VLM for scaling up the\ndataset. We train vision-language models on KALE and demonstrate improvements\non vision-language tasks. Our experiments show the utility of KALE for training\nmore capable and knowledgeable multimodal models. We release the KALE dataset\nat https://huggingface.co/datasets/Salesforce/blip3-kale"
    },
    {
      "id": "2411.07457v1",
      "title": "DecoPrompt : Decoding Prompts Reduces Hallucinations when Large Language Models Meet False Premises",
      "summary": "While large language models (LLMs) have demonstrated increasing power, they\nhave also called upon studies on their hallucinated outputs that deviate from\nfactually correct statements. In this paper, we focus on one important scenario\nof false premises, where LLMs are distracted by misaligned claims although the\nmodel possesses the required factual knowledge to answer original questions\naccurately. Inspired by the observation that entropy of the false-premise\nprompt is closely related to its likelihood to elicit hallucination generation,\nwe propose a new prompting algorithm, named DecoPrompt, to mitigate\nhallucination. DecoPrompt leverages LLMs to \"decode\" the false-premise prompts\nwithout really eliciting hallucination output from LLMs. We perform experiments\non two datasets, demonstrating that DecoPrompt can reduce hallucinations\neffectively on outputs from different LLMs. Moreover, DecoPrompt exhibits\ncross-model transferability, which facilitates its applications to scenarios\nsuch as LLMs of large sizes or unavailable model logits."
    },
    {
      "id": "2411.07453v1",
      "title": "Research on fault diagnosis of nuclear power first-second circuit based on hierarchical multi-granularity classification network",
      "summary": "The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model."
    },
    {
      "id": "2411.07451v1",
      "title": "Optimizing Data Delivery: Insights from User Preferences on Visuals, Tables, and Text",
      "summary": "In this work, we research user preferences to see a chart, table, or text\ngiven a question asked by the user. This enables us to understand when it is\nbest to show a chart, table, or text to the user for the specific question. For\nthis, we conduct a user study where users are shown a question and asked what\nthey would prefer to see and used the data to establish that a user's personal\ntraits does influence the data outputs that they prefer. Understanding how user\ncharacteristics impact a user's preferences is critical to creating data tools\nwith a better user experience. Additionally, we investigate to what degree an\nLLM can be used to replicate a user's preference with and without user\npreference data. Overall, these findings have significant implications\npertaining to the development of data tools and the replication of human\npreferences using LLMs. Furthermore, this work demonstrates the potential use\nof LLMs to replicate user preference data which has major implications for\nfuture user modeling and personalization research."
    },
    {
      "id": "2411.07447v1",
      "title": "The Effect of Scheduling and Preemption on the Efficiency of LLM Inference Serving",
      "summary": "The growing usage of Large Language Models (LLMs) highlights the demands and\nchallenges in scalable LLM inference systems, affecting deployment and\ndevelopment processes. On the deployment side, there is a lack of comprehensive\nanalysis on the conditions under which a particular scheduler performs better\nor worse, with performance varying substantially across different schedulers,\nhardware, models, and workloads. Manually testing each configuration on GPUs\ncan be prohibitively expensive. On the development side, unpredictable\nperformance and unknown upper limits can lead to inconclusive trial-and-error\nprocesses, consuming resources on ideas that end up ineffective. To address\nthese challenges, we introduce INFERMAX, an analytical framework that uses\ninference cost models to compare various schedulers, including an optimal\nscheduler formulated as a constraint satisfaction problem (CSP) to establish an\nupper bound on performance. Our framework offers in-depth analysis and raises\nessential questions, challenging assumptions and exploring opportunities for\nmore efficient scheduling. Notably, our findings indicate that preempting\nrequests can reduce GPU costs by 30% compared to avoiding preemptions at all.\nWe believe our methods and insights will facilitate the cost-effective\ndeployment and development of scalable, efficient inference systems and pave\nthe way for cost-based scheduling."
    },
    {
      "id": "2411.07446v1",
      "title": "Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection",
      "summary": "Automatic prompt engineering aims to enhance the generation quality of large\nlanguage models (LLMs). Recent works utilize feedbacks generated from erroneous\ncases to guide the prompt optimization. During inference, they may further\nretrieve several semantically-related exemplars and concatenate them to the\noptimized prompts to improve the performance. However, those works only utilize\nthe feedback at the current step, ignoring historical and unseleccted feedbacks\nwhich are potentially beneficial. Moreover, the selection of exemplars only\nconsiders the general semantic relationship and may not be optimal in terms of\ntask performance and matching with the optimized prompt. In this work, we\npropose an Exemplar-Guided Reflection with Memory mechanism (ERM) to realize\nmore efficient and accurate prompt optimization. Specifically, we design an\nexemplar-guided reflection mechanism where the feedback generation is\nadditionally guided by the generated exemplars. We further build two kinds of\nmemory to fully utilize the historical feedback information and support more\neffective exemplar retrieval. Empirical evaluations show our method surpasses\nprevious state-of-the-arts with less optimization steps, i.e., improving F1\nscore by 10.1 on LIAR dataset, and reducing half of the optimization steps on\nProTeGi."
    },
    {
      "id": "2411.07444v1",
      "title": "Input-Based Ensemble-Learning Method for Dynamic Memory Configuration of Serverless Computing Functions",
      "summary": "In today's Function-as-a-Service offerings, a programmer is usually\nresponsible for configuring function memory for its successful execution, which\nallocates proportional function resources such as CPU and network. However,\nright-sizing the function memory force developers to speculate performance and\nmake ad-hoc configuration decisions. Recent research has highlighted that a\nfunction's input characteristics, such as input size, type and number of\ninputs, significantly impact its resource demand, run-time performance and\ncosts with fluctuating workloads. This correlation further makes memory\nconfiguration a non-trivial task. On that account, an input-aware function\nmemory allocator not only improves developer productivity by completely hiding\nresource-related decisions but also drives an opportunity to reduce resource\nwastage and offer a finer-grained cost-optimised pricing scheme. Therefore, we\npresent MemFigLess, a serverless solution that estimates the memory requirement\nof a serverless function with input-awareness. The framework executes function\nprofiling in an offline stage and trains a multi-output Random Forest\nRegression model on the collected metrics to invoke input-aware optimal\nconfigurations. We evaluate our work with the state-of-the-art approaches on\nAWS Lambda service to find that MemFigLess is able to capture the input-aware\nresource relationships and allocate upto 82% less resources and save up to 87%\nrun-time costs."
    },
    {
      "id": "2411.07441v1",
      "title": "Automatically Detecting Online Deceptive Patterns in Real-time",
      "summary": "Deceptive patterns (DPs) in digital interfaces manipulate users into making\nunintended decisions, exploiting cognitive biases and psychological\nvulnerabilities. These patterns have become ubiquitous across various digital\nplatforms. While efforts to mitigate DPs have emerged from legal and technical\nperspectives, a significant gap in usable solutions that empower users to\nidentify and make informed decisions about DPs in real-time remains. In this\nwork, we introduce AutoBot, an automated, deceptive pattern detector that\nanalyzes websites' visual appearances using machine learning techniques to\nidentify and notify users of DPs in real-time. AutoBot employs a two-staged\npipeline that processes website screenshots, identifying interactable elements\nand extracting textual features without relying on HTML structure. By\nleveraging a custom language model, AutoBot understands the context surrounding\nthese elements to determine the presence of deceptive patterns. We implement\nAutoBot as a lightweight Chrome browser extension that performs all analyses\nlocally, minimizing latency and preserving user privacy. Through extensive\nevaluation, we demonstrate AutoBot's effectiveness in enhancing users' ability\nto navigate digital environments safely while providing a valuable tool for\nregulators to assess and enforce compliance with DP regulations."
    },
    {
      "id": "2411.07432v1",
      "title": "Fast unsupervised ground metric learning with tree-Wasserstein distance",
      "summary": "The performance of unsupervised methods such as clustering depends on the\nchoice of distance metric between features, or ground metric. Commonly, ground\nmetrics are decided with heuristics or learned via supervised algorithms.\nHowever, since many datasets are unlabelled, unsupervised ground metric\nlearning approaches have been introduced. One recent, promising option uses\nWasserstein singular vectors (WSV), which emerge when computing optimal\ntransport distances between features and samples simultaneously. While WSV is\neffective, it has complexity $\\mathcal{O}(n^5)$, which is prohibitively\nexpensive in some applications. In this work, we propose to augment the WSV\nmethod by embedding samples and features on trees, on which we compute the\ntree-Wasserstein distance (TWD). We demonstrate theoretically and empirically\nthat the algorithm converges to a better approximation of the full WSV approach\nthan the best known alternatives, and does so with $\\mathcal{O}(n^3)$\ncomplexity. In addition, we prove that the initial tree structure can be chosen\nflexibly, since tree geometry does not constrain the richness of the\napproximation up to the number of edge weights. This proof suggests a fast,\nrecursive algorithm for computing the tree parameter basis set, which we find\ncrucial to realising the efficiency gains at scale. Finally, we employ the\ntree-WSV algorithm to several single-cell RNA sequencing genomics datasets,\ndemonstrating its scalability and utility for unsupervised cell-type clustering\nproblems. These results poise unsupervised ground metric learning with TWD as a\nlow-rank approximation of WSV with the potential for widespread low-compute\napplication."
    },
    {
      "id": "2411.07428v1",
      "title": "Just Label the Repeats for In-The-Wild Audio-to-Score Alignment",
      "summary": "We propose an efficient workflow for high-quality offline alignment of\nin-the-wild performance audio and corresponding sheet music scans (images).\nRecent work on audio-to-score alignment extends dynamic time warping (DTW) to\nbe theoretically able to handle jumps in sheet music induced by repeat\nsigns-this method requires no human annotations, but we show that it often\nyields low-quality alignments. As an alternative, we propose a workflow and\ninterface that allows users to quickly annotate jumps (by clicking on repeat\nsigns), requiring a small amount of human supervision but yielding much higher\nquality alignments on average. Additionally, we refine audio and score feature\nrepresentations to improve alignment quality by: (1) integrating measure\ndetection into the score feature representation, and (2) using raw onset\nprediction probabilities from a music transcription model instead of piano\nroll. We propose an evaluation protocol for audio-to-score alignment that\ncomputes the distance between the estimated and ground truth alignment in units\nof measures. Under this evaluation, we find that our proposed jump annotation\nworkflow and improved feature representations together improve alignment\naccuracy by 150% relative to prior work (33% to 82%)."
    },
    {
      "id": "2411.07426v1",
      "title": "Evaluating Detection Thresholds: The Impact of False Positives and Negatives on Super-Resolution Ultrasound Localization Microscopy",
      "summary": "Super-resolution ultrasound imaging with ultrasound localization microscopy\n(ULM) offers a high-resolution view of microvascular structures. Yet, ULM image\nquality heavily relies on precise microbubble (MB) detection. Despite the\ncrucial role of localization algorithms, there has been limited focus on the\npractical pitfalls in MB detection tasks such as setting the detection\nthreshold. This study examines how False Positives (FPs) and False Negatives\n(FNs) affect ULM image quality by systematically adding controlled detection\nerrors to simulated data. Results indicate that while both FP and FN rates\nimpact Peak Signal-to-Noise Ratio (PSNR) similarly, increasing FP rates from\n0\\% to 20\\% decreases Structural Similarity Index (SSIM) by 7\\%, whereas same\nFN rates cause a greater drop of around 45\\%. Moreover, dense MB regions are\nmore resilient to detection errors, while sparse regions show high sensitivity,\nshowcasing the need for robust MB detection frameworks to enhance\nsuper-resolution imaging."
    },
    {
      "id": "2411.07425v1",
      "title": "Predicting BWR Criticality with Data-Driven Machine Learning Model",
      "summary": "One of the challenges in operating nuclear power plants is to decide the\namount of fuel needed in a cycle. Large-scale nuclear power plants are designed\nto operate at base load, meaning that they are expected to always operate at\nfull power. Economically, a nuclear power plant should burn enough fuel to\nmaintain criticality until the end of a cycle (EOC). If the reactor goes\nsubcritical before the end of a cycle, it may result in early coastdown as the\nfuel in the core is already depleted. On contrary, if the reactor still has\nsignificant excess reactivity by the end of a cycle, the remaining fuels will\nremain unused. In both cases, the plant may lose a significant amount of money.\nThis work proposes an innovative method based on a data-driven deep learning\nmodel to estimate the excess criticality of a boiling water reactor."
    },
    {
      "id": "2411.07417v1",
      "title": "Untangling Hate Speech Definitions: A Semantic Componential Analysis Across Cultures and Domains",
      "summary": "Hate speech relies heavily on cultural influences, leading to varying\nindividual interpretations. For that reason, we propose a Semantic Componential\nAnalysis (SCA) framework for a cross-cultural and cross-domain analysis of hate\nspeech definitions. We create the first dataset of definitions derived from\nfive domains: online dictionaries, research papers, Wikipedia articles,\nlegislation, and online platforms, which are later analyzed into semantic\ncomponents. Our analysis reveals that the components differ from definition to\ndefinition, yet many domains borrow definitions from one another without taking\ninto account the target culture. We conduct zero-shot model experiments using\nour proposed dataset, employing three popular open-sourced LLMs to understand\nthe impact of different definitions on hate speech detection. Our findings\nindicate that LLMs are sensitive to definitions: responses for hate speech\ndetection change according to the complexity of definitions used in the prompt."
    },
    {
      "id": "2411.07414v1",
      "title": "Comparing Targeting Strategies for Maximizing Social Welfare with Limited Resources",
      "summary": "Machine learning is increasingly used to select which individuals receive\nlimited-resource interventions in domains such as human services, education,\ndevelopment, and more. However, it is often not apparent what the right\nquantity is for models to predict. In particular, policymakers rarely have\naccess to data from a randomized controlled trial (RCT) that would enable\naccurate estimates of treatment effects -- which individuals would benefit more\nfrom the intervention. Observational data is more likely to be available,\ncreating a substantial risk of bias in treatment effect estimates.\nPractitioners instead commonly use a technique termed \"risk-based targeting\"\nwhere the model is just used to predict each individual's status quo outcome\n(an easier, non-causal task). Those with higher predicted risk are offered\ntreatment. There is currently almost no empirical evidence to inform which\nchoices lead to the most effect machine learning-informed targeting strategies\nin social domains. In this work, we use data from 5 real-world RCTs in a\nvariety of domains to empirically assess such choices. We find that risk-based\ntargeting is almost always inferior to targeting based on even biased estimates\nof treatment effects. Moreover, these results hold even when the policymaker\nhas strong normative preferences for assisting higher-risk individuals. Our\nresults imply that, despite the widespread use of risk prediction models in\napplied settings, practitioners may be better off incorporating even weak\nevidence about heterogeneous causal effects to inform targeting."
    },
    {
      "id": "2411.07413v1",
      "title": "ODEStream: A Buffer-Free Online Learning Framework with ODE-based Adaptor for Streaming Time Series Forecasting",
      "summary": "Addressing the challenges of irregularity and concept drift in streaming time\nseries is crucial in real-world predictive modelling. Previous studies in time\nseries continual learning often propose models that require buffering of long\nsequences, potentially restricting the responsiveness of the inference system.\nMoreover, these models are typically designed for regularly sampled data, an\nunrealistic assumption in real-world scenarios. This paper introduces\nODEStream, a novel buffer-free continual learning framework that incorporates a\ntemporal isolation layer that integrates temporal dependencies within the data.\nSimultaneously, it leverages the capability of neural ordinary differential\nequations to process irregular sequences and generate a continuous data\nrepresentation, enabling seamless adaptation to changing dynamics in a data\nstreaming scenario. Our approach focuses on learning how the dynamics and\ndistribution of historical data change with time, facilitating the direct\nprocessing of streaming sequences. Evaluations on benchmark real-world datasets\ndemonstrate that ODEStream outperforms the state-of-the-art online learning and\nstreaming analysis baselines, providing accurate predictions over extended\nperiods while minimising performance degradation over time by learning how the\nsequence dynamics change."
    },
    {
      "id": "2411.07407v1",
      "title": "Using Generative AI and Multi-Agents to Provide Automatic Feedback",
      "summary": "This study investigates the use of generative AI and multi-agent systems to\nprovide automatic feedback in educational contexts, particularly for student\nconstructed responses in science assessments. The research addresses a key gap\nin the field by exploring how multi-agent systems, called AutoFeedback, can\nimprove the quality of GenAI-generated feedback, overcoming known issues such\nas over-praise and over-inference that are common in single-agent large\nlanguage models (LLMs). The study developed a multi-agent system consisting of\ntwo AI agents: one for generating feedback and another for validating and\nrefining it. The system was tested on a dataset of 240 student responses, and\nits performance was compared to that of a single-agent LLM. Results showed that\nAutoFeedback significantly reduced the occurrence of over-praise and\nover-inference errors, providing more accurate and pedagogically sound\nfeedback. The findings suggest that multi-agent systems can offer a more\nreliable solution for generating automated feedback in educational settings,\nhighlighting their potential for scalable and personalized learning support.\nThese results have important implications for educators and researchers seeking\nto leverage AI in formative assessments, offering a pathway to more effective\nfeedback mechanisms that enhance student learning outcomes."
    },
    {
      "id": "2411.07404v1",
      "title": "Controllable Context Sensitivity and the Knob Behind It",
      "summary": "When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior."
    },
    {
      "id": "2411.08073v1",
      "title": "LoRA-BERT: a Natural Language Processing Model for Robust and Accurate Prediction of long non-coding RNAs",
      "summary": "Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans."
    },
    {
      "id": "2411.07398v1",
      "title": "Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews",
      "summary": "With the increasing proliferation of mobile applications in our everyday\nexperiences, the concerns surrounding ethics have surged significantly. Users\ngenerally communicate their feedback, report issues, and suggest new\nfunctionalities in application (app) reviews, frequently emphasizing safety,\nprivacy, and accountability concerns. Incorporating these reviews is essential\nto developing successful products. However, app reviews related to ethical\nconcerns generally use domain-specific language and are expressed using a more\nvaried vocabulary. Thus making automated ethical concern-related app review\nextraction a challenging and time-consuming effort.\n  This study proposes a novel Natural Language Processing (NLP) based approach\nthat combines Natural Language Inference (NLI), which provides a deep\ncomprehension of language nuances, and a decoder-only (LLaMA-like) Large\nLanguage Model (LLM) to extract ethical concern-related app reviews at scale.\nUtilizing 43,647 app reviews from the mental health domain, the proposed\nmethodology 1) Evaluates four NLI models to extract potential privacy reviews\nand compares the results of domain-specific privacy hypotheses with generic\nprivacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to\nprivacy concerns; and 3) Uses the best NLI and LLM models further to extract\nnew privacy reviews from the dataset. Results show that the\nDeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses\nyields the best performance, and Llama3.1-8B-Instruct LLM performs best in the\nclassification of app reviews. Then, using NLI+LLM, an additional 1,008 new\nprivacy-related reviews were extracted that were not identified through the\nkeyword-based approach in previous research, thus demonstrating the\neffectiveness of the proposed approach."
    },
    {
      "id": "2411.07396v1",
      "title": "Toward Optimal Search and Retrieval for RAG",
      "summary": "Retrieval-augmented generation (RAG) is a promising method for addressing\nsome of the memory-related challenges associated with Large Language Models\n(LLMs). Two separate systems form the RAG pipeline, the retriever and the\nreader, and the impact of each on downstream task performance is not\nwell-understood. Here, we work towards the goal of understanding how retrievers\ncan be optimized for RAG pipelines for common tasks such as Question Answering\n(QA). We conduct experiments focused on the relationship between retrieval and\nRAG performance on QA and attributed QA and unveil a number of insights useful\nto practitioners developing high-performance RAG pipelines. For example,\nlowering search accuracy has minor implications for RAG performance while\npotentially increasing retrieval speed and memory efficiency."
    },
    {
      "id": "2411.07395v1",
      "title": "Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery",
      "summary": "This study introduces a novel data-centric approach to improve real-time\nsurgical guidance using fiber-based fluorescence lifetime imaging (FLIm). A key\naspect of the methodology is the accurate detection of the aiming beam, which\nis essential for localizing points used to map FLIm measurements onto the\ntissue region within the surgical field. The primary challenge arises from the\ncomplex and variable conditions encountered in the surgical environment,\nparticularly in Transoral Robotic Surgery (TORS). Uneven illumination in the\nsurgical field can cause reflections, reduce contrast, and results in\ninconsistent color representation, further complicating aiming beam detection.\nTo overcome these challenges, an instance segmentation model was developed\nusing a data-centric training strategy that improves accuracy by minimizing\nlabel noise and enhancing detection robustness. The model was evaluated on a\ndataset comprising 40 in vivo surgical videos, demonstrating a median detection\nrate of 85%. This performance was maintained when the model was integrated in a\nclinical system, achieving a similar detection rate of 85% during TORS\nprocedures conducted in patients. The system's computational efficiency,\nmeasured at approximately 24 frames per second (FPS), was sufficient for\nreal-time surgical guidance. This study enhances the reliability of FLIm-based\naiming beam detection in complex surgical environments, advancing the\nfeasibility of real-time, image-guided interventions for improved surgical\nprecision"
    },
    {
      "id": "2411.07392v1",
      "title": "Feature-Space Semantic Invariance: Enhanced OOD Detection for Open-Set Domain Generalization",
      "summary": "Open-set domain generalization addresses a real-world challenge: training a\nmodel to generalize across unseen domains (domain generalization) while also\ndetecting samples from unknown classes not encountered during training\n(open-set recognition). However, most existing approaches tackle these issues\nseparately, limiting their practical applicability. To overcome this\nlimitation, we propose a unified framework for open-set domain generalization\nby introducing Feature-space Semantic Invariance (FSI). FSI maintains semantic\nconsistency across different domains within the feature space, enabling more\naccurate detection of OOD instances in unseen domains. Additionally, we adopt a\ngenerative model to produce synthetic data with novel domain styles or class\nlabels, enhancing model robustness. Initial experiments show that our method\nimproves AUROC by 9.1% to 18.9% on ColoredMNIST, while also significantly\nincreasing in-distribution classification accuracy."
    },
    {
      "id": "2411.07391v1",
      "title": "Federated Learning Client Pruning for Noisy Labels",
      "summary": "Federated Learning (FL) enables collaborative model training across\ndecentralized edge devices while preserving data privacy. However, existing FL\nmethods often assume clean annotated datasets, impractical for\nresource-constrained edge devices. In reality, noisy labels are prevalent,\nposing significant challenges to FL performance. Prior approaches attempt label\ncorrection and robust training techniques but exhibit limited efficacy,\nparticularly under high noise levels. This paper introduces ClipFL (Federated\nLearning Client Pruning), a novel framework addressing noisy labels from a\nfresh perspective. ClipFL identifies and excludes noisy clients based on their\nperformance on a clean validation dataset, tracked using a Noise Candidacy\nScore (NCS). The framework comprises three phases: pre-client pruning to\nidentify potential noisy clients and calculate their NCS, client pruning to\nexclude a percentage of clients with the highest NCS, and post-client pruning\nfor fine-tuning the global model with standard FL on clean clients. Empirical\nevaluation demonstrates ClipFL's efficacy across diverse datasets and noise\nlevels, achieving accurate noisy client identification, superior performance,\nfaster convergence, and reduced communication costs compared to\nstate-of-the-art FL methods. Our code is available at\nhttps://github.com/MMorafah/ClipFL."
    },
    {
      "id": "2411.07388v1",
      "title": "Firing Rate Models as Associative Memory: Excitatory-Inhibitory Balance for Robust Retrieval",
      "summary": "Firing rate models are dynamical systems widely used in applied and\ntheoretical neuroscience to describe local cortical dynamics in neuronal\npopulations. By providing a macroscopic perspective of neuronal activity, these\nmodels are essential for investigating oscillatory phenomena, chaotic behavior,\nand associative memory processes. Despite their widespread use, the application\nof firing rate models to associative memory networks has received limited\nmathematical exploration, and most existing studies are focused on specific\nmodels. Conversely, well-established associative memory designs, such as\nHopfield networks, lack key biologically-relevant features intrinsic to firing\nrate models, including positivity and interpretable synaptic matrices that\nreflect excitatory and inhibitory interactions. To address this gap, we propose\na general framework that ensures the emergence of re-scaled memory patterns as\nstable equilibria in the firing rate dynamics. Furthermore, we analyze the\nconditions under which the memories are locally and globally asymptotically\nstable, providing insights into constructing biologically-plausible and robust\nsystems for associative memory retrieval."
    },
    {
      "id": "2411.07387v1",
      "title": "Isochrony-Controlled Speech-to-Text Translation: A study on translating from Sino-Tibetan to Indo-European Languages",
      "summary": "End-to-end speech translation (ST), which translates source language speech\ndirectly into target language text, has garnered significant attention in\nrecent years. Many ST applications require strict length control to ensure that\nthe translation duration matches the length of the source audio, including both\nspeech and pause segments. Previous methods often controlled the number of\nwords or characters generated by the Machine Translation model to approximate\nthe source sentence's length without considering the isochrony of pauses and\nspeech segments, as duration can vary between languages. To address this, we\npresent improvements to the duration alignment component of our\nsequence-to-sequence ST model. Our method controls translation length by\npredicting the duration of speech and pauses in conjunction with the\ntranslation process. This is achieved by providing timing information to the\ndecoder, ensuring it tracks the remaining duration for speech and pauses while\ngenerating the translation. The evaluation on the Zh-En test set of CoVoST 2,\ndemonstrates that the proposed Isochrony-Controlled ST achieves 0.92 speech\noverlap and 8.9 BLEU, which has only a 1.4 BLEU drop compared to the ST\nbaseline."
    },
    {
      "id": "2411.07381v1",
      "title": "BeeManc at the PLABA Track of TAC-2024: RoBERTa for task 1 and LLaMA3.1 and GPT-4o for task 2",
      "summary": "This report is the system description of the BeeManc team for shared task\nPlain Language Adaptation of Biomedical Abstracts (PLABA) 2024. This report\ncontains two sections corresponding to the two sub-tasks in PLABA 2024. In task\none, we applied fine-tuned ReBERTa-Base models to identify and classify the\ndifficult terms, jargon and acronyms in the biomedical abstracts and reported\nthe F1 score. Due to time constraints, we didn't finish the replacement task.\nIn task two, we leveraged Llamma3.1-70B-Instruct and GPT-4o with the one-shot\nprompts to complete the abstract adaptation and reported the scores in BLEU,\nSARI, BERTScore, LENS, and SALSA. From the official Evaluation from PLABA-2024\non Task 1A and 1B, our \\textbf{much smaller fine-tuned RoBERTa-Base} model\nranked 3rd and 2nd respectively on the two sub-task, and the \\textbf{1st on\naveraged F1 scores across the two tasks} from 9 evaluated systems. Our share\nour fine-tuned models and related resources at\n\\url{https://github.com/HECTA-UoM/PLABA2024}"
    },
    {
      "id": "2411.07378v1",
      "title": "Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data",
      "summary": "Artificial intelligence (AI) in medical device software (MDSW) represents a\ntransformative clinical technology, attracting increasing attention within both\nthe medical community and the regulators. In this study, we leverage a\ndata-driven approach to automatically extract and analyze AI-enabled medical\ndevices (AIMD) from the National Medical Products Administration (NMPA)\nregulatory database. The continued increase in publicly available regulatory\ndata requires scalable methods for analysis. Automation of regulatory\ninformation screening is essential to create reproducible insights that can be\nquickly updated in an ever changing medical device landscape. More than 4\nmillion entries were assessed, identifying 2,174 MDSW registrations, including\n531 standalone applications and 1,643 integrated within medical devices, of\nwhich 43 were AI-enabled. It was shown that the leading medical specialties\nutilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology\n(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of\ndata extracting providing a greater ability to compare and contrast. This study\nprovides the first extensive, data-driven exploration of AIMD in China,\nshowcasing the potential of automated regulatory data analysis in understanding\nand advancing the landscape of AI in medical technology."
    },
    {
      "id": "2411.07376v1",
      "title": "Ensemble Learning for Microbubble Localization in Super-Resolution Ultrasound",
      "summary": "Super-resolution ultrasound (SR-US) is a powerful imaging technique for\ncapturing microvasculature and blood flow at high spatial resolution. However,\naccurate microbubble (MB) localization remains a key challenge, as errors in\nlocalization can propagate through subsequent stages of the super-resolution\nprocess, affecting overall performance. In this paper, we explore the potential\nof ensemble learning techniques to enhance MB localization by increasing\ndetection sensitivity and reducing false positives. Our study evaluates the\neffectiveness of ensemble methods on both in vivo and simulated outputs of a\nDeformable DEtection TRansformer (Deformable DETR) network. As a result of our\nstudy, we are able to demonstrate the advantages of these ensemble approaches\nby showing improved precision and recall in MB detection and offering insights\ninto their application in SR-US."
    },
    {
      "id": "2411.07372v1",
      "title": "Identifying Differential Patient Care Through Inverse Intent Inference",
      "summary": "Sepsis is a life-threatening condition defined by end-organ dysfunction due\nto a dysregulated host response to infection. Although the Surviving Sepsis\nCampaign has launched and has been releasing sepsis treatment guidelines to\nunify and normalize the care for sepsis patients, it has been reported in\nnumerous studies that disparities in care exist across the trajectory of\npatient stay in the emergency department and intensive care unit. Here, we\napply a number of reinforcement learning techniques including behavioral\ncloning, imitation learning, and inverse reinforcement learning, to learn the\noptimal policy in the management of septic patient subgroups using expert\ndemonstrations. Then we estimate the counterfactual optimal policies by\napplying the model to another subset of unseen medical populations and identify\nthe difference in cure by comparing it to the real policy. Our data comes from\nthe sepsis cohort of MIMIC-IV and the clinical data warehouses of the Mass\nGeneral Brigham healthcare system. The ultimate objective of this work is to\nuse the optimal learned policy function to estimate the counterfactual\ntreatment policy and identify deviations across sub-populations of interest. We\nhope this approach would help us identify any disparities in care and also\nchanges in cure in response to the publication of national sepsis treatment\nguidelines."
    },
    {
      "id": "2411.07362v1",
      "title": "Factorised Active Inference for Strategic Multi-Agent Interactions",
      "summary": "Understanding how individual agents make strategic decisions within\ncollectives is important for advancing fields as diverse as economics,\nneuroscience, and multi-agent systems. Two complementary approaches can be\nintegrated to this end. The Active Inference framework (AIF) describes how\nagents employ a generative model to adapt their beliefs about and behaviour\nwithin their environment. Game theory formalises strategic interactions between\nagents with potentially competing objectives. To bridge the gap between the\ntwo, we propose a factorisation of the generative model whereby each agent\nmaintains explicit, individual-level beliefs about the internal states of other\nagents, and uses them for strategic planning in a joint context. We apply our\nmodel to iterated general-sum games with 2 and 3 players, and study the\nensemble effects of game transitions, where the agents' preferences (game\npayoffs) change over time. This non-stationarity, beyond that caused by\nreciprocal adaptation, reflects a more naturalistic environment in which agents\nneed to adapt to changing social contexts. Finally, we present a dynamical\nanalysis of key AIF quantities: the variational free energy (VFE) and the\nexpected free energy (EFE) from numerical simulation data. The ensemble-level\nEFE allows us to characterise the basins of attraction of games with multiple\nNash Equilibria under different conditions, and we find that it is not\nnecessarily minimised at the aggregate level. By integrating AIF and game\ntheory, we can gain deeper insights into how intelligent collectives emerge,\nlearn, and optimise their actions in dynamic environments, both cooperative and\nnon-cooperative."
    },
    {
      "id": "2411.07348v1",
      "title": "Exploring Variational Autoencoders for Medical Image Generation: A Comprehensive Study",
      "summary": "Variational autoencoder (VAE) is one of the most common techniques in the\nfield of medical image generation, where this architecture has shown advanced\nresearchers in recent years and has developed into various architectures. VAE\nhas advantages including improving datasets by adding samples in smaller\ndatasets and in datasets with imbalanced classes, and this is how data\naugmentation works. This paper provides a comprehensive review of studies on\nVAE in medical imaging, with a special focus on their ability to create\nsynthetic images close to real data so that they can be used for data\naugmentation. This study reviews important architectures and methods used to\ndevelop VAEs for medical images and provides a comparison with other generative\nmodels such as GANs on issues such as image quality, and low diversity of\ngenerated samples. We discuss recent developments and applications in several\nmedical fields highlighting the ability of VAEs to improve segmentation and\nclassification accuracy."
    },
    {
      "id": "2411.07343v1",
      "title": "Multi-head Span-based Detector for AI-generated Fragments in Scientific Papers",
      "summary": "This paper describes a system designed to distinguish between AI-generated\nand human-written scientific excerpts in the DAGPap24 competition hosted within\nthe Fourth Workshop on Scientific Document Processing. In this competition the\ntask is to find artificially generated token-level text fragments in documents\nof a scientific domain. Our work focuses on the use of a multi-task learning\narchitecture with two heads. The application of this approach is justified by\nthe specificity of the task, where class spans are continuous over several\nhundred characters. We considered different encoder variations to obtain a\nstate vector for each token in the sequence, as well as a variation in\nsplitting fragments into tokens to further feed into the input of a\ntransform-based encoder. This approach allows us to achieve a 9% quality\nimprovement relative to the baseline solution score on the development set\n(from 0.86 to 0.95) using the average macro F1-score, as well as a score of\n0.96 on a closed test part of the dataset from the competition."
    },
    {
      "id": "2411.07340v1",
      "title": "Warmstarting for Scaling Language Models",
      "summary": "Scaling model sizes to scale performance has worked remarkably well for the\ncurrent large language models paradigm. The research and empirical findings of\nvarious scaling studies led to novel scaling results and laws that guides\nsubsequent research. High training costs for contemporary scales of data and\nmodels result in a lack of thorough understanding of how to tune and arrive at\nsuch training setups. One direction to ameliorate the cost of pretraining large\nmodels is to warmstart the large-scale training from smaller models that are\ncheaper to tune. In this work, we attempt to understand if the behavior of\noptimal hyperparameters can be retained under warmstarting for scaling. We\nexplore simple operations that allow the application of theoretically motivated\nmethods of zero-shot transfer of optimal hyperparameters using {\\mu}Transfer.\nWe investigate the aspects that contribute to the speedup in convergence and\nthe preservation of stable training dynamics under warmstarting with\n{\\mu}Transfer. We find that shrinking smaller model weights, zero-padding, and\nperturbing the resulting larger model with scaled initialization from {\\mu}P\nenables effective warmstarting of $\\mut{}$."
    },
    {
      "id": "2411.07336v1",
      "title": "SetLexSem Challenge: Using Set Operations to Evaluate the Lexical and Semantic Robustness of Language Models",
      "summary": "Set theory is foundational to mathematics and, when sets are finite, to\nreasoning about the world. An intelligent system should perform set operations\nconsistently, regardless of superficial variations in the operands. Initially\ndesigned for semantically-oriented NLP tasks, large language models (LLMs) are\nnow being evaluated on algorithmic tasks. Because sets are comprised of\narbitrary symbols (e.g. numbers, words), they provide an opportunity to test,\nsystematically, the invariance of LLMs' algorithmic abilities under simple\nlexical or semantic variations. To this end, we present the SetLexSem\nChallenge, a synthetic benchmark that evaluates the performance of LLMs on set\noperations. SetLexSem assesses the robustness of LLMs' instruction-following\nabilities under various conditions, focusing on the set operations and the\nnature and construction of the set members. Evaluating seven LLMs with\nSetLexSem, we find that they exhibit poor robustness to variation in both\noperation and operands. We show -- via the framework's systematic sampling of\nset members along lexical and semantic dimensions -- that LLMs are not only not\nrobust to variation along these dimensions but demonstrate unique failure modes\nin particular, easy-to-create semantic groupings of \"deceptive\" sets. We find\nthat rigorously measuring language model robustness to variation in frequency\nand length is challenging and present an analysis that measures them\nindependently. The code for reproducing the results of this paper, and for\ngenerating the SetLexSem Challenge dataset, is available at\n\\href{https://github.com/amazon-science/SetLexSem-Challenge}{https://github.com/amazon-science/SetLexSem-Challenge}."
    },
    {
      "id": "2411.07335v1",
      "title": "Multimodal Fusion Balancing Through Game-Theoretic Regularization",
      "summary": "Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets."
    },
    {
      "id": "2411.07320v1",
      "title": "Richer Output for Richer Countries: Uncovering Geographical Disparities in Generated Stories and Travel Recommendations",
      "summary": "While a large body of work inspects language models for biases concerning\ngender, race, occupation and religion, biases of geographical nature are\nrelatively less explored. Some recent studies benchmark the degree to which\nlarge language models encode geospatial knowledge. However, the impact of the\nencoded geographical knowledge (or lack thereof) on real-world applications has\nnot been documented. In this work, we examine large language models for two\ncommon scenarios that require geographical knowledge: (a) travel\nrecommendations and (b) geo-anchored story generation. Specifically, we study\nfour popular language models, and across about $100$K travel requests, and\n$200$K story generations, we observe that travel recommendations corresponding\nto poorer countries are less unique with fewer location references, and stories\nfrom these regions more often convey emotions of hardship and sadness compared\nto those from wealthier nations."
    },
    {
      "id": "2411.07317v1",
      "title": "SynRL: Aligning Synthetic Clinical Trial Data with Human-preferred Clinical Endpoints Using Reinforcement Learning",
      "summary": "Each year, hundreds of clinical trials are conducted to evaluate new medical\ninterventions, but sharing patient records from these trials with other\ninstitutions can be challenging due to privacy concerns and federal\nregulations. To help mitigate privacy concerns, researchers have proposed\nmethods for generating synthetic patient data. However, existing approaches for\ngenerating synthetic clinical trial data disregard the usage requirements of\nthese data, including maintaining specific properties of clinical outcomes, and\nonly use post hoc assessments that are not coupled with the data generation\nprocess. In this paper, we propose SynRL which leverages reinforcement learning\nto improve the performance of patient data generators by customizing the\ngenerated data to meet the user-specified requirements for synthetic data\noutcomes and endpoints. Our method includes a data value critic function to\nevaluate the quality of the generated data and uses reinforcement learning to\nalign the data generator with the users' needs based on the critic's feedback.\nWe performed experiments on four clinical trial datasets and demonstrated the\nadvantages of SynRL in improving the quality of the generated synthetic data\nwhile keeping the privacy risks low. We also show that SynRL can be utilized as\na general framework that can customize data generation of multiple types of\nsynthetic data generators. Our code is available at\nhttps://anonymous.4open.science/r/SynRL-DB0F/."
    },
    {
      "id": "2411.08072v1",
      "title": "Modeling variable guide efficiency in pooled CRISPR screens with ContrastiveVI+",
      "summary": "Genetic screens mediated via CRISPR-Cas9 combined with high-content readouts\nhave emerged as powerful tools for biological discovery. However, computational\nanalyses of these screens come with additional challenges beyond those found\nwith standard scRNA-seq analyses. For example, perturbation-induced variations\nof interest may be subtle and masked by other dominant source of variation\nshared with controls, and variable guide efficiency results in some cells not\nundergoing genetic perturbation despite expressing a guide RNA. While a number\nof methods have been developed to address the former problem by explicitly\ndisentangling perturbation-induced variations from those shared with controls,\nless attention has been paid to the latter problem of noisy perturbation\nlabels. To address this issue, here we propose ContrastiveVI+, a generative\nmodeling framework that both disentangles perturbation-induced from\nnon-perturbation-related variations while also inferring whether cells truly\nunderwent genomic edits. Applied to three large-scale Perturb-seq datasets, we\nfind that ContrastiveVI+ better recovers known perturbation-induced variations\ncompared to previous methods while successfully identifying cells that escaped\nthe functional consequences of guide RNA expression. An open-source\nimplementation of our model is available at\n\\url{https://github.com/insitro/contrastive_vi_plus}."
    },
    {
      "id": "2411.07315v2",
      "title": "Harnessing Smartphone Sensors for Enhanced Road Safety: A Comprehensive Dataset and Review",
      "summary": "Severe collisions can result from aggressive driving and poor road\nconditions, emphasizing the need for effective monitoring to ensure safety.\nSmartphones, with their array of built-in sensors, offer a practical and\naffordable solution for road-sensing. However, the lack of reliable,\nstandardized datasets has hindered progress in assessing road conditions and\ndriving patterns. This study addresses this gap by introducing a comprehensive\ndataset derived from smartphone sensors, which surpasses existing datasets by\nincorporating a diverse range of sensors including accelerometer, gyroscope,\nmagnetometer, GPS, gravity, orientation, and uncalibrated sensors. These\nsensors capture extensive parameters such as acceleration force, gravitation,\nrotation rate, magnetic field strength, and vehicle speed, providing a detailed\nunderstanding of road conditions and driving behaviors. The dataset is designed\nto enhance road safety, infrastructure maintenance, traffic management, and\nurban planning. By making this dataset available to the community, the study\naims to foster collaboration, inspire further research, and facilitate the\ndevelopment of innovative solutions in intelligent transportation systems."
    },
    {
      "id": "2411.07314v1",
      "title": "Anomaly Detection in OKTA Logs using Autoencoders",
      "summary": "Okta logs are used today to detect cybersecurity events using various\nrule-based models with restricted look back periods. These functions have\nlimitations, such as a limited retrospective analysis, a predefined rule set,\nand susceptibility to generating false positives. To address this, we adopt\nunsupervised techniques, specifically employing autoencoders. To properly use\nan autoencoder, we need to transform and simplify the complexity of the log\ndata we receive from our users. This transformed and filtered data is then fed\ninto the autoencoder, and the output is evaluated."
    },
    {
      "id": "2411.07308v1",
      "title": "X-DFS: Explainable Artificial Intelligence Guided Design-for-Security Solution Space Exploration",
      "summary": "Design and manufacturing of integrated circuits predominantly use a globally\ndistributed semiconductor supply chain involving diverse entities. The modern\nsemiconductor supply chain has been designed to boost production efficiency,\nbut is filled with major security concerns such as malicious modifications\n(hardware Trojans), reverse engineering (RE), and cloning. While being\ndeployed, digital systems are also subject to a plethora of threats such as\npower, timing, and electromagnetic (EM) side channel attacks. Many\nDesign-for-Security (DFS) solutions have been proposed to deal with these\nvulnerabilities, and such solutions (DFS) relays on strategic modifications\n(e.g., logic locking, side channel resilient masking, and dummy logic\ninsertion) of the digital designs for ensuring a higher level of security.\nHowever, most of these DFS strategies lack robust formalism, are often not\nhuman-understandable, and require an extensive amount of human expert effort\nduring their development/use. All of these factors make it difficult to keep up\nwith the ever growing number of microelectronic vulnerabilities. In this work,\nwe propose X-DFS, an explainable Artificial Intelligence (AI) guided DFS\nsolution-space exploration approach that can dramatically cut down the\nmitigation strategy development/use time while enriching our understanding of\nthe vulnerability by providing human-understandable decision rationale. We\nimplement X-DFS and comprehensively evaluate it for reverse engineering threats\n(SAIL, SWEEP, and OMLA) and formalize a generalized mechanism for applying\nX-DFS to defend against other threats such as hardware Trojans, fault attacks,\nand side channel attacks for seamless future extensions."
    },
    {
      "id": "2411.07302v1",
      "title": "Merit-Based Sortition in Decentralized Systems",
      "summary": "In decentralized systems, it is often necessary to select an 'active' subset\nof participants from the total participant pool, with the goal of satisfying\ncomputational limitations or optimizing resource efficiency. This selection can\nsometimes be made at random, mirroring the sortition practice invented in\nclassical antiquity aimed at achieving a high degree of statistical\nrepresentativeness. However, the recent emergence of specialized decentralized\nnetworks that solve concrete coordination problems and are characterized by\nmeasurable success metrics often requires prioritizing performance optimization\nover representativeness. We introduce a simple algorithm for 'merit-based\nsortition', in which the quality of each participant influences its probability\nof being drafted into the active set, while simultaneously retaining\nrepresentativeness by allowing inactive participants an infinite number of\nchances to be drafted into the active set with non-zero probability. Using a\nsuite of numerical experiments, we demonstrate that our algorithm boosts the\nquality metric describing the performance of the active set by $>2$ times the\nintrinsic stochasticity. This implies that merit-based sortition ensures a\nstatistically significant performance boost to the drafted, 'active' set, while\nretaining the property of classical, random sortition that it enables upward\nmobility from a much larger 'inactive' set. This way, merit-based sortition\nfulfils a key requirement for decentralized systems in need of performance\noptimization."
    },
    {
      "id": "2411.07300v1",
      "title": "Artificial Intelligence Ecosystem for Automating Self-Directed Teaching",
      "summary": "This research introduces an innovative artificial intelligence-driven\neducational concept designed to optimize self-directed learning through\npersonalized course delivery and automated teaching assistance. The system\nleverages fine-tuned AI models to create an adaptive learning environment that\nencompasses customized roadmaps, automated presentation generation, and\nthree-dimensional modeling for complex concept visualization. By integrating\nreal-time virtual assistance for doubt resolution, the platform addresses the\nimmediate educational needs of learners while promoting autonomous learning\npractices. This study explores the psychological advantages of self-directed\nlearning and demonstrates how AI automation can enhance educational outcomes\nthrough personalized content delivery and interactive support mechanisms. The\nresearch contributes to the growing field of educational technology by\npresenting a comprehensive framework that combines automated content\ngeneration, visual learning aids, and intelligent tutoring to create an\nefficient, scalable solution for modern educational needs. Preliminary findings\nsuggest that this approach not only accommodates diverse learning styles but\nalso strengthens student engagement and knowledge retention through its\nemphasis on self-paced, independent learning methodologies."
    },
    {
      "id": "2411.07279v1",
      "title": "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning",
      "summary": "Language models have shown impressive performance on tasks within their\ntraining distribution, but often struggle with novel problems requiring complex\nreasoning. We investigate the effectiveness of test-time training (TTT) --\nupdating model parameters temporarily during inference using a loss derived\nfrom input data -- as a mechanism for improving models' reasoning capabilities,\nusing the Abstraction and Reasoning Corpus (ARC) as a benchmark. Through\nsystematic experimentation, we identify three crucial components for successful\nTTT: (1) initial finetuning on similar tasks (2) auxiliary task format and\naugmentations (3) per-instance training. TTT significantly improves performance\non ARC tasks, achieving up to 6x improvement in accuracy compared to base\nfine-tuned models; applying TTT to an 8B-parameter language model, we achieve\n53% accuracy on the ARC's public validation set, improving the state-of-the-art\nby nearly 25% for public and purely neural approaches. By ensembling our method\nwith recent program generation approaches, we get SoTA public validation\naccuracy of 61.9%, matching the average human score. Our findings suggest that\nexplicit symbolic search is not the only path to improved abstract reasoning in\nneural language models; additional test-time applied to continued training on\nfew-shot examples can also be extremely effective."
    },
    {
      "id": "2411.07240v1",
      "title": "UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts",
      "summary": "The evaluation of mathematical reasoning capabilities is essential for\nadvancing Artificial General Intelligence (AGI). While Large Language Models\n(LLMs) have shown impressive performance in solving mathematical problems,\nexisting benchmarks such as GSM8K and MATH present limitations, including\nnarrow problem definitions with specific numbers and reliance on predetermined\nrules that hinder accurate assessments of reasoning and adaptability. This\npaper introduces the UTMath Benchmark, which robustly evaluates the models\nthrough extensive unit tests. It consists of 1,053 problems across 9\nmathematical domains, with over 68 test cases per problem. We propose an\ninnovative evaluation framework inspired by unit testing in software\ndevelopment, focusing on both accuracy and reliability of results. Furthermore,\nwe introduce the Reasoning-to-Coding of Thoughts (RCoT) approach, which\nencourages LLMs to perform explicit reasoning before generating code, leading\nto generating more advanced solution and improved performance. Furthermore, we\nare releasing not only the UTMath benchmark but also the UTMath-Train training\ndataset (more than 70k samples), to support the community in further exploring\nmathematical reasoning."
    },
    {
      "id": "2411.07238v1",
      "title": "OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model",
      "summary": "OpenThaiGPT 1.5 is an advanced Thai language chat model based on Qwen v2.5,\nfinetuned on over 2,000,000 Thai instruction pairs. This report provides an\nengineering perspective on the model's development, capabilities, and\nperformance. We discuss the model's architecture, training process, and key\nfeatures, including multi-turn conversation support, Retrieval Augmented\nGeneration (RAG) compatibility, and tool-calling functionality. Benchmark\nresults demonstrate OpenThaiGPT 1.5's state-of-the-art performance on various\nThai language tasks, outperforming other open-source Thai language models. We\nalso address practical considerations such as GPU memory requirements and\ndeployment strategies."
    },
    {
      "id": "2411.07239v1",
      "title": "DeepONet as a Multi-Operator Extrapolation Model: Distributed Pretraining with Physics-Informed Fine-Tuning",
      "summary": "We propose a novel fine-tuning method to achieve multi-operator learning\nthrough training a distributed neural operator with diverse function data and\nthen zero-shot fine-tuning the neural network using physics-informed losses for\ndownstream tasks. Operator learning effectively approximates solution operators\nfor PDEs and various PDE-related problems, yet it often struggles to generalize\nto new tasks. To address this, we investigate fine-tuning a pretrained model,\nwhile carefully selecting an initialization that enables rapid adaptation to\nnew tasks with minimal data. Our approach combines distributed learning to\nintegrate data from various operators in pre-training, while physics-informed\nmethods enable zero-shot fine-tuning, minimizing the reliance on downstream\ndata. We investigate standard fine-tuning and Low-Rank Adaptation fine-tuning,\napplying both to train complex nonlinear target operators that are difficult to\nlearn only using random initialization. Through comprehensive numerical\nexamples, we demonstrate the advantages of our approach, showcasing significant\nimprovements in accuracy. Our findings provide a robust framework for advancing\nmulti-operator learning and highlight the potential of transfer learning\ntechniques in this domain."
    },
    {
      "id": "2411.07237v1",
      "title": "Contextualized Evaluations: Taking the Guesswork Out of Language Model Evaluations",
      "summary": "Language model users often issue queries that lack specification, where the\ncontext under which a query was issued -- such as the user's identity, the\nquery's intent, and the criteria for a response to be useful -- is not\nexplicit. For instance, a good response to a subjective query like \"What book\nshould I read next?\" would depend on the user's preferences, and a good\nresponse to an open-ended query like \"How do antibiotics work against\nbacteria?\" would depend on the user's expertise. This makes evaluation of\nresponses to such queries an ill-posed task, as evaluators may make arbitrary\njudgments about the response quality. To remedy this, we present contextualized\nevaluations, a protocol that synthetically constructs context surrounding an\nunderspecified query and provides it during evaluation. We find that the\npresence of context can 1) alter conclusions drawn from evaluation, even\nflipping win rates between model pairs, 2) nudge evaluators to make fewer\njudgments based on surface-level criteria, like style, and 3) provide new\ninsights about model behavior across diverse contexts. Specifically, our\nprocedure uncovers an implicit bias towards WEIRD contexts in models' \"default\"\nresponses and we find that models are not equally sensitive to following\ndifferent contexts, even when they are provided in prompts."
    },
    {
      "id": "2411.07233v1",
      "title": "Score-based generative diffusion with \"active\" correlated noise sources",
      "summary": "Diffusion models exhibit robust generative properties by approximating the\nunderlying distribution of a dataset and synthesizing data by sampling from the\napproximated distribution. In this work, we explore how the generative\nperformance may be be modulated if noise sources with temporal correlations --\nakin to those used in the field of active matter -- are used for the\ndestruction of the data in the forward process. Our numerical and analytical\nexperiments suggest that the corresponding reverse process may exhibit improved\ngenerative properties."
    },
    {
      "id": "2411.07232v2",
      "title": "Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models",
      "summary": "Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics."
    },
    {
      "id": "2411.07228v1",
      "title": "Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving",
      "summary": "To enhance large language models (LLMs) for chemistry problem solving,\nseveral LLM-based agents augmented with tools have been proposed, such as\nChemCrow and Coscientist. However, their evaluations are narrow in scope,\nleaving a large gap in understanding the benefits of tools across diverse\nchemistry tasks. To bridge this gap, we develop ChemAgent, an enhanced\nchemistry agent over ChemCrow, and conduct a comprehensive evaluation of its\nperformance on both specialized chemistry tasks and general chemistry\nquestions. Surprisingly, ChemAgent does not consistently outperform its base\nLLMs without tools. Our error analysis with a chemistry expert suggests that:\nFor specialized chemistry tasks, such as synthesis prediction, we should\naugment agents with specialized tools; however, for general chemistry questions\nlike those in exams, agents' ability to reason correctly with chemistry\nknowledge matters more, and tool augmentation does not always help."
    },
    {
      "id": "2411.07224v1",
      "title": "TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on Pre-trained Language Models",
      "summary": "With the widespread of digital environments, reliable authentication and\ncontinuous access control has become crucial. It can minimize cyber attacks and\nprevent frauds, specially those associated with identity theft. A particular\ninterest lies on keystroke dynamics (KD), which refers to the task of\nrecognizing individuals' identity based on their unique typing style. In this\nwork, we propose the use of pre-trained language models (PLMs) to recognize\nsuch patterns. Although PLMs have shown high performance on multiple NLP\nbenchmarks, the use of these models on specific tasks requires customization.\nBERT and RoBERTa, for instance, rely on subword tokenization, and they cannot\nbe directly applied to KD, which requires temporal-character information to\nrecognize users. Recent character-aware PLMs are able to process both subwords\nand character-level information and can be an alternative solution.\nNotwithstanding, they are still not suitable to be directly fine-tuned for KD\nas they are not optimized to account for user's temporal typing information\n(e.g., hold time and flight time). To overcome this limitation, we propose\nTempCharBERT, an architecture that incorporates temporal-character information\nin the embedding layer of CharBERT. This allows modeling keystroke dynamics for\nthe purpose of user identification and authentication. Our results show a\nsignificant improvement with this customization. We also showed the feasibility\nof training TempCharBERT on a federated learning settings in order to foster\ndata privacy."
    },
    {
      "id": "2411.07223v1",
      "title": "Grounding Video Models to Actions through Goal Conditioned Exploration",
      "summary": "Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations."
    },
    {
      "id": "2411.07218v1",
      "title": "TreeCoders: Trees of Transformers",
      "summary": "In this paper, we introduce TreeCoders, a novel family of transformer trees.\nWe moved away from traditional linear transformers to complete k-ary trees.\nTransformer blocks serve as nodes, and generic classifiers learn to select the\nbest child and route the sequence of tokens to a specific leaf. The selectors,\nmoved outside the transformer blocks, allow for the use of a variety of\narchitecture without further modifications. Furthermore, our proposed\narchitecture supports sparse node activation due to the logarithmic complexity\nof a tree search. We validate our idea by testing a series of decoder-only tree\ntransformers, achieving competitive results across a diverse range of language\ndatasets. Our study demonstrates that the proposed tree transformer model\noutperforms a size-equivalent linear transformer model 76\\% of the time over a\nwide range of tree architectures. Furthermore, our proposed model naturally\nlends itself to distributed implementation."
    },
    {
      "id": "2411.07217v3",
      "title": "Feature Selection Based on Wasserstein Distance",
      "summary": "This paper presents a novel feature selection method leveraging the\nWasserstein distance to improve feature selection in machine learning. Unlike\ntraditional methods based on correlation or Kullback-Leibler (KL) divergence,\nour approach uses the Wasserstein distance to assess feature similarity,\ninherently capturing class relationships and making it robust to noisy labels.\nWe introduce a Markov blanket-based feature selection algorithm and demonstrate\nits effectiveness. Our analysis shows that the Wasserstein distance-based\nfeature selection method effectively reduces the impact of noisy labels without\nrelying on specific noise models. We provide a lower bound on its\neffectiveness, which remains meaningful even in the presence of noise.\nExperimental results across multiple datasets demonstrate that our approach\nconsistently outperforms traditional methods, particularly in noisy settings."
    },
    {
      "id": "2411.07213v1",
      "title": "Comparing Bottom-Up and Top-Down Steering Approaches on In-Context Learning Tasks",
      "summary": "A key objective of interpretability research on large language models (LLMs)\nis to develop methods for robustly steering models toward desired behaviors. To\nthis end, two distinct approaches to interpretability -- ``bottom-up\" and\n``top-down\" -- have been presented, but there has been little quantitative\ncomparison between them. We present a case study comparing the effectiveness of\nrepresentative vector steering methods from each branch: function vectors (FV;\narXiv:2310.15213), as a bottom-up method, and in-context vectors (ICV;\narXiv:2311.06668) as a top-down method. While both aim to capture compact\nrepresentations of broad in-context learning tasks, we find they are effective\nonly on specific types of tasks: ICVs outperform FVs in behavioral shifting,\nwhereas FVs excel in tasks requiring more precision. We discuss the\nimplications for future evaluations of steering methods and for further\nresearch into top-down and bottom-up steering given these findings."
    },
    {
      "id": "2411.07207v2",
      "title": "General Geospatial Inference with a Population Dynamics Foundation Model",
      "summary": "Supporting the health and well-being of dynamic populations around the world\nrequires governmental agencies, organizations and researchers to understand and\nreason over complex relationships between human behavior and local contexts in\norder to identify high-risk groups and strategically allocate limited\nresources. Traditional approaches to these classes of problems often entail\ndeveloping manually curated, task-specific features and models to represent\nhuman behavior and the natural and built environment, which can be challenging\nto adapt to new, or even, related tasks. To address this, we introduce a\nPopulation Dynamics Foundation Model (PDFM) that aims to capture the\nrelationships between diverse data modalities and is applicable to a broad\nrange of geospatial tasks. We first construct a geo-indexed dataset for postal\ncodes and counties across the United States, capturing rich aggregated\ninformation on human behavior from maps, busyness, and aggregated search\ntrends, and environmental factors such as weather and air quality. We then\nmodel this data and the complex relationships between locations using a graph\nneural network, producing embeddings that can be adapted to a wide range of\ndownstream tasks using relatively simple models. We evaluate the effectiveness\nof our approach by benchmarking it on 27 downstream tasks spanning three\ndistinct domains: health indicators, socioeconomic factors, and environmental\nmeasurements. The approach achieves state-of-the-art performance on all 27\ngeospatial interpolation tasks, and on 25 out of the 27 extrapolation and\nsuper-resolution tasks. We combined the PDFM with a state-of-the-art\nforecasting foundation model, TimesFM, to predict unemployment and poverty,\nachieving performance that surpasses fully supervised forecasting. The full set\nof embeddings and sample code are publicly available for researchers."
    },
    {
      "id": "2411.07200v1",
      "title": "'Explaining RL Decisions with Trajectories': A Reproducibility Study",
      "summary": "This work investigates the reproducibility of the paper 'Explaining RL\ndecisions with trajectories'. The original paper introduces a novel approach in\nexplainable reinforcement learning based on the attribution decisions of an\nagent to specific clusters of trajectories encountered during training. We\nverify the main claims from the paper, which state that (i) training on less\ntrajectories induces a lower initial state value, (ii) trajectories in a\ncluster present similar high-level patterns, (iii) distant trajectories\ninfluence the decision of an agent, and (iv) humans correctly identify the\nattributed trajectories to the decision of the agent. We recover the\nenvironments used by the authors based on the partial original code they\nprovided for one of the environments (Grid-World), and implemented the\nremaining from scratch (Seaquest, HalfCheetah, Breakout and Q*Bert). While we\nconfirm that (i), (ii), and (iii) partially hold, we extend on the largely\nqualitative experiments from the authors by introducing a quantitative metric\nto further support (iii), and new experiments and visual results for (i).\nMoreover, we investigate the use of different clustering algorithms and encoder\narchitectures to further support (ii). We could not support (iv), given the\nlimited extent of the original experiments. We conclude that, while some of the\nclaims can be supported, further investigations and experiments could be of\ninterest. We recognise the novelty of the work from the authors and hope that\nour work paves the way for clearer and more transparent approaches."
    },
    {
      "id": "2411.07199v1",
      "title": "OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision",
      "summary": "Instruction-guided image editing methods have demonstrated significant\npotential by training diffusion models on automatically synthesized or manually\nannotated image editing pairs. However, these methods remain far from\npractical, real-life applications. We identify three primary challenges\ncontributing to this gap. Firstly, existing models have limited editing skills\ndue to the biased synthesis process. Secondly, these methods are trained with\ndatasets with a high volume of noise and artifacts. This is due to the\napplication of simple filtering methods like CLIP-score. Thirdly, all these\ndatasets are restricted to a single low resolution and fixed aspect ratio,\nlimiting the versatility to handle real-world use cases. In this paper, we\npresent \\omniedit, which is an omnipotent editor to handle seven different\nimage editing tasks with any aspect ratio seamlessly. Our contribution is in\nfour folds: (1) \\omniedit is trained by utilizing the supervision from seven\ndifferent specialist models to ensure task coverage. (2) we utilize importance\nsampling based on the scores provided by large multimodal models (like GPT-4o)\ninstead of CLIP-score to improve the data quality. (3) we propose a new editing\narchitecture called EditNet to greatly boost the editing success rate, (4) we\nprovide images with different aspect ratios to ensure that our model can handle\nany image in the wild. We have curated a test set containing images of\ndifferent aspect ratios, accompanied by diverse instructions to cover different\ntasks. Both automatic evaluation and human evaluations demonstrate that\n\\omniedit can significantly outperform all the existing models. Our code,\ndataset and model will be available at\n\\url{https://tiger-ai-lab.github.io/OmniEdit/}"
    },
    {
      "id": "2411.07192v1",
      "title": "Data-Driven Predictive Control of Nonholonomic Robots Based on a Bilinear Koopman Realization: Data Does Not Replace Geometry",
      "summary": "Advances in machine learning and the growing trend towards effortless data\ngeneration in real-world systems has led to an increasing interest for\ndata-inferred models and data-based control in robotics. It seems appealing to\ngovern robots solely based on data, bypassing the traditional, more elaborate\npipeline of system modeling through first-principles and subsequent controller\ndesign. One promising data-driven approach is the Extended Dynamic Mode\nDecomposition (EDMD) for control-affine systems, a system class which contains\nmany vehicles and machines of immense practical importance including, e.g.,\ntypical wheeled mobile robots. EDMD can be highly data-efficient,\ncomputationally inexpensive, can deal with nonlinear dynamics as prevalent in\nrobotics and mechanics, and has a sound theoretical foundation rooted in\nKoopman theory. On this background, this present paper examines how EDMD models\ncan be integrated into predictive controllers for nonholonomic mobile robots.\nIn addition to the conventional kinematic mobile robot, we also cover the\ncomplete data-driven control pipeline - from data acquisition to control design\n- when the robot is not treated in terms of first-order kinematics but in a\nsecond-order manner, allowing to account for actuator dynamics. Using only\nreal-world measurement data, it is shown in both simulations and hardware\nexperiments that the surrogate models enable high-precision predictive\ncontrollers in the studied cases. However, the findings raise significant\nconcerns about purely data-centric approaches that overlook the underlying\ngeometry of nonholonomic systems, showing that, for nonholonomic systems, some\ngeometric insight seems necessary and cannot be easily compensated for with\nlarge amounts of data."
    },
    {
      "id": "2411.07191v1",
      "title": "The Super Weight in Large Language Models",
      "summary": "Recent works have shown a surprising result: a small fraction of Large\nLanguage Model (LLM) parameter outliers are disproportionately important to the\nquality of the model. LLMs contain billions of parameters, so these small\nfractions, such as 0.01%, translate to hundreds of thousands of parameters. In\nthis work, we present an even more surprising finding: Pruning as few as a\nsingle parameter can destroy an LLM's ability to generate text -- increasing\nperplexity by 3 orders of magnitude and reducing zero-shot accuracy to\nguessing. We propose a data-free method for identifying such parameters, termed\nsuper weights, using a single forward pass through the model. We additionally\nfind that these super weights induce correspondingly rare and large activation\noutliers, termed super activations. When preserved with high precision, super\nactivations can improve simple round-to-nearest quantization to become\ncompetitive with state-of-the-art methods. For weight quantization, we\nsimilarly find that by preserving the super weight and clipping other weight\noutliers, round-to-nearest quantization can scale to much larger block sizes\nthan previously considered. To facilitate further research into super weights,\nwe provide an index of super weight coordinates for common, openly available\nLLMs."
    },
    {
      "id": "2411.07186v1",
      "title": "NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics",
      "summary": "Large language models (LLMs) prompted with text and audio represent the state\nof the art in various auditory tasks, including speech, music, and general\naudio, showing emergent abilities on unseen tasks. However, these capabilities\nhave yet to be fully demonstrated in bioacoustics tasks, such as detecting\nanimal vocalizations in large recordings, classifying rare and endangered\nspecies, and labeling context and behavior - tasks that are crucial for\nconservation, biodiversity monitoring, and the study of animal behavior. In\nthis work, we present NatureLM-audio, the first audio-language foundation model\nspecifically designed for bioacoustics. Our carefully curated training dataset\ncomprises text-audio pairs spanning a diverse range of bioacoustics, speech,\nand music data, designed to address the challenges posed by limited annotated\ndatasets in the field. We demonstrate successful transfer of learned\nrepresentations from music and speech to bioacoustics, and our model shows\npromising generalization to unseen taxa and tasks. Importantly, we test\nNatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state of\nthe art (SotA) on several bioacoustics tasks, including zero-shot\nclassification of unseen species. To advance bioacoustics research, we also\nopen-source the code for generating training and benchmark data, as well as for\ntraining the model."
    },
    {
      "id": "2411.07277v1",
      "title": "Constructing Gaussian Processes via Samplets",
      "summary": "Gaussian Processes face two primary challenges: constructing models for large\ndatasets and selecting the optimal model. This master's thesis tackles these\nchallenges in the low-dimensional case. We examine recent convergence results\nto identify models with optimal convergence rates and pinpoint essential\nparameters. Utilizing this model, we propose a Samplet-based approach to\nefficiently construct and train the Gaussian Processes, reducing the cubic\ncomputational complexity to a log-linear scale. This method facilitates optimal\nregression while maintaining efficient performance."
    },
    {
      "id": "2411.07185v1",
      "title": "Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation",
      "summary": "Multi-source unsupervised domain adaptation aims to leverage labeled data\nfrom multiple source domains for training a machine learning model to\ngeneralize well on a target domain without labels. Source domain selection\nplays a crucial role in determining the model's performance. It relies on the\nsimilarities amongst source and target domains. Nonetheless, existing work for\nsource domain selection often involves heavyweight computational procedures,\nespecially when dealing with numerous source domains and the need to identify\nthe best ones from them. In this paper, we introduce a framework for gradual\nfine tuning (GFT) of machine learning models on multiple source domains. We\nrepresent multiple source domains as an undirected weighted graph. We then give\na new generalization error bound for GFT along any path within the graph, which\nis used to determine the optimal path corresponding to the optimal training\norder. With this formulation, we introduce three lightweight graph-routing\nstrategies which tend to minimize the error bound. Our best strategy improves\n$2.3\\%$ of accuracy over the state-of-the-art on Natural Language Inference\n(NLI) task and achieves competitive performance on Sentiment Analysis (SA)\ntask, especially a $3.9\\%$ improvement on a more diverse subset of data we use\nfor SA."
    },
    {
      "id": "2411.07182v1",
      "title": "Revisiting Ensembling in One-Shot Federated Learning",
      "summary": "Federated learning (FL) is an appealing approach to training machine learning\nmodels without sharing raw data. However, standard FL algorithms are iterative\nand thus induce a significant communication cost. One-shot federated learning\n(OFL) trades the iterative exchange of models between clients and the server\nwith a single round of communication, thereby saving substantially on\ncommunication costs. Not surprisingly, OFL exhibits a performance gap in terms\nof accuracy with respect to FL, especially under high data heterogeneity. We\nintroduce FENS, a novel federated ensembling scheme that approaches the\naccuracy of FL with the communication efficiency of OFL. Learning in FENS\nproceeds in two phases: first, clients train models locally and send them to\nthe server, similar to OFL; second, clients collaboratively train a lightweight\nprediction aggregator model using FL. We showcase the effectiveness of FENS\nthrough exhaustive experiments spanning several datasets and heterogeneity\nlevels. In the particular case of heterogeneously distributed CIFAR-10 dataset,\nFENS achieves up to a 26.9% higher accuracy over state-of-the-art (SOTA) OFL,\nbeing only 3.1% lower than FL. At the same time, FENS incurs at most 4.3x more\ncommunication than OFL, whereas FL is at least 10.9x more\ncommunication-intensive than FENS."
    },
    {
      "id": "2411.07180v1",
      "title": "Counterfactual Generation from Language Models",
      "summary": "Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to intervene on\nthese models. To understand the impact of interventions precisely, it is useful\nto examine counterfactuals -- e.g., how a given sentence would have appeared\nhad it been generated by the model following a specific intervention. We\nhighlight that counterfactual reasoning is conceptually distinct from\ninterventions, as articulated in Pearl's causal hierarchy. Based on this\nobservation, we propose a framework for generating true string counterfactuals\nby reformulating language models as Generalized Structural-equation. Models\nusing the Gumbel-max trick. This allows us to model the joint distribution over\noriginal strings and their counterfactuals resulting from the same\ninstantiation of the sampling noise. We develop an algorithm based on hindsight\nGumbel sampling that allows us to infer the latent noise variables and generate\ncounterfactuals of observed strings. Our experiments demonstrate that the\napproach produces meaningful counterfactuals while at the same time showing\nthat commonly used intervention techniques have considerable undesired side\neffects."
    },
    {
      "id": "2411.07179v1",
      "title": "Joint Age-State Belief is All You Need: Minimizing AoII via Pull-Based Remote Estimation",
      "summary": "Age of incorrect information (AoII) is a recently proposed freshness and\nmismatch metric that penalizes an incorrect estimation along with its duration.\nTherefore, keeping track of AoII requires the knowledge of both the source and\nestimation processes. In this paper, we consider a time-slotted pull-based\nremote estimation system under a sampling rate constraint where the information\nsource is a general discrete-time Markov chain (DTMC) process. Moreover, packet\ntransmission times from the source to the monitor are non-zero which disallows\nthe monitor to have perfect information on the actual AoII process at any time.\nHence, for this pull-based system, we propose the monitor to maintain a\nsufficient statistic called {\\em belief} which stands for the joint\ndistribution of the age and source processes to be obtained from the history of\nall observations. Using belief, we first propose a maximum a posteriori (MAP)\nestimator to be used at the monitor as opposed to existing martingale\nestimators in the literature. Second, we obtain the optimality equations from\nthe belief-MDP (Markov decision process) formulation. Finally, we propose two\nbelief-dependent policies one of which is based on deep reinforcement learning,\nand the other one is a threshold-based policy based on the instantaneous\nexpected AoII."
    },
    {
      "id": "2411.07176v2",
      "title": "More Expressive Attention with Negative Weights",
      "summary": "We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights."
    },
    {
      "id": "2411.07175v1",
      "title": "Continual Memorization of Factoids in Large Language Models",
      "summary": "Large language models can absorb a massive amount of knowledge through\npretraining, but pretraining is inefficient for acquiring long-tailed or\nspecialized facts. Therefore, fine-tuning on specialized or new knowledge that\nreflects changes in the world has become popular, though it risks disrupting\nthe model's original capabilities. We study this fragility in the context of\ncontinual memorization, where the model is trained on a small set of long-tail\nfactoids (factual associations) and must retain these factoids after multiple\nstages of subsequent training on other datasets. Through extensive experiments,\nwe show that LLMs suffer from forgetting across a wide range of subsequent\ntasks, and simple replay techniques do not fully prevent forgetting, especially\nwhen the factoid datasets are trained in the later stages. We posit that there\nare two ways to alleviate forgetting: 1) protect the memorization process as\nthe model learns the factoids, or 2) reduce interference from training in later\nstages. With this insight, we develop an effective mitigation strategy: REMIX\n(Random and Generic Data Mixing). REMIX prevents forgetting by mixing generic\ndata sampled from pretraining corpora or even randomly generated word sequences\nduring each stage, despite being unrelated to the memorized factoids in the\nfirst stage. REMIX can recover performance from severe forgetting, often\noutperforming replay-based methods that have access to the factoids from the\nfirst stage. We then analyze how REMIX alters the learning process and find\nthat successful forgetting prevention is associated with a pattern: the model\nstores factoids in earlier layers than usual and diversifies the set of layers\nthat store these factoids. The efficacy of REMIX invites further investigation\ninto the underlying dynamics of memorization and forgetting, opening exciting\npossibilities for future research."
    },
    {
      "id": "2411.07171v1",
      "title": "Anytime Sequential Halving in Monte-Carlo Tree Search",
      "summary": "Monte-Carlo Tree Search (MCTS) typically uses multi-armed bandit (MAB)\nstrategies designed to minimize cumulative regret, such as UCB1, as its\nselection strategy. However, in the root node of the search tree, it is more\nsensible to minimize simple regret. Previous work has proposed using Sequential\nHalving as selection strategy in the root node, as, in theory, it performs\nbetter with respect to simple regret. However, Sequential Halving requires a\nbudget of iterations to be predetermined, which is often impractical. This\npaper proposes an anytime version of the algorithm, which can be halted at any\narbitrary time and still return a satisfactory result, while being designed\nsuch that it approximates the behavior of Sequential Halving. Empirical results\nin synthetic MAB problems and ten different board games demonstrate that the\nalgorithm's performance is competitive with Sequential Halving and UCB1 (and\ntheir analogues in MCTS)."
    },
    {
      "id": "2411.07168v1",
      "title": "Enhancing Predictive Maintenance in Mining Mobile Machinery through a TinyML-enabled Hierarchical Inference Network",
      "summary": "Mining machinery operating in variable environments faces high wear and\nunpredictable stress, challenging Predictive Maintenance (PdM). This paper\nintroduces the Edge Sensor Network for Predictive Maintenance (ESN-PdM), a\nhierarchical inference framework across edge devices, gateways, and cloud\nservices for real-time condition monitoring. The system dynamically adjusts\ninference locations--on-device, on-gateway, or on-cloud--based on trade-offs\namong accuracy, latency, and battery life, leveraging Tiny Machine Learning\n(TinyML) techniques for model optimization on resource-constrained devices.\nPerformance evaluations showed that on-sensor and on-gateway inference modes\nachieved over 90\\% classification accuracy, while cloud-based inference reached\n99\\%. On-sensor inference reduced power consumption by approximately 44\\%,\nenabling up to 104 hours of operation. Latency was lowest for on-device\ninference (3.33 ms), increasing when offloading to the gateway (146.67 ms) or\ncloud (641.71 ms). The ESN-PdM framework provides a scalable, adaptive solution\nfor reliable anomaly detection and PdM, crucial for maintaining machinery\nuptime in remote environments. By balancing accuracy, latency, and energy\nconsumption, this approach advances PdM frameworks for industrial applications."
    },
    {
      "id": "2411.07163v1",
      "title": "A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19",
      "summary": "Monitoring public sentiment via social media is potentially helpful during\nhealth crises such as the COVID-19 pandemic. However, traditional\nfrequency-based, data-driven neural network-based approaches can miss newly\nrelevant content due to the evolving nature of language in a dynamically\nevolving environment. Human-curated symbolic knowledge sources, such as\nlexicons for standard language and slang terms, can potentially elevate social\nmedia signals in evolving language. We introduce a neurosymbolic method that\nintegrates neural networks with symbolic knowledge sources, enhancing the\ndetection and interpretation of mental health-related tweets relevant to\nCOVID-19. Our method was evaluated using a corpus of large datasets\n(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news\narticles) and multiple knowledge graphs. This method dynamically adapts to\nevolving language, outperforming purely data-driven models with an F1 score\nexceeding 92\\%. This approach also showed faster adaptation to new data and\nlower computational demands than fine-tuning pre-trained large language models\n(LLMs). This study demonstrates the benefit of neurosymbolic methods in\ninterpreting text in a dynamic environment for tasks such as health\nsurveillance."
    },
    {
      "id": "2411.07161v1",
      "title": "RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration",
      "summary": "This study investigates the efficacy of Multi-Agent Systems in eliciting\ncross-agent communication and enhancing collective intelligence through group\ndecision-making in a decentralized setting. Unlike centralized mechanisms,\nwhere a fixed hierarchy governs social choice, decentralized group\ndecision-making allows agents to engage in joint deliberation. Our research\nfocuses on the dynamics of communication and decision-making within various\nsocial choice methods. By applying different voting rules in various\nenvironments, we find that moderate decision flexibility yields better\noutcomes. Additionally, exploring the linguistic features of agent-to-agent\nconversations reveals indicators of effective collaboration, offering insights\ninto communication patterns that facilitate or hinder collaboration. Finally,\nwe propose various methods for determining the optimal stopping point in\nmulti-agent collaborations based on linguistic cues. Our findings contribute to\na deeper understanding of how decentralized decision-making and group\nconversation shape multi-agent collaboration, with implications for the design\nof more effective MAS environments."
    },
    {
      "id": "2411.07156v1",
      "title": "A Primer on Word Embeddings: AI Techniques for Text Analysis in Social Work",
      "summary": "Word embeddings represent a transformative technology for analyzing text data\nin social work research, offering sophisticated tools for understanding case\nnotes, policy documents, research literature, and other text-based materials.\nThis methodological paper introduces word embeddings to social work\nresearchers, explaining how these mathematical representations capture meaning\nand relationships in text data more effectively than traditional keyword-based\napproaches. We discuss fundamental concepts, technical foundations, and\npractical applications, including semantic search, clustering, and retrieval\naugmented generation. The paper demonstrates how embeddings can enhance\nresearch workflows through concrete examples from social work practice, such as\nanalyzing case notes for housing instability patterns and comparing social work\nlicensing examinations across languages. While highlighting the potential of\nembeddings for advancing social work research, we acknowledge limitations\nincluding information loss, training data constraints, and potential biases. We\nconclude that successfully implementing embedding technologies in social work\nrequires developing domain-specific models, creating accessible tools, and\nestablishing best practices aligned with social work's ethical principles. This\nintegration can enhance our ability to analyze complex patterns in text data\nwhile supporting more effective services and interventions."
    },
    {
      "id": "2411.07154v1",
      "title": "Conditional simulation via entropic optimal transport: Toward non-parametric estimation of conditional Brenier maps",
      "summary": "Conditional simulation is a fundamental task in statistical modeling:\nGenerate samples from the conditionals given finitely many data points from a\njoint distribution. One promising approach is to construct conditional Brenier\nmaps, where the components of the map pushforward a reference distribution to\nconditionals of the target. While many estimators exist, few, if any, come with\nstatistical or algorithmic guarantees. To this end, we propose a non-parametric\nestimator for conditional Brenier maps based on the computational scalability\nof \\emph{entropic} optimal transport. Our estimator leverages a result of\nCarlier et al. (2010), which shows that optimal transport maps under a rescaled\nquadratic cost asymptotically converge to conditional Brenier maps; our\nestimator is precisely the entropic analogues of these converging maps. We\nprovide heuristic justifications for choosing the scaling parameter in the cost\nas a function of the number of samples by fully characterizing the Gaussian\nsetting. We conclude by comparing the performance of the estimator to other\nmachine learning and non-parametric approaches on benchmark datasets and\nBayesian inference problems."
    },
    {
      "id": "2411.07152v1",
      "title": "HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals",
      "summary": "Task-Oriented Dialogue (TOD) systems assist users in completing tasks through\nnatural language interactions, often relying on a single-layered workflow\nstructure for slot-filling in public tasks, such as hotel bookings. However, in\nenterprise environments, which involve rich domain-specific knowledge, TOD\nsystems face challenges due to task complexity and the lack of standardized\ndocumentation. In this work, we introduce HierTOD, an enterprise TOD system\ndriven by hierarchical goals and can support composite workflows. By focusing\non goal-driven interactions, our system serves a more proactive role,\nfacilitating mixed-initiative dialogue and improving task completion. Equipped\nwith components for natural language understanding, composite goal retriever,\ndialogue management, and response generation, backed by a well-organized data\nservice with domain knowledge base and retrieval engine, HierTOD delivers\nefficient task assistance. Furthermore, our system implementation unifies two\nTOD paradigms: slot-filling for information collection and step-by-step\nguidance for task execution. Our human study demonstrates the effectiveness and\nhelpfulness of HierTOD in performing both paradigms."
    },
    {
      "id": "2411.07150v1",
      "title": "Variational Graph Contrastive Learning",
      "summary": "Graph representation learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-supervised learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of graph\ncharacteristics while controlling the distribution of generated subgraphs. We\nemploy optimal transport distances, including Wasserstein and\nGromov-Wasserstein distances, to effectively measure the similarity between\nsubgraphs, enhancing the robustness of the contrastive learning process.\nExtensive experiments across multiple benchmarks demonstrate that SGEC\noutperforms or presents competitive performance against state-of-the-art\napproaches. Our findings provide insights into the design of SSL methods for\nGRL, emphasizing the importance of the distribution of the generated\ncontrastive pairs."
    },
    {
      "id": "2411.07142v1",
      "title": "Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt",
      "summary": "Financial documents are filled with specialized terminology, arcane jargon,\nand curious acronyms that pose challenges for general-purpose text embeddings.\nYet, few text embeddings specialized for finance have been reported in the\nliterature, perhaps in part due to a lack of public datasets and benchmarks. We\npresent BAM embeddings, a set of text embeddings finetuned on a carefully\nconstructed dataset of 14.3M query-passage pairs. Demonstrating the benefits of\ndomain-specific training, BAM embeddings achieve Recall@1 of 62.8% on a\nheld-out test set, vs. only 39.2% for the best general-purpose text embedding\nfrom OpenAI. Further, BAM embeddings increase question answering accuracy by 8%\non FinanceBench and show increased sensitivity to the finance-specific elements\nthat are found in detailed, forward-looking and company and date-specific\nqueries. To support further research we describe our approach in detail,\nquantify the importance of hard negative mining and dataset scale."
    },
    {
      "id": "2411.07140v2",
      "title": "Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models",
      "summary": "New LLM evaluation benchmarks are important to align with the rapid\ndevelopment of Large Language Models (LLMs). In this work, we present Chinese\nSimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality\nability of language models to answer short questions, and Chinese SimpleQA\nmainly has five properties (i.e., Chinese, Diverse, High-quality, Static,\nEasy-to-evaluate). Specifically, first, we focus on the Chinese language over 6\nmajor topics with 99 diverse subtopics. Second, we conduct a comprehensive\nquality control process to achieve high-quality questions and answers, where\nthe reference answers are static and cannot be changed over time. Third,\nfollowing SimpleQA, the questions and answers are very short, and the grading\nprocess is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we\nperform a comprehensive evaluation on the factuality abilities of existing\nLLMs. Finally, we hope that Chinese SimpleQA could guide the developers to\nbetter understand the Chinese factuality abilities of their models and\nfacilitate the growth of foundation models."
    },
    {
      "id": "2411.07135v1",
      "title": "Edify 3D: Scalable High-Quality 3D Asset Generation",
      "summary": "We introduce Edify 3D, an advanced solution designed for high-quality 3D\nasset generation. Our method first synthesizes RGB and surface normal images of\nthe described object at multiple viewpoints using a diffusion model. The\nmulti-view observations are then used to reconstruct the shape, texture, and\nPBR materials of the object. Our method can generate high-quality 3D assets\nwith detailed geometry, clean shape topologies, high-resolution textures, and\nmaterials within 2 minutes of runtime."
    },
    {
      "id": "2411.07133v2",
      "title": "Stronger Models are NOT Stronger Teachers for Instruction Tuning",
      "summary": "Instruction tuning has been widely adopted to ensure large language models\n(LLMs) follow user instructions effectively. The resulting\ninstruction-following capabilities of LLMs heavily rely on the instruction\ndatasets used for tuning. Recently, synthetic instruction datasets have emerged\nas an economically viable solution to provide LLMs diverse and high-quality\ninstructions. However, existing approaches typically assume that larger or\nstronger models are stronger teachers for instruction tuning, and hence simply\nadopt these models as response generators to the synthetic instructions. In\nthis paper, we challenge this commonly-adopted assumption. Our extensive\nexperiments across five base models and twenty response generators reveal that\nlarger and stronger models are not necessarily stronger teachers of smaller\nmodels. We refer to this phenomenon as the Larger Models' Paradox. We observe\nthat existing metrics cannot precisely predict the effectiveness of response\ngenerators since they ignore the compatibility between teachers and base models\nbeing fine-tuned. We thus develop a novel metric, named as\nCompatibility-Adjusted Reward (CAR) to measure the effectiveness of response\ngenerators. Our experiments across five base models demonstrate that CAR\noutperforms almost all baselines."
    },
    {
      "id": "2411.07132v1",
      "title": "Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis",
      "summary": "Although text-to-image (T2I) models exhibit remarkable generation\ncapabilities, they frequently fail to accurately bind semantically related\nobjects or attributes in the input prompts; a challenge termed semantic\nbinding. Previous approaches either involve intensive fine-tuning of the entire\nT2I model or require users or large language models to specify generation\nlayouts, adding complexity. In this paper, we define semantic binding as the\ntask of associating a given object with its attribute, termed attribute\nbinding, or linking it to other related sub-objects, referred to as object\nbinding. We introduce a novel method called Token Merging (ToMe), which\nenhances semantic binding by aggregating relevant tokens into a single\ncomposite token. This ensures that the object, its attributes and sub-objects\nall share the same cross-attention map. Additionally, to address potential\nconfusion among main objects with complex textual prompts, we propose end token\nsubstitution as a complementary strategy. To further refine our approach in the\ninitial stages of T2I generation, where layouts are determined, we incorporate\ntwo auxiliary losses, an entropy loss and a semantic binding loss, to\niteratively update the composite token to improve the generation integrity. We\nconducted extensive experiments to validate the effectiveness of ToMe,\ncomparing it against various existing methods on the T2I-CompBench and our\nproposed GPT-4o object binding benchmark. Our method is particularly effective\nin complex scenarios that involve multiple objects and attributes, which\nprevious methods often fail to address. The code will be publicly available at\n\\url{https://github.com/hutaihang/ToMe}."
    },
    {
      "id": "2411.07130v1",
      "title": "Retrieval or Global Context Understanding? On Many-Shot In-Context Learning for Long-Context Evaluation",
      "summary": "Language models (LMs) have demonstrated an improved capacity to handle\nlong-context information, yet existing long-context benchmarks primarily\nmeasure LMs' retrieval abilities with extended inputs, e.g., pinpointing a\nshort phrase from long-form text. Therefore, they may fall short when\nevaluating models' global context understanding capacity, such as synthesizing\nand reasoning over content across input to generate the response. In this\npaper, we study long-context language model (LCLM) evaluation through many-shot\nin-context learning (ICL). Concretely, we identify the skills each ICL task\nrequires, and examine models' long-context capabilities on them. We first ask:\nWhat types of ICL tasks benefit from additional demonstrations, and are these\ntasks effective at evaluating LCLMs? We find that classification and\nsummarization tasks show notable performance improvements with additional\ndemonstrations, while translation and reasoning tasks do not exhibit clear\ntrends. This suggests the classification tasks predominantly test models'\nretrieval skills. Next, we ask: To what extent does each task require retrieval\nskills versus global context understanding from LCLMs? We develop metrics to\ncategorize ICL tasks into two groups: (i) retrieval tasks that require strong\nretrieval ability to pinpoint relevant examples, and (ii) global context\nunderstanding tasks that necessitate a deeper comprehension of the full input.\nWe find that not all datasets can effectively evaluate these long-context\ncapabilities. To address this gap, we introduce a new many-shot ICL benchmark,\nMANYICLBENCH, designed to characterize LCLMs' retrieval and global context\nunderstanding capabilities separately. Benchmarking 11 open-weight LCLMs with\nMANYICLBENCH, we find that while state-of-the-art models perform well in\nretrieval tasks up to 64k tokens, many show significant drops in global context\ntasks at just 16k tokens."
    },
    {
      "id": "2411.07127v1",
      "title": "Benchmarking LLMs' Judgments with No Gold Standard",
      "summary": "We introduce the GEM (Generative Estimator for Mutual Information), an\nevaluation metric for assessing language generation by Large Language Models\n(LLMs), particularly in generating informative judgments, without the need for\na gold standard reference. GEM broadens the scenarios where we can benchmark\nLLM generation performance-from traditional ones, like machine translation and\nsummarization, where gold standard references are readily available, to\nsubjective tasks without clear gold standards, such as academic peer review.\n  GEM uses a generative model to estimate mutual information between candidate\nand reference responses, without requiring the reference to be a gold standard.\nIn experiments on a human-annotated dataset, GEM demonstrates competitive\ncorrelations with human scores compared to the state-of-the-art GPT-4o\nExaminer, and outperforms all other baselines. Additionally, GEM is more robust\nagainst strategic manipulations, such as rephrasing or elongation, which can\nartificially inflate scores under a GPT-4o Examiner.\n  We also present GRE-bench (Generating Review Evaluation Benchmark) which\nevaluates LLMs based on how well they can generate high-quality peer reviews\nfor academic research papers. Because GRE-bench is based upon GEM, it inherits\nits robustness properties. Additionally, GRE-bench circumvents data\ncontamination problems (or data leakage) by using the continuous influx of new\nopen-access research papers and peer reviews each year. We show GRE-bench\nresults of various popular LLMs on their peer review capabilities using the\nICLR2023 dataset."
    },
    {
      "id": "2411.07126v1",
      "title": "Edify Image: High-Quality Image Generation with Pixel Space Laplacian Diffusion Models",
      "summary": "We introduce Edify Image, a family of diffusion models capable of generating\nphotorealistic image content with pixel-perfect accuracy. Edify Image utilizes\ncascaded pixel-space diffusion models trained using a novel Laplacian diffusion\nprocess, in which image signals at different frequency bands are attenuated at\nvarying rates. Edify Image supports a wide range of applications, including\ntext-to-image synthesis, 4K upsampling, ControlNets, 360 HDR panorama\ngeneration, and finetuning for image customization."
    },
    {
      "id": "2411.07123v1",
      "title": "Fast and Robust Contextual Node Representation Learning over Dynamic Graphs",
      "summary": "Real-world graphs grow rapidly with edge and vertex insertions over time,\nmotivating the problem of efficiently maintaining robust node representation\nover evolving graphs. Recent efficient GNNs are designed to decouple recursive\nmessage passing from the learning process, and favor Personalized PageRank\n(PPR) as the underlying feature propagation mechanism. However, most PPR-based\nGNNs are designed for static graphs, and efficient PPR maintenance remains as\nan open problem. Further, there is surprisingly little theoretical\njustification for the choice of PPR, despite its impressive empirical\nperformance.\n  In this paper, we are inspired by the recent PPR formulation as an explicit\n$\\ell_1$-regularized optimization problem and propose a unified dynamic graph\nlearning framework based on sparse node-wise attention. We also present a set\nof desired properties to justify the choice of PPR in STOA GNNs, and serves as\nthe guideline for future node attention designs. Meanwhile, we take advantage\nof the PPR-equivalent optimization formulation and employ the proximal gradient\nmethod (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.\nFinally, we instantiate a simple-yet-effective model (\\textsc{GoPPE}) with\nrobust positional encodings by maximizing PPR previously used as attention. The\nmodel performs comparably to or better than the STOA baselines and greatly\noutperforms when the initial node attributes are noisy during graph evolution,\ndemonstrating the effectiveness and robustness of \\textsc{GoPPE}."
    },
    {
      "id": "2411.07122v1",
      "title": "SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering in LLMs",
      "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ngenerating human-like text, but their output may not be aligned with the user\nor even produce harmful content. This paper presents a novel approach to detect\nand steer concepts such as toxicity before generation. We introduce the Sparse\nConditioned Autoencoder (SCAR), a single trained module that extends the\notherwise untouched LLM. SCAR ensures full steerability, towards and away from\nconcepts (e.g., toxic content), without compromising the quality of the model's\ntext generation on standard evaluation benchmarks. We demonstrate the effective\napplication of our approach through a variety of concepts, including toxicity,\nsafety, and writing style alignment. As such, this work establishes a robust\nframework for controlling LLM generations, ensuring their ethical and safe\ndeployment in real-world applications."
    },
    {
      "id": "2411.07120v1",
      "title": "Efficient Adaptive Optimization via Subset-Norm and Subspace-Momentum: Fast, Memory-Reduced Training with Convergence Guarantees",
      "summary": "We introduce two complementary techniques for efficient adaptive optimization\nthat reduce memory requirements while accelerating training of large-scale\nneural networks. The first technique, Subset-Norm adaptive step size,\ngeneralizes AdaGrad-Norm and AdaGrad(-Coordinate) by reducing the second moment\nterm's memory footprint from $O(d)$ to $O(\\sqrt{d})$ through step-size sharing,\nwhere $d$ is the model size. For non-convex smooth objectives under\ncoordinate-wise sub-gaussian gradient noise, we prove a noise-adapted\nhigh-probability convergence guarantee showing improved dimensional dependence\nover existing methods. Our second technique, Subspace-Momentum, reduces the\nmomentum state's memory footprint by operating in a low-dimensional subspace\nwhile applying standard SGD in the orthogonal complement. We establish\nhigh-probability convergence rates under similar relaxed assumptions. Empirical\nevaluation on LLaMA models from 60M to 1B parameters demonstrates the\neffectiveness of our methods, where combining subset-norm with\nsubspace-momentum achieves Adam's validation perplexity in approximately half\nthe training tokens (6.8B vs 13.1B) while using only 20% of the Adam's\noptimizer-states memory footprint and requiring minimal additional\nhyperparameter tuning."
    },
    {
      "id": "2411.07118v1",
      "title": "ConvMixFormer- A Resource-efficient Convolution Mixer for Transformer-based Dynamic Hand Gesture Recognition",
      "summary": "Transformer models have demonstrated remarkable success in many domains such\nas natural language processing (NLP) and computer vision. With the growing\ninterest in transformer-based architectures, they are now utilized for gesture\nrecognition. So, we also explore and devise a novel ConvMixFormer architecture\nfor dynamic hand gestures. The transformers use quadratic scaling of the\nattention features with the sequential data, due to which these models are\ncomputationally complex and heavy. We have considered this drawback of the\ntransformer and designed a resource-efficient model that replaces the\nself-attention in the transformer with the simple convolutional layer-based\ntoken mixer. The computational cost and the parameters used for the\nconvolution-based mixer are comparatively less than the quadratic\nself-attention. Convolution-mixer helps the model capture the local spatial\nfeatures that self-attention struggles to capture due to their sequential\nprocessing nature. Further, an efficient gate mechanism is employed instead of\na conventional feed-forward network in the transformer to help the model\ncontrol the flow of features within different stages of the proposed model.\nThis design uses fewer learnable parameters which is nearly half the vanilla\ntransformer that helps in fast and efficient training. The proposed method is\nevaluated on NVidia Dynamic Hand Gesture and Briareo datasets and our model has\nachieved state-of-the-art results on single and multimodal inputs. We have also\nshown the parameter efficiency of the proposed ConvMixFormer model compared to\nother methods. The source code is available at\nhttps://github.com/mallikagarg/ConvMixFormer."
    },
    {
      "id": "2411.07114v1",
      "title": "TinyML Security: Exploring Vulnerabilities in Resource-Constrained Machine Learning Systems",
      "summary": "Tiny Machine Learning (TinyML) systems, which enable machine learning\ninference on highly resource-constrained devices, are transforming edge\ncomputing but encounter unique security challenges. These devices, restricted\nby RAM and CPU capabilities two to three orders of magnitude smaller than\nconventional systems, make traditional software and hardware security solutions\nimpractical. The physical accessibility of these devices exacerbates their\nsusceptibility to side-channel attacks and information leakage. Additionally,\nTinyML models pose security risks, with weights potentially encoding sensitive\ndata and query interfaces that can be exploited. This paper offers the first\nthorough survey of TinyML security threats. We present a device taxonomy that\ndifferentiates between IoT, EdgeML, and TinyML, highlighting vulnerabilities\nunique to TinyML. We list various attack vectors, assess their threat levels\nusing the Common Vulnerability Scoring System, and evaluate both existing and\npossible defenses. Our analysis identifies where traditional security measures\nare adequate and where solutions tailored to TinyML are essential. Our results\nunderscore the pressing need for specialized security solutions in TinyML to\nensure robust and secure edge computing applications. We aim to inform the\nresearch community and inspire innovative approaches to protecting this rapidly\nevolving and critical field."
    },
    {
      "id": "2411.07111v1",
      "title": "Building a Taiwanese Mandarin Spoken Language Model: A First Attempt",
      "summary": "This technical report presents our initial attempt to build a spoken large\nlanguage model (LLM) for Taiwanese Mandarin, specifically tailored to enable\nreal-time, speech-to-speech interaction in multi-turn conversations. Our\nend-to-end model incorporates a decoder-only transformer architecture and aims\nto achieve seamless interaction while preserving the conversational flow,\nincluding full-duplex capabilities allowing simultaneous speaking and\nlistening. The paper also details the training process, including data\npreparation with synthesized dialogues and adjustments for real-time\ninteraction. We also developed a platform to evaluate conversational fluency\nand response coherence in multi-turn dialogues. We hope the release of the\nreport can contribute to the future development of spoken LLMs in Taiwanese\nMandarin."
    },
    {
      "id": "2411.07107v1",
      "title": "Training Neural Networks as Recognizers of Formal Languages",
      "summary": "Characterizing the computational power of neural network architectures in\nterms of formal language theory remains a crucial line of research, as it\ndescribes lower and upper bounds on the reasoning capabilities of modern AI.\nHowever, when empirically testing these bounds, existing work often leaves a\ndiscrepancy between experiments and the formal claims they are meant to\nsupport. The problem is that formal language theory pertains specifically to\nrecognizers: machines that receive a string as input and classify whether it\nbelongs to a language. On the other hand, it is common to instead use proxy\ntasks that are similar in only an informal sense, such as language modeling or\nsequence-to-sequence transduction. We correct this mismatch by training and\nevaluating neural networks directly as binary classifiers of strings, using a\ngeneral method that can be applied to a wide variety of languages. As part of\nthis, we extend an algorithm recently proposed by Sn{\\ae}bjarnarson et al.\n(2024) to do length-controlled sampling of strings from regular languages, with\nmuch better asymptotic time complexity than previous methods. We provide\nresults on a variety of languages across the Chomsky hierarchy for three neural\narchitectures: a simple RNN, an LSTM, and a causally-masked transformer. We\nfind that the RNN and LSTM often outperform the transformer, and that auxiliary\ntraining objectives such as language modeling can help, although no single\nobjective uniformly improves performance across languages and architectures.\nOur contributions will facilitate theoretically sound empirical testing of\nlanguage recognition claims in future work. We have released our datasets as a\nbenchmark called FLaRe (Formal Language Recognition), along with our code."
    },
    {
      "id": "2411.07104v2",
      "title": "Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal Pushing",
      "summary": "Recently, quadrupedal locomotion has achieved significant success, but their\nmanipulation capabilities, particularly in handling large objects, remain\nlimited, restricting their usefulness in demanding real-world applications such\nas search and rescue, construction, industrial automation, and room\norganization. This paper tackles the task of obstacle-aware, long-horizon\npushing by multiple quadrupedal robots. We propose a hierarchical multi-agent\nreinforcement learning framework with three levels of control. The high-level\ncontroller integrates an RRT planner and a centralized adaptive policy to\ngenerate subgoals, while the mid-level controller uses a decentralized\ngoal-conditioned policy to guide the robots toward these sub-goals. A\npre-trained low-level locomotion policy executes the movement commands. We\nevaluate our method against several baselines in simulation, demonstrating\nsignificant improvements over baseline approaches, with 36.0% higher success\nrates and 24.5% reduction in completion time than the best baseline. Our\nframework successfully enables long-horizon, obstacle-aware manipulation tasks\nlike Push-Cuboid and Push-T on Go1 robots in the real world."
    },
    {
      "id": "2411.07102v1",
      "title": "Effectively Leveraging Momentum Terms in Stochastic Line Search Frameworks for Fast Optimization of Finite-Sum Problems",
      "summary": "In this work, we address unconstrained finite-sum optimization problems, with\nparticular focus on instances originating in large scale deep learning\nscenarios. Our main interest lies in the exploration of the relationship\nbetween recent line search approaches for stochastic optimization in the\noverparametrized regime and momentum directions. First, we point out that\ncombining these two elements with computational benefits is not\nstraightforward. To this aim, we propose a solution based on mini-batch\npersistency. We then introduce an algorithmic framework that exploits a mix of\ndata persistency, conjugate-gradient type rules for the definition of the\nmomentum parameter and stochastic line searches. The resulting algorithm is\nempirically shown to outperform other popular methods from the literature,\nobtaining state-of-the-art results in both convex and nonconvex large scale\ntraining problems."
    },
    {
      "id": "2411.07099v1",
      "title": "Bounded Rationality Equilibrium Learning in Mean Field Games",
      "summary": "Mean field games (MFGs) tractably model behavior in large agent populations.\nThe literature on learning MFG equilibria typically focuses on finding Nash\nequilibria (NE), which assume perfectly rational agents and are hence\nimplausible in many realistic situations. To overcome these limitations, we\nincorporate bounded rationality into MFGs by leveraging the well-known concept\nof quantal response equilibria (QRE). Two novel types of MFG QRE enable the\nmodeling of large agent populations where individuals only noisily estimate the\ntrue objective. We also introduce a second source of bounded rationality to\nMFGs by restricting agents' planning horizon. The resulting novel receding\nhorizon (RH) MFGs are combined with QRE and existing approaches to model\ndifferent aspects of bounded rationality in MFGs. We formally define MFG QRE\nand RH MFGs and compare them to existing equilibrium concepts such as\nentropy-regularized NE. Subsequently, we design generalized fixed point\niteration and fictitious play algorithms to learn QRE and RH equilibria. After\na theoretical analysis, we give different examples to evaluate the capabilities\nof our learning algorithms and outline practical differences between the\nequilibrium concepts."
    },
    {
      "id": "2411.07098v1",
      "title": "A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs",
      "summary": "As modern web services increasingly rely on REST APIs, their thorough testing\nhas become crucial. Furthermore, the advent of REST API specifications such as\nthe OpenAPI Specification has led to the emergence of many black-box REST API\ntesting tools. However, these tools often focus on individual test elements in\nisolation (e.g., APIs, parameters, values), resulting in lower coverage and\nless effectiveness in detecting faults (i.e., 500 response codes). To address\nthese limitations, we present AutoRestTest, the first black-box framework to\nadopt a dependency-embedded multi-agent approach for REST API testing,\nintegrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property\nDependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats\nREST API testing as a separable problem, where four agents -- API, dependency,\nparameter, and value -- collaborate to optimize API exploration. LLMs handle\ndomain-specific value restrictions, the SPDG model simplifies the search space\nfor dependencies using a similarity score between API operations, and MARL\ndynamically optimizes the agents' behavior. Evaluated on 12 real-world REST\nservices, AutoRestTest outperforms the four leading black-box REST API testing\ntools, including those assisted by RESTGPT (which augments realistic test\ninputs using LLMs), in terms of code coverage, operation coverage, and fault\ndetection. Notably, AutoRestTest is the only tool able to identify an internal\nserver error in Spotify. Our ablation study underscores the significant\ncontributions of the agent learning, SPDG, and LLM components."
    },
    {
      "id": "2411.07094v1",
      "title": "Differentially-Private Collaborative Online Personalized Mean Estimation",
      "summary": "We consider the problem of collaborative personalized mean estimation under a\nprivacy constraint in an environment of several agents continuously receiving\ndata according to arbitrary unknown agent-specific distributions. In\nparticular, we provide a method based on hypothesis testing coupled with\ndifferential privacy and data variance estimation. Two privacy mechanisms and\ntwo data variance estimation schemes are proposed, and we provide a theoretical\nconvergence analysis of the proposed algorithm for any bounded unknown\ndistributions on the agents' data, showing that collaboration provides faster\nconvergence than a fully local approach where agents do not share data.\nMoreover, we provide analytical performance curves for the case with an oracle\nclass estimator, i.e., the class structure of the agents, where agents\nreceiving data from distributions with the same mean are considered to be in\nthe same class, is known. The theoretical faster-than-local convergence\nguarantee is backed up by extensive numerical results showing that for a\nconsidered scenario the proposed approach indeed converges much faster than a\nfully local approach, and performs comparably to ideal performance where all\ndata is public. This illustrates the benefit of private collaboration in an\nonline setting."
    },
    {
      "id": "2411.07089v1",
      "title": "Towards Characterizing Cyber Networks with Large Language Models",
      "summary": "Threat hunting analyzes large, noisy, high-dimensional data to find sparse\nadversarial behavior. We believe adversarial activities, however they are\ndisguised, are extremely difficult to completely obscure in high dimensional\nspace. In this paper, we employ these latent features of cyber data to find\nanomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEM\nwas trained on Zeek network traffic logs from both a real-world production\nnetwork and an from Internet of Things (IoT) cybersecurity testbed. The model\nis deliberately overtrained on a sliding window of data to characterize each\nwindow closely. We use the Adjusted Rand Index (ARI) to comparing the k-means\nclustering of CLEM output to expert labeling of the embeddings. Our approach\ndemonstrates that there is promise in using natural language modeling to\nunderstand cyber data."
    },
    {
      "id": "2411.07087v2",
      "title": "OCMDP: Observation-Constrained Markov Decision Process",
      "summary": "In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency."
    },
    {
      "id": "2411.07086v1",
      "title": "To Train or Not to Train: Balancing Efficiency and Training Cost in Deep Reinforcement Learning for Mobile Edge Computing",
      "summary": "Artificial Intelligence (AI) is a key component of 6G networks, as it enables\ncommunication and computing services to adapt to end users' requirements and\ndemand patterns. The management of Mobile Edge Computing (MEC) is a meaningful\nexample of AI application: computational resources available at the network\nedge need to be carefully allocated to users, whose jobs may have different\npriorities and latency requirements. The research community has developed\nseveral AI algorithms to perform this resource allocation, but it has neglected\na key aspect: learning is itself a computationally demanding task, and\nconsidering free training results in idealized conditions and performance in\nsimulations. In this work, we consider a more realistic case in which the cost\nof learning is specifically accounted for, presenting a new algorithm to\ndynamically select when to train a Deep Reinforcement Learning (DRL) agent that\nallocates resources. Our method is highly general, as it can be directly\napplied to any scenario involving a training overhead, and it can approach the\nsame performance as an ideal learning agent even under realistic training\nconditions."
    },
    {
      "id": "2411.07076v1",
      "title": "StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification",
      "summary": "Existing large vision-language models (LVLMs) are largely limited to\nprocessing short, seconds-long videos and struggle with generating coherent\ndescriptions for extended video spanning minutes or more. Long video\ndescription introduces new challenges, such as plot-level consistency across\ndescriptions. To address these, we figure out audio-visual character\nidentification, matching character names to each dialogue, as a key factor. We\npropose StoryTeller, a system for generating dense descriptions of long videos,\nincorporating both low-level visual concepts and high-level plot information.\nStoryTeller uses a multimodal large language model that integrates visual,\naudio, and text modalities to perform audio-visual character identification on\nminute-long video clips. The results are then fed into a LVLM to enhance\nconsistency of video description. We validate our approach on movie description\ntasks and introduce MovieStory101, a dataset with dense descriptions for\nthree-minute movie clips. To evaluate long video descriptions, we create\nMovieQA, a large set of multiple-choice questions for the MovieStory101 test\nset. We assess descriptions by inputting them into GPT-4 to answer these\nquestions, using accuracy as an automatic evaluation metric. Experiments show\nthat StoryTeller outperforms all open and closed-source baselines on MovieQA,\nachieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and\ndemonstrating a +15.56% advantage in human side-by-side evaluations.\nAdditionally, incorporating audio-visual character identification from\nStoryTeller improves the performance of all video description models, with\nGemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,\nrespectively, in accuracy on MovieQA."
    },
    {
      "id": "2411.07075v1",
      "title": "Transformer verbatim in-context retrieval across time and scale",
      "summary": "To predict upcoming text, language models must in some cases retrieve\nin-context information verbatim. In this report, we investigated how the\nability of language models to retrieve arbitrary in-context nouns developed\nduring training (across time) and as language models trained on the same\ndataset increase in size (across scale). We then asked whether learning of\nin-context retrieval correlates with learning of more challenging zero-shot\nbenchmarks. Furthermore, inspired by semantic effects in human short-term\nmemory, we evaluated the retrieval with respect to a major semantic component\nof target nouns, namely whether they denote a concrete or abstract entity, as\nrated by humans. We show that verbatim in-context retrieval developed in a\nsudden transition early in the training process, after about 1% of the training\ntokens. This was observed across model sizes (from 14M and up to 12B\nparameters), and the transition occurred slightly later for the two smallest\nmodels. We further found that the development of verbatim in-context retrieval\nis positively correlated with the learning of zero-shot benchmarks. Around the\ntransition point, all models showed the advantage of retrieving concrete nouns\nas opposed to abstract nouns. In all but two smallest models, the advantage\ndissipated away toward the end of training."
    },
    {
      "id": "2411.07072v1",
      "title": "An Interpretable X-ray Style Transfer via Trainable Local Laplacian Filter",
      "summary": "Radiologists have preferred visual impressions or 'styles' of X-ray images\nthat are manually adjusted to their needs to support their diagnostic\nperformance. In this work, we propose an automatic and interpretable X-ray\nstyle transfer by introducing a trainable version of the Local Laplacian Filter\n(LLF). From the shape of the LLF's optimized remap function, the\ncharacteristics of the style transfer can be inferred and reliability of the\nalgorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray\nstyle features by replacing the remap function with a Multi-Layer Perceptron\n(MLP) and adding a trainable normalization layer. We demonstrate the\neffectiveness of the proposed method by transforming unprocessed mammographic\nX-ray images into images that match the style of target mammograms and achieve\na Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline\nLLF style transfer method from Aubry et al."
    },
    {
      "id": "2411.07071v1",
      "title": "Universal Response and Emergence of Induction in LLMs",
      "summary": "While induction is considered a key mechanism for in-context learning in\nLLMs, understanding its precise circuit decomposition beyond toy models remains\nelusive. Here, we study the emergence of induction behavior within LLMs by\nprobing their response to weak single-token perturbations of the residual\nstream. We find that LLMs exhibit a robust, universal regime in which their\nresponse remains scale-invariant under changes in perturbation strength,\nthereby allowing us to quantify the build-up of token correlations throughout\nthe model. By applying our method, we observe signatures of induction behavior\nwithin the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across\nall models, we find that these induction signatures gradually emerge within\nintermediate layers and identify the relevant model sections composing this\nbehavior. Our results provide insights into the collective interplay of\ncomponents within LLMs and serve as a benchmark for large-scale circuit\nanalysis."
    },
    {
      "id": "2411.07070v2",
      "title": "On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models",
      "summary": "The pretraining and fine-tuning approach has become the leading technique for\nvarious NLP applications. However, recent studies reveal that fine-tuning data,\ndue to their sensitive nature, domain-specific characteristics, and\nidentifiability, pose significant privacy concerns. To help develop more\nprivacy-resilient fine-tuning models, we introduce a novel active privacy\nauditing framework, dubbed Parsing, designed to identify and quantify privacy\nleakage risks during the supervised fine-tuning (SFT) of language models (LMs).\nThe framework leverages improved white-box membership inference attacks (MIAs)\nas the core technology, utilizing novel learning objectives and a two-stage\npipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the\nexposure of privacy risks. Additionally, we have improved the effectiveness of\nMIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our\nresearch aims to provide the SFT community of LMs with a reliable, ready-to-use\nprivacy auditing tool, and to offer valuable insights into safeguarding privacy\nduring the fine-tuning process. Experimental results confirm the framework's\nefficiency across various models and tasks, emphasizing notable privacy\nconcerns in the fine-tuning process. Project code available for\nhttps://anonymous.4open.science/r/PARSING-4817/."
    },
    {
      "id": "2411.07276v1",
      "title": "Empirical Quantum Advantage Analysis of Quantum Kernel in Gene Expression Data",
      "summary": "The incorporation of quantum ansatz with machine learning classification\nmodels demonstrates the ability to extract patterns from data for\nclassification tasks. However, taking advantage of the enhanced computational\npower of quantum machine learning necessitates dealing with various\nconstraints. In this paper, we focus on constraints like finding suitable\ndatasets where quantum advantage is achievable and evaluating the relevance of\nfeatures chosen by classical and quantum methods. Additionally, we compare\nquantum and classical approaches using benchmarks and estimate the\ncomputational complexity of quantum circuits to assess real-world usability.\nFor our experimental validation, we selected the gene expression dataset, given\nthe critical role of genetic variations in regulating physiological behavior\nand disease susceptibility. Through this study, we aim to contribute to the\nadvancement of quantum machine learning methodologies, offering valuable\ninsights into their potential for addressing complex classification challenges\nin various domains."
    },
    {
      "id": "2411.07066v1",
      "title": "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training",
      "summary": "Network pruning is a set of computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has focused on pruning and re-training, which\nnowadays is inconvenient due to the vast amount of pre-trained models, which\nare in any case too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAl}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs, that\nmodifies the block-wise and row-wise sparsity ratios to maximize the\n\\emph{neuron alignment} among activations. Moreover, differently from existing\nmethods, our approach adaptively selects the best parameters for the block-wise\nand row-wise sparsity ratios w.r.t. to the model and the desired sparsity\n(given as input), and requires \\emph{no re-training}. We test our method on 4\ndifferent LLM families and 3 different sparsity ratios, showing how it\nconsistently outperforms the latest state-of-the-art techniques. The code is\navailable at https://github.com/eliacunegatti/NeuroAL."
    },
    {
      "id": "2411.07061v1",
      "title": "General framework for online-to-nonconvex conversion: Schedule-free SGD is also effective for nonconvex optimization",
      "summary": "This work investigates the effectiveness of schedule-free methods, developed\nby A. Defazio et al. (NeurIPS 2024), in nonconvex optimization settings,\ninspired by their remarkable empirical success in training neural networks.\nSpecifically, we show that schedule-free SGD achieves optimal iteration\ncomplexity for nonsmooth, nonconvex optimization problems. Our proof begins\nwith the development of a general framework for online-to-nonconvex conversion,\nwhich converts a given online learning algorithm into an optimization algorithm\nfor nonconvex losses. Our general framework not only recovers existing\nconversions but also leads to two novel conversion schemes. Notably, one of\nthese new conversions corresponds directly to schedule-free SGD, allowing us to\nestablish its optimality. Additionally, our analysis provides valuable insights\ninto the parameter choices for schedule-free SGD, addressing a theoretical gap\nthat the convex theory cannot explain."
    },
    {
      "id": "2411.07055v1",
      "title": "Reconstruction of neuromorphic dynamics from a single scalar time series using variational autoencoder and neural network map",
      "summary": "This paper examines the reconstruction of a family of dynamical systems with\nneuromorphic behavior using a single scalar time series. A model of a\nphysiological neuron based on the Hodgkin-Huxley formalism is considered.\nSingle time series of one of its variables is shown to be enough to train a\nneural network that can operate as a discrete time dynamical system with one\ncontrol parameter. The neural network system is created in two steps. First,\nthe delay-coordinate embedding vectors are constructed form the original time\nseries and their dimension is reduced with by means of a variational\nautoencoder to obtain the recovered state-space vectors. It is shown that an\nappropriate reduced dimension can be determined by analyzing the autoencoder\ntraining process. Second, pairs of the recovered state-space vectors at\nconsecutive time steps supplied with a constant value playing the role of a\ncontrol parameter are used to train another neural network to make it operate\nas a recurrent map. The regimes of thus created neural network system observed\nwhen its control parameter is varied are in very good accordance with those of\nthe original system, though they were not explicitly presented during training."
    },
    {
      "id": "2411.08069v1",
      "title": "Intelligent Green Efficiency for Intrusion Detection",
      "summary": "Artificial Intelligence (AI) has emerged in popularity recently, recording\ngreat progress in various industries. However, the environmental impact of AI\nis a growing concern, in terms of the energy consumption and carbon footprint\nof Machine Learning (ML) and Deep Learning (DL) models, making essential\ninvestigate Green AI, an attempt to reduce the climate impact of AI systems.\nThis paper presents an assessment of different programming languages and\nFeature Selection (FS) methods to improve computation performance of AI\nfocusing on Network Intrusion Detection (NID) and cyber-attack classification\ntasks. Experiments were conducted using five ML models - Random Forest,\nXGBoost, LightGBM, Multi-Layer Perceptron, and Long Short-Term Memory -\nimplemented in four programming languages - Python, Java, R, and Rust - along\nwith three FS methods - Information Gain, Recursive Feature Elimination, and\nChi-Square. The obtained results demonstrated that FS plays an important role\nenhancing the computational efficiency of AI models without compromising\ndetection accuracy, highlighting languages like Python and R, that benefit from\na rich AI libraries environment. These conclusions can be useful to design\nefficient and sustainable AI systems that still provide a good generalization\nand a reliable detection."
    },
    {
      "id": "2411.07043v1",
      "title": "Unified Bayesian representation for high-dimensional multi-modal biomedical data for small-sample classification",
      "summary": "We present BALDUR, a novel Bayesian algorithm designed to deal with\nmulti-modal datasets and small sample sizes in high-dimensional settings while\nproviding explainable solutions. To do so, the proposed model combines within a\ncommon latent space the different data views to extract the relevant\ninformation to solve the classification task and prune out the\nirrelevant/redundant features/data views. Furthermore, to provide generalizable\nsolutions in small sample size scenarios, BALDUR efficiently integrates dual\nkernels over the views with a small sample-to-feature ratio. Finally, its\nlinear nature ensures the explainability of the model outcomes, allowing its\nuse for biomarker identification. This model was tested over two different\nneurodegeneration datasets, outperforming the state-of-the-art models and\ndetecting features aligned with markers already described in the scientific\nliterature."
    },
    {
      "id": "2411.07042v1",
      "title": "Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications",
      "summary": "AI companions based on large language models can role-play and converse very\nnaturally. When value conflicts arise between the AI companion and the user, it\nmay offend or upset the user. Yet, little research has examined such conflicts.\nWe first conducted a formative study that analyzed 151 user complaints about\nconflicts with AI companions, providing design implications for our study.\nBased on these, we created Minion, a technology probe to help users resolve\nhuman-AI value conflicts. Minion applies a user-empowerment intervention method\nthat provides suggestions by combining expert-driven and user-driven conflict\nresolution strategies. We conducted a technology probe study, creating 40 value\nconflict scenarios on Character.AI and Talkie. 22 participants completed 274\ntasks and successfully resolved conflicts 94.16% of the time. We summarize user\nresponses, preferences, and needs in resolving value conflicts, and propose\ndesign implications to reduce conflicts and empower users to resolve them more\neffectively."
    },
    {
      "id": "2411.07038v1",
      "title": "Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind",
      "summary": "In social sciences, researchers often face challenges when conducting\nlarge-scale experiments, particularly due to the simulations' complexity and\nthe lack of technical expertise required to develop such frameworks.\nAgent-Based Modeling (ABM) is a computational approach that simulates agents'\nactions and interactions to evaluate how their behaviors influence the\noutcomes. However, the traditional implementation of ABM can be demanding and\ncomplex. Generative Agent-Based Modeling (GABM) offers a solution by enabling\nscholars to create simulations where AI-driven agents can generate complex\nbehaviors based on underlying rules and interactions. This paper introduces a\nframework for designing reliable experiments using GABM, making sophisticated\nsimulation techniques more accessible to researchers across various fields. We\nprovide a step-by-step guide for selecting appropriate tools, designing the\nmodel, establishing experimentation protocols, and validating results."
    },
    {
      "id": "2411.07037v1",
      "title": "LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios",
      "summary": "As Large Language Models (LLMs) continue to advance in natural language\nprocessing (NLP), their ability to stably follow instructions in long-context\ninputs has become crucial for real-world applications. While existing\nbenchmarks assess various LLM capabilities, they rarely focus on\ninstruction-following in long-context scenarios or stability on different\ninputs. In response, we introduce the Long-context Instruction-Following\nBenchmark (LIFBench), a scalable dataset designed to evaluate LLMs'\ninstruction-following capabilities and stability across long contexts. LIFBench\ncomprises three long-context scenarios and eleven diverse tasks, supported by\n2,766 instructions generated through an automated expansion method across three\ndimensions: length, expression, and variables. For evaluation, we propose\nLIFEval, a rubric-based assessment framework that provides precise, automated\nscoring of complex LLM responses without relying on LLM-assisted evaluations or\nhuman judgments. This approach facilitates a comprehensive analysis of model\nperformance and stability across various perspectives. We conduct extensive\nexperiments on 20 notable LLMs across six length intervals, analyzing their\ninstruction-following capabilities and stability. Our work contributes LIFBench\nand LIFEval as robust tools for assessing LLM performance in complex,\nlong-context settings, providing insights that can inform future LLM\ndevelopment."
    },
    {
      "id": "2411.07031v1",
      "title": "Evaluating the Accuracy of Chatbots in Financial Literature",
      "summary": "We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields."
    },
    {
      "id": "2411.07022v1",
      "title": "HeteroSample: Meta-path Guided Sampling for Heterogeneous Graph Representation Learning",
      "summary": "The rapid expansion of Internet of Things (IoT) has resulted in vast,\nheterogeneous graphs that capture complex interactions among devices, sensors,\nand systems. Efficient analysis of these graphs is critical for deriving\ninsights in IoT scenarios such as smart cities, industrial IoT, and intelligent\ntransportation systems. However, the scale and diversity of IoT-generated data\npresent significant challenges, and existing methods often struggle with\npreserving the structural integrity and semantic richness of these complex\ngraphs. Many current approaches fail to maintain the balance between\ncomputational efficiency and the quality of the insights generated, leading to\npotential loss of critical information necessary for accurate decision-making\nin IoT applications. We introduce HeteroSample, a novel sampling method\ndesigned to address these challenges by preserving the structural integrity,\nnode and edge type distributions, and semantic patterns of IoT-related graphs.\nHeteroSample works by incorporating the novel top-leader selection, balanced\nneighborhood expansion, and meta-path guided sampling strategies. The key idea\nis to leverage the inherent heterogeneous structure and semantic relationships\nencoded by meta-paths to guide the sampling process. This approach ensures that\nthe resulting subgraphs are representative of the original data while\nsignificantly reducing computational overhead. Extensive experiments\ndemonstrate that HeteroSample outperforms state-of-the-art methods, achieving\nup to 15% higher F1 scores in tasks such as link prediction and node\nclassification, while reducing runtime by 20%.These advantages make\nHeteroSample a transformative tool for scalable and accurate IoT applications,\nenabling more effective and efficient analysis of complex IoT systems,\nultimately driving advancements in smart cities, industrial IoT, and beyond."
    },
    {
      "id": "2411.07019v1",
      "title": "UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction",
      "summary": "Beyond-triple fact representations including hyper-relational facts with\nauxiliary key-value pairs, temporal facts with additional timestamps, and\nnested facts implying relationships between facts, are gaining significant\nattention. However, existing link prediction models are usually designed for\none specific type of facts, making it difficult to generalize to other fact\nrepresentations. To overcome this limitation, we propose a Unified Hierarchical\nRepresentation learning framework (UniHR) for unified knowledge graph link\nprediction. It consists of a unified Hierarchical Data Representation (HiDR)\nmodule and a unified Hierarchical Structure Learning (HiSL) module as graph\nencoder. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested\nfactual KGs into triple-based representations. Then HiSL incorporates\nintra-fact and inter-fact message passing, focusing on enhancing the semantic\ninformation within individual facts and enriching the structural information\nbetween facts. Experimental results across 7 datasets from 3 types of KGs\ndemonstrate that our UniHR outperforms baselines designed for one specific kind\nof KG, indicating strong generalization capability of HiDR form and the\neffectiveness of HiSL module. Code and data are available at\nhttps://github.com/Lza12a/UniHR."
    },
    {
      "id": "2411.07018v1",
      "title": "Data-Driven Gradient Optimization for Field Emission Management in a Superconducting Radio-Frequency Linac",
      "summary": "Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings."
    },
    {
      "id": "2411.07015v1",
      "title": "Leveraging LSTM for Predictive Modeling of Satellite Clock Bias",
      "summary": "Satellite clock bias prediction plays a crucial role in enhancing the\naccuracy of satellite navigation systems. In this paper, we propose an approach\nutilizing Long Short-Term Memory (LSTM) networks to predict satellite clock\nbias. We gather data from the PRN 8 satellite of the Galileo and preprocess it\nto obtain a single difference sequence, crucial for normalizing the data.\nNormalization allows resampling of the data, ensuring that the predictions are\nequidistant and complete. Our methodology involves training the LSTM model on\nvarying lengths of datasets, ranging from 7 days to 31 days. We employ a\ntraining set consisting of two days' worth of data in each case. Our LSTM model\nexhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11\n$\\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used\nfor similar time-series forecasting projects, being 170 times more accurate\nthan RNN, 2.3 $\\times$ 10$^7$ times more accurate than MLP, and 1.9 $\\times$\n10$^4$ times more accurate than ARIMA. This study holds significant potential\nin enhancing the accuracy and efficiency of low-power receivers used in various\ndevices, particularly those requiring power conservation. By providing more\naccurate predictions of satellite clock bias, the findings of this research can\nbe integrated into the algorithms of such devices, enabling them to function\nwith heightened precision while conserving power. Improved accuracy in clock\nbias predictions ensures that low-power receivers can maintain optimal\nperformance levels, thereby enhancing the overall reliability and effectiveness\nof satellite navigation systems. Consequently, this advancement holds promise\nfor a wide range of applications, including remote areas, IoT devices, wearable\ntechnology, and other devices where power efficiency and navigation accuracy\nare paramount."
    },
    {
      "id": "2411.07013v1",
      "title": "A neural-network based anomaly detection system and a safety protocol to protect vehicular network",
      "summary": "This thesis addresses the use of Cooperative Intelligent Transport Systems\n(CITS) to improve road safety and efficiency by enabling vehicle-to-vehicle\ncommunication, highlighting the importance of secure and accurate data\nexchange. To ensure safety, the thesis proposes a Machine Learning-based\nMisbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networks\nto detect and mitigate incorrect or misleading messages within vehicular\nnetworks. Trained offline on the VeReMi dataset, the detection model is tested\nin real-time within a platooning scenario, demonstrating that it can prevent\nnearly all accidents caused by misbehavior by triggering a defense protocol\nthat dissolves the platoon if anomalies are detected. The results show that\nwhile the system can accurately detect general misbehavior, it struggles to\nlabel specific types due to varying traffic conditions, implying the difficulty\nof creating a universally adaptive protocol. However, the thesis suggests that\nwith more data and further refinement, this MDS could be implemented in\nreal-world CITS, enhancing driving safety by mitigating risks from misbehavior\nin cooperative driving networks."
    },
    {
      "id": "2411.07009v1",
      "title": "Hierarchical Conditional Tabular GAN for Multi-Tabular Synthetic Data Generation",
      "summary": "The generation of synthetic data is a state-of-the-art approach to leverage\nwhen access to real data is limited or privacy regulations limit the usability\nof sensitive data. A fair amount of research has been conducted on synthetic\ndata generation for single-tabular datasets, but only a limited amount of\nresearch has been conducted on multi-tabular datasets with complex table\nrelationships. In this paper we propose the algorithm HCTGAN to synthesize\nmulti-tabular data from complex multi-tabular datasets. We compare our results\nto the probabilistic model HMA1. Our findings show that our proposed algorithm\ncan more efficiently sample large amounts of synthetic data for deep and\ncomplex multi-tabular datasets, whilst achieving adequate data quality and\nalways guaranteeing referential integrity. We conclude that the HCTGAN\nalgorithm is suitable for generating large amounts of synthetic data\nefficiently for deep multi-tabular datasets with complex relationships. We\nadditionally suggest that the HMA1 model should be used on smaller datasets\nwhen emphasis is on data quality."
    },
    {
      "id": "2411.07008v1",
      "title": "Permutative redundancy and uncertainty of the objective in deep learning",
      "summary": "Implications of uncertain objective functions and permutative symmetry of\ntraditional deep learning architectures are discussed. It is shown that\ntraditional architectures are polluted by an astronomical number of equivalent\nglobal and local optima. Uncertainty of the objective makes local optima\nunattainable, and, as the size of the network grows, the global optimization\nlandscape likely becomes a tangled web of valleys and ridges. Some remedies\nwhich reduce or eliminate ghost optima are discussed including forced\npre-pruning, re-ordering, ortho-polynomial activations, and modular\nbio-inspired architectures."
    },
    {
      "id": "2411.07007v1",
      "title": "Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching",
      "summary": "In inverse reinforcement learning (IRL), an agent seeks to replicate expert\ndemonstrations through interactions with the environment. Traditionally, IRL is\ntreated as an adversarial game, where an adversary searches over reward models,\nand a learner optimizes the reward through repeated RL procedures. This\ngame-solving approach is both computationally expensive and difficult to\nstabilize. In this work, we propose a novel approach to IRL by direct policy\noptimization: exploiting a linear factorization of the return as the inner\nproduct of successor features and a reward vector, we design an IRL algorithm\nby policy gradient descent on the gap between the learner and expert features.\nOur non-adversarial method does not require learning a reward function and can\nbe solved seamlessly with existing actor-critic RL algorithms. Remarkably, our\napproach works in state-only settings without expert action labels, a setting\nwhich behavior cloning (BC) cannot solve. Empirical results demonstrate that\nour method learns from as few as a single expert demonstration and achieves\nimproved performance on various control tasks."
    },
    {
      "id": "2411.07006v1",
      "title": "Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs",
      "summary": "Lifting uses a representative of indistinguishable individuals to exploit\nsymmetries in probabilistic relational models, denoted as parametric factor\ngraphs, to speed up inference while maintaining exact answers. In this paper,\nwe show how lifting can be applied to causal inference in partially directed\ngraphs, i.e., graphs that contain both directed and undirected edges to\nrepresent causal relationships between random variables. We present partially\ndirected parametric causal factor graphs (PPCFGs) as a generalisation of\npreviously introduced parametric causal factor graphs, which require a fully\ndirected graph. We further show how causal inference can be performed on a\nlifted level in PPCFGs, thereby extending the applicability of lifted causal\ninference to a broader range of models requiring less prior knowledge about\ncausal relationships."
    },
    {
      "id": "2411.07003v1",
      "title": "Enhancing Robot Assistive Behaviour with Reinforcement Learning and Theory of Mind",
      "summary": "The adaptation to users' preferences and the ability to infer and interpret\nhumans' beliefs and intents, which is known as the Theory of Mind (ToM), are\ntwo crucial aspects for achieving effective human-robot collaboration. Despite\nits importance, very few studies have investigated the impact of adaptive\nrobots with ToM abilities. In this work, we present an exploratory comparative\nstudy to investigate how social robots equipped with ToM abilities impact\nusers' performance and perception. We design a two-layer architecture. The\nQ-learning agent on the first layer learns the robot's higher-level behaviour.\nOn the second layer, a heuristic-based ToM infers the user's intended strategy\nand is responsible for implementing the robot's assistance, as well as\nproviding the motivation behind its choice. We conducted a user study in a\nreal-world setting, involving 56 participants who interacted with either an\nadaptive robot capable of ToM, or with a robot lacking such abilities. Our\nfindings suggest that participants in the ToM condition performed better,\naccepted the robot's assistance more often, and perceived its ability to adapt,\npredict and recognise their intents to a higher degree. Our preliminary\ninsights could inform future research and pave the way for designing more\ncomplex computation architectures for adaptive behaviour with ToM capabilities."
    },
    {
      "id": "2411.06995v1",
      "title": "Which PPML Would a User Choose? A Structured Decision Support Framework for Developers to Rank PPML Techniques Based on User Acceptance Criteria",
      "summary": "Using Privacy-Enhancing Technologies (PETs) for machine learning often\ninfluences the characteristics of a machine learning approach, e.g., the needed\ncomputational power, timing of the answers or how the data can be utilized.\nWhen designing a new service, the developer faces the problem that some\ndecisions require a trade-off. For example, the use of a PET may cause a delay\nin the responses or adding noise to the data to improve the users' privacy\nmight have a negative impact on the accuracy of the machine learning approach.\nAs of now, there is no structured way how the users' perception of a machine\nlearning based service can contribute to the selection of Privacy Preserving\nMachine Learning (PPML) methods. This is especially a challenge since one\ncannot assume that users have a deep technical understanding of these\ntechnologies. Therefore, they can only be asked about certain attributes that\nthey can perceive when using the service and not directly which PPML they\nprefer.\n  This study introduces a decision support framework with the aim of supporting\nthe selection of PPML technologies based on user preferences. Based on prior\nwork analysing User Acceptance Criteria (UAC), we translate these criteria into\ndifferentiating characteristics for various PPML techniques. As a final result,\nwe achieve a technology ranking based on the User Acceptance Criteria while\nproviding technology insights for the developers. We demonstrate its\napplication using the use case of classifying privacy-relevant information.\n  Our contribution consists of the decision support framework which consists of\na process to connect PPML technologies with UAC, a process for evaluating the\ncharacteristics that separate PPML techniques, and a ranking method to evaluate\nthe best PPML technique for the use case."
    },
    {
      "id": "2411.06990v1",
      "title": "Causal-discovery-based root-cause analysis and its application in time-series prediction error diagnosis",
      "summary": "Recent rapid advancements of machine learning have greatly enhanced the\naccuracy of prediction models, but most models remain \"black boxes\", making\nprediction error diagnosis challenging, especially with outliers. This lack of\ntransparency hinders trust and reliability in industrial applications.\nHeuristic attribution methods, while helpful, often fail to capture true causal\nrelationships, leading to inaccurate error attributions. Various root-cause\nanalysis methods have been developed using Shapley values, yet they typically\nrequire predefined causal graphs, limiting their applicability for prediction\nerrors in machine learning models. To address these limitations, we introduce\nthe Causal-Discovery-based Root-Cause Analysis (CD-RCA) method that estimates\ncausal relationships between the prediction error and the explanatory\nvariables, without needing a pre-defined causal graph. By simulating synthetic\nerror data, CD-RCA can identify variable contributions to outliers in\nprediction errors by Shapley values. Extensive simulations show CD-RCA\noutperforms current heuristic attribution methods, and a sensitivity analysis\nreveals new patterns where Shapley values may misattribute errors, paving the\nway for more accurate error attribution methods."
    },
    {
      "id": "2411.06989v1",
      "title": "Token2Wave",
      "summary": "This paper provides an in-depth analysis of Token2Wave, a novel token\nrepresentation method derived from the Wave Network, designed to capture both\nglobal and local semantics of input text through wave-inspired complex vectors.\nIn Token2Wave, each token is represented with a magnitude component, capturing\nthe global semantics of the entire input text, and a phase component, encoding\nthe relationships between individual tokens and the global semantics. Building\non prior research that demonstrated the effectiveness of wave-like operations,\nsuch as interference and modulation, during forward propagation, this study\ninvestigates the convergence behavior, backpropagation characteristics, and\nembedding independence within the Token2Wave framework. A detailed\ncomputational complexity analysis shows that Token2Wave can significantly\nreduce video memory usage and training time compared to BERT. Gradient\ncomparisons for the [CLS] token, total input text, and classifier parameters\nfurther highlight Token2Wave's unique characteristics. This research offers new\ninsights into wave-based token representations, demonstrating their potential\nto enable efficient and computationally friendly language model architectures."
    },
    {
      "id": "2411.06965v1",
      "title": "Imitation from Diverse Behaviors: Wasserstein Quality Diversity Imitation Learning with Single-Step Archive Exploration",
      "summary": "Learning diverse and high-performance behaviors from a limited set of\ndemonstrations is a grand challenge. Traditional imitation learning methods\nusually fail in this task because most of them are designed to learn one\nspecific behavior even with multiple demonstrations. Therefore, novel\ntechniques for quality diversity imitation learning are needed to solve the\nabove challenge. This work introduces Wasserstein Quality Diversity Imitation\nLearning (WQDIL), which 1) improves the stability of imitation learning in the\nquality diversity setting with latent adversarial training based on a\nWasserstein Auto-Encoder (WAE), and 2) mitigates a behavior-overfitting issue\nusing a measure-conditioned reward function with a single-step archive\nexploration bonus. Empirically, our method significantly outperforms\nstate-of-the-art IL methods, achieving near-expert or beyond-expert QD\nperformance on the challenging continuous control tasks derived from MuJoCo\nenvironments."
    },
    {
      "id": "2411.06959v1",
      "title": "ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis",
      "summary": "Recently, token-based generation have demonstrated their effectiveness in\nimage synthesis. As a representative example, non-autoregressive Transformers\n(NATs) can generate decent-quality images in a few steps. NATs perform\ngeneration in a progressive manner, where the latent tokens of a resulting\nimage are incrementally revealed. At each step, the unrevealed image regions\nare padded with mask tokens and inferred by NAT. In this paper, we delve into\nthe mechanisms behind the effectiveness of NATs and uncover two important\npatterns that naturally emerge from NATs: Spatially (within a step), although\nmask and visible tokens are processed uniformly by NATs, the interactions\nbetween them are highly asymmetric. In specific, mask tokens mainly gather\ninformation for decoding, while visible tokens tend to primarily provide\ninformation, and their deep representations can be built only upon themselves.\nTemporally (across steps), the interactions between adjacent generation steps\nmostly concentrate on updating the representations of a few critical tokens,\nwhile the computation for the majority of tokens is generally repetitive.\nDriven by these findings, we propose EfficientNAT (ENAT), a NAT model that\nexplicitly encourages these critical interactions inherent in NATs. At the\nspatial level, we disentangle the computations of visible and mask tokens by\nencoding visible tokens independently, while decoding mask tokens conditioned\non the fully encoded visible tokens. At the temporal level, we prioritize the\ncomputation of the critical tokens at each step, while maximally reusing\npreviously computed token representations to supplement necessary information.\nENAT improves the performance of NATs notably with significantly reduced\ncomputational cost. Experiments on ImageNet-256, ImageNet-512 and MS-COCO\nvalidate the effectiveness of ENAT. Code is available at\nhttps://github.com/LeapLabTHU/ENAT."
    },
    {
      "id": "2411.06958v1",
      "title": "Data-driven discovery of mechanical models directly from MRI spectral data",
      "summary": "Finding interpretable biomechanical models can provide insight into the\nfunctionality of organs with regard to physiology and disease. However,\nidentifying broadly applicable dynamical models for in vivo tissue remains\nchallenging. In this proof of concept study we propose a reconstruction\nframework for data-driven discovery of dynamical models from experimentally\nobtained undersampled MRI spectral data. The method makes use of the previously\ndeveloped spectro-dynamic framework which allows for reconstruction of\ndisplacement fields at high spatial and temporal resolution required for model\nidentification. The proposed framework combines this method with data-driven\ndiscovery of interpretable models using Sparse Identification of Non-linear\nDynamics (SINDy). The design of the reconstruction algorithm is such that a\nsymbiotic relation between the reconstruction of the displacement fields and\nthe model identification is created. Our method does not rely on periodicity of\nthe motion. It is successfully validated using spectral data of a dynamic\nphantom gathered on a clinical MRI scanner. The dynamic phantom is programmed\nto perform motion adhering to 5 different (non-linear) ordinary differential\nequations. The proposed framework performed better than a 2-step approach where\nthe displacement fields were first reconstructed from the undersampled data\nwithout any information on the model, followed by data-driven discovery of the\nmodel using the reconstructed displacement fields. This study serves as a first\nstep in the direction of data-driven discovery of in vivo models."
    },
    {
      "id": "2411.06950v1",
      "title": "Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual Alignment with Human Smell Experiences",
      "summary": "Aligning AI with human intent is important, yet perceptual alignment-how AI\ninterprets what we see, hear, or smell-remains underexplored. This work focuses\non olfaction, human smell experiences. We conducted a user study with 40\nparticipants to investigate how well AI can interpret human descriptions of\nscents. Participants performed \"sniff and describe\" interactive tasks, with our\ndesigned AI system attempting to guess what scent the participants were\nexperiencing based on their descriptions. These tasks evaluated the Large\nLanguage Model's (LLMs) contextual understanding and representation of scent\nrelationships within its internal states - high-dimensional embedding space.\nBoth quantitative and qualitative methods were used to evaluate the AI system's\nperformance. Results indicated limited perceptual alignment, with biases\ntowards certain scents, like lemon and peppermint, and continued failing to\nidentify others, like rosemary. We discuss these findings in light of human-AI\nalignment advancements, highlighting the limitations and opportunities for\nenhancing HCI systems with multisensory experience integration."
    },
    {
      "id": "2411.06946v1",
      "title": "Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models",
      "summary": "Gastrointestinal (GI) tract cancers account for a substantial portion of the\nglobal cancer burden, where early diagnosis is critical for improved management\nand patient outcomes. The complex aetiologies and overlapping symptoms across\nGI cancers often delay diagnosis, leading to suboptimal treatment strategies.\nCancer-related queries are crucial for timely diagnosis, treatment, and patient\neducation, as access to accurate, comprehensive information can significantly\ninfluence outcomes. However, the complexity of cancer as a disease, combined\nwith the vast amount of available data, makes it difficult for clinicians and\npatients to quickly find precise answers. To address these challenges, we\nleverage large language models (LLMs) such as GPT-3.5 Turbo to generate\naccurate, contextually relevant responses to cancer-related queries.\nPre-trained with medical data, these models provide timely, actionable insights\nthat support informed decision-making in cancer diagnosis and care, ultimately\nimproving patient outcomes. We calculate two metrics: A1 (which represents the\nfraction of entities present in the model-generated answer compared to the gold\nstandard) and A2 (which represents the linguistic correctness and\nmeaningfulness of the model-generated answer with respect to the gold\nstandard), achieving maximum values of 0.546 and 0.881, respectively."
    },
    {
      "id": "2411.06928v1",
      "title": "Electroencephalogram-based Multi-class Decoding of Attended Speakers' Direction with Audio Spatial Spectrum",
      "summary": "Decoding the directional focus of an attended speaker from listeners'\nelectroencephalogram (EEG) signals is essential for developing brain-computer\ninterfaces to improve the quality of life for individuals with hearing\nimpairment. Previous works have concentrated on binary directional focus\ndecoding, i.e., determining whether the attended speaker is on the left or\nright side of the listener. However, a more precise decoding of the exact\ndirection of the attended speaker is necessary for effective speech processing.\nAdditionally, audio spatial information has not been effectively leveraged,\nresulting in suboptimal decoding results. In this paper, we observe that, on\nour recently presented dataset with 15-class directional focus, models relying\nexclusively on EEG inputs exhibits significantly lower accuracy when decoding\nthe directional focus in both leave-one-subject-out and leave-one-trial-out\nscenarios. By integrating audio spatial spectra with EEG features, the decoding\naccuracy can be effectively improved. We employ the CNN, LSM-CNN, and\nEEG-Deformer models to decode the directional focus from listeners' EEG signals\nwith the auxiliary audio spatial spectra. The proposed Sp-Aux-Deformer model\nachieves notable 15-class decoding accuracies of 57.48% and 61.83% in\nleave-one-subject-out and leave-one-trial-out scenarios, respectively."
    },
    {
      "id": "2411.06927v1",
      "title": "Multi-modal Iterative and Deep Fusion Frameworks for Enhanced Passive DOA Sensing via a Green Massive H2AD MIMO Receiver",
      "summary": "Most existing DOA estimation methods assume ideal source incident angles with\nminimal noise. Moreover, directly using pre-estimated angles to calculate\nweighted coefficients can lead to performance loss. Thus, a green multi-modal\n(MM) fusion DOA framework is proposed to realize a more practical, low-cost and\nhigh time-efficiency DOA estimation for a H$^2$AD array. Firstly, two more\nefficient clustering methods, global maximum cos\\_similarity clustering\n(GMaxCS) and global minimum distance clustering (GMinD), are presented to infer\nmore precise true solutions from the candidate solution sets. Based on this, an\niteration weighted fusion (IWF)-based method is introduced to iteratively\nupdate weighted fusion coefficients and the clustering center of the true\nsolution classes by using the estimated values. Particularly, the coarse DOA\ncalculated by fully digital (FD) subarray, serves as the initial cluster\ncenter. The above process yields two methods called MM-IWF-GMaxCS and\nMM-IWF-GMinD. To further provide a higher-accuracy DOA estimation, a fusion\nnetwork (fusionNet) is proposed to aggregate the inferred two-part true angles\nand thus generates two effective approaches called MM-fusionNet-GMaxCS and\nMM-fusionNet-GMinD. The simulation outcomes show the proposed four approaches\ncan achieve the ideal DOA performance and the CRLB. Meanwhile, proposed\nMM-fusionNet-GMaxCS and MM-fusionNet-GMinD exhibit superior DOA performance\ncompared to MM-IWF-GMaxCS and MM-IWF-GMinD, especially in extremely-low SNR\nrange."
    },
    {
      "id": "2411.06919v1",
      "title": "Understanding Generalization in Quantum Machine Learning with Margins",
      "summary": "Understanding and improving generalization capabilities is crucial for both\nclassical and quantum machine learning (QML). Recent studies have revealed\nshortcomings in current generalization theories, particularly those relying on\nuniform bounds, across both classical and quantum settings. In this work, we\npresent a margin-based generalization bound for QML models, providing a more\nreliable framework for evaluating generalization. Our experimental studies on\nthe quantum phase recognition (QPR) dataset demonstrate that margin-based\nmetrics are strong predictors of generalization performance, outperforming\ntraditional metrics like parameter count. By connecting this margin-based\nmetric to quantum information theory, we demonstrate how to enhance the\ngeneralization performance of QML through a classical-quantum hybrid approach\nwhen applied to classical data."
    },
    {
      "id": "2411.06917v1",
      "title": "Efficient Unsupervised Domain Adaptation Regression for Spatial-Temporal Air Quality Sensor Fusion",
      "summary": "The deployment of affordable Internet of Things (IoT) sensors for air\npollution monitoring has increased in recent years due to their scalability and\ncost-effectiveness. However, accurately calibrating these sensors in\nuncontrolled environments remains a significant challenge. While expensive\nreference sensors can provide accurate ground truth data, they are often\ndeployed on a limited scale due to high costs, leading to a scarcity of labeled\ndata. In diverse urban environments, data distributions constantly shift due to\nvarying factors such as traffic patterns, industrial activities, and weather\nconditions, which impact sensor readings. Consequently, traditional machine\nlearning models -- despite their increasing deployment for environmental sensor\ncalibration -- often struggle to provide reliable pollutant measurements across\ndifferent locations due to domain shifts. To address these challenges, we\npropose a novel unsupervised domain adaptation (UDA) method specifically\ntailored for regression tasks on graph-structured data. Our approach leverages\nGraph Neural Networks (GNNs) to model the relationships between sensors. To\neffectively capture critical spatial-temporal interactions, we incorporate\nspatial-temporal graph neural networks (STGNNs), which extend GNNs by\nincorporating temporal dynamics. To handle the resulting larger embeddings, we\npropose a domain adaptation method using a closed-form solution inspired by the\nTikhonov-regularized least-squares problem. This method leverages Cholesky\ndecomposition and power iteration to align the subspaces between source and\ntarget domains. By aligning these subspaces, our approach allows low-cost IoT\nsensors to learn calibration parameters from expensive reference sensors. This\nfacilitates reliable pollutant measurements in new locations without the need\nfor additional costly equipment."
    },
    {
      "id": "2411.06916v1",
      "title": "Slowing Down Forgetting in Continual Learning",
      "summary": "A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods to slow down\nforgetting. We further demonstrate the performance gain from our framework\nacross a large series of experiments, including different CL scenarios (class\nincremental, domain incremental, task incremental learning) different datasets\n(MNIST, CIFAR10), and different network architectures. Across all experiments,\nwe find large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers."
    },
    {
      "id": "2411.06911v2",
      "title": "Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI",
      "summary": "Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall."
    },
    {
      "id": "2411.06908v1",
      "title": "EVQAScore: Efficient Video Question Answering Data Evaluation",
      "summary": "Video question-answering (QA) is a core task in video understanding.\nEvaluating the quality of video QA and video caption data quality for training\nvideo large language models (VideoLLMs) is an essential challenge. Although\nvarious methods have been proposed for assessing video caption quality, there\nremains a lack of dedicated evaluation methods for Video QA. To address this\ngap, we introduce EVQAScore, a reference-free method that leverages keyword\nextraction to assess both video caption and video QA data quality.\nAdditionally, we incorporate frame sampling and rescaling techniques to enhance\nthe efficiency and robustness of our evaluation, this enables our score to\nevaluate the quality of extremely long videos. Our approach achieves\nstate-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for\nSpearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on\nthe VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using\nEVQAScore for data selection, we achieved SOTA results with only 12.5\\% of the\noriginal data volume, outperforming the previous SOTA method PAC-S and 100\\% of\ndata."
    },
    {
      "id": "2411.06899v1",
      "title": "LongSafetyBench: Long-Context LLMs Struggle with Safety Issues",
      "summary": "With the development of large language models (LLMs), the sequence length of\nthese models continues to increase, drawing significant attention to\nlong-context language models. However, the evaluation of these models has been\nprimarily limited to their capabilities, with a lack of research focusing on\ntheir safety. Existing work, such as ManyShotJailbreak, has to some extent\ndemonstrated that long-context language models can exhibit safety concerns.\nHowever, the methods used are limited and lack comprehensiveness. In response,\nwe introduce \\textbf{LongSafetyBench}, the first benchmark designed to\nobjectively and comprehensively evaluate the safety of long-context models.\nLongSafetyBench consists of 10 task categories, with an average length of\n41,889 words. After testing eight long-context language models on\nLongSafetyBench, we found that existing models generally exhibit insufficient\nsafety capabilities. The proportion of safe responses from most mainstream\nlong-context LLMs is below 50\\%. Moreover, models' safety performance in\nlong-context scenarios does not always align with that in short-context\nscenarios. Further investigation revealed that long-context models tend to\noverlook harmful content within lengthy texts. We also proposed a simple yet\neffective solution, allowing open-source models to achieve performance\ncomparable to that of top-tier closed-source models. We believe that\nLongSafetyBench can serve as a valuable benchmark for evaluating the safety\ncapabilities of long-context language models. We hope that our work will\nencourage the broader community to pay attention to the safety of long-context\nmodels and contribute to the development of solutions to improve the safety of\nlong-context LLMs."
    },
    {
      "id": "2411.06890v2",
      "title": "SPARTAN: A Sparse Transformer Learning Local Causation",
      "summary": "Causal structures play a central role in world models that flexibly adapt to\nchanges in the environment. While recent works motivate the benefits of\ndiscovering local causal graphs for dynamics modelling, in this work we\ndemonstrate that accurately capturing these relationships in complex settings\nremains challenging for the current state-of-the-art. To remedy this\nshortcoming, we postulate that sparsity is a critical ingredient for the\ndiscovery of such local causal structures. To this end we present the SPARse\nTrANsformer World model (SPARTAN), a Transformer-based world model that learns\nlocal causal structures between entities in a scene. By applying sparsity\nregularisation on the attention pattern between object-factored tokens, SPARTAN\nidentifies sparse local causal models that accurately predict future object\nstates. Furthermore, we extend our model to capture sparse interventions with\nunknown targets on the dynamics of the environment. This results in a highly\ninterpretable world model that can efficiently adapt to changes. Empirically,\nwe evaluate SPARTAN against the current state-of-the-art in object-centric\nworld models on observation-based environments and demonstrate that our model\ncan learn accurate local causal graphs and achieve significantly improved\nfew-shot adaptation to changes in the dynamics of the environment as well as\nrobustness against removing irrelevant distractors."
    },
    {
      "id": "2411.06881v1",
      "title": "WassFFed: Wasserstein Fair Federated Learning",
      "summary": "Federated Learning (FL) employs a training approach to address scenarios\nwhere users' data cannot be shared across clients. Achieving fairness in FL is\nimperative since training data in FL is inherently geographically distributed\namong diverse user groups. Existing research on fairness predominantly assumes\naccess to the entire training data, making direct transfer to FL challenging.\nHowever, the limited existing research on fairness in FL does not effectively\naddress two key challenges, i.e., (CH1) Current methods fail to deal with the\ninconsistency between fair optimization results obtained with surrogate\nfunctions and fair classification results. (CH2) Directly aggregating local\nfair models does not always yield a globally fair model due to non Identical\nand Independent data Distributions (non-IID) among clients. To address these\nchallenges, we propose a Wasserstein Fair Federated Learning framework, namely\nWassFFed. To tackle CH1, we ensure that the outputs of local models, rather\nthan the loss calculated with surrogate functions or classification results\nwith a threshold, remain independent of various user groups. To resolve CH2, we\nemploy a Wasserstein barycenter calculation of all local models' outputs for\neach user group, bringing local model outputs closer to the global output\ndistribution to ensure consistency between the global model and local models.\nWe conduct extensive experiments on three real-world datasets, demonstrating\nthat WassFFed outperforms existing approaches in striking a balance between\naccuracy and fairness."
    },
    {
      "id": "2411.06878v1",
      "title": "GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs",
      "summary": "Graph-based patterns are extensively employed and favored by practitioners\nwithin industrial companies due to their capacity to represent the behavioral\nattributes and topological relationships among users, thereby offering enhanced\ninterpretability in comparison to black-box models commonly utilized for\nclassification and recognition tasks. For instance, within the scenario of\ntransaction risk management, a graph pattern that is characteristic of a\nparticular risk category can be readily employed to discern transactions\nfraught with risk, delineate networks of criminal activity, or investigate the\nmethodologies employed by fraudsters. Nonetheless, graph data in industrial\nsettings is often characterized by its massive scale, encompassing data sets\nwith millions or even billions of nodes, making the manual extraction of graph\npatterns not only labor-intensive but also necessitating specialized knowledge\nin particular domains of risk. Moreover, existing methodologies for mining\ngraph patterns encounter significant obstacles when tasked with analyzing\nlarge-scale attributed graphs. In this work, we introduce GraphRPM, an\nindustry-purpose parallel and distributed risk pattern mining framework on\nlarge attributed graphs. The framework incorporates a novel edge-involved graph\nisomorphism network alongside optimized operations for parallel graph\ncomputation, which collectively contribute to a considerable reduction in\ncomputational complexity and resource expenditure. Moreover, the intelligent\nfiltration of efficacious risky graph patterns is facilitated by the proposed\nevaluation metrics. Comprehensive experimental evaluations conducted on\nreal-world datasets of varying sizes substantiate the capability of GraphRPM to\nadeptly address the challenges inherent in mining patterns from large-scale\nindustrial attributed graphs, thereby underscoring its substantial value for\nindustrial deployment."
    },
    {
      "id": "2411.06872v1",
      "title": "Multi-Modal interpretable automatic video captioning",
      "summary": "Video captioning aims to describe video contents using natural language\nformat that involves understanding and interpreting scenes, actions and events\nthat occurs simultaneously on the view. Current approaches have mainly\nconcentrated on visual cues, often neglecting the rich information available\nfrom other important modality of audio information, including their\ninter-dependencies. In this work, we introduce a novel video captioning method\ntrained with multi-modal contrastive loss that emphasizes both multi-modal\nintegration and interpretability. Our approach is designed to capture the\ndependency between these modalities, resulting in more accurate, thus pertinent\ncaptions. Furthermore, we highlight the importance of interpretability,\nemploying multiple attention mechanisms that provide explanation into the\nmodel's decision-making process. Our experimental results demonstrate that our\nproposed method performs favorably against the state-of the-art models on\ncommonly used benchmark datasets of MSR-VTT and VATEX."
    },
    {
      "id": "2411.06870v1",
      "title": "AI-Native Multi-Access Future Networks -- The REASON Architecture",
      "summary": "The development of the sixth generation of communication networks (6G) has\nbeen gaining momentum over the past years, with a target of being introduced by\n2030. Several initiatives worldwide are developing innovative solutions and\nsetting the direction for the key features of these networks. Some common\nemerging themes are the tight integration of AI, the convergence of multiple\naccess technologies and sustainable operation, aiming to meet stringent\nperformance and societal requirements. To that end, we are introducing REASON -\nRealising Enabling Architectures and Solutions for Open Networks. The REASON\nproject aims to address technical challenges in future network deployments,\nsuch as E2E service orchestration, sustainability, security and trust\nmanagement, and policy management, utilising AI-native principles, considering\nmultiple access technologies and cloud-native solutions.\n  This paper presents REASON's architecture and the identified requirements for\nfuture networks. The architecture is meticulously designed for modularity,\ninteroperability, scalability, simplified troubleshooting, flexibility, and\nenhanced security, taking into consideration current and future standardisation\nefforts, and the ease of implementation and training. It is structured into\nfour horizontal layers: Physical Infrastructure, Network Service, Knowledge,\nand End-User Application, complemented by two vertical layers: Management and\nOrchestration, and E2E Security. This layered approach ensures a robust,\nadaptable framework to support the diverse and evolving requirements of 6G\nnetworks, fostering innovation and facilitating seamless integration of\nadvanced technologies."
    },
    {
      "id": "2411.06869v1",
      "title": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models",
      "summary": "Category-agnostic pose estimation (CAPE) has traditionally relied on support\nimages with annotated keypoints, a process that is often cumbersome and may\nfail to fully capture the necessary correspondences across diverse object\ncategories. Recent efforts have begun exploring the use of text-based queries,\nwhere the need for support keypoints is eliminated. However, the optimal use of\ntextual descriptions for keypoints remains an underexplored area. In this work,\nwe introduce CapeLLM, a novel approach that leverages a text-based multimodal\nlarge language model (MLLM) for CAPE. Our method only employs query image and\ndetailed text descriptions as an input to estimate category-agnostic keypoints.\nWe conduct extensive experiments to systematically explore the design space of\nLLM-based CAPE, investigating factors such as choosing the optimal description\nfor keypoints, neural network architectures, and training strategies. Thanks to\nthe advanced reasoning capabilities of the pre-trained MLLM, CapeLLM\ndemonstrates superior generalization and robust performance. Our approach sets\na new state-of-the-art on the MP-100 benchmark in the challenging 1-shot\nsetting, marking a significant advancement in the field of category-agnostic\npose estimation."
    },
    {
      "id": "2411.06868v1",
      "title": "Effect sizes as a statistical feature-selector-based learning to detect breast cancer",
      "summary": "Breast cancer detection is still an open research field, despite a tremendous\neffort devoted to work in this area. Effect size is a statistical concept that\nmeasures the strength of the relationship between two variables on a numeric\nscale. Feature selection is widely used to reduce the dimensionality of data by\nselecting only a subset of predictor variables to improve a learning model. In\nthis work, an algorithm and experimental results demonstrate the feasibility of\ndeveloping a statistical feature-selector-based learning tool capable of\nreducing the data dimensionality using parametric effect size measures from\nfeatures extracted from cell nuclei images. The SVM classifier with a linear\nkernel as a learning tool achieved an accuracy of over 90%. These excellent\nresults suggest that the effect size is within the standards of the\nfeature-selector methods"
    },
    {
      "id": "2411.06866v1",
      "title": "Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering",
      "summary": "Commonsense question answering is a crucial task that requires machines to\nemploy reasoning according to commonsense. Previous studies predominantly\nemploy an extracting-and-modeling paradigm to harness the information in KG,\nwhich first extracts relevant subgraphs based on pre-defined rules and then\nproceeds to design various strategies aiming to improve the representations and\nfusion of the extracted structural knowledge. Despite their effectiveness,\nthere are still two challenges. On one hand, subgraphs extracted by rule-based\nmethods may have the potential to overlook critical nodes and result in\nuncontrollable subgraph size. On the other hand, the misalignment between graph\nand text modalities undermines the effectiveness of knowledge fusion,\nultimately impacting the task performance. To deal with the problems above, we\npropose a novel framework: \\textbf{S}ubgraph R\\textbf{E}trieval Enhanced by\nGra\\textbf{P}h-\\textbf{T}ext \\textbf{A}lignment, named \\textbf{SEPTA}. Firstly,\nwe transform the knowledge graph into a database of subgraph vectors and\npropose a BFS-style subgraph sampling strategy to avoid information loss,\nleveraging the analogy between BFS and the message-passing mechanism. In\naddition, we propose a bidirectional contrastive learning approach for\ngraph-text alignment, which effectively enhances both subgraph retrieval and\nknowledge fusion. Finally, all the retrieved information is combined for\nreasoning in the prediction module. Extensive experiments on five datasets\ndemonstrate the effectiveness and robustness of our framework."
    },
    {
      "id": "2411.06863v1",
      "title": "Computable Model-Independent Bounds for Adversarial Quantum Machine Learning",
      "summary": "By leveraging the principles of quantum mechanics, QML opens doors to novel\napproaches in machine learning and offers potential speedup. However, machine\nlearning models are well-documented to be vulnerable to malicious\nmanipulations, and this susceptibility extends to the models of QML. This\nsituation necessitates a thorough understanding of QML's resilience against\nadversarial attacks, particularly in an era where quantum computing\ncapabilities are expanding. In this regard, this paper examines\nmodel-independent bounds on adversarial performance for QML. To the best of our\nknowledge, we introduce the first computation of an approximate lower bound for\nadversarial error when evaluating model resilience against sophisticated\nquantum-based adversarial attacks. Experimental results are compared to the\ncomputed bound, demonstrating the potential of QML models to achieve high\nrobustness. In the best case, the experimental error is only 10% above the\nestimated bound, offering evidence of the inherent robustness of quantum\nmodels. This work not only advances our theoretical understanding of quantum\nmodel resilience but also provides a precise reference bound for the future\ndevelopment of robust QML algorithms."
    },
    {
      "id": "2411.06860v1",
      "title": "Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models",
      "summary": "Phishing attacks remain a persistent threat to online security, demanding\nrobust detection methods. This study investigates the use of machine learning\nto identify phishing URLs, emphasizing the crucial role of feature selection\nand model interpretability for improved performance. Employing Recursive\nFeature Elimination, the research pinpointed key features like \"length_url,\"\n\"time_domain_activation\" and \"Page_rank\" as strong indicators of phishing\nattempts. The study evaluated various algorithms, including CatBoost, XGBoost,\nand Explainable Boosting Machine, assessing their robustness and scalability.\nXGBoost emerged as highly efficient in terms of runtime, making it well-suited\nfor large datasets. CatBoost, on the other hand, demonstrated resilience by\nmaintaining high accuracy even with reduced features. To enhance transparency\nand trustworthiness, Explainable AI techniques, such as SHAP, were employed to\nprovide insights into feature importance. The study's findings highlight that\neffective feature selection and model interpretability can significantly\nbolster phishing detection systems, paving the way for more efficient and\nadaptable defenses against evolving cyber threats"
    },
    {
      "id": "2411.06858v1",
      "title": "Scientific machine learning in ecological systems: A study on the predator-prey dynamics",
      "summary": "In this study, we apply two pillars of Scientific Machine Learning: Neural\nOrdinary Differential Equations (Neural ODEs) and Universal Differential\nEquations (UDEs) to the Lotka Volterra Predator Prey Model, a fundamental\necological model describing the dynamic interactions between predator and prey\npopulations. The Lotka-Volterra model is critical for understanding ecological\ndynamics, population control, and species interactions, as it is represented by\na system of differential equations. In this work, we aim to uncover the\nunderlying differential equations without prior knowledge of the system,\nrelying solely on training data and neural networks. Using robust modeling in\nthe Julia programming language, we demonstrate that both Neural ODEs and UDEs\ncan be effectively utilized for prediction and forecasting of the\nLotka-Volterra system. More importantly, we introduce the forecasting breakdown\npoint: the time at which forecasting fails for both Neural ODEs and UDEs. We\nobserve how UDEs outperform Neural ODEs by effectively recovering the\nunderlying dynamics and achieving accurate forecasting with significantly less\ntraining data. Additionally, we introduce Gaussian noise of varying magnitudes\n(from mild to high) to simulate real-world data perturbations and show that\nUDEs exhibit superior robustness, effectively recovering the underlying\ndynamics even in the presence of noisy data, while Neural ODEs struggle with\nhigh levels of noise. Through extensive hyperparameter optimization, we offer\ninsights into neural network architectures, activation functions, and\noptimizers that yield the best results. This study opens the door to applying\nScientific Machine Learning frameworks for forecasting tasks across a wide\nrange of ecological and scientific domains."
    },
    {
      "id": "2411.06855v2",
      "title": "A Unified Multi-Task Learning Architecture for Hate Detection Leveraging User-Based Information",
      "summary": "Hate speech, offensive language, aggression, racism, sexism, and other\nabusive language are common phenomena in social media. There is a need for\nArtificial Intelligence(AI)based intervention which can filter hate content at\nscale. Most existing hate speech detection solutions have utilized the features\nby treating each post as an isolated input instance for the classification.\nThis paper addresses this issue by introducing a unique model that improves\nhate speech identification for the English language by utilising intra-user and\ninter-user-based information. The experiment is conducted over single-task\nlearning (STL) and multi-task learning (MTL) paradigms that use deep neural\nnetworks, such as convolutional neural networks (CNN), gated recurrent unit\n(GRU), bidirectional encoder representations from the transformer (BERT), and A\nLite BERT (ALBERT). We use three benchmark datasets and conclude that combining\ncertain user features with textual features gives significant improvements in\nmacro-F1 and weighted-F1."
    },
    {
      "id": "2411.06852v1",
      "title": "Evaluating Large Language Models on Financial Report Summarization: An Empirical Study",
      "summary": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\nversatility across various applications, including natural language\nunderstanding, domain-specific knowledge tasks, etc. However, applying LLMs to\ncomplex, high-stakes domains like finance requires rigorous evaluation to\nensure reliability, accuracy, and compliance with industry standards. To\naddress this need, we conduct a comprehensive and comparative study on three\nstate-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their\neffectiveness in generating automated financial reports. Our primary motivation\nis to explore how these models can be harnessed within finance, a field\ndemanding precision, contextual relevance, and robustness against erroneous or\nmisleading information. By examining each model's capabilities, we aim to\nprovide an insightful assessment of their strengths and limitations. Our paper\noffers benchmarks for financial report analysis, encompassing proposed metrics\nsuch as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative\nevaluation framework that integrates both quantitative metrics (e.g.,\nprecision, recall) and qualitative analyses (e.g., contextual fit, consistency)\nto provide a holistic view of each model's output quality. Additionally, we\nmake our financial dataset publicly available, inviting researchers and\npractitioners to leverage, scrutinize, and enhance our findings through broader\ncommunity engagement and collaborative improvement. Our dataset is available on\nhuggingface."
    },
    {
      "id": "2411.06851v1",
      "title": "Fast and Efficient Transformer-based Method for Bird's Eye View Instance Prediction",
      "summary": "Accurate object detection and prediction are critical to ensure the safety\nand efficiency of self-driving architectures. Predicting object trajectories\nand occupancy enables autonomous vehicles to anticipate movements and make\ndecisions with future information, increasing their adaptability and reducing\nthe risk of accidents. Current State-Of-The-Art (SOTA) approaches often isolate\nthe detection, tracking, and prediction stages, which can lead to significant\nprediction errors due to accumulated inaccuracies between stages. Recent\nadvances have improved the feature representation of multi-camera perception\nsystems through Bird's-Eye View (BEV) transformations, boosting the development\nof end-to-end systems capable of predicting environmental elements directly\nfrom vehicle sensor data. These systems, however, often suffer from high\nprocessing times and number of parameters, creating challenges for real-world\ndeployment. To address these issues, this paper introduces a novel BEV instance\nprediction architecture based on a simplified paradigm that relies only on\ninstance segmentation and flow prediction. The proposed system prioritizes\nspeed, aiming at reduced parameter counts and inference times compared to\nexisting SOTA architectures, thanks to the incorporation of an efficient\ntransformer-based architecture. Furthermore, the implementation of the proposed\narchitecture is optimized for performance improvements in PyTorch version 2.1.\nCode and trained models are available at\nhttps://github.com/miguelag99/Efficient-Instance-Prediction"
    },
    {
      "id": "2411.06850v1",
      "title": "1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs",
      "summary": "This paper presents a detailed system description of our entry for the\nCHiPSAL 2025 shared task, focusing on language detection, hate speech\nidentification, and target detection in Devanagari script languages. We\nexperimented with a combination of large language models and their ensembles,\nincluding MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like\nfocal loss to address challenges in the natural understanding of Devanagari\nlanguages, such as multilingual processing and class imbalance. Our approach\nachieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804\nfor Sub-tasks A, B, and C respectively. This work provides insights into the\neffectiveness of transformer models in tasks with domain-specific and\nlinguistic challenges, as well as areas for potential improvement in future\niterations."
    },
    {
      "id": "2411.06848v1",
      "title": "Generative Feature Training of Thin 2-Layer Networks",
      "summary": "We consider the approximation of functions by 2-layer neural networks with a\nsmall number of hidden weights based on the squared loss and small datasets.\nDue to the highly non-convex energy landscape, gradient-based training often\nsuffers from local minima. As a remedy, we initialize the hidden weights with\nsamples from a learned proposal distribution, which we parameterize as a deep\ngenerative model. To train this model, we exploit the fact that with fixed\nhidden weights, the optimal output weights solve a linear equation. After\nlearning the generative model, we refine the sampled weights with a\ngradient-based post-processing in the latent space. Here, we also include a\nregularization scheme to counteract potential noise. Finally, we demonstrate\nthe effectiveness of our approach by numerical examples."
    },
    {
      "id": "2411.06839v1",
      "title": "LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models",
      "summary": "In this paper, we propose a novel LLM-Neo framework that efficiently\ntransfers knowledge from a large language model (LLM) teacher to a compact\nstudent. Initially, we revisit the knowledge distillation (KD) and low-rank\nadaption (LoRA), and argue that they share the same paradigm. Inspired by this\nobservation, we explore the strategy that combines LoRA and KD to enhance the\nefficiency of knowledge transfer. We first summarize some guidelines for this\ndesign and further develop the LLM-Neo. Experimental results on compressing\nLlama 2 and Llama 3 show that LLM-Neo outperforms various baselines. Further\nanalysis demonstrates the robustness of the proposed LLM-Neo on variants of\nLoRA. The trained models have been available at\n\\href{https://huggingface.co/collections/yang31210999/llm-neo-66e3c882f5579b829ff57eba}{this\nrepository}."
    },
    {
      "id": "2411.06837v1",
      "title": "Persuasion with Large Language Models: a Survey",
      "summary": "The rapid rise of Large Language Models (LLMs) has created new disruptive\npossibilities for persuasive communication, by enabling fully-automated\npersonalized and interactive content generation at an unprecedented scale. In\nthis paper, we survey the research field of LLM-based persuasion that has\nemerged as a result. We begin by exploring the different modes in which LLM\nSystems are used to influence human attitudes and behaviors. In areas such as\npolitics, marketing, public health, e-commerce, and charitable giving, such LLM\nSystems have already achieved human-level or even super-human persuasiveness.\nWe identify key factors influencing their effectiveness, such as the manner of\npersonalization and whether the content is labelled as AI-generated. We also\nsummarize the experimental designs that have been used to evaluate progress.\nOur survey suggests that the current and future potential of LLM-based\npersuasion poses profound ethical and societal risks, including the spread of\nmisinformation, the magnification of biases, and the invasion of privacy. These\nrisks underscore the urgent need for ethical guidelines and updated regulatory\nframeworks to avoid the widespread deployment of irresponsible and harmful LLM\nSystems."
    },
    {
      "id": "2411.06836v1",
      "title": "Spatially Constrained Transformer with Efficient Global Relation Modelling for Spatio-Temporal Prediction",
      "summary": "Accurate spatio-temporal prediction is crucial for the sustainable\ndevelopment of smart cities. However, current approaches often struggle to\ncapture important spatio-temporal relationships, particularly overlooking\nglobal relations among distant city regions. Most existing techniques\npredominantly rely on Convolutional Neural Networks (CNNs) to capture global\nrelations. However, CNNs exhibit neighbourhood bias, making them insufficient\nfor capturing distant relations. To address this limitation, we propose\nST-SampleNet, a novel transformer-based architecture that combines CNNs with\nself-attention mechanisms to capture both local and global relations\neffectively. Moreover, as the number of regions increases, the quadratic\ncomplexity of self-attention becomes a challenge. To tackle this issue, we\nintroduce a lightweight region sampling strategy that prunes non-essential\nregions and enhances the efficiency of our approach. Furthermore, we introduce\na spatially constrained position embedding that incorporates spatial\nneighbourhood information into the self-attention mechanism, aiding in semantic\ninterpretation and improving the performance of ST-SampleNet. Our experimental\nevaluation on three real-world datasets demonstrates the effectiveness of\nST-SampleNet. Additionally, our efficient variant achieves a 40% reduction in\ncomputational costs with only a marginal compromise in performance,\napproximately 1%."
    },
    {
      "id": "2411.06835v1",
      "title": "HarmLevelBench: Evaluating Harm-Level Compliance and the Impact of Quantization on Model Alignment",
      "summary": "With the introduction of the transformers architecture, LLMs have\nrevolutionized the NLP field with ever more powerful models. Nevertheless,\ntheir development came up with several challenges. The exponential growth in\ncomputational power and reasoning capabilities of language models has\nheightened concerns about their security. As models become more powerful,\nensuring their safety has become a crucial focus in research. This paper aims\nto address gaps in the current literature on jailbreaking techniques and the\nevaluation of LLM vulnerabilities. Our contributions include the creation of a\nnovel dataset designed to assess the harmfulness of model outputs across\nmultiple harm levels, as well as a focus on fine-grained harm-level analysis.\nUsing this framework, we provide a comprehensive benchmark of state-of-the-art\njailbreaking attacks, specifically targeting the Vicuna 13B v1.5 model.\nAdditionally, we examine how quantization techniques, such as AWQ and GPTQ,\ninfluence the alignment and robustness of models, revealing trade-offs between\nenhanced robustness with regards to transfer attacks and potential increases in\nvulnerability on direct ones. This study aims to demonstrate the influence of\nharmful input queries on the complexity of jailbreaking techniques, as well as\nto deepen our understanding of LLM vulnerabilities and improve methods for\nassessing model robustness when confronted with harmful content, particularly\nin the context of compression strategies."
    },
    {
      "id": "2411.06833v1",
      "title": "Learning Interpretable Network Dynamics via Universal Neural Symbolic Regression",
      "summary": "Discovering governing equations of complex network dynamics is a fundamental\nchallenge in contemporary science with rich data, which can uncover the\nmysterious patterns and mechanisms of the formation and evolution of complex\nphenomena in various fields and assist in decision-making. In this work, we\ndevelop a universal computational tool that can automatically, efficiently, and\naccurately learn the symbolic changing patterns of complex system states by\ncombining the excellent fitting ability from deep learning and the equation\ninference ability from pre-trained symbolic regression. We conduct intensive\nexperimental verifications on more than ten representative scenarios from\nphysics, biochemistry, ecology, epidemiology, etc. Results demonstrate the\noutstanding effectiveness and efficiency of our tool by comparing with the\nstate-of-the-art symbolic regression techniques for network dynamics. The\napplication to real-world systems including global epidemic transmission and\npedestrian movements has verified its practical applicability. We believe that\nour tool can serve as a universal solution to dispel the fog of hidden\nmechanisms of changes in complex phenomena, advance toward interpretability,\nand inspire more scientific discoveries."
    },
    {
      "id": "2411.06832v1",
      "title": "Optimized Quality of Service prediction in FSO Links over South Africa using Ensemble Learning",
      "summary": "Fibre optic communication system is expected to increase exponentially in\nterms of application due to the numerous advantages over copper wires. The\noptical network evolution presents several advantages such as over\nlong-distance, low-power requirement, higher carrying capacity and high\nbandwidth among others Such network bandwidth surpasses methods of transmission\nthat include copper cables and microwaves. Despite these benefits, free-space\noptical communications are severely impacted by harsh weather situations like\nmist, precipitation, blizzard, fume, soil, and drizzle debris in the\natmosphere, all of which have an impact on the Quality of Service (QoS)\nrendered by the systems. The primary goal of this article is to optimize the\nQoS using the ensemble learning models Random Forest, ADaBoost Regression,\nStacking Regression, Gradient Boost Regression, and Multilayer Neural Network.\nTo accomplish the stated goal, meteorological data, visibility, wind speed, and\naltitude were obtained from the South Africa Weather Services archive during a\nten-year period (2010 to 2019) at four different locations: Polokwane,\nKimberley, Bloemfontein, and George. We estimated the data rate, power\nreceived, fog-induced attenuation, bit error rate and power penalty using the\ncollected and processed data. The RMSE and R-squared values of the model across\nall the study locations, Polokwane, Kimberley, Bloemfontein, and George, are\n0.0073 and 0.9951, 0.0065 and 0.9998, 0.0060 and 0.9941, and 0.0032 and 0.9906,\nrespectively. The result showed that using ensemble learning techniques in\ntransmission modeling can significantly enhance service quality and meet\ncustomer service level agreements and ensemble method was successful in\nefficiently optimizing the signal to noise ratio, which in turn enhanced the\nQoS at the point of reception."
    },
    {
      "id": "2411.06826v1",
      "title": "Adaptive Conditional Expert Selection Network for Multi-domain Recommendation",
      "summary": "Mixture-of-Experts (MOE) has recently become the de facto standard in\nMulti-domain recommendation (MDR) due to its powerful expressive ability.\nHowever, such MOE-based method typically employs all experts for each instance,\nleading to scalability issue and low-discriminability between domains and\nexperts. Furthermore, the design of commonly used domain-specific networks\nexacerbates the scalability issues. To tackle the problems, We propose a novel\nmethod named CESAA consists of Conditional Expert Selection (CES) Module and\nAdaptive Expert Aggregation (AEA) Module to tackle these challenges.\nSpecifically, CES first combines a sparse gating strategy with domain-shared\nexperts. Then AEA utilizes mutual information loss to strengthen the\ncorrelations between experts and specific domains, and significantly improve\nthe distinction between experts. As a result, only domain-shared experts and\nselected domain-specific experts are activated for each instance, striking a\nbalance between computational efficiency and model performance. Experimental\nresults on both public ranking and industrial retrieval datasets verify the\neffectiveness of our method in MDR tasks."
    },
    {
      "id": "2411.06824v1",
      "title": "Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs",
      "summary": "There is a growing interest in training domain-expert LLMs that excel in\nspecific technical fields compared to their general-purpose instruction-tuned\ncounterparts. However, these expert models often experience a loss in their\nsafety abilities in the process, making them capable of generating harmful\ncontent. As a solution, we introduce an efficient and effective merging-based\nalignment method called \\textsc{MergeAlign} that interpolates the domain and\nalignment vectors, creating safer domain-specific models while preserving their\nutility. We apply \\textsc{MergeAlign} on Llama3 variants that are experts in\nmedicine and finance, obtaining substantial alignment improvements with minimal\nto no degradation on domain-specific benchmarks. We study the impact of model\nmerging through model similarity metrics and contributions of individual models\nbeing merged. We hope our findings open new research avenues and inspire more\nefficient development of safe expert LLMs."
    },
    {
      "id": "2411.06823v1",
      "title": "Large Language Model in Medical Informatics: Direct Classification and Enhanced Text Representations for Automatic ICD Coding",
      "summary": "Addressing the complexity of accurately classifying International\nClassification of Diseases (ICD) codes from medical discharge summaries is\nchallenging due to the intricate nature of medical documentation. This paper\nexplores the use of Large Language Models (LLM), specifically the LLAMA\narchitecture, to enhance ICD code classification through two methodologies:\ndirect application as a classifier and as a generator of enriched text\nrepresentations within a Multi-Filter Residual Convolutional Neural Network\n(MultiResCNN) framework. We evaluate these methods by comparing them against\nstate-of-the-art approaches, revealing LLAMA's potential to significantly\nimprove classification outcomes by providing deep contextual insights into\nmedical texts."
    },
    {
      "id": "2411.06815v1",
      "title": "Streetwise Agents: Empowering Offline RL Policies to Outsmart Exogenous Stochastic Disturbances in RTC",
      "summary": "The difficulty of exploring and training online on real production systems\nlimits the scope of real-time online data/feedback-driven decision making. The\nmost feasible approach is to adopt offline reinforcement learning from limited\ntrajectory samples. However, after deployment, such policies fail due to\nexogenous factors that temporarily or permanently disturb/alter the transition\ndistribution of the assumed decision process structure induced by offline\nsamples. This results in critical policy failures and generalization errors in\nsensitive domains like Real-Time Communication (RTC). We solve this crucial\nproblem of identifying robust actions in presence of domain shifts due to\nunseen exogenous stochastic factors in the wild. As it is impossible to learn\ngeneralized offline policies within the support of offline data that are robust\nto these unseen exogenous disturbances, we propose a novel post-deployment\nshaping of policies (Streetwise), conditioned on real-time characterization of\nout-of-distribution sub-spaces. This leads to robust actions in bandwidth\nestimation (BWE) of network bottlenecks in RTC and in standard benchmarks. Our\nextensive experimental results on BWE and other standard offline RL benchmark\nenvironments demonstrate a significant improvement ($\\approx$ 18% on some\nscenarios) in final returns wrt. end-user metrics over state-of-the-art\nbaselines."
    },
    {
      "id": "2411.06812v1",
      "title": "Generative midtended cognition and Artificial Intelligence. Thinging with thinging things",
      "summary": "This paper introduces the concept of ``generative midtended cognition'',\nexploring the integration of generative AI with human cognition. The term\n\"generative\" reflects AI's ability to iteratively produce structured outputs,\nwhile \"midtended\" captures the potential hybrid (human-AI) nature of the\nprocess. It stands between traditional conceptions of intended creation,\nunderstood directed from within, and extended processes that bring\nexo-biological processes into the creative process. We examine current\ngenerative technologies (based on multimodal transformer architectures typical\nof large language models like ChatGPT), to explain how they can transform human\ncognitive agency beyond what standard theories of extended cognition can\ncapture. We suggest that the type of cognitive activity typical of the coupling\nbetween a human and generative technologies is closer (but not equivalent) to\nsocial cognition than to classical extended cognitive paradigms. Yet, it\ndeserves a specific treatment. We provide an explicit definition of generative\nmidtended cognition in which we treat interventions by AI systems as\nconstitutive of the agent's intentional creative processes. Furthermore, we\ndistinguish two dimensions of generative hybrid creativity: 1. Width: captures\nthe sensitivity of the context of the generative process (from the single\nletter to the whole historical and surrounding data), 2. Depth: captures the\ngranularity of iteration loops involved in the process. Generative midtended\ncognition stands in the middle depth between conversational forms of cognition\nin which complete utterances or creative units are exchanged, and\nmicro-cognitive (e.g. neural) subpersonal processes. Finally, the paper\ndiscusses the potential risks and benefits of widespread generative AI\nadoption, including the challenges of authenticity, generative power asymmetry,\nand creative boost or atrophy."
    },
    {
      "id": "2411.06810v1",
      "title": "JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset",
      "summary": "Learning-based image compression methods have improved in recent years and\nstarted to outperform traditional codecs. However, neural-network approaches\ncan unexpectedly introduce visual artifacts in some images. We therefore\npropose methods to separately detect three types of artifacts (texture and\nboundary degradation, color change, and text corruption), to localize the\naffected regions, and to quantify the artifact strength. We consider only those\nregions that exhibit distortion due solely to the neural compression but that a\ntraditional codec recovers successfully at a comparable bitrate. We employed\nour methods to collect artifacts for the JPEG AI verification model with\nrespect to HM-18.0, the H.265 reference software. We processed about 350,000\nunique images from the Open Images dataset using different compression-quality\nparameters; the result is a dataset of 46,440 artifacts validated through\ncrowd-sourced subjective assessment. Our proposed dataset and methods are\nvaluable for testing neural-network-based image codecs, identifying bugs in\nthese codecs, and enhancing their performance. We make source code of the\nmethods and the dataset publicly available."
    },
    {
      "id": "2411.06805v1",
      "title": "AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant",
      "summary": "The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses."
    },
    {
      "id": "2411.06804v1",
      "title": "Predicting ionic conductivity in solids from the machine-learned potential energy landscape",
      "summary": "Discovering new superionic materials is essential for advancing solid-state\nbatteries, which offer improved energy density and safety compared to the\ntraditional lithium-ion batteries with liquid electrolytes. Conventional\ncomputational methods for identifying such materials are resource-intensive and\nnot easily scalable. Recently, universal interatomic potential models have been\ndeveloped using equivariant graph neural networks. These models are trained on\nextensive datasets of first-principles force and energy calculations. One can\nachieve significant computational advantages by leveraging them as the\nfoundation for traditional methods of assessing the ionic conductivity, such as\nmolecular dynamics or nudged elastic band techniques. However, the\ngeneralization error from model inference on diverse atomic structures arising\nin such calculations can compromise the reliability of the results. In this\nwork, we propose an approach for the quick and reliable evaluation of ionic\nconductivity through the analysis of a universal interatomic potential. Our\nmethod incorporates a set of heuristic structure descriptors that effectively\nemploy the rich knowledge of the underlying model while requiring minimal\ngeneralization capabilities. Using our descriptors, we rank lithium-containing\nmaterials in the Materials Project database according to their expected ionic\nconductivity. Eight out of the ten highest-ranked materials are confirmed to be\nsuperionic at room temperature in first-principles calculations. Notably, our\nmethod achieves a speed-up factor of approximately 50 compared to molecular\ndynamics driven by a machine-learning potential, and is at least 3,000 times\nfaster compared to first-principles molecular dynamics."
    },
    {
      "id": "2411.06799v1",
      "title": "Structuring the Processing Frameworks for Data Stream Evaluation and Application",
      "summary": "The following work addresses the problem of frameworks for data stream\nprocessing that can be used to evaluate the solutions in an environment that\nresembles real-world applications. The definition of structured frameworks\nstems from a need to reliably evaluate the data stream classification methods,\nconsidering the constraints of delayed and limited label access. The current\nexperimental evaluation often boundlessly exploits the assumption of their\ncomplete and immediate access to monitor the recognition quality and to adapt\nthe methods to the changing concepts. The problem is leveraged by reviewing\ncurrently described methods and techniques for data stream processing and\nverifying their outcomes in simulated environment. The effect of the work is a\nproposed taxonomy of data stream processing frameworks, showing the linkage\nbetween drift detection and classification methods considering a natural\nphenomenon of label delay."
    },
    {
      "id": "2411.06798v1",
      "title": "LA4SR: illuminating the dark proteome with generative AI",
      "summary": "AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts."
    },
    {
      "id": "2411.06792v1",
      "title": "Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks",
      "summary": "By exploiting discrete signal processing and simulating brain neuron\ncommunication, Spiking Neural Networks (SNNs) offer a low-energy alternative to\nArtificial Neural Networks (ANNs). However, existing SNN models, still face\nhigh computational costs due to the numerous time steps as well as network\ndepth and scale. The tens of billions of neurons and trillions of synapses in\nthe human brain are developed from only 20,000 genes, which inspires us to\ndesign an efficient genetic encoding strategy that dynamic evolves to regulate\nlarge-scale deep SNNs at low cost. Therefore, we first propose a genetically\nscaled SNN encoding scheme that incorporates globally shared genetic\ninteractions to indirectly optimize neuronal encoding instead of weight, which\nobviously brings about reductions in parameters and energy consumption. Then, a\nspatio-temporal evolutionary framework is designed to optimize the inherently\ninitial wiring rules. Two dynamic regularization operators in the fitness\nfunction evolve the neuronal encoding to a suitable distribution and enhance\ninformation quality of the genetic interaction respectively, substantially\naccelerating evolutionary speed and improving efficiency. Experiments show that\nour approach compresses parameters by approximately 50\\% to 80\\%, while\noutperforming models on the same architectures by 0.21\\% to 4.38\\% on CIFAR-10,\nCIFAR-100 and ImageNet. In summary, the consistent trends of the proposed\ngenetically encoded spatio-temporal evolution across different datasets and\narchitectures highlight its significant enhancements in terms of efficiency,\nbroad scalability and robustness, demonstrating the advantages of the\nbrain-inspired evolutionary genetic coding for SNN optimization."
    },
    {
      "id": "2411.06790v1",
      "title": "Large-scale moral machine experiment on large language models",
      "summary": "The rapid advancement of Large Language Models (LLMs) and their potential\nintegration into autonomous driving systems necessitates understanding their\nmoral decision-making capabilities. While our previous study examined four\nprominent LLMs using the Moral Machine experimental framework, the dynamic\nlandscape of LLM development demands a more comprehensive analysis. Here, we\nevaluate moral judgments across 51 different LLMs, including multiple versions\nof proprietary models (GPT, Claude, Gemini) and open-source alternatives\n(Llama, Gemma), to assess their alignment with human moral preferences in\nautonomous driving scenarios. Using a conjoint analysis framework, we evaluated\nhow closely LLM responses aligned with human preferences in ethical dilemmas\nand examined the effects of model size, updates, and architecture. Results\nshowed that proprietary models and open-source models exceeding 10 billion\nparameters demonstrated relatively close alignment with human judgments, with a\nsignificant negative correlation between model size and distance from human\njudgments in open-source models. However, model updates did not consistently\nimprove alignment with human preferences, and many LLMs showed excessive\nemphasis on specific ethical principles. These findings suggest that while\nincreasing model size may naturally lead to more human-like moral judgments,\npractical implementation in autonomous driving systems requires careful\nconsideration of the trade-off between judgment quality and computational\nefficiency. Our comprehensive analysis provides crucial insights for the\nethical design of autonomous systems and highlights the importance of\nconsidering cultural contexts in AI moral decision-making."
    },
    {
      "id": "2411.06786v1",
      "title": "ScaleKD: Strong Vision Transformers Could Be Excellent Teachers",
      "summary": "In this paper, we question if well pre-trained vision transformer (ViT)\nmodels could be used as teachers that exhibit scalable properties to advance\ncross architecture knowledge distillation (KD) research, in the context of\nusing large-scale datasets for evaluation. To make this possible, our analysis\nunderlines the importance of seeking effective strategies to align (1) feature\ncomputing paradigm differences, (2) model scale differences, and (3) knowledge\ndensity differences. By combining three coupled components namely cross\nattention projector, dual-view feature mimicking and teacher parameter\nperception tailored to address the above problems, we present a simple and\neffective KD method, called ScaleKD. Our method can train student backbones\nthat span across a variety of convolutional neural network (CNN), multi-layer\nperceptron (MLP), and ViT architectures on image classification datasets,\nachieving state-of-the-art distillation performance. For instance, taking a\nwell pre-trained Swin-L as the teacher model, our method gets\n75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for\nMobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16\nmodels trained on ImageNet-1K dataset from scratch, showing\n3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the\nindividually trained counterparts. Intriguingly, when scaling up the size of\nteacher models or their pre-training datasets, our method showcases the desired\nscalable properties, bringing increasingly larger gains to student models. The\nstudent backbones trained by our method transfer well on downstream MS-COCO and\nADE20K datasets. More importantly, our method could be used as a more efficient\nalternative to the time-intensive pre-training paradigm for any target student\nmodel if a strong pre-trained ViT is available, reducing the amount of viewed\ntraining samples up to 195x."
    },
    {
      "id": "2411.06785v1",
      "title": "White-Box Diffusion Transformer for single-cell RNA-seq generation",
      "summary": "As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps://github.com/lingximamo/White-Box-Diffusion-Transformer"
    },
    {
      "id": "2411.06782v1",
      "title": "QuadWBG: Generalizable Quadrupedal Whole-Body Grasping",
      "summary": "Legged robots with advanced manipulation capabilities have the potential to\nsignificantly improve household duties and urban maintenance. Despite\nconsiderable progress in developing robust locomotion and precise manipulation\nmethods, seamlessly integrating these into cohesive whole-body control for\nreal-world applications remains challenging. In this paper, we present a\nmodular framework for robust and generalizable whole-body loco-manipulation\ncontroller based on a single arm-mounted camera. By using reinforcement\nlearning (RL), we enable a robust low-level policy for command execution over 5\ndimensions (5D) and a grasp-aware high-level policy guided by a novel metric,\nGeneralized Oriented Reachability Map (GORM). The proposed system achieves\nstate-of-the-art one-time grasping accuracy of 89% in the real world, including\nchallenging tasks such as grasping transparent objects. Through extensive\nsimulations and real-world experiments, we demonstrate that our system can\neffectively manage a large workspace, from floor level to above body height,\nand perform diverse whole-body loco-manipulation tasks."
    },
    {
      "id": "2411.06781v1",
      "title": "MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting",
      "summary": "Forecasting temporal processes such as virus spreading in epidemics often\nrequires more than just observed time-series data, especially at the beginning\nof a wave when data is limited. Traditional methods employ mechanistic models\nlike the SIR family, which make strong assumptions about the underlying\nspreading process, often represented as a small set of compact differential\nequations. Data-driven methods such as deep neural networks make no such\nassumptions and can capture the generative process in more detail, but fail in\nlong-term forecasting due to data limitations. We propose a new hybrid method\ncalled MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the\nlimitations of these two major approaches. MP-PINN instils the spreading\nmechanism into a neural network, enabling the mechanism to update in phases\nover time, reflecting the dynamics of the epidemics due to policy\ninterventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves\nsuperior performance over pure data-driven or model-driven approaches for both\nshort-term and long-term forecasting."
    },
    {
      "id": "2411.06776v1",
      "title": "Machine vision-aware quality metrics for compressed image and video assessment",
      "summary": "A main goal in developing video-compression algorithms is to enhance\nhuman-perceived visual quality while maintaining file size. But modern\nvideo-analysis efforts such as detection and recognition, which are integral to\nvideo surveillance and autonomous vehicles, involve so much data that they\nnecessitate machine-vision processing with minimal human intervention. In such\ncases, the video codec must be optimized for machine vision. This paper\nexplores the effects of compression on detection and recognition algorithms\n(objects, faces, and license plates) and introduces novel full-reference\nimage/video-quality metrics for each task, tailored to machine vision.\nExperimental results indicate our proposed metrics correlate better with the\nmachine-vision results for the respective tasks than do existing\nimage/video-quality metrics."
    },
    {
      "id": "2411.06773v1",
      "title": "Model Partition and Resource Allocation for Split Learning in Vehicular Edge Networks",
      "summary": "The integration of autonomous driving technologies with vehicular networks\npresents significant challenges in privacy preservation, communication\nefficiency, and resource allocation. This paper proposes a novel U-shaped split\nfederated learning (U-SFL) framework to address these challenges on the way of\nrealizing in vehicular edge networks. U-SFL is able to enhance privacy\nprotection by keeping both raw data and labels on the vehicular user (VU) side\nwhile enabling parallel processing across multiple vehicles. To optimize\ncommunication efficiency, we introduce a semantic-aware auto-encoder (SAE) that\nsignificantly reduces the dimensionality of transmitted data while preserving\nessential semantic information. Furthermore, we develop a deep reinforcement\nlearning (DRL) based algorithm to solve the NP-hard problem of dynamic resource\nallocation and split point selection. Our comprehensive evaluation demonstrates\nthat U-SFL achieves comparable classification performance to traditional split\nlearning (SL) while substantially reducing data transmission volume and\ncommunication latency. The proposed DRL-based optimization algorithm shows good\nconvergence in balancing latency, energy consumption, and learning performance."
    },
    {
      "id": "2411.06772v1",
      "title": "A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts",
      "summary": "Front-line police officers often categorize all police call reported cases of\nTelecom Fraud into 14 subcategories to facilitate targeted prevention measures,\nsuch as precise public education. However, the associated data is characterized\nby its large volume, diverse information content, and variations in expression.\nCurrently, there is a lack of efficient and accurate intelligent models to\nreplace manual classification, which, while precise, is relatively inefficient.\nTo address these challenges, this paper proposes a text classification model\nthat combines adversarial training with Pre-trained Language Model and neural\nnetworks. The Linguistically-motivated Pre-trained Language Model model\nextracts three types of language features and then utilizes the Fast Gradient\nMethod algorithm to perturb the generated embedding layer. Subsequently, the\nBi-directional Long Short-Term Memory and Convolutional Neural Networks\nnetworks extract contextual syntactic information and local semantic\ninformation, respectively. The model achieved an 83.9% classification accuracy\nwhen trained on a portion of telecom fraud case data provided by the\noperational department. The model established in this paper has been deployed\nin the operational department, freeing up a significant amount of manpower and\nimproving the department's efficiency in combating Telecom Fraud crimes.\nFurthermore, considering the universality of the model established in this\npaper, other application scenarios await further exploration."
    },
    {
      "id": "2411.06770v2",
      "title": "Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis",
      "summary": "Combining gradient compression methods (e.g., CountSketch, quantization) and\nadaptive optimizers (e.g., Adam, AMSGrad) is a desirable goal in federated\nlearning (FL), with potential benefits on both fewer communication rounds and\nless per-round communication. In spite of the preliminary empirical success of\nsketched adaptive methods, existing convergence analyses show the communication\ncost to have a linear dependence on the ambient dimension, i.e., number of\nparameters, which is prohibitively high for modern deep learning models. In\nthis work, we introduce specific sketched adaptive federated learning (SAFL)\nalgorithms and, as our main contribution, provide theoretical convergence\nanalyses in different FL settings with guarantees on communication cost\ndepending only logarithmically (instead of linearly) on the ambient dimension.\nUnlike existing analyses, we show that the entry-wise sketching noise existent\nin the preconditioners and the first moments of SAFL can be implicitly\naddressed by leveraging the recently-popularized anisotropic curvatures in deep\nlearning losses, e.g., fast decaying loss Hessian eigen-values. In the i.i.d.\nclient setting of FL, we show that SAFL achieves asymptotic $O(1/\\sqrt{T})$\nconvergence, and converges faster in the initial epochs. In the non-i.i.d.\nclient setting, where non-adaptive methods lack convergence guarantees, we show\nthat SACFL (SAFL with clipping) algorithms can provably converge in spite of\nthe additional heavy-tailed noise. Our theoretical claims are supported by\nempirical studies on vision and language tasks, and in both fine-tuning and\ntraining-from-scratch regimes. Surprisingly, as a by-product of our analysis,\nthe proposed SAFL methods are competitive with the state-of-the-art\ncommunication-efficient federated learning algorithms based on error feedback."
    },
    {
      "id": "2411.06767v1",
      "title": "PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing",
      "summary": "Code Large Language Models (Code LLMs), such as Code llama and\nDeepSeek-Coder, have demonstrated exceptional performance in the code\ngeneration tasks. However, most existing models focus on the abilities of\ngenerating correct code, but often struggle with bug repair. We introduce a\nsuit of methods to enhance LLM's SQL bug-fixing abilities. The methods are\nmainly consisted of two parts: A Progressive Dataset Construction (PDC) from\nscratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data\nexpansion methods from the perspectives of breadth first and depth first\nrespectively. DM-SFT introduces an efficient bug-fixing supervised learning\napproach, which effectively reduce the total training steps and mitigate the\n\"disorientation\" in SQL code bug-fixing training. In our evaluation, the code\nLLM models trained with two methods have exceeds all current best performing\nmodel which size is much larger."
    },
    {
      "id": "2411.06765v1",
      "title": "Research on an intelligent fault diagnosis method for nuclear power plants based on ETCN-SSA combined algorithm",
      "summary": "Utilizing fault diagnosis methods is crucial for nuclear power professionals\nto achieve efficient and accurate fault diagnosis for nuclear power plants\n(NPPs). The performance of traditional methods is limited by their dependence\non complex feature extraction and skilled expert knowledge, which can be\ntime-consuming and subjective. This paper proposes a novel intelligent fault\ndiagnosis method for NPPs that combines enhanced temporal convolutional network\n(ETCN) with sparrow search algorithm (SSA). ETCN utilizes temporal\nconvolutional network (TCN), self-attention (SA) mechanism and residual block\nfor enhancing performance. ETCN excels at extracting local features and\ncapturing time series information, while SSA adaptively optimizes its\nhyperparameters for superior performance. The proposed method's performance is\nexperimentally verified on a CPR1000 simulation dataset. Compared to other\nadvanced intelligent fault diagnosis methods, the proposed one demonstrates\nsuperior performance across all evaluation metrics. This makes it a promising\ntool for NPP intelligent fault diagnosis, ultimately enhancing operational\nreliability."
    },
    {
      "id": "2411.06764v1",
      "title": "Multi-Stage Knowledge Integration of Vision-Language Models for Continual Learning",
      "summary": "Vision Language Models (VLMs), pre-trained on large-scale image-text\ndatasets, enable zero-shot predictions for unseen data but may underperform on\nspecific unseen tasks. Continual learning (CL) can help VLMs effectively adapt\nto new data distributions without joint training, but faces challenges of\ncatastrophic forgetting and generalization forgetting. Although significant\nprogress has been achieved by distillation-based methods, they exhibit two\nsevere limitations. One is the popularly adopted single-teacher paradigm fails\nto impart comprehensive knowledge, The other is the existing methods\ninadequately leverage the multimodal information in the original training\ndataset, instead they rely on additional data for distillation, which increases\ncomputational and storage overhead. To mitigate both limitations, by drawing on\nKnowledge Integration Theory (KIT), we propose a Multi-Stage Knowledge\nIntegration network (MulKI) to emulate the human learning process in\ndistillation methods. MulKI achieves this through four stages, including\nEliciting Ideas, Adding New Ideas, Distinguishing Ideas, and Making\nConnections. During the four stages, we first leverage prototypes to align\nacross modalities, eliciting cross-modal knowledge, then adding new knowledge\nby constructing fine-grained intra- and inter-modality relationships with\nprototypes. After that, knowledge from two teacher models is adaptively\ndistinguished and re-weighted. Finally, we connect between models from intra-\nand inter-task, integrating preceding and new knowledge. Our method\ndemonstrates significant improvements in maintaining zero-shot capabilities\nwhile supporting continual learning across diverse downstream tasks, showcasing\nits potential in adapting VLMs to evolving data distributions."
    },
    {
      "id": "2411.06762v1",
      "title": "Precision Glass Thermoforming Assisted by Neural Networks",
      "summary": "Glass with good processability, chemical inertness, and optical transparency\nhas been widely used in optical and aesthetic products, many of which require\ncurve pro-files with high precision. To meet the increasingly tightened\ngeometrical tolerances and fast product updating rates, the traditional\napproach of developing a thermoform-ing process through trials and errors can\ncause a large waste of time and resources and often end up with failure. Hence,\nthere is a need to develop an efficient predictive model, replacing the costly\nsimulations or experiments, to assist the design of preci-sion glass\nthermoforming. In this work, we report a dimensionless back-propagation neural\nnetwork (BPNN) that can adequately predict the form errors and thus compen-sate\nfor these errors in mold design to achieve precision glass molding. Based on\nthe precision molds, also discussed is the issue of error magnification\nconsidering that cover glass for AR/VR glasses or smartphones, with extremely\nlarge scale of produc-tion, may require a lower level of mold machining\naccuracy. It is expected that this BPNN will also be implementable in the\nglass-manufacturing industry, i.e., trained using industrial data for precision\nmold designs."
    },
    {
      "id": "2411.06749v1",
      "title": "KLCBL: An Improved Police Incident Classification Model",
      "summary": "Police incident data is crucial for public security intelligence, yet\ngrassroots agencies struggle with efficient classification due to manual\ninefficiency and automated system limitations, especially in telecom and online\nfraud cases. This research proposes a multichannel neural network model, KLCBL,\nintegrating Kolmogorov-Arnold Networks (KAN), a linguistically enhanced text\npreprocessing approach (LERT), Convolutional Neural Network (CNN), and\nBidirectional Long Short-Term Memory (BiLSTM) for police incident\nclassification. Evaluated with real data, KLCBL achieved 91.9% accuracy,\noutperforming baseline models. The model addresses classification challenges,\nenhances police informatization, improves resource allocation, and offers broad\napplicability to other classification tasks."
    },
    {
      "id": "2411.06746v1",
      "title": "Neuromodulated Meta-Learning",
      "summary": "Humans excel at adapting perceptions and actions to diverse environments,\nenabling efficient interaction with the external world. This adaptive\ncapability relies on the biological nervous system (BNS), which activates\ndifferent brain regions for distinct tasks. Meta-learning similarly trains\nmachines to handle multiple tasks but relies on a fixed network structure, not\nas flexible as BNS. To investigate the role of flexible network structure (FNS)\nin meta-learning, we conduct extensive empirical and theoretical analyses,\nfinding that model performance is tied to structure, with no universally\noptimal pattern across tasks. This reveals the crucial role of FNS in\nmeta-learning, ensuring meta-learning to generate the optimal structure for\neach task, thereby maximizing the performance and learning efficiency of\nmeta-learning. Motivated by this insight, we propose to define, measure, and\nmodel FNS in meta-learning. First, we define that an effective FNS should\npossess frugality, plasticity, and sensitivity. Then, to quantify FNS in\npractice, we present three measurements for these properties, collectively\nforming the \\emph{structure constraint} with theoretical supports. Building on\nthis, we finally propose Neuromodulated Meta-Learning (NeuronML) to model FNS\nin meta-learning. It utilizes bi-level optimization to update both weights and\nstructure with the structure constraint. Extensive theoretical and empirical\nevaluations demonstrate the effectiveness of NeuronML on various tasks. Code is\npublicly available at\n\\href{https://github.com/WangJingyao07/NeuronML}{https://github.com/WangJingyao07/NeuronML}."
    },
    {
      "id": "2411.06741v1",
      "title": "Methane projections from Canada's oil sands tailings using scientific deep learning reveal significant underestimation",
      "summary": "Bitumen extraction for the production of synthetic crude oil in Canada's\nAthabasca Oil Sands industry has recently come under spotlight for being a\nsignificant source of greenhouse gas emission. A major cause of concern is\nmethane, a greenhouse gas produced by the anaerobic biodegradation of\nhydrocarbons in oil sands residues, or tailings, stored in settle basins\ncommonly known as oil sands tailing ponds. In order to determine the methane\nemitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory\ncontrolled experiments, and industrial reports to train a physics constrained\nmachine learning model. Our trained model can successfully identify the\ndirections of active ponds and estimate their emission levels, which are\ngenerally hard to obtain due to data sampling restrictions. We found that each\nactive oil sands tailing pond could emit between 950 to 1500 tonnes of methane\nper year, whose environmental impact is equivalent to carbon dioxide emissions\nfrom at least 6000 gasoline powered vehicles. Although abandoned ponds are\noften presumed to have insignificant emissions, our findings indicate that\nthese ponds could become active over time and potentially emit up to 1000\ntonnes of methane each year. Taking an average over all datasets that was used\nin model training, we estimate that emissions around major oil sands regions\nwould need to be reduced by approximately 12% over a year, to reduce the\naverage methane concentrations to 2005 levels."
    },
    {
      "id": "2411.06740v1",
      "title": "Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening",
      "summary": "Molecular docking enables virtual screening of compound libraries to identify\npotential ligands that target proteins of interest, a crucial step in drug\ndevelopment; however, as the size of the compound library increases, the\ncomputational complexity of traditional docking models increases. Deep learning\nalgorithms can provide data-driven research and development models to increase\nthe speed of the docking process. Unfortunately, few models can achieve\nsuperior screening performance compared to that of traditional models.\nTherefore, a novel deep learning-based docking approach named Dockformer is\nintroduced in this study. Dockformer leverages multimodal information to\ncapture the geometric topology and structural knowledge of molecules and can\ndirectly generate binding conformations with the corresponding confidence\nmeasures in an end-to-end manner. The experimental results show that Dockformer\nachieves success rates of 90.53\\% and 82.71\\% on the PDBbind core set and\nPoseBusters benchmarks, respectively, and more than a 100-fold increase in the\ninference process speed, outperforming almost all state-of-the-art docking\nmethods. In addition, the ability of Dockformer to identify the main protease\ninhibitors of coronaviruses is demonstrated in a real-world virtual screening\nscenario. Considering its high docking accuracy and screening efficiency,\nDockformer can be regarded as a powerful and robust tool in the field of drug\ndesign."
    },
    {
      "id": "2411.06739v1",
      "title": "Beating Adversarial Low-Rank MDPs with Unknown Transition and Bandit Feedback",
      "summary": "We consider regret minimization in low-rank MDPs with fixed transition and\nadversarial losses. Previous work has investigated this problem under either\nfull-information loss feedback with unknown transitions (Zhao et al., 2024), or\nbandit loss feedback with known transition (Foster et al., 2022). First, we\nimprove the $poly(d, A, H)T^{5/6}$ regret bound of Zhao et al. (2024) to\n$poly(d, A, H)T^{2/3}$ for the full-information unknown transition setting,\nwhere d is the rank of the transitions, A is the number of actions, H is the\nhorizon length, and T is the number of episodes. Next, we initiate the study on\nthe setting with bandit loss feedback and unknown transitions. Assuming that\nthe loss has a linear structure, we propose both model based and model free\nalgorithms achieving $poly(d, A, H)T^{2/3}$ regret, though they are\ncomputationally inefficient. We also propose oracle-efficient model-free\nalgorithms with $poly(d, A, H)T^{4/5}$ regret. We show that the linear\nstructure is necessary for the bandit case without structure on the reward\nfunction, the regret has to scale polynomially with the number of states. This\nis contrary to the full-information case (Zhao et al., 2024), where the regret\ncan be independent of the number of states even for unstructured reward\nfunction."
    },
    {
      "id": "2411.06736v2",
      "title": "Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When Memory",
      "summary": "Significant advances have been made in developing general-purpose embodied AI\nin environments like Minecraft through the adoption of LLM-augmented\nhierarchical approaches. While these approaches, which combine high-level\nplanners with low-level controllers, show promise, low-level controllers\nfrequently become performance bottlenecks due to repeated failures. In this\npaper, we argue that the primary cause of failure in many low-level controllers\nis the absence of an episodic memory system. To address this, we introduce Mr.\nSteve (Memory Recall Steve-1), a novel low-level controller equipped with Place\nEvent Memory (PEM), a form of episodic memory that captures what, where, and\nwhen information from episodes. This directly addresses the main limitation of\nthe popular low-level controller, Steve-1. Unlike previous models that rely on\nshort-term memory, PEM organizes spatial and event-based data, enabling\nefficient recall and navigation in long-horizon tasks. Additionally, we propose\nan Exploration Strategy and a Memory-Augmented Task Solving Framework, allowing\nagents to alternate between exploration and task-solving based on recalled\nevents. Our approach significantly improves task-solving and exploration\nefficiency compared to existing methods. We will release our code and demos on\nthe project page: https://sites.google.com/view/mr-steve."
    },
    {
      "id": "2411.06735v1",
      "title": "Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data",
      "summary": "Current forecasting approaches are largely unimodal and ignore the rich\ntextual data that often accompany the time series due to lack of well-curated\nmultimodal benchmark dataset. In this work, we develop TimeText Corpus (TTC), a\ncarefully curated, time-aligned text and time dataset for multimodal\nforecasting. Our dataset is composed of sequences of numbers and text aligned\nto timestamps, and includes data from two different domains: climate science\nand healthcare. Our data is a significant contribution to the rare selection of\navailable multimodal datasets. We also propose the Hybrid Multi-Modal\nForecaster (Hybrid-MMF), a multimodal LLM that jointly forecasts both text and\ntime series data using shared embeddings. However, contrary to our\nexpectations, our Hybrid-MMF model does not outperform existing baselines in\nour experiments. This negative result highlights the challenges inherent in\nmultimodal forecasting. Our code and data are available at\nhttps://github.com/Rose-STL-Lab/Multimodal_ Forecasting."
    },
    {
      "id": "2411.06733v1",
      "title": "GSL-PCD: Improving Generalist-Specialist Learning with Point Cloud Feature-based Task Partitioning",
      "summary": "Generalization in Deep Reinforcement Learning (DRL) across unseen environment\nvariations often requires training over a diverse set of scenarios. Many\nexisting DRL algorithms struggle with efficiency when handling numerous\nvariations. The Generalist-Specialist Learning (GSL) framework addresses this\nby first training a generalist model on all variations, then creating\nspecialists from the generalist's weights, each focusing on a subset of\nvariations. The generalist then refines its learning with assistance from the\nspecialists. However, random task partitioning in GSL can impede performance by\nassigning vastly different variations to the same specialist, often resulting\nin each specialist focusing on only one variation, which raises computational\ncosts. To improve this, we propose Generalist-Specialist Learning with Point\nCloud Feature-based Task Partitioning (GSL-PCD). Our approach clusters\nenvironment variations based on features extracted from object point clouds and\nuses balanced clustering with a greedy algorithm to assign similar variations\nto the same specialist. Evaluations on robotic manipulation tasks from the\nManiSkill benchmark demonstrate that point cloud feature-based partitioning\noutperforms vanilla partitioning by 9.4%, with a fixed number of specialists,\nand reduces computational and sample requirements by 50% to achieve comparable\nperformance."
    },
    {
      "id": "2411.06729v1",
      "title": "Reverse Prompt Engineering",
      "summary": "This paper explores a new black-box, zero-shot language model inversion\nproblem and proposes an innovative framework for prompt reconstruction using\nonly text outputs from a language model. Leveraging a large language model\nalongside an optimization algorithm, the proposed method effectively recovers\nprompts with minimal resources. Experimental results on several datasets\nderived from public sources indicate that the proposed approach achieves\nhigh-quality prompt recovery and generates prompts more similar to the\noriginals than current state-of-the-art methods. Additionally, the use-case\nstudy demonstrates the method's strong potential for generating high-quality\ntext data."
    },
    {
      "id": "2411.06728v1",
      "title": "On the Principles of ReLU Networks with One Hidden Layer",
      "summary": "A neural network with one hidden layer or a two-layer network (regardless of\nthe input layer) is the simplest feedforward neural network, whose mechanism\nmay be the basis of more general network architectures. However, even to this\ntype of simple architecture, it is also a ``black box''; that is, it remains\nunclear how to interpret the mechanism of its solutions obtained by the\nback-propagation algorithm and how to control the training process through a\ndeterministic way. This paper systematically studies the first problem by\nconstructing universal function-approximation solutions. It is shown that, both\ntheoretically and experimentally, the training solution for the one-dimensional\ninput could be completely understood, and that for a higher-dimensional input\ncan also be well interpreted to some extent. Those results pave the way for\nthoroughly revealing the black box of two-layer ReLU networks and advance the\nunderstanding of deep ReLU networks."
    },
    {
      "id": "2411.06723v1",
      "title": "Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy",
      "summary": "Chatbots or conversational agents (CAs) are increasingly used to improve\naccess to digital psychotherapy. Many current systems rely on rigid, rule-based\ndesigns, heavily dependent on expert-crafted dialogue scripts for guiding\ntherapeutic conversations. Although recent advances in large language models\n(LLMs) offer the potential for more flexible interactions, their lack of\ncontrollability and transparency poses significant challenges in sensitive\nareas like psychotherapy. In this work, we explored how aligning LLMs with\nexpert-crafted scripts can enhance psychotherapeutic chatbot performance. Our\ncomparative study showed that LLMs aligned with expert-crafted scripts through\nprompting and fine-tuning significantly outperformed both pure LLMs and\nrule-based chatbots, achieving a more effective balance between dialogue\nflexibility and adherence to therapeutic principles. Building on findings, we\nproposed ``Script-Strategy Aligned Generation (SSAG)'', a flexible alignment\napproach that reduces reliance on fully scripted content while enhancing LLMs'\ntherapeutic adherence and controllability. In a 10-day field study, SSAG\ndemonstrated performance comparable to full script alignment and outperformed\nrule-based chatbots, empirically supporting SSAG as an efficient approach for\naligning LLMs with domain expertise. Our work advances LLM applications in\npsychotherapy by providing a controllable, adaptable, and scalable solution for\ndigital interventions, reducing reliance on expert effort. It also provides a\ncollaborative framework for domain experts and developers to efficiently build\nexpertise-aligned chatbots, broadening access to psychotherapy and behavioral\ninterventions."
    },
    {
      "id": "2411.06722v1",
      "title": "Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models",
      "summary": "Presenting users with diverse responses from foundation models is crucial for\nenhancing user experience and accommodating varying preferences. However,\ngenerating multiple high-quality and diverse responses without sacrificing\naccuracy remains a challenge, especially when using greedy sampling. In this\nwork, we propose a novel framework, Synthesize-Partition-Adapt (SPA), that\nleverages the abundant synthetic data available in many domains to elicit\ndiverse responses from foundation models. By leveraging signal provided by data\nattribution methods such as influence functions, SPA partitions data into\nsubsets, each targeting unique aspects of the data, and trains multiple model\nadaptations optimized for these subsets. Experimental results demonstrate the\neffectiveness of our approach in diversifying foundation model responses while\nmaintaining high quality, showcased through the HumanEval and MBPP tasks in the\ncode generation domain and several tasks in the natural language understanding\ndomain, highlighting its potential to enrich user experience across various\napplications."
    },
    {
      "id": "2411.06720v1",
      "title": "Real-time Monitoring and Analysis of Track and Field Athletes Based on Edge Computing and Deep Reinforcement Learning Algorithm",
      "summary": "This research focuses on real-time monitoring and analysis of track and field\nathletes, addressing the limitations of traditional monitoring systems in terms\nof real-time performance and accuracy. We propose an IoT-optimized system that\nintegrates edge computing and deep learning algorithms. Traditional systems\noften experience delays and reduced accuracy when handling complex motion data,\nwhereas our method, by incorporating a SAC-optimized deep learning model within\nthe IoT architecture, achieves efficient motion recognition and real-time\nfeedback. Experimental results show that this system significantly outperforms\ntraditional methods in response time, data processing accuracy, and energy\nefficiency, particularly excelling in complex track and field events. This\nresearch not only enhances the precision and efficiency of athlete monitoring\nbut also provides new technical support and application prospects for sports\nscience research."
    },
    {
      "id": "2411.06719v1",
      "title": "Shallow Signed Distance Functions for Kinematic Collision Bodies",
      "summary": "We present learning-based implicit shape representations designed for\nreal-time avatar collision queries arising in the simulation of clothing.\nSigned distance functions (SDFs) have been used for such queries for many years\ndue to their computational efficiency. Recently deep neural networks have been\nused for implicit shape representations (DeepSDFs) due to their ability to\nrepresent multiple shapes with modest memory requirements compared to\ntraditional representations over dense grids. However, the computational\nexpense of DeepSDFs prevents their use in real-time clothing simulation\napplications. We design a learning-based representation of SDFs for human\navatars whoes bodies change shape kinematically due to joint-based skinning.\nRather than using a single DeepSDF for the entire avatar, we use a collection\nof extremely computationally efficient (shallow) neural networks that represent\nlocalized deformations arising from changes in body shape induced by the\nvariation of a single joint. This requires a stitching process to combine each\nshallow SDF in the collection together into one SDF representing the signed\nclosest distance to the boundary of the entire body. To achieve this we augment\neach shallow SDF with an additional output that resolves whether or not the\nindividual shallow SDF value is referring to a closest point on the boundary of\nthe body, or to a point on the interior of the body (but on the boundary of the\nindividual shallow SDF). Our model is extremely fast and accurate and we\ndemonstrate its applicability with real-time simulation of garments driven by\nanimated characters."
    },
    {
      "id": "2411.06718v1",
      "title": "Truth, beauty, and goodness in grand unification: a machine learning approach",
      "summary": "We investigate the flavour sector of the supersymmetric $SU(5)$ Grand Unified\nTheory (GUT) model using machine learning techniques. The minimal $SU(5)$ model\nis known to predict fermion masses that disagree with observed values in\nnature. There are two well-known approaches to address this issue: one involves\nintroducing a 45-representation Higgs field, while the other employs a\nhigher-dimensional operator involving the 24-representation GUT Higgs field. We\ncompare these two approaches by numerically optimising a loss function, defined\nas the ratio of determinants of mass matrices. Our findings indicate that the\n24-Higgs approach achieves the observed fermion masses with smaller\nmodifications to the original minimal $SU(5)$ model."
    },
    {
      "id": "2411.06714v1",
      "title": "DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations",
      "summary": "Weather radar data synthesis can fill in data for areas where ground\nobservations are missing. Existing methods often employ reconstruction-based\napproaches with MSE loss to reconstruct radar data from satellite observation.\nHowever, such methods lead to over-smoothing, which hinders the generation of\nhigh-frequency details or high-value observation areas associated with\nconvective weather. To address this issue, we propose a two-stage\ndiffusion-based method called DiffSR. We first pre-train a reconstruction model\non global-scale data to obtain radar estimation and then synthesize radar\nreflectivity by combining radar estimation results with satellite data as\nconditions for the diffusion model. Extensive experiments show that our method\nachieves state-of-the-art (SOTA) results, demonstrating the ability to generate\nhigh-frequency details and high-value areas."
    },
    {
      "id": "2411.06713v1",
      "title": "Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models",
      "summary": "This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned\nfor medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and\nLlama-3.2-3B) in clinical documentation. We analyzed de-identified patient\ntranscripts from partner clinics, using clinician-provided SOAP notes as the\nground truth. Each model generated SOAP summaries using zero-shot prompting,\nwith performance assessed via recall, precision, and F1 scores. Sporo\noutperformed all models, achieving the highest recall (73.3%), precision\n(78.6%), and F1 score (75.3%) with the lowest performance variance.\nStatistically significant differences (p < 0.05) were found between Sporo and\nthe other models, with post-hoc tests showing significant improvements over\nGPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to\n10%, the difference was not statistically significant (p = 0.25). Clinical user\nsatisfaction, measured with a modified PDQI-9 inventory, favored Sporo.\nEvaluations indicated Sporo's outputs were more accurate and relevant. This\nhighlights the potential of Sporo's multi-agentic architecture to improve\nclinical workflows."
    },
    {
      "id": "2411.06711v1",
      "title": "Anytime Probabilistically Constrained Provably Convergent Online Belief Space Planning",
      "summary": "Taking into account future risk is essential for an autonomously operating\nrobot to find online not only the best but also a safe action to execute. In\nthis paper, we build upon the recently introduced formulation of probabilistic\nbelief-dependent constraints. We present an anytime approach employing the\nMonte Carlo Tree Search (MCTS) method in continuous domains. Unlike previous\napproaches, our method assures safety anytime with respect to the currently\nexpanded search tree without relying on the convergence of the search. We prove\nconvergence in probability with an exponential rate of a version of our\nalgorithms and study proposed techniques via extensive simulations. Even with a\ntiny number of tree queries, the best action found by our approach is much\nsafer than the baseline. Moreover, our approach constantly finds better than\nthe baseline action in terms of objective. This is because we revise the values\nand statistics maintained in the search tree and remove from them the\ncontribution of the pruned actions."
    },
    {
      "id": "2411.06710v1",
      "title": "Model Fusion through Bayesian Optimization in Language Model Fine-Tuning",
      "summary": "Fine-tuning pre-trained models for downstream tasks is a widely adopted\ntechnique known for its adaptability and reliability across various domains.\nDespite its conceptual simplicity, fine-tuning entails several troublesome\nengineering choices, such as selecting hyperparameters and determining\ncheckpoints from an optimization trajectory. To tackle the difficulty of\nchoosing the best model, one effective solution is model fusion, which combines\nmultiple models in a parameter space. However, we observe a large discrepancy\nbetween loss and metric landscapes during the fine-tuning of pre-trained\nlanguage models. Building on this observation, we introduce a novel model\nfusion technique that optimizes both the desired metric and loss through\nmulti-objective Bayesian optimization. In addition, to effectively select\nhyperparameters, we establish a two-stage procedure by integrating Bayesian\noptimization processes into our framework. Experiments across various\ndownstream tasks show considerable performance improvements using our Bayesian\noptimization-guided method."
    },
    {
      "id": "2411.06697v1",
      "title": "Learning a Single Neuron Robustly to Distributional Shifts and Adversarial Label Noise",
      "summary": "We study the problem of learning a single neuron with respect to the\n$L_2^2$-loss in the presence of adversarial distribution shifts, where the\nlabels can be arbitrary, and the goal is to find a ``best-fit'' function. More\nprecisely, given training samples from a reference distribution\n$\\mathcal{p}_0$, the goal is to approximate the vector $\\mathbf{w}^*$ which\nminimizes the squared loss with respect to the worst-case distribution that is\nclose in $\\chi^2$-divergence to $\\mathcal{p}_{0}$. We design a computationally\nefficient algorithm that recovers a vector $ \\hat{\\mathbf{w}}$ satisfying\n$\\mathbb{E}_{\\mathcal{p}^*} (\\sigma(\\hat{\\mathbf{w}} \\cdot \\mathbf{x}) - y)^2\n\\leq C \\, \\mathbb{E}_{\\mathcal{p}^*} (\\sigma(\\mathbf{w}^* \\cdot \\mathbf{x}) -\ny)^2 + \\epsilon$, where $C>1$ is a dimension-independent constant and\n$(\\mathbf{w}^*, \\mathcal{p}^*)$ is the witness attaining the min-max risk\n$\\min_{\\mathbf{w}~:~\\|\\mathbf{w}\\| \\leq W} \\max_{\\mathcal{p}}\n\\mathbb{E}_{(\\mathbf{x}, y) \\sim \\mathcal{p}} (\\sigma(\\mathbf{w} \\cdot\n\\mathbf{x}) - y)^2 - \\nu \\chi^2(\\mathcal{p}, \\mathcal{p}_0)$. Our algorithm\nfollows a primal-dual framework and is designed by directly bounding the risk\nwith respect to the original, nonconvex $L_2^2$ loss. From an optimization\nstandpoint, our work opens new avenues for the design of primal-dual algorithms\nunder structured nonconvexity."
    },
    {
      "id": "2411.06691v1",
      "title": "Autonomous Droplet Microfluidic Design Framework with Large Language Models",
      "summary": "Droplet-based microfluidic devices have substantial promise as cost-effective\nalternatives to current assessment tools in biological research. Moreover,\nmachine learning models that leverage tabular data, including input design\nparameters and their corresponding efficiency outputs, are increasingly\nutilised to automate the design process of these devices and to predict their\nperformance. However, these models fail to fully leverage the data presented in\nthe tables, neglecting crucial contextual information, including column\nheadings and their associated descriptions. This study presents\nMicroFluidic-LLMs, a framework designed for processing and feature extraction,\nwhich effectively captures contextual information from tabular data formats.\nMicroFluidic-LLMs overcomes processing challenges by transforming the content\ninto a linguistic format and leveraging pre-trained large language models\n(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11\nprediction tasks, covering aspects such as geometry, flow conditions, regimes,\nand performance, utilising a publicly available dataset on flow-focusing\ndroplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can\nempower deep neural network models to be highly effective and straightforward\nwhile minimising the need for extensive data preprocessing. Moreover, the\nexceptional performance of deep neural network models, particularly when\ncombined with advanced natural language processing models such as DistilBERT\nand GPT-2, reduces the mean absolute error in the droplet diameter and\ngeneration rate by nearly 5- and 7-fold, respectively, and enhances the regime\nclassification accuracy by over 4%, compared with the performance reported in a\nprevious study. This study lays the foundation for the huge potential\napplications of LLMs and machine learning in a wider spectrum of microfluidic\napplications."
    },
    {
      "id": "2411.06688v1",
      "title": "Shedding Light on Problems with Hyperbolic Graph Learning",
      "summary": "Recent papers in the graph machine learning literature have introduced a\nnumber of approaches for hyperbolic representation learning. The asserted\nbenefits are improved performance on a variety of graph tasks, node\nclassification and link prediction included. Claims have also been made about\nthe geometric suitability of particular hierarchical graph datasets to\nrepresentation in hyperbolic space. Despite these claims, our work makes a\nsurprising discovery: when simple Euclidean models with comparable numbers of\nparameters are properly trained in the same environment, in most cases, they\nperform as well, if not better, than all introduced hyperbolic graph\nrepresentation learning models, even on graph datasets previously claimed to be\nthe most hyperbolic as measured by Gromov $\\delta$-hyperbolicity (i.e., perfect\ntrees). This observation gives rise to a simple question: how can this be? We\nanswer this question by taking a careful look at the field of hyperbolic graph\nrepresentation learning as it stands today, and find that a number of papers\nfail to diligently present baselines, make faulty modelling assumptions when\nconstructing algorithms, and use misleading metrics to quantify geometry of\ngraph datasets. We take a closer look at each of these three problems,\nelucidate the issues, perform an analysis of methods, and introduce a\nparametric family of benchmark datasets to ascertain the applicability of\n(hyperbolic) graph neural networks."
    },
    {
      "id": "2411.06685v1",
      "title": "High-Frequency Enhanced Hybrid Neural Representation for Video Compression",
      "summary": "Neural Representations for Videos (NeRV) have simplified the video codec\nprocess and achieved swift decoding speeds by encoding video content into a\nneural network, presenting a promising solution for video compression. However,\nexisting work overlooks the crucial issue that videos reconstructed by these\nmethods lack high-frequency details. To address this problem, this paper\nintroduces a High-Frequency Enhanced Hybrid Neural Representation Network. Our\nmethod focuses on leveraging high-frequency information to improve the\nsynthesis of fine details by the network. Specifically, we design a wavelet\nhigh-frequency encoder that incorporates Wavelet Frequency Decomposer (WFD)\nblocks to generate high-frequency feature embeddings. Next, we design the\nHigh-Frequency Feature Modulation (HFM) block, which leverages the extracted\nhigh-frequency embeddings to enhance the fitting process of the decoder.\nFinally, with the refined Harmonic decoder block and a Dynamic Weighted\nFrequency Loss, we further reduce the potential loss of high-frequency\ninformation. Experiments on the Bunny and UVG datasets demonstrate that our\nmethod outperforms other methods, showing notable improvements in detail\npreservation and compression performance."
    },
    {
      "id": "2411.06681v1",
      "title": "WDMoE: Wireless Distributed Mixture of Experts for Large Language Models",
      "summary": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but the role of wireless networks in\nsupporting LLMs has not been thoroughly explored. In this paper, we propose a\nwireless distributed Mixture of Experts (WDMoE) architecture to enable\ncollaborative deployment of LLMs across edge servers at the base station (BS)\nand mobile devices in wireless networks. Specifically, we decompose the MoE\nlayer in LLMs by placing the gating network and the preceding neural network\nlayer at BS, while distributing the expert networks among the devices. This\ndeployment leverages the parallel inference capabilities of expert networks on\nmobile devices, effectively utilizing the limited computing and caching\nresources of these devices. Accordingly, we develop a performance metric for\nWDMoE-based LLMs, which accounts for both model capability and latency. To\nminimize the latency while maintaining accuracy, we jointly optimize expert\nselection and bandwidth allocation based on the performance metric. Moreover,\nwe build a hardware testbed using NVIDIA Jetson kits to validate the\neffectiveness of WDMoE. Both theoretical simulations and practical hardware\nexperiments demonstrate that the proposed method can significantly reduce the\nlatency without compromising LLM performance."
    },
    {
      "id": "2411.06672v1",
      "title": "What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance",
      "summary": "We explore the impact of pre-training data composition on the performance of\nsmall language models in a sample-efficient setting. Using datasets limited to\n10 million words, we evaluate several dataset sources, including child-directed\nspeech (CHILDES), classic books (Gutenberg), synthetic data (TinyStories), and\na mix of these (Mix) across different model sizes ranging from 18 million to\n705 million parameters. Our experiments show that smaller models (e.g.,\nGPT2-97M, GPT2-705M, Llama-360M) perform better when trained on more complex\nand rich datasets like Gutenberg. Models trained on the CHILDES and TinyStories\ndatasets underperformed across all model sizes. These findings suggest that the\noptimal dataset for sample efficient training depends on the model size, and\nthat neither child-directed speech nor simplified stories are optimal for\nlanguage models of all sizes. We highlight the importance of considering both\ndataset composition and model capacity for effective sample efficient language\nmodel training."
    },
    {
      "id": "2411.06666v1",
      "title": "Adversarial Detection with a Dynamically Stable System",
      "summary": "Adversarial detection is designed to identify and reject maliciously crafted\nadversarial examples(AEs) which are generated to disrupt the classification of\ntarget models.\n  Presently, various input transformation-based methods have been developed on\nadversarial example detection, which typically rely on empirical experience and\nlead to unreliability against new attacks.\n  To address this issue, we propose and conduct a Dynamically Stable System\n(DSS), which can effectively detect the adversarial examples from normal\nexamples according to the stability of input examples.\n  Particularly, in our paper, the generation of adversarial examples is\nconsidered as the perturbation process of a Lyapunov dynamic system, and we\npropose an example stability mechanism, in which a novel control term is added\nin adversarial example generation to ensure that the normal examples can\nachieve dynamic stability while the adversarial examples cannot achieve the\nstability.\n  Then, based on the proposed example stability mechanism, a Dynamically Stable\nSystem (DSS) is proposed, which can utilize the disruption and restoration\nactions to determine the stability of input examples and detect the adversarial\nexamples through changes in the stability of the input examples.\n  In comparison with existing methods in three benchmark datasets(MNIST,\nCIFAR10, and CIFAR100), our evaluation results show that our proposed DSS can\nachieve ROC-AUC values of 99.83%, 97.81% and 94.47%, surpassing the\nstate-of-the-art(SOTA) values of 97.35%, 91.10% and 93.49% in the other 7\nmethods."
    },
    {
      "id": "2411.06660v1",
      "title": "Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation",
      "summary": "Knowledge graph completion (KGC) is a task of inferring missing triples based\non existing Knowledge Graphs (KGs). Both structural and semantic information\nare vital for successful KGC. However, existing methods only use either the\nstructural knowledge from the KG embeddings or the semantic information from\npre-trained language models (PLMs), leading to suboptimal model performance.\nMoreover, since PLMs are not trained on KGs, directly using PLMs to encode\ntriples may be inappropriate. To overcome these limitations, we propose a novel\nframework called Bridge, which jointly encodes structural and semantic\ninformation of KGs. Specifically, we strategically encode entities and\nrelations separately by PLMs to better utilize the semantic knowledge of PLMs\nand enable structured representation learning via a structural learning\nprinciple. Furthermore, to bridge the gap between KGs and PLMs, we employ a\nself-supervised representation learning method called BYOL to fine-tune PLMs\nwith two different views of a triple. Unlike BYOL, which uses augmentation\nmethods to create two semantically similar views of the same image, potentially\naltering the semantic information. We strategically separate the triple into\ntwo parts to create different views, thus avoiding semantic alteration.\nExperiments demonstrate that Bridge outperforms the SOTA models on three\nbenchmark datasets."
    },
    {
      "id": "2411.06659v1",
      "title": "An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning",
      "summary": "Incremental graph learning has gained significant attention for its ability\nto address the catastrophic forgetting problem in graph representation\nlearning. However, traditional methods often rely on a large number of labels\nfor node classification, which is impractical in real-world applications. This\nmakes few-shot incremental learning on graphs a pressing need. Current methods\ntypically require extensive training samples from meta-learning to build memory\nand perform intensive fine-tuning of GNN parameters, leading to high memory\nconsumption and potential loss of previously learned knowledge. To tackle these\nchallenges, we introduce Mecoin, an efficient method for building and\nmaintaining memory. Mecoin employs Structured Memory Units to cache prototypes\nof learned categories, as well as Memory Construction Modules to update these\nprototypes for new categories through interactions between the nodes and the\ncached prototypes. Additionally, we have designed a Memory Representation\nAdaptation Module to store probabilities associated with each class prototype,\nreducing the need for parameter fine-tuning and lowering the forgetting rate.\nWhen a sample matches its corresponding class prototype, the relevant\nprobabilities are retrieved from the MRaM. Knowledge is then distilled back\ninto the GNN through a Graph Knowledge Distillation Module, preserving the\nmodel's memory. We analyze the effectiveness of Mecoin in terms of\ngeneralization error and explore the impact of different distillation\nstrategies on model performance through experiments and VC-dimension analysis.\nCompared to other related works, Mecoin shows superior performance in accuracy\nand forgetting rate. Our code is publicly available on the\nhttps://github.com/Arvin0313/Mecoin-GFSCIL.git ."
    },
    {
      "id": "2411.06657v1",
      "title": "Renaissance: Investigating the Pretraining of Vision-Language Encoders",
      "summary": "In the past several years there has been an explosion of available models for\nvision-language tasks. Unfortunately, the literature still leaves open a number\nof questions related to best practices in designing and training such models.\nIn this paper we seek to answer several questions related to the pretraining of\nvision-language encoders through meta-analysis. In our first set of\nexperiments, we show that we can save significant compute at no cost to\ndownstream performance, by freezing large parts of vision-language models\nduring pretraining. In our second set of experiments we examine the effect of\nbasing a VL transformer on a vision model versus a text model. Additionally, we\nintroduce a VL modeling platform called Renaissance that we use to conduct all\nof the experiments. This program offers a great deal of flexibility in\ncreating, training and evaluating transformer encoders for VL modeling. The\nsource code for Renaissance can be found at\nhttps://github.com/bsu-slim/renaissance."
    },
    {
      "id": "2411.06655v1",
      "title": "Explore the Reasoning Capability of LLMs in the Chess Testbed",
      "summary": "Reasoning is a central capability of human intelligence. In recent years,\nwith the advent of large-scale datasets, pretrained large language models have\nemerged with new capabilities, including reasoning. However, these models still\nstruggle with long-term, complex reasoning tasks, such as playing chess. Based\non the observation that expert chess players employ a dual approach combining\nlong-term strategic play with short-term tactical play along with language\nexplanation, we propose improving the reasoning capability of large language\nmodels in chess by integrating annotated strategy and tactic. Specifically, we\ncollect a dataset named MATE, which consists of 1 million chess positions with\ncandidate moves annotated by chess experts for strategy and tactics. We\nfinetune the LLaMA-3-8B model and compare it against state-of-the-art\ncommercial language models in the task of selecting better chess moves. Our\nexperiments show that our models perform better than GPT, Claude, and Gemini\nmodels. We find that language explanations can enhance the reasoning capability\nof large language models."
    },
    {
      "id": "2411.06651v2",
      "title": "Machine learning-enabled velocity model building with uncertainty quantification",
      "summary": "Accurately characterizing migration velocity models is crucial for a wide\nrange of geophysical applications, from hydrocarbon exploration to monitoring\nof CO2 sequestration projects. Traditional velocity model building methods such\nas Full-Waveform Inversion (FWI) are powerful but often struggle with the\ninherent complexities of the inverse problem, including noise, limited\nbandwidth, receiver aperture and computational constraints. To address these\nchallenges, we propose a scalable methodology that integrates generative\nmodeling, in the form of Diffusion networks, with physics-informed summary\nstatistics, making it suitable for complicated imaging problems including field\ndatasets. By defining these summary statistics in terms of subsurface-offset\nimage volumes for poor initial velocity models, our approach allows for\ncomputationally efficient generation of Bayesian posterior samples for\nmigration velocity models that offer a useful assessment of uncertainty. To\nvalidate our approach, we introduce a battery of tests that measure the quality\nof the inferred velocity models, as well as the quality of the inferred\nuncertainties. With modern synthetic datasets, we reconfirm gains from using\nsubsurface-image gathers as the conditioning observable. For complex velocity\nmodel building involving salt, we propose a new iterative workflow that refines\namortized posterior approximations with salt flooding and demonstrate how the\nuncertainty in the velocity model can be propagated to the final product\nreverse time migrated images. Finally, we present a proof of concept on field\ndatasets to show that our method can scale to industry-sized problems."
    },
    {
      "id": "2411.06650v1",
      "title": "Quantum Policy Gradient in Reproducing Kernel Hilbert Space",
      "summary": "Parametrised quantum circuits offer expressive and data-efficient\nrepresentations for machine learning. Due to quantum states residing in a\nhigh-dimensional complex Hilbert space, parametrised quantum circuits have a\nnatural interpretation in terms of kernel methods. The representation of\nquantum circuits in terms of quantum kernels has been studied widely in quantum\nsupervised learning, but has been overlooked in the context of quantum\nreinforcement learning. This paper proposes parametric and non-parametric\npolicy gradient and actor-critic algorithms with quantum kernel policies in\nquantum environments. This approach, implemented with both numerical and\nanalytical quantum policy gradient techniques, allows exploiting the many\nadvantages of kernel methods, including available analytic forms for the\ngradient of the policy and tunable expressiveness. The proposed approach is\nsuitable for vector-valued action spaces and each of the formulations\ndemonstrates a quadratic reduction in query complexity compared to their\nclassical counterparts. Two actor-critic algorithms, one based on stochastic\npolicy gradient and one based on deterministic policy gradient (comparable to\nthe popular DDPG algorithm), demonstrate additional query complexity reductions\ncompared to quantum policy gradient algorithms under favourable conditions."
    },
    {
      "id": "2411.06649v1",
      "title": "A Novel Combined Data-Driven Approach for Electricity Theft Detection",
      "summary": "The two-way flow of information and energy is an important feature of the\nEnergy Internet. Data analytics is a powerful tool in the information flow that\naims to solve practical problems using data mining techniques. As the problem\nof electricity thefts via tampering with smart meters continues to increase,\nthe abnormal behaviors of thefts become more diversified and more difficult to\ndetect. Thus, a data analytics method for detecting various types of\nelectricity thefts is required. However, the existing methods either require a\nlabeled dataset or additional system information which is difficult to obtain\nin reality or have poor detection accuracy. In this paper, we combine two novel\ndata mining techniques to solve the problem. One technique is the Maximum\nInformation Coefficient (MIC), which can find the correlations between the\nnon-technical loss (NTL) and a certain electricity behavior of the consumer.\nMIC can be used to precisely detect thefts that appear normal in shapes. The\nother technique is the clustering technique by fast search and find of density\npeaks (CFSFDP). CFSFDP finds the abnormal users among thousands of load\nprofiles, making it quite suitable for detecting electricity thefts with\narbitrary shapes. Next, a framework for combining the advantages of the two\ntechniques is proposed. Numerical experiments on the Irish smart meter dataset\nare conducted to show the good performance of the combined method."
    },
    {
      "id": "2411.06646v1",
      "title": "Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data",
      "summary": "When training deep neural networks, a model's generalization error is often\nobserved to follow a power scaling law dependent both on the model size and the\ndata size. Perhaps the best known example of such scaling laws are for\ntransformer-based large language models, where networks with billions of\nparameters are trained on trillions of tokens of text. Yet, despite sustained\nwidespread interest, a rigorous understanding of why transformer scaling laws\nexist is still missing. To answer this question, we establish novel statistical\nestimation and mathematical approximation theories for transformers when the\ninput data are concentrated on a low-dimensional manifold. Our theory predicts\na power law between the generalization error and both the training data size\nand the network size for transformers, where the power depends on the intrinsic\ndimension $d$ of the training data. Notably, the constructed model architecture\nis shallow, requiring only logarithmic depth in $d$. By leveraging\nlow-dimensional data structures under a manifold hypothesis, we are able to\nexplain transformer scaling laws in a way which respects the data geometry.\nMoreover, we test our theory with empirical observation by training LLMs on\nnatural language datasets. We find the observed empirical data scaling laws\nclosely agree with our theoretical predictions. Taken together, these results\nrigorously show the intrinsic dimension of data to be a crucial quantity\naffecting transformer scaling laws in both theory and practice."
    },
    {
      "id": "2411.06639v1",
      "title": "Predicting Country Instability Using Bayesian Deep Learning and Random Forest",
      "summary": "Country instability is a global issue, with unpredictably high levels of\ninstability thwarting socio-economic growth and possibly causing a slew of\nnegative consequences. As a result, uncertainty prediction models for a country\nare becoming increasingly important in the real world, and they are expanding\nto provide more input from 'big data' collections, as well as the\ninterconnectedness of global economies and social networks. This has culminated\nin massive volumes of qualitative data from outlets like television, print,\ndigital, and social media, necessitating the use of artificial intelligence\n(AI) tools like machine learning to make sense of it all and promote predictive\nprecision [1]. The Global Database of Activities, Voice, and Tone (GDELT\nProject) records broadcast, print, and web news in over 100 languages every\nsecond of every day, identifying the people, locations, organisations, counts,\nthemes, outlets, and events that propel our global community and offering a\nfree open platform for computation on the entire world. The main goal of our\nresearch is to investigate how, when our data grows more voluminous and\nfine-grained, we can conduct a more complex methodological analysis of\npolitical conflict. The GDELT dataset, which was released in 2012, is the first\nand potentially the most technologically sophisticated publicly accessible\ndataset on political conflict."
    },
    {
      "id": "2411.06638v1",
      "title": "Model Editing for LLMs4Code: How Far are We?",
      "summary": "Large Language Models for Code (LLMs4Code) have been found to exhibit\noutstanding performance in the software engineering domain, especially the\nremarkable performance in coding tasks. However, even the most advanced\nLLMs4Code can inevitably contain incorrect or outdated code knowledge. Due to\nthe high cost of training LLMs4Code, it is impractical to re-train the models\nfor fixing these problematic code knowledge. Model editing is a new technical\nfield for effectively and efficiently correcting erroneous knowledge in LLMs,\nwhere various model editing techniques and benchmarks have been proposed\nrecently. Despite that, a comprehensive study that thoroughly compares and\nanalyzes the performance of the state-of-the-art model editing techniques for\nadapting the knowledge within LLMs4Code across various code-related tasks is\nnotably absent. To bridge this gap, we perform the first systematic study on\napplying state-of-the-art model editing approaches to repair the inaccuracy of\nLLMs4Code. To that end, we introduce a benchmark named CLMEEval, which consists\nof two datasets, i.e., CoNaLa-Edit (CNLE) with 21K+ code generation samples and\nCodeSearchNet-Edit (CSNE) with 16K+ code summarization samples. With the help\nof CLMEEval, we evaluate six advanced model editing techniques on three\nLLMs4Code: CodeLlama (7B), CodeQwen1.5 (7B), and Stable-Code (3B). Our findings\ninclude that the external memorization-based GRACE approach achieves the best\nknowledge editing effectiveness and specificity (the editing does not influence\nuntargeted knowledge), while generalization (whether the editing can generalize\nto other semantically-identical inputs) is a universal challenge for existing\ntechniques. Furthermore, building on in-depth case analysis, we introduce an\nenhanced version of GRACE called A-GRACE, which incorporates contrastive\nlearning to better capture the semantics of the inputs."
    },
    {
      "id": "2411.06635v2",
      "title": "Mixed Effects Deep Learning for the interpretable analysis of single cell RNA sequencing data by quantifying and visualizing batch effects",
      "summary": "Single-cell RNA sequencing (scRNA-seq) data are often confounded by technical\nor biological batch effects. Existing deep learning models mitigate these\neffects but often discard batch-specific information, potentially losing\nvaluable biological insights. We propose a Mixed Effects Deep Learning (MEDL)\nautoencoder framework that separately models batch-invariant (fixed effects)\nand batch-specific (random effects) components. By decoupling batch-invariant\nbiological states from batch variations, our framework integrates both into\npredictive models. Our approach also generates 2D visualizations of how the\nsame cell appears across batches, enhancing interpretability. Retaining both\nfixed and random effect latent spaces improves classification accuracy.\n  We applied our framework to three datasets spanning the cardiovascular system\n(Healthy Heart), Autism Spectrum Disorder (ASD), and Acute Myeloid Leukemia\n(AML). With 147 batches in the Healthy Heart dataset, far exceeding typical\nnumbers, we tested our framework's ability to handle many batches. In the ASD\ndataset, our approach captured donor heterogeneity between autistic and healthy\nindividuals. In the AML dataset, it distinguished donor heterogeneity despite\nmissing cell types and diseased donors exhibiting both healthy and malignant\ncells. These results highlight our framework's ability to characterize fixed\nand random effects, enhance batch effect visualization, and improve prediction\naccuracy across diverse datasets."
    },
    {
      "id": "2411.06634v1",
      "title": "Inductive Graph Few-shot Class Incremental Learning",
      "summary": "Node classification with Graph Neural Networks (GNN) under a fixed set of\nlabels is well known in contrast to Graph Few-Shot Class Incremental Learning\n(GFSCIL), which involves learning a GNN classifier as graph nodes and classes\ngrowing over time sporadically. We introduce inductive GFSCIL that continually\nlearns novel classes with newly emerging nodes while maintaining performance on\nold classes without accessing previous data. This addresses the practical\nconcern of transductive GFSCIL, which requires storing the entire graph with\nhistorical data. Compared to the transductive GFSCIL, the inductive setting\nexacerbates catastrophic forgetting due to inaccessible previous data during\nincremental training, in addition to overfitting issue caused by label\nsparsity. Thus, we propose a novel method, called Topology-based class\nAugmentation and Prototype calibration (TAP). To be specific, it first creates\na triple-branch multi-topology class augmentation method to enhance model\ngeneralization ability. As each incremental session receives a disjoint\nsubgraph with nodes of novel classes, the multi-topology class augmentation\nmethod helps replicate such a setting in the base session to boost backbone\nversatility. In incremental learning, given the limited number of novel class\nsamples, we propose an iterative prototype calibration to improve the\nseparation of class prototypes. Furthermore, as backbone fine-tuning poses the\nfeature distribution drift, prototypes of old classes start failing over time,\nwe propose the prototype shift method for old classes to compensate for the\ndrift. We showcase the proposed method on four datasets."
    },
    {
      "id": "2411.06632v1",
      "title": "Few-shot Semantic Learning for Robust Multi-Biome 3D Semantic Mapping in Off-Road Environments",
      "summary": "Off-road environments pose significant perception challenges for high-speed\nautonomous navigation due to unstructured terrain, degraded sensing conditions,\nand domain-shifts among biomes. Learning semantic information across these\nconditions and biomes can be challenging when a large amount of ground truth\ndata is required. In this work, we propose an approach that leverages a\npre-trained Vision Transformer (ViT) with fine-tuning on a small (<500 images),\nsparse and coarsely labeled (<30% pixels) multi-biome dataset to predict 2D\nsemantic segmentation classes. These classes are fused over time via a novel\nrange-based metric and aggregated into a 3D semantic voxel map. We demonstrate\nzero-shot out-of-biome 2D semantic segmentation on the Yamaha (52.9 mIoU) and\nRellis (55.5 mIoU) datasets along with few-shot coarse sparse labeling with\nexisting data for improved segmentation performance on Yamaha (66.6 mIoU) and\nRellis (67.2 mIoU). We further illustrate the feasibility of using a voxel map\nwith a range-based semantic fusion approach to handle common off-road hazards\nlike pop-up hazards, overhangs, and water features."
    },
    {
      "id": "2411.06626v1",
      "title": "Exploring social bots: A feature-based approach to improve bot detection in social networks",
      "summary": "The importance of social media in our daily lives has unfortunately led to an\nincrease in the spread of misinformation, political messages and malicious\nlinks. One of the most popular ways of carrying out those activities is using\nautomated accounts, also known as bots, which makes the detection of such\naccounts a necessity. This paper addresses that problem by investigating\nfeatures based on the user account profile and its content, aiming to\nunderstand the relevance of each feature as a basis for improving future bot\ndetectors. Through an exhaustive process of research, inference and feature\nselection, we are able to surpass the state of the art on several metrics using\nclassical machine learning algorithms and identify the types of features that\nare most important in detecting automated accounts."
    },
    {
      "id": "2411.06624v1",
      "title": "A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning",
      "summary": "Recent regulatory proposals for artificial intelligence emphasize fairness\nrequirements for machine learning models. However, precisely defining the\nappropriate measure of fairness is challenging due to philosophical, cultural\nand political contexts. Biases can infiltrate machine learning models in\ncomplex ways depending on the model's context, rendering a single common metric\nof fairness insufficient. This ambiguity highlights the need for criteria to\nguide the selection of context-aware measures, an issue of increasing\nimportance given the proliferation of ever tighter regulatory requirements. To\naddress this, we developed a flowchart to guide the selection of contextually\nappropriate fairness measures. Twelve criteria were used to formulate the\nflowchart. This included consideration of model assessment criteria, model\nselection criteria, and data bias. We also review fairness literature in the\ncontext of machine learning and link it to core regulatory instruments to\nassist policymakers, AI developers, researchers, and other stakeholders in\nappropriately addressing fairness concerns and complying with relevant\nregulatory requirements."
    },
    {
      "id": "2411.06618v1",
      "title": "Using Diffusion Models as Generative Replay in Continual Federated Learning -- What will Happen?",
      "summary": "Federated learning (FL) has become a cornerstone in decentralized learning,\nwhere, in many scenarios, the incoming data distribution will change\ndynamically over time, introducing continuous learning (CL) problems. This\ncontinual federated learning (CFL) task presents unique challenges,\nparticularly regarding catastrophic forgetting and non-IID input data. Existing\nsolutions include using a replay buffer to store historical data or leveraging\ngenerative adversarial networks. Nevertheless, motivated by recent advancements\nin the diffusion model for generative tasks, this paper introduces DCFL, a\nnovel framework tailored to address the challenges of CFL in dynamic\ndistributed learning environments. Our approach harnesses the power of the\nconditional diffusion model to generate synthetic historical data at each local\ndevice during communication, effectively mitigating latent shifts in dynamic\ndata distribution inputs. We provide the convergence bound for the proposed CFL\nframework and demonstrate its promising performance across multiple datasets,\nshowcasing its effectiveness in tackling the complexities of CFL tasks."
    },
    {
      "id": "2411.06616v1",
      "title": "MEANT: Multimodal Encoder for Antecedent Information",
      "summary": "The stock market provides a rich well of information that can be split across\nmodalities, making it an ideal candidate for multimodal evaluation. Multimodal\ndata plays an increasingly important role in the development of machine\nlearning and has shown to positively impact performance. But information can do\nmore than exist across modes -- it can exist across time. How should we attend\nto temporal data that consists of multiple information types? This work\nintroduces (i) the MEANT model, a Multimodal Encoder for Antecedent information\nand (ii) a new dataset called TempStock, which consists of price, Tweets, and\ngraphical data with over a million Tweets from all of the companies in the S&P\n500 Index. We find that MEANT improves performance on existing baselines by\nover 15%, and that the textual information affects performance far more than\nthe visual information on our time-dependent task from our ablation study."
    },
    {
      "id": "2411.07794v1",
      "title": "Feature Fusion Transferability Aware Transformer for Unsupervised Domain Adaptation",
      "summary": "Unsupervised domain adaptation (UDA) aims to leverage the knowledge learned\nfrom labeled source domains to improve performance on the unlabeled target\ndomains. While Convolutional Neural Networks (CNNs) have been dominant in\nprevious UDA methods, recent research has shown promise in applying Vision\nTransformers (ViTs) to this task. In this study, we propose a novel Feature\nFusion Transferability Aware Transformer (FFTAT) to enhance ViT performance in\nUDA tasks. Our method introduces two key innovations: First, we introduce a\npatch discriminator to evaluate the transferability of patches, generating a\ntransferability matrix. We integrate this matrix into self-attention, directing\nthe model to focus on transferable patches. Second, we propose a feature fusion\ntechnique to fuse embeddings in the latent space, enabling each embedding to\nincorporate information from all others, thereby improving generalization.\nThese two components work in synergy to enhance feature representation\nlearning. Extensive experiments on widely used benchmarks demonstrate that our\nmethod significantly improves UDA performance, achieving state-of-the-art\n(SOTA) results."
    },
    {
      "id": "2411.06613v1",
      "title": "Are Neuromorphic Architectures Inherently Privacy-preserving? An Exploratory Study",
      "summary": "While machine learning (ML) models are becoming mainstream, especially in\nsensitive application areas, the risk of data leakage has become a growing\nconcern. Attacks like membership inference (MIA) have shown that trained models\ncan reveal sensitive data, jeopardizing confidentiality. While traditional\nArtificial Neural Networks (ANNs) dominate ML applications, neuromorphic\narchitectures, specifically Spiking Neural Networks (SNNs), are emerging as\npromising alternatives due to their low power consumption and event-driven\nprocessing, akin to biological neurons. Privacy in ANNs is well-studied;\nhowever, little work has explored the privacy-preserving properties of SNNs.\nThis paper examines whether SNNs inherently offer better privacy. Using MIAs,\nwe assess the privacy resilience of SNNs versus ANNs across diverse datasets.\nWe analyze the impact of learning algorithms (surrogate gradient and\nevolutionary), frameworks (snnTorch, TENNLab, LAVA), and parameters on SNN\nprivacy. Our findings show that SNNs consistently outperform ANNs in privacy\npreservation, with evolutionary algorithms offering additional resilience. For\ninstance, on CIFAR-10, SNNs achieve an AUC of 0.59, significantly lower than\nANNs' 0.82, and on CIFAR-100, SNNs maintain an AUC of 0.58 compared to ANNs'\n0.88. Additionally, we explore the privacy-utility trade-off with\nDifferentially Private Stochastic Gradient Descent (DPSGD), finding that SNNs\nsustain less accuracy loss than ANNs under similar privacy constraints."
    },
    {
      "id": "2411.06611v2",
      "title": "vTune: Verifiable Fine-Tuning for LLMs Through Backdooring",
      "summary": "As fine-tuning large language models (LLMs) becomes increasingly prevalent,\nusers often rely on third-party services with limited visibility into their\nfine-tuning processes. This lack of transparency raises the question: how do\nconsumers verify that fine-tuning services are performed correctly? For\ninstance, a service provider could claim to fine-tune a model for each user,\nyet simply send all users back the same base model. To address this issue, we\npropose vTune, a simple method that uses a small number of backdoor data points\nadded to the training data to provide a statistical test for verifying that a\nprovider fine-tuned a custom model on a particular user's dataset. Unlike\nexisting works, vTune is able to scale to verification of fine-tuning on\nstate-of-the-art LLMs, and can be used both with open-source and closed-source\nmodels. We test our approach across several model families and sizes as well as\nacross multiple instruction-tuning datasets, and find that the statistical test\nis satisfied with p-values on the order of $\\sim 10^{-40}$, with no negative\nimpact on downstream task performance. Further, we explore several attacks that\nattempt to subvert vTune and demonstrate the method's robustness to these\nattacks."
    },
    {
      "id": "2411.06608v1",
      "title": "MolMiner: Transformer architecture for fragment-based autoregressive generation of molecular stories",
      "summary": "Deep generative models for molecular discovery have become a very popular\nchoice in new high-throughput screening paradigms. These models have been\ndeveloped inheriting from the advances in natural language processing and\ncomputer vision, achieving ever greater results. However, generative molecular\nmodelling has unique challenges that are often overlooked. Chemical validity,\ninterpretability of the generation process and flexibility to variable\nmolecular sizes are among some of the remaining challenges for generative\nmodels in computational materials design. In this work, we propose an\nautoregressive approach that decomposes molecular generation into a sequence of\ndiscrete and interpretable steps using molecular fragments as units, a\n'molecular story'. Enforcing chemical rules in the stories guarantees the\nchemical validity of the generated molecules, the discrete sequential steps of\na molecular story makes the process transparent improving interpretability, and\nthe autoregressive nature of the approach allows the size of the molecule to be\na decision of the model. We demonstrate the validity of the approach in a\nmulti-target inverse design of electroactive organic compounds, focusing on the\ntarget properties of solubility, redox potential, and synthetic accessibility.\nOur results show that the model can effectively bias the generation\ndistribution according to the prompted multi-target objective."
    },
    {
      "id": "2411.06606v1",
      "title": "Gen-AI for User Safety: A Survey",
      "summary": "Machine Learning and data mining techniques (i.e. supervised and unsupervised\ntechniques) are used across domains to detect user safety violations. Examples\ninclude classifiers used to detect whether an email is spam or a web-page is\nrequesting bank login information. However, existing ML/DM classifiers are\nlimited in their ability to understand natural languages w.r.t the context and\nnuances. The aforementioned challenges are overcome with the arrival of Gen-AI\ntechniques, along with their inherent ability w.r.t translation between\nlanguages, fine-tuning between various tasks and domains.\n  In this manuscript, we provide a comprehensive overview of the various work\ndone while using Gen-AI techniques w.r.t user safety. In particular, we first\nprovide the various domains (e.g. phishing, malware, content moderation,\ncounterfeit, physical safety) across which Gen-AI techniques have been applied.\nNext, we provide how Gen-AI techniques can be used in conjunction with various\ndata modalities i.e. text, images, videos, audio, executable binaries to detect\nviolations of user-safety. Further, also provide an overview of how Gen-AI\ntechniques can be used in an adversarial setting. We believe that this work\nrepresents the first summarization of Gen-AI techniques for user-safety."
    },
    {
      "id": "2411.06601v1",
      "title": "OffLight: An Offline Multi-Agent Reinforcement Learning Framework for Traffic Signal Control",
      "summary": "Efficient traffic signal control is critical for modern urban mobility, but\ntraditional systems often struggle to adapt to complex city traffic patterns.\nMulti-Agent Reinforcement Learning, or MARL, offers adaptive solutions, yet\nonline MARL methods require extensive real-time interactions, which are costly\nand time-intensive. Offline MARL addresses these issues by using historical\ntraffic data, but it faces challenges due to the diverse behavior policies in\nreal-world datasets, where different controllers complicate learning."
    },
    {
      "id": "2411.06600v1",
      "title": "Few measurement shots challenge generalization in learning to classify entanglement",
      "summary": "The ability to extract general laws from a few known examples depends on the\ncomplexity of the problem and on the amount of training data. In the quantum\nsetting, the learner's generalization performance is further challenged by the\ndestructive nature of quantum measurements that, together with the no-cloning\ntheorem, limits the amount of information that can be extracted from each\ntraining sample. In this paper we focus on hybrid quantum learning techniques\nwhere classical machine-learning methods are paired with quantum algorithms and\nshow that, in some settings, the uncertainty coming from a few measurement\nshots can be the dominant source of errors. We identify an instance of this\npossibly general issue by focusing on the classification of maximally entangled\nvs. separable states, showing that this toy problem becomes challenging for\nlearners unaware of entanglement theory. Finally, we introduce an estimator\nbased on classical shadows that performs better in the big data, few copy\nregime. Our results show that the naive application of classical\nmachine-learning methods to the quantum setting is problematic, and that a\nbetter theoretical foundation of quantum learning is required."
    },
    {
      "id": "2411.06590v1",
      "title": "CriticAL: Critic Automation with Language Models",
      "summary": "Understanding the world through models is a fundamental goal of scientific\nresearch. While large language model (LLM) based approaches show promise in\nautomating scientific discovery, they often overlook the importance of\ncriticizing scientific models. Criticizing models deepens scientific\nunderstanding and drives the development of more accurate models. Automating\nmodel criticism is difficult because it traditionally requires a human expert\nto define how to compare a model with data and evaluate if the discrepancies\nare significant--both rely heavily on understanding the modeling assumptions\nand domain. Although LLM-based critic approaches are appealing, they introduce\nnew challenges: LLMs might hallucinate the critiques themselves. Motivated by\nthis, we introduce CriticAL (Critic Automation with Language Models). CriticAL\nuses LLMs to generate summary statistics that capture discrepancies between\nmodel predictions and data, and applies hypothesis tests to evaluate their\nsignificance. We can view CriticAL as a verifier that validates models and\ntheir critiques by embedding them in a hypothesis testing framework. In\nexperiments, we evaluate CriticAL across key quantitative and qualitative\ndimensions. In settings where we synthesize discrepancies between models and\ndatasets, CriticAL reliably generates correct critiques without hallucinating\nincorrect ones. We show that both human and LLM judges consistently prefer\nCriticAL's critiques over alternative approaches in terms of transparency and\nactionability. Finally, we show that CriticAL's critiques enable an LLM\nscientist to improve upon human-designed models on real-world datasets."
    },
    {
      "id": "2411.06583v1",
      "title": "Enhancing frozen histological section images using permanent-section-guided deep learning with nuclei attention",
      "summary": "In histological pathology, frozen sections are often used for rapid diagnosis\nduring surgeries, as they can be produced within minutes. However, they suffer\nfrom artifacts and often lack crucial diagnostic details, particularly within\nthe cell nuclei region. Permanent sections, on the other hand, contain more\ndiagnostic detail but require a time-intensive preparation process. Here, we\npresent a generative deep learning approach to enhance frozen section images by\nleveraging guidance from permanent sections. Our method places a strong\nemphasis on the nuclei region, which contains critical information in both\nfrozen and permanent sections. Importantly, our approach avoids generating\nartificial data in blank regions, ensuring that the network only enhances\nexisting features without introducing potentially unreliable information. We\nachieve this through a segmented attention network, incorporating\nnuclei-segmented images during training and adding an additional loss function\nto refine the nuclei details in the generated permanent images. We validated\nour method across various tissues, including kidney, breast, and colon. This\napproach significantly improves histological efficiency and diagnostic\naccuracy, enhancing frozen section images within seconds, and seamlessly\nintegrating into existing laboratory workflows."
    },
    {
      "id": "2411.06581v1",
      "title": "Federated LLMs Fine-tuned with Adaptive Importance-Aware LoRA",
      "summary": "Federated fine-tuning of pre-trained Large Language Models (LLMs) enables\ntask-specific adaptation across diverse datasets while preserving data privacy.\nHowever, the large model size and heterogeneity in client resources pose\nsignificant computational and communication challenges. To address these\nissues, in this paper, we propose a novel Heterogeneous Adaptive Federated\nLow-Rank Adaptation (LoRA) fine-tuned LLM framework (HAFL). To accommodate\nclient resource heterogeneity, we first introduce an importance-based parameter\ntruncation scheme, which allows clients to have different LoRA ranks, and\nsmoothed sensitivity scores are used as importance indicators. Despite its\nflexibility, the truncation process may cause performance degradation. To\ntackle this problem, we develop an importance-based parameter freezing scheme.\nIn this approach, both the cloud server and clients maintain the same LoRA\nrank, while clients selectively update only the most important decomposed LoRA\nrank-1 matrices, keeping the rest frozen. To mitigate the information dilution\ncaused by the zero-padding aggregation method, we propose an adaptive\naggregation approach that operates at the decomposed rank-1 matrix level.\nExperiments on the 20 News Group classification task show that our method\nconverges quickly with low communication size, and avoids performance\ndegradation when distributing models to clients compared to truncation-based\nheterogeneous LoRA rank scheme. Additionally, our adaptive aggregation method\nachieves faster convergence compared to the zero-padding approach."
    },
    {
      "id": "2411.06577v1",
      "title": "Discovering emergent connections in quantum physics research via dynamic word embeddings",
      "summary": "As the field of quantum physics evolves, researchers naturally form subgroups\nfocusing on specialized problems. While this encourages in-depth exploration,\nit can limit the exchange of ideas across structurally similar problems in\ndifferent subfields. To encourage cross-talk among these different specialized\nareas, data-driven approaches using machine learning have recently shown\npromise to uncover meaningful connections between research concepts, promoting\ncross-disciplinary innovation. Current state-of-the-art approaches represent\nconcepts using knowledge graphs and frame the task as a link prediction\nproblem, where connections between concepts are explicitly modeled. In this\nwork, we introduce a novel approach based on dynamic word embeddings for\nconcept combination prediction. Unlike knowledge graphs, our method captures\nimplicit relationships between concepts, can be learned in a fully unsupervised\nmanner, and encodes a broader spectrum of information. We demonstrate that this\nrepresentation enables accurate predictions about the co-occurrence of concepts\nwithin research abstracts over time. To validate the effectiveness of our\napproach, we provide a comprehensive benchmark against existing methods and\noffer insights into the interpretability of these embeddings, particularly in\nthe context of quantum physics research. Our findings suggest that this\nrepresentation offers a more flexible and informative way of modeling\nconceptual relationships in scientific literature."
    },
    {
      "id": "2411.06573v1",
      "title": "An Energy-Based Self-Adaptive Learning Rate for Stochastic Gradient Descent: Enhancing Unconstrained Optimization with VAV method",
      "summary": "Optimizing the learning rate remains a critical challenge in machine\nlearning, essential for achieving model stability and efficient convergence.\nThe Vector Auxiliary Variable (VAV) algorithm introduces a novel energy-based\nself-adjustable learning rate optimization method designed for unconstrained\noptimization problems. It incorporates an auxiliary variable $r$ to facilitate\nefficient energy approximation without backtracking while adhering to the\nunconditional energy dissipation law. Notably, VAV demonstrates superior\nstability with larger learning rates and achieves faster convergence in the\nearly stage of the training process. Comparative analyses demonstrate that VAV\noutperforms Stochastic Gradient Descent (SGD) across various tasks. This paper\nalso provides rigorous proof of the energy dissipation law and establishes the\nconvergence of the algorithm under reasonable assumptions. Additionally, $r$\nacts as an empirical lower bound of the training loss in practice, offering a\nnovel scheduling approach that further enhances algorithm performance."
    },
    {
      "id": "2411.06572v1",
      "title": "Fitting Multiple Machine Learning Models with Performance Based Clustering",
      "summary": "Traditional machine learning approaches assume that data comes from a single\ngenerating mechanism, which may not hold for most real life data. In these\ncases, the single mechanism assumption can result in suboptimal performance. We\nintroduce a clustering framework that eliminates this assumption by grouping\nthe data according to the relations between the features and the target values\nand we obtain multiple separate models to learn different parts of the data. We\nfurther extend our framework to applications having streaming data where we\nproduce outcomes using an ensemble of models. For this, the ensemble weights\nare updated based on the incoming data batches. We demonstrate the performance\nof our approach over the widely-studied real life datasets, showing significant\nimprovements over the traditional single-model approaches."
    },
    {
      "id": "2411.06568v1",
      "title": "Learning Loss Landscapes in Preference Optimization",
      "summary": "We present an empirical study investigating how specific properties of\npreference datasets, such as mixed-quality or noisy data, affect the\nperformance of Preference Optimization (PO) algorithms. Our experiments,\nconducted in MuJoCo environments, reveal several scenarios where\nstate-of-the-art PO methods experience significant drops in performance. To\naddress this issue, we introduce a novel PO framework based on mirror descent,\nwhich can recover existing methods like Direct Preference Optimization (DPO)\nand Odds-Ratio Preference Optimization (ORPO) for specific choices of the\nmirror map. Within this framework, we employ evolutionary strategies to\ndiscover new loss functions capable of handling the identified problematic\nscenarios. These new loss functions lead to significant performance\nimprovements over DPO and ORPO across several tasks. Additionally, we\ndemonstrate the generalization capability of our approach by applying the\ndiscovered loss functions to fine-tuning large language models using\nmixed-quality data, where they outperform ORPO."
    },
    {
      "id": "2411.06565v1",
      "title": "Foundation Model for Composite Materials and Microstructural Analysis",
      "summary": "The rapid advancement of machine learning has unlocked numerous opportunities\nfor materials science, particularly in accelerating the design and analysis of\nmaterials. However, a significant challenge lies in the scarcity and high cost\nof obtaining high-quality materials datasets. In other fields, such as natural\nlanguage processing, foundation models pre-trained on large datasets have\nachieved exceptional success in transfer learning, effectively leveraging\nlatent features to achieve high performance on tasks with limited data. Despite\nthis progress, the concept of foundation models remains underexplored in\nmaterials science. Here, we present a foundation model specifically designed\nfor composite materials. Our model is pre-trained on a dataset of short-fiber\ncomposites to learn robust latent features. During transfer learning, the MMAE\naccurately predicts homogenized stiffness, with an R2 score reaching as high as\n0.959 and consistently exceeding 0.91, even when trained on limited data. These\nfindings validate the feasibility and effectiveness of foundation models in\ncomposite materials. We anticipate extending this approach to more complex\nthree-dimensional composite materials, polycrystalline materials, and beyond.\nMoreover, this framework enables high-accuracy predictions even when\nexperimental data are scarce, paving the way for more efficient and\ncost-effective materials design and analysis."
    },
    {
      "id": "2411.06559v1",
      "title": "Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents",
      "summary": "Language agents have demonstrated promising capabilities in automating\nweb-based tasks, though their current reactive approaches still underperform\nlargely compared to humans. While incorporating advanced planning algorithms,\nparticularly tree search methods, could enhance these agents' performance,\nimplementing tree search directly on live websites poses significant safety\nrisks and practical constraints due to irreversible actions such as confirming\na purchase. In this paper, we introduce a novel paradigm that augments language\nagents with model-based planning, pioneering the innovative use of large\nlanguage models (LLMs) as world models in complex web environments. Our method,\nWebDreamer, builds on the key insight that LLMs inherently encode comprehensive\nknowledge about website structures and functionalities. Specifically,\nWebDreamer uses LLMs to simulate outcomes for each candidate action (e.g.,\n\"what would happen if I click this button?\") using natural language\ndescriptions, and then evaluates these imagined outcomes to determine the\noptimal action at each step. Empirical results on two representative web agent\nbenchmarks with online interaction -- VisualWebArena and Mind2Web-live --\ndemonstrate that WebDreamer achieves substantial improvements over reactive\nbaselines. By establishing the viability of LLMs as world models in web\nenvironments, this work lays the groundwork for a paradigm shift in automated\nweb interaction. More broadly, our findings open exciting new avenues for\nfuture research into 1) optimizing LLMs specifically for world modeling in\ncomplex, dynamic environments, and 2) model-based speculative planning for\nlanguage agents."
    },
    {
      "id": "2411.06554v1",
      "title": "The KIPARLA Forest treebank of spoken Italian: an overview of initial design choices",
      "summary": "The paper presents an overview of initial design choices discussed towards\nthe creation of a treebank for the Italian KIParla corpus"
    },
    {
      "id": "2411.07272v1",
      "title": "ASTD Patterns for Integrated Continuous Anomaly Detection In Data Logs",
      "summary": "This paper investigates the use of the ASTD language for ensemble anomaly\ndetection in data logs. It uses a sliding window technique for continuous\nlearning in data streams, coupled with updating learning models upon the\ncompletion of each window to maintain accurate detection and align with current\ndata trends. It proposes ASTD patterns for combining learning models,\nespecially in the context of unsupervised learning, which is commonly used for\ndata streams. To facilitate this, a new ASTD operator is proposed, the\nQuantified Flow, which enables the seamless combination of learning models\nwhile ensuring that the specification remains concise. Our contribution is a\nspecification pattern, highlighting the capacity of ASTDs to abstract and\nmodularize anomaly detection systems. The ASTD language provides a unique\napproach to develop data flow anomaly detection systems, grounded in the\ncombination of processes through the graphical representation of the language\noperators. This simplifies the design task for developers, who can focus\nprimarily on defining the functional operations that constitute the system."
    },
    {
      "id": "2411.06549v1",
      "title": "In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages",
      "summary": "Since the COVID-19 pandemic, clinicians have seen a large and sustained\ninflux in patient portal messages, significantly contributing to clinician\nburnout. To the best of our knowledge, there are no large-scale public patient\nportal messages corpora researchers can use to build tools to optimize\nclinician portal workflows. Informed by our ongoing work with a regional\nhospital, this study introduces an LLM-powered framework for configurable and\nrealistic patient portal message generation. Our approach leverages few-shot\ngrounded text generation, requiring only a small number of de-identified\npatient portal messages to help LLMs better match the true style and tone of\nreal data. Clinical experts in our team deem this framework as HIPAA-friendly,\nunlike existing privacy-preserving approaches to synthetic text generation\nwhich cannot guarantee all sensitive attributes will be protected. Through\nextensive quantitative and human evaluation, we show that our framework\nproduces data of higher quality than comparable generation methods as well as\nall related datasets. We believe this work provides a path forward for (i) the\nrelease of large-scale synthetic patient message datasets that are\nstylistically similar to ground-truth samples and (ii) HIPAA-friendly data\ngeneration which requires minimal human de-identification efforts."
    },
    {
      "id": "2411.06548v1",
      "title": "CineXDrama: Relevance Detection and Sentiment Analysis of Bangla YouTube Comments on Movie-Drama using Transformers: Insights from Interpretability Tool",
      "summary": "In recent years, YouTube has become the leading platform for Bangla movies\nand dramas, where viewers express their opinions in comments that convey their\nsentiments about the content. However, not all comments are relevant for\nsentiment analysis, necessitating a filtering mechanism. We propose a system\nthat first assesses the relevance of comments and then analyzes the sentiment\nof those deemed relevant. We introduce a dataset of 14,000 manually collected\nand preprocessed comments, annotated for relevance (relevant or irrelevant) and\nsentiment (positive or negative). Eight transformer models, including\nBanglaBERT, were used for classification tasks, with BanglaBERT achieving the\nhighest accuracy (83.99% for relevance detection and 93.3% for sentiment\nanalysis). The study also integrates LIME to interpret model decisions,\nenhancing transparency."
    },
    {
      "id": "2411.06542v2",
      "title": "Is Linear Feedback on Smoothed Dynamics Sufficient for Stabilizing Contact-Rich Plans?",
      "summary": "Designing planners and controllers for contact-rich manipulation is extremely\nchallenging as contact violates the smoothness conditions that many\ngradient-based controller synthesis tools assume. Contact smoothing\napproximates a non-smooth system with a smooth one, allowing one to use these\nsynthesis tools more effectively. However, applying classical control synthesis\nmethods to smoothed contact dynamics remains relatively under-explored. This\npaper analyzes the efficacy of linear controller synthesis using differential\nsimulators based on contact smoothing. We introduce natural baselines for\nleveraging contact smoothing to compute (a) open-loop plans robust to uncertain\nconditions and/or dynamics, and (b) feedback gains to stabilize around\nopen-loop plans. Using robotic bimanual whole-body manipulation as a testbed,\nwe perform extensive empirical experiments on over 300 trajectories and analyze\nwhy LQR seems insufficient for stabilizing contact-rich plans. The video\nsummarizing this paper and hardware experiments is found here:\nhttps://youtu.be/HLaKi6qbwQg?si=_zCAmBBD6rGSitm9."
    },
    {
      "id": "2411.06538v1",
      "title": "A Next-Generation Approach to Airline Reservations: Integrating Cloud Microservices with AI and Blockchain for Enhanced Operational Performance",
      "summary": "This research proposes the development of a next generation airline\nreservation system that incorporates the Cloud microservices, distributed\nartificial intelligence modules and the blockchain technology to improve on the\nefficiency, safety and customer satisfaction. The traditional reservation\nsystems encounter issues related to the expansion of the systems, the integrity\nof the data provided and the level of service offered to the customers, which\nis the main focus of this architecture through the modular and data centric\ndesign approaches. This will allow different operations such as reservations,\npayments, and customer data management among others to be performed separately\nthereby facilitating high availability of the system by 30% and enhancing\nperformance of the system by 40% on its scalability. Such systems contain AI\ndriven modules that utilize the past booking patterns along with the profile of\nthe customer to estimate the demand and make recommendations, which increases\nto 25 % of customer engagement. Moreover, blockchain is effective in engaging\nan incorruptible ledger system for the all transactions therefore mitigating\nfraud incidences and increasing the clarity by 20%. The system was subjected to\nanalysis using a simulator and using machine learning evaluations that rated it\nagainst other conventional systems. The results show that there were clear\nenhancements in the speed of transactions where the rates of secure data\nprocessing rose by 35%, and the system response time by 15 %. The system can\nalso be used for other high transaction industries like logistics and\nhospitality. This structural design is indicative of how the use of advanced\ntechnologies will revolutionize the airline reservation sector. The\nimplications are growing effectiveness, improvement in security and greater\ncustomer contentment."
    },
    {
      "id": "2411.06535v1",
      "title": "Probabilistic Consensus through Ensemble Validation: A Framework for LLM Reliability",
      "summary": "Large Language Models (LLMs) have shown significant advances in text\ngeneration but often lack the reliability needed for autonomous deployment in\nhigh-stakes domains like healthcare, law, and finance. Existing approaches rely\non external knowledge or human oversight, limiting scalability. We introduce a\nnovel framework that repurposes ensemble methods for content validation through\nmodel consensus. In tests across 78 complex cases requiring factual accuracy\nand causal consistency, our framework improved precision from 73.1% to 93.9%\nwith two models (95% CI: 83.5%-97.9%) and to 95.6% with three models (95% CI:\n85.2%-98.8%). Statistical analysis indicates strong inter-model agreement\n($\\kappa$ > 0.76) while preserving sufficient independence to catch errors\nthrough disagreement. We outline a clear pathway to further enhance precision\nwith additional validators and refinements. Although the current approach is\nconstrained by multiple-choice format requirements and processing latency, it\noffers immediate value for enabling reliable autonomous AI systems in critical\napplications."
    },
    {
      "id": "2411.06529v1",
      "title": "Thermodynamically-Informed Iterative Neural Operators for Heterogeneous Elastic Localization",
      "summary": "Engineering problems frequently require solution of governing equations with\nspatially-varying discontinuous coefficients. Even for linear elliptic\nproblems, mapping large ensembles of coefficient fields to solutions can become\na major computational bottleneck using traditional numerical solvers.\nFurthermore, machine learning methods such as neural operators struggle to fit\nthese maps due to sharp transitions and high contrast in the coefficient fields\nand a scarcity of informative training data. In this work, we focus on a\ncanonical problem in computational mechanics: prediction of local elastic\ndeformation fields over heterogeneous material structures subjected to periodic\nboundary conditions. We construct a hybrid approximation for the\ncoefficient-to-solution map using a Thermodynamically-informed Iterative Neural\nOperator (TherINO). Rather than using coefficient fields as direct inputs and\niterating over a learned latent space, we employ thermodynamic encodings --\ndrawn from the constitutive equations -- and iterate over the solution space\nitself. Through an extensive series of case studies, we elucidate the\nadvantages of these design choices in terms of efficiency, accuracy, and\nflexibility. We also analyze the model's stability and extrapolation properties\non out-of-distribution coefficient fields and demonstrate an improved\nspeed-accuracy tradeoff for predicting elastic quantities of interest."
    },
    {
      "id": "2411.06528v1",
      "title": "Epistemic Integrity in Large Language Models",
      "summary": "Large language models are increasingly relied upon as sources of information,\nbut their propensity for generating false or misleading statements with high\nconfidence poses risks for users and society. In this paper, we confront the\ncritical problem of epistemic miscalibration $\\unicode{x2013}$ where a model's\nlinguistic assertiveness fails to reflect its true internal certainty. We\nintroduce a new human-labeled dataset and a novel method for measuring the\nlinguistic assertiveness of Large Language Models (LLMs) which cuts error rates\nby over 50% relative to previous benchmarks. Validated across multiple\ndatasets, our method reveals a stark misalignment between how confidently\nmodels linguistically present information and their actual accuracy. Further\nhuman evaluations confirm the severity of this miscalibration. This evidence\nunderscores the urgent risk of the overstated certainty LLMs hold which may\nmislead users on a massive scale. Our framework provides a crucial step forward\nin diagnosing this miscalibration, offering a path towards correcting it and\nmore trustworthy AI across domains."
    },
    {
      "id": "2411.06525v1",
      "title": "I2VControl-Camera: Precise Video Camera Control with Adjustable Motion Strength",
      "summary": "Video generation technologies are developing rapidly and have broad potential\napplications. Among these technologies, camera control is crucial for\ngenerating professional-quality videos that accurately meet user expectations.\nHowever, existing camera control methods still suffer from several limitations,\nincluding control precision and the neglect of the control for subject motion\ndynamics. In this work, we propose I2VControl-Camera, a novel camera control\nmethod that significantly enhances controllability while providing\nadjustability over the strength of subject motion. To improve control\nprecision, we employ point trajectory in the camera coordinate system instead\nof only extrinsic matrix information as our control signal. To accurately\ncontrol and adjust the strength of subject motion, we explicitly model the\nhigher-order components of the video trajectory expansion, not merely the\nlinear terms, and design an operator that effectively represents the motion\nstrength. We use an adapter architecture that is independent of the base model\nstructure. Experiments on static and dynamic scenes show that our framework\noutperformances previous methods both quantitatively and qualitatively."
    },
    {
      "id": "2411.06524v1",
      "title": "Does This Summary Answer My Question? Modeling Query-Focused Summary Readers with Rational Speech Acts",
      "summary": "Query-focused summarization (QFS) is the task of generating a summary in\nresponse to a user-written query. Despite its user-oriented nature, there has\nbeen limited work in QFS in explicitly considering a user's understanding of a\ngenerated summary, potentially causing QFS systems to underperform at inference\ntime. In this paper, we adapt the Rational Speech Act (RSA) framework, a model\nof human communication, to explicitly model a reader's understanding of a\nquery-focused summary and integrate it within the generation method of existing\nQFS systems. In particular, we introduce the answer reconstruction objective\nwhich approximates a reader's understanding of a summary by their ability to\nuse it to reconstruct the answer to their initial query. Using this objective,\nwe are able to re-rank candidate summaries generated by existing QFS systems\nand select summaries that better align with their corresponding query and\nreference summary. More generally, our study suggests that a simple and\neffective way of improving a language generation system designed for a\nuser-centered task may be to explicitly incorporate its user requirements into\nthe system's generation procedure."
    },
    {
      "id": "2411.06518v1",
      "title": "Causal Representation Learning from Multimodal Biological Observations",
      "summary": "Prevalent in biological applications (e.g., human phenotype measurements),\nmultimodal datasets can provide valuable insights into the underlying\nbiological mechanisms. However, current machine learning models designed to\nanalyze such datasets still lack interpretability and theoretical guarantees,\nwhich are essential to biological applications. Recent advances in causal\nrepresentation learning have shown promise in uncovering the interpretable\nlatent causal variables with formal theoretical certificates. Unfortunately,\nexisting works for multimodal distributions either rely on restrictive\nparametric assumptions or provide rather coarse identification results,\nlimiting their applicability to biological research which favors a detailed\nunderstanding of the mechanisms.\n  In this work, we aim to develop flexible identification conditions for\nmultimodal data and principled methods to facilitate the understanding of\nbiological datasets. Theoretically, we consider a flexible nonparametric latent\ndistribution (c.f., parametric assumptions in prior work) permitting causal\nrelationships across potentially different modalities. We establish\nidentifiability guarantees for each latent component, extending the subspace\nidentification results from prior work. Our key theoretical ingredient is the\nstructural sparsity of the causal connections among distinct modalities, which,\nas we will discuss, is natural for a large collection of biological systems.\nEmpirically, we propose a practical framework to instantiate our theoretical\ninsights. We demonstrate the effectiveness of our approach through extensive\nexperiments on both numerical and synthetic datasets. Results on a real-world\nhuman phenotype dataset are consistent with established medical research,\nvalidating our theoretical and methodological framework."
    },
    {
      "id": "2411.07271v1",
      "title": "Multi-hop Upstream Preemptive Traffic Signal Control with Deep Reinforcement Learning",
      "summary": "Traffic signal control is crucial for managing congestion in urban networks.\nExisting myopic pressure-based control methods focus only on immediate upstream\nlinks, leading to suboptimal green time allocation and increased network\ndelays. Effective signal control, however, inherently requires a broader\nspatial scope, as traffic conditions further upstream can significantly impact\ntraffic at the current location. This paper introduces a novel concept based on\nthe Markov chain theory, namely multi-hop upstream pressure, that generalizes\nthe conventional pressure to account for traffic conditions beyond the\nimmediate upstream links. This farsighted and compact metric informs the deep\nreinforcement learning agent to preemptively clear the present queues, guiding\nthe agent to optimize signal timings with a broader spatial awareness.\nSimulations on synthetic and realistic (Toronto) scenarios demonstrate\ncontrollers utilizing multi-hop upstream pressure significantly reduce overall\nnetwork delay by prioritizing traffic movements based on a broader\nunderstanding of upstream congestion."
    },
    {
      "id": "2411.07795v1",
      "title": "InvisMark: Invisible and Robust Watermarking for AI-generated Image Provenance",
      "summary": "The proliferation of AI-generated images has intensified the need for robust\ncontent authentication methods. We present InvisMark, a novel watermarking\ntechnique designed for high-resolution AI-generated images. Our approach\nleverages advanced neural network architectures and training strategies to\nembed imperceptible yet highly robust watermarks. InvisMark achieves\nstate-of-the-art performance in imperceptibility (PSNR$\\sim$51, SSIM $\\sim$\n0.998) while maintaining over 97\\% bit accuracy across various image\nmanipulations. Notably, we demonstrate the successful encoding of 256-bit\nwatermarks, significantly expanding payload capacity while preserving image\nquality. This enables the embedding of UUIDs with error correction codes,\nachieving near-perfect decoding success rates even under challenging image\ndistortions. We also address potential vulnerabilities against advanced attacks\nand propose mitigation strategies. By combining high imperceptibility, extended\npayload capacity, and resilience to manipulations, InvisMark provides a robust\nfoundation for ensuring media provenance in an era of increasingly\nsophisticated AI-generated content. Source code of this paper is available at:\nhttps://github.com/microsoft/InvisMark."
    },
    {
      "id": "2411.06510v1",
      "title": "Offline Handwritten Signature Verification Using a Stream-Based Approach",
      "summary": "Handwritten Signature Verification (HSV) systems distinguish between genuine\nand forged signatures. Traditional HSV development involves a static batch\nconfiguration, constraining the system's ability to model signatures to the\nlimited data available. Signatures exhibit high intra-class variability and are\nsensitive to various factors, including time and external influences, imparting\nthem a dynamic nature. This paper investigates the signature learning process\nwithin a data stream context. We propose a novel HSV approach with an adaptive\nsystem that receives an infinite sequence of signatures and is updated over\ntime. Experiments were carried out on GPDS Synthetic, CEDAR, and MCYT datasets.\nResults demonstrate the superior performance of the proposed method compared to\nstandard approaches that use a Support Vector Machine as a classifier.\nImplementation of the method is available at\nhttps://github.com/kdMoura/stream_hsv."
    },
    {
      "id": "2411.06508v1",
      "title": "Understanding the Role of Equivariance in Self-supervised Learning",
      "summary": "Contrastive learning has been a leading paradigm for self-supervised\nlearning, but it is widely observed that it comes at the price of sacrificing\nuseful features (\\eg colors) by being invariant to data augmentations. Given\nthis limitation, there has been a surge of interest in equivariant\nself-supervised learning (E-SSL) that learns features to be augmentation-aware.\nHowever, even for the simplest rotation prediction method, there is a lack of\nrigorous understanding of why, when, and how E-SSL learns useful features for\ndownstream tasks. To bridge this gap between practice and theory, we establish\nan information-theoretic perspective to understand the generalization ability\nof E-SSL. In particular, we identify a critical explaining-away effect in E-SSL\nthat creates a synergy between the equivariant and classification tasks. This\nsynergy effect encourages models to extract class-relevant features to improve\nits equivariant prediction, which, in turn, benefits downstream tasks requiring\nsemantic features. Based on this perspective, we theoretically analyze the\ninfluence of data transformations and reveal several principles for practical\ndesigns of E-SSL. Our theory not only aligns well with existing E-SSL methods\nbut also sheds light on new directions by exploring the benefits of model\nequivariance. We believe that a theoretically grounded understanding on the\nrole of equivariance would inspire more principled and advanced designs in this\nfield. Code is available at https://github.com/kaotty/Understanding-ESSL."
    },
    {
      "id": "2411.06506v1",
      "title": "CULL-MT: Compression Using Language and Layer pruning for Machine Translation",
      "summary": "Multilingual machine translation models often outperform traditional\nbilingual models by leveraging translation knowledge transfer. Recent\nadvancements have led to these models supporting hundreds of languages and\nachieving state-of-the-art results across various translation directions.\nHowever, as these models grow larger, their inference operations become\nincreasingly costly. In many use cases, there is no need to support such a wide\nrange of language pairs, as translation is typically needed in only a few\nselected directions. In this paper, we present CULL-MT, a compression method\nfor machine translation models based on structural layer pruning and selected\nlanguage directions. Our approach identifies and prunes unimportant layers\nusing a greedy strategy, then mitigates the impact by applying knowledge\ndistillation from the original model along with parameter-efficient\nfine-tuning. We apply CULL-MT to the NLLB-3.3B and LLaMA3.1-8B-Instruct models.\nIn a multi-way translation scenario (Persian, French, and German to English),\nwe find the NLLB-3.3B model to be robust, allowing 25% of layers to be pruned\nwith only a 0.9 spBLEU drop. However, LLaMA3.1-8B-Instruct is more sensitive,\nwith a 2.0 spBLEU drop after pruning 5 layers."
    },
    {
      "id": "2411.06503v2",
      "title": "Diffusion Sampling Correction via Approximately 10 Parameters",
      "summary": "Diffusion Probabilistic Models (DPMs) have demonstrated exceptional\nperformance in generative tasks, but this comes at the expense of sampling\nefficiency. To enhance sampling speed without sacrificing quality, various\ndistillation-based accelerated sampling algorithms have been recently proposed.\nHowever, they typically require significant additional training costs and model\nparameter storage, which limit their practical application. In this work, we\npropose PCA-based Adaptive Search (PAS), which optimizes existing solvers for\nDPMs with minimal learnable parameters and training costs. Specifically, we\nfirst employ PCA to obtain a few orthogonal unit basis vectors to span the\nhigh-dimensional sampling space, which enables us to learn just a set of\ncoordinates to correct the sampling direction; furthermore, based on the\nobservation that the cumulative truncation error exhibits an ``S''-shape, we\ndesign an adaptive search strategy that further enhances the sampling\nefficiency and reduces the number of stored parameters to approximately 10.\nExtensive experiments demonstrate that PAS can significantly enhance existing\nfast solvers in a plug-and-play manner with negligible costs. For instance, on\nCIFAR10, PAS requires only 12 parameters and less than 1 minute of training on\na single NVIDIA A100 GPU to optimize the DDIM from 15.69 FID (NFE=10) to 4.37."
    },
    {
      "id": "2411.06501v1",
      "title": "Individual Regret in Cooperative Stochastic Multi-Armed Bandits",
      "summary": "We study the regret in stochastic Multi-Armed Bandits (MAB) with multiple\nagents that communicate over an arbitrary connected communication graph. We\nshow a near-optimal individual regret bound of $\\tilde{O}(\\sqrt{AT/m}+A)$,\nwhere $A$ is the number of actions, $T$ the time horizon, and $m$ the number of\nagents. In particular, assuming a sufficient number of agents, we achieve a\nregret bound of $\\tilde{O}(A)$, which is independent of the sub-optimality gaps\nand the diameter of the communication graph. To the best of our knowledge, our\nstudy is the first to show an individual regret bound in cooperative stochastic\nMAB that is independent of the graph's diameter and applicable to\nnon-fully-connected communication graphs."
    },
    {
      "id": "2411.06500v1",
      "title": "Towards Graph Neural Network Surrogates Leveraging Mechanistic Expert Knowledge for Pandemic Response",
      "summary": "During the COVID-19 crisis, mechanistic models have been proven fundamental\nto guide evidence-based decision making. However, time-critical decisions in a\ndynamically changing environment restrict the time available for modelers to\ngather supporting evidence. As infectious disease dynamics are often\nheterogeneous on a spatial or demographic scale, models should be resolved\naccordingly. In addition, with a large number of potential interventions, all\nscenarios can barely be computed on time, even when using supercomputing\nfacilities. We suggest to combine complex mechanistic models with data-driven\nsurrogate models to allow for on-the-fly model adaptations by public health\nexperts. We build upon a spatially and demographically resolved infectious\ndisease model and train a graph neural network for data sets representing early\nphases of the pandemic. The resulting networks reached an execution time of\nless than a second, a significant speedup compared to the metapopulation\napproach. The suggested approach yields potential for on-the-fly execution and,\nthus, integration of disease dynamics models in low-barrier website\napplications. For the approach to be used with decision-making, datasets with\nlarger variance will have to be considered."
    },
    {
      "id": "2411.06499v1",
      "title": "Mitigating covariate shift in non-colocated data with learned parameter priors",
      "summary": "When training data are distributed across{ time or space,} covariate shift\nacross fragments of training data biases cross-validation, compromising model\nselection and assessment. We present \\textit{Fragmentation-Induced\ncovariate-shift Remediation} ($FIcsR$), which minimizes an $f$-divergence\nbetween a fragment's covariate distribution and that of the standard\ncross-validation baseline. We s{how} an equivalence with popular\nimportance-weighting methods. {The method}'s numerical solution poses a\ncomputational challenge owing to the overparametrized nature of a neural\nnetwork, and we derive a Fisher Information approximation. When accumulated\nover fragments, this provides a global estimate of the amount of shift\nremediation thus far needed, and we incorporate that as a prior via the\nminimization objective. In the paper, we run extensive classification\nexperiments on multiple data classes, over $40$ datasets, and with data batched\nover multiple sequence lengths. We extend the study to the $k$-fold\ncross-validation setting through a similar set of experiments. An ablation\nstudy exposes the method to varying amounts of shift and demonstrates slower\ndegradation with $FIcsR$ in place. The results are promising under all these\nconditions; with improved accuracy against batch and fold state-of-the-art by\nmore than $5\\%$ and $10\\%$, respectively."
    },
    {
      "id": "2411.06498v1",
      "title": "Barriers to Complexity-Theoretic Proofs that Achieving AGI Using Machine Learning is Intractable",
      "summary": "A recent paper (van Rooij et al. 2024) claims to have proved that achieving\nhuman-like intelligence using learning from data is intractable in a\ncomplexity-theoretic sense. We identify that the proof relies on an unjustified\nassumption about the distribution of (input, output) pairs to the system. We\nbriefly discuss that assumption in the context of two fundamental barriers to\nrepairing the proof: the need to precisely define ``human-like,\" and the need\nto account for the fact that a particular machine learning system will have\nparticular inductive biases that are key to the analysis."
    },
    {
      "id": "2411.06493v2",
      "title": "LProtector: An LLM-driven Vulnerability Detection System",
      "summary": "This paper presents LProtector, an automated vulnerability detection system\nfor C/C++ codebases driven by the large language model (LLM) GPT-4o and\nRetrieval-Augmented Generation (RAG). As software complexity grows, traditional\nmethods face challenges in detecting vulnerabilities effectively. LProtector\nleverages GPT-4o's powerful code comprehension and generation capabilities to\nperform binary classification and identify vulnerabilities within target\ncodebases. We conducted experiments on the Big-Vul dataset, showing that\nLProtector outperforms two state-of-the-art baselines in terms of F1 score,\ndemonstrating the potential of integrating LLMs with vulnerability detection."
    },
    {
      "id": "2411.08719v1",
      "title": "Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training in LLMs",
      "summary": "Large Language Models (LLMs) have attracted significant attention due to\ntheir human-like language understanding and generation capabilities, as well as\ntheir applicability across various domains.\n  These models, characterized by their massive scale and extensive training\ndata, continue to push the boundaries of what is possible in natural language\nprocessing. The Llama 3 series, for instance, exemplifies this trend with its\nflagship model boasting 405 billion parameters trained on 15.6 trillion tokens.\nThe immense computational demands associated with training such models have\nspurred ongoing research into optimizing the efficiency of the training\nprocess, particularly through the use of lower-precision formats.\n  NVIDIA's H100 GPU, which introduces support for FP8 in addition to the more\nconventional FP16 and BF16 formats, has emerged as a focal point in this\noptimization effort. Preliminary studies suggest that FP8 could offer\nsubstantial reductions in training time without sacrificing model performance\nwhen compared to BF16, making it a promising candidate for large-scale model\ntraining. However, the broader implications of adopting FP8, particularly in\nterms of training stability and downstream task performance, have yet to be\nfully understood.\n  In this study, we delve into the practical trade-offs involved in adopting\nFP8 over BF16 for training LLMs."
    },
    {
      "id": "2411.06490v1",
      "title": "Hermes: A Large Language Model Framework on the Journey to Autonomous Networks",
      "summary": "The drive toward automating cellular network operations has grown with the\nincreasing complexity of these systems. Despite advancements, full autonomy\ncurrently remains out of reach due to reliance on human intervention for\nmodeling network behaviors and defining policies to meet target requirements.\nNetwork Digital Twins (NDTs) have shown promise in enhancing network\nintelligence, but the successful implementation of this technology is\nconstrained by use case-specific architectures, limiting its role in advancing\nnetwork autonomy. A more capable network intelligence, or \"telecommunications\nbrain\", is needed to enable seamless, autonomous management of cellular\nnetwork. Large Language Models (LLMs) have emerged as potential enablers for\nthis vision but face challenges in network modeling, especially in reasoning\nand handling diverse data types. To address these gaps, we introduce Hermes, a\nchain of LLM agents that uses \"blueprints\" for constructing NDT instances\nthrough structured and explainable logical steps. Hermes allows automatic,\nreliable, and accurate network modeling of diverse use cases and\nconfigurations, thus marking progress toward fully autonomous network\noperations."
    },
    {
      "id": "2411.06477v1",
      "title": "VocalTweets: Investigating Social Media Offensive Language Among Nigerian Musicians",
      "summary": "Musicians frequently use social media to express their opinions, but they\noften convey different messages in their music compared to their posts online.\nSome utilize these platforms to abuse their colleagues, while others use it to\nshow support for political candidates or engage in activism, as seen during the\n#EndSars protest. There are extensive research done on offensive language\ndetection on social media, the usage of offensive language by musicians has\nreceived limited attention. In this study, we introduce VocalTweets, a\ncode-switched and multilingual dataset comprising tweets from 12 prominent\nNigerian musicians, labeled with a binary classification method as Normal or\nOffensive. We trained a model using HuggingFace's base-Twitter-RoBERTa,\nachieving an F1 score of 74.5. Additionally, we conducted cross-corpus\nexperiments with the OLID dataset to evaluate the generalizability of our\ndataset."
    },
    {
      "id": "2411.06469v1",
      "title": "ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical Prediction?",
      "summary": "Large Language Models (LLMs) hold great promise to revolutionize current\nclinical systems for their superior capacities on medical text processing tasks\nand medical licensing exams. Meanwhile, traditional ML models such as SVM and\nXGBoost have still been mainly adopted in clinical prediction tasks. An\nemerging question is Can LLMs beat traditional ML models in clinical\nprediction? Thus, we build a new benchmark ClinicalBench to comprehensively\nstudy the clinical predictive modeling capacities of both general-purpose and\nmedical LLMs, and compare them with traditional ML models. ClinicalBench\nembraces three common clinical prediction tasks, two databases, 14\ngeneral-purpose LLMs, 8 medical LLMs, and 11 traditional ML models. Through\nextensive empirical investigation, we discover that both general-purpose and\nmedical LLMs, even with different model scales, diverse prompting or\nfine-tuning strategies, still cannot beat traditional ML models in clinical\nprediction yet, shedding light on their potential deficiency in clinical\nreasoning and decision-making. We call for caution when practitioners adopt\nLLMs in clinical applications. ClinicalBench can be utilized to bridge the gap\nbetween LLMs' development for healthcare and real-world clinical practice."
    },
    {
      "id": "2411.06465v1",
      "title": "Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator",
      "summary": "In large language model (LLM) training, several parallelization strategies,\nincluding Tensor Parallelism (TP), Pipeline Parallelism (PP), Data Parallelism\n(DP), as well as Sequence Parallelism (SP) and Context Parallelism (CP), are\nemployed to distribute model parameters, activations, and optimizer states\nacross devices. Identifying the optimal parallelization configuration for each\nenvironment while avoiding GPU memory overflow remains a challenging task. In\nthis study, we provide precise formulas to estimate the memory consumed by\nparameters, gradients, optimizer states, and activations for 4D parallel\ntraining (DP, TP, PP, CP) in the Llama architecture. We conducted 454\nexperiments on A100 and H100 GPUs, incorporating often neglected factors such\nas temporary buffers and memory fragmentation into our analysis. Results\nindicate that when the estimated memory usage is below 80\\% of the available\nGPU memory, the training never encounters out-of-memory errors. This simple yet\neffective formula allows us to identify parallelization configurations that\ncould lead to memory overflow in advance, significantly reducing the\nconfiguration search space. Additionally, through a comprehensive exploration\nof optimal configurations in 4D parallelism, our analysis of the 454\nexperimental results provides empirical insights into optimal 4D parallelism\nconfigurations."
    },
    {
      "id": "2411.06463v1",
      "title": "RL-Pruner: Structured Pruning Using Reinforcement Learning for CNN Compression and Acceleration",
      "summary": "Convolutional Neural Networks (CNNs) have demonstrated exceptional\nperformance in recent years. Compressing these models not only reduces storage\nrequirements, making deployment to edge devices feasible, but also accelerates\ninference, thereby reducing latency and computational costs. Structured\npruning, which removes filters at the layer level, directly modifies the model\narchitecture. This approach achieves a more compact architecture while\nmaintaining target accuracy, ensuring that the compressed model retains good\ncompatibility and hardware efficiency. Our method is based on a key\nobservation: filters in different layers of a neural network have varying\nimportance to the model's performance. When the number of filters to prune is\nfixed, the optimal pruning distribution across different layers is uneven to\nminimize performance loss. Layers that are more sensitive to pruning should\naccount for a smaller proportion of the pruning distribution. To leverage this\ninsight, we propose RL-Pruner, which uses reinforcement learning to learn the\noptimal pruning distribution. RL-Pruner can automatically extract dependencies\nbetween filters in the input model and perform pruning, without requiring\nmodel-specific pruning implementations. We conducted experiments on models such\nas GoogleNet, ResNet, and MobileNet, comparing our approach to other structured\npruning methods to validate its effectiveness. Our code is available at\nhttps://github.com/Beryex/RLPruner-CNN."
    },
    {
      "id": "2411.06448v1",
      "title": "Over-parameterized Student Model via Tensor Decomposition Boosted Knowledge Distillation",
      "summary": "Increased training parameters have enabled large pre-trained models to excel\nin various downstream tasks. Nevertheless, the extensive computational\nrequirements associated with these models hinder their widespread adoption\nwithin the community. We focus on Knowledge Distillation (KD), where a compact\nstudent model is trained to mimic a larger teacher model, facilitating the\ntransfer of knowledge of large models. In contrast to much of the previous\nwork, we scale up the parameters of the student model during training, to\nbenefit from overparameterization without increasing the inference latency. In\nparticular, we propose a tensor decomposition strategy that effectively\nover-parameterizes the relatively small student model through an efficient and\nnearly lossless decomposition of its parameter matrices into higher-dimensional\ntensors. To ensure efficiency, we further introduce a tensor constraint loss to\nalign the high-dimensional tensors between the student and teacher models.\nComprehensive experiments validate the significant performance enhancement by\nour approach in various KD tasks, covering computer vision and natural language\nprocessing areas. Our code is available at\nhttps://github.com/intell-sci-comput/OPDF."
    },
    {
      "id": "2411.06447v1",
      "title": "Multi-Parameter Molecular MRI Quantification using Physics-Informed Self-Supervised Learning",
      "summary": "Biophysical model fitting plays a key role in obtaining quantitative\nparameters from physiological signals and images. However, the model complexity\nfor molecular magnetic resonance imaging (MRI) often translates into excessive\ncomputation time, which makes clinical use impractical. Here, we present a\ngeneric computational approach for solving the parameter extraction inverse\nproblem posed by ordinary differential equation (ODE) modeling coupled with\nexperimental measurement of the system dynamics. This is achieved by\nformulating a numerical ODE solver to function as a step-wise analytical one,\nthereby making it compatible with automatic differentiation-based optimization.\nThis enables efficient gradient-based model fitting, and provides a new\napproach to parameter quantification based on self-supervised learning from a\nsingle data observation. The neural-network-based train-by-fit pipeline was\nused to quantify semisolid magnetization transfer (MT) and chemical exchange\nsaturation transfer (CEST) amide proton exchange parameters in the human brain,\nin an in-vivo molecular MRI study (n=4). The entire pipeline of the first whole\nbrain quantification was completed in 18.3$\\pm$8.3 minutes, which is an\norder-of-magnitude faster than comparable alternatives. Reusing the\nsingle-subject-trained network for inference in new subjects took 1.0$\\pm$0.2\ns, to provide results in agreement with literature values and scan-specific fit\nresults (Pearson's r>0.98, p<0.0001)."
    },
    {
      "id": "2411.06445v1",
      "title": "Prompt-Efficient Fine-Tuning for GPT-like Deep Models to Reduce Hallucination and to Improve Reproducibility in Scientific Text Generation Using Stochastic Optimisation Techniques",
      "summary": "Large Language Models (LLMs) are increasingly adopted for complex scientific\ntext generation tasks, yet they often suffer from limitations in accuracy,\nconsistency, and hallucination control. This thesis introduces a\nParameter-Efficient Fine-Tuning (PEFT) approach tailored for GPT-like models,\naiming to mitigate hallucinations and enhance reproducibility, particularly in\nthe computational domain of mass spectrometry. We implemented Low-Rank\nAdaptation (LoRA) adapters to refine GPT-2, termed MS-GPT, using a specialized\ncorpus of mass spectrometry literature. Through novel evaluation methods\napplied to LLMs, including BLEU, ROUGE, and Perplexity scores, the fine-tuned\nMS-GPT model demonstrated superior text coherence and reproducibility compared\nto the baseline GPT-2, confirmed through statistical analysis with the Wilcoxon\nrank-sum test. Further, we propose a reproducibility metric based on cosine\nsimilarity of model outputs under controlled prompts, showcasing MS-GPT's\nenhanced stability. This research highlights PEFT's potential to optimize LLMs\nfor scientific contexts, reducing computational costs while improving model\nreliability."
    },
    {
      "id": "2411.08063v1",
      "title": "MatPilot: an LLM-enabled AI Materials Scientist under the Framework of Human-Machine Collaboration",
      "summary": "The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization."
    },
    {
      "id": "2411.06442v1",
      "title": "Local Implicit Wavelet Transformer for Arbitrary-Scale Super-Resolution",
      "summary": "Implicit neural representations have recently demonstrated promising\npotential in arbitrary-scale Super-Resolution (SR) of images. Most existing\nmethods predict the pixel in the SR image based on the queried coordinate and\nensemble nearby features, overlooking the importance of incorporating\nhigh-frequency prior information in images, which results in limited\nperformance in reconstructing high-frequency texture details in images. To\naddress this issue, we propose the Local Implicit Wavelet Transformer (LIWT) to\nenhance the restoration of high-frequency texture details. Specifically, we\ndecompose the features extracted by an encoder into four sub-bands containing\ndifferent frequency information using Discrete Wavelet Transform (DWT). We then\nintroduce the Wavelet Enhanced Residual Module (WERM) to transform these four\nsub-bands into high-frequency priors, followed by utilizing the Wavelet Mutual\nProjected Fusion (WMPF) and the Wavelet-aware Implicit Attention (WIA) to fully\nexploit the high-frequency prior information for recovering high-frequency\ndetails in images. We conducted extensive experiments on benchmark datasets to\nvalidate the effectiveness of LIWT. Both qualitative and quantitative results\ndemonstrate that LIWT achieves promising performance in arbitrary-scale SR\ntasks, outperforming other state-of-the-art methods. The code is available at\nhttps://github.com/dmhdmhdmh/LIWT."
    },
    {
      "id": "2411.06441v1",
      "title": "Detecting AutoEncoder is Enough to Catch LDM Generated Images",
      "summary": "In recent years, diffusion models have become one of the main methods for\ngenerating images. However, detecting images generated by these models remains\na challenging task. This paper proposes a novel method for detecting images\ngenerated by Latent Diffusion Models (LDM) by identifying artifacts introduced\nby their autoencoders. By training a detector to distinguish between real\nimages and those reconstructed by the LDM autoencoder, the method enables\ndetection of generated images without directly training on them. The novelty of\nthis research lies in the fact that, unlike similar approaches, this method\ndoes not require training on synthesized data, significantly reducing\ncomputational costs and enhancing generalization ability. Experimental results\nshow high detection accuracy with minimal false positives, making this approach\na promising tool for combating fake images."
    },
    {
      "id": "2411.06438v1",
      "title": "PLM-Based Discrete Diffusion Language Models with Entropy-Adaptive Gibbs Sampling",
      "summary": "Recently, discrete diffusion language models have demonstrated promising\nresults in NLP. However, there has been limited research on integrating\nPretrained Language Models (PLMs) into discrete diffusion models, resulting in\nunderwhelming performance in downstream NLP generation tasks. This integration\nis particularly challenging because of the discrepancy between step-wise\ndenoising strategy of diffusion models and single-step mask prediction approach\nof MLM-based PLMs. In this paper, we introduce Diffusion-EAGS, a novel approach\nthat effectively integrates PLMs with the diffusion models. Furthermore, as it\nis challenging for PLMs to determine where to apply denoising during the\ndiffusion process, we integrate an entropy tracking module to assist them.\nFinally, we propose entropy-based noise scheduling in the forward process to\nimprove the effectiveness of entropy-adaptive sampling throughout the\ngeneration phase. Experimental results show that Diffusion-EAGS outperforms\nexisting diffusion baselines in downstream generation tasks, achieving high\ntext quality and diversity with precise token-level control. We also show that\nour model is capable of adapting to bilingual and low-resource settings, which\nare common in real-world applications."
    },
    {
      "id": "2411.06437v1",
      "title": "CTC-Assisted LLM-Based Contextual ASR",
      "summary": "Contextual ASR or hotword customization holds substantial practical value.\nDespite the impressive performance of current end-to-end (E2E) automatic speech\nrecognition (ASR) systems, they often face challenges in accurately recognizing\nrare words. Typical E2E contextual ASR models commonly feature complex\narchitectures and decoding mechanisms, limited in performance and susceptible\nto interference from distractor words. With large language model (LLM)-based\nASR models emerging as the new mainstream, we propose a CTC-Assisted LLM-Based\nContextual ASR model with an efficient filtering algorithm. By using coarse CTC\ndecoding results to filter potential relevant hotwords and incorporating them\ninto LLM prompt input, our model attains WER/B-WER of 1.27%/3.67% and\n2.72%/8.02% on the Librispeech test-clean and test-other sets targeting on\nrecognizing rare long-tail words, demonstrating significant improvements\ncompared to the baseline LLM-based ASR model, and substantially surpassing\nother related work. More remarkably, with the help of the large language model\nand proposed filtering algorithm, our contextual ASR model still performs well\nwith 2000 biasing words."
    },
    {
      "id": "2411.06436v1",
      "title": "Predictors of disease outbreaks at continentalscale in the African region: Insights and predictions with geospatial artificial intelligence using earth observations and routine disease surveillance data",
      "summary": "Objectives: Our research adopts computational techniques to analyze disease\noutbreaks weekly over a large geographic area while maintaining local-level\nanalysis by incorporating relevant high-spatial resolution cultural and\nenvironmental datasets. The abundance of data about disease outbreaks gives\nscientists an excellent opportunity to uncover patterns in disease spread and\nmake future predictions. However, data over a sizeable geographic area quickly\noutpace human cognition. Our study area covers a significant portion of the\nAfrican continent (about 17,885,000 km2). The data size makes computational\nanalysis vital to assist human decision-makers. Methods: We first applied\nglobal and local spatial autocorrelation for malaria, cholera, meningitis, and\nyellow fever case counts. We then used machine learning to predict the weekly\npresence of these diseases in the second-level administrative district. Lastly,\nwe used machine learning feature importance methods on the variables that\naffect spread. Results: Our spatial autocorrelation results show that\ngeographic nearness is critical but varies in effect and space. Moreover, we\nidentified many interesting hot and cold spots and spatial outliers. The\nmachine learning model infers a binary class of cases or none with the best F1\nscore of 0.96 for malaria. Machine learning feature importance uncovered\ncritical cultural and environmental factors affecting outbreaks and variations\nbetween diseases. Conclusions: Our study shows that data analytics and machine\nlearning are vital to understanding and monitoring disease outbreaks locally\nacross vast areas. The speed at which these methods produce insights can be\ncritical during epidemics and emergencies."
    },
    {
      "id": "2411.06429v1",
      "title": "Reinforcement learning for Quantum Tiq-Taq-Toe",
      "summary": "Quantum Tiq-Taq-Toe is a well-known benchmark and playground for both quantum\ncomputing and machine learning. Despite its popularity, no reinforcement\nlearning (RL) methods have been applied to Quantum Tiq-Taq-Toe. Although there\nhas been some research on Quantum Chess this game is significantly more complex\nin terms of computation and analysis. Therefore, we study the combination of\nquantum computing and reinforcement learning in Quantum Tiq-Taq-Toe, which may\nserve as an accessible testbed for the integration of both fields.\n  Quantum games are challenging to represent classically due to their inherent\npartial observability and the potential for exponential state complexity. In\nQuantum Tiq-Taq-Toe, states are observed through Measurement (a 3x3 matrix of\nstate probabilities) and Move History (a 9x9 matrix of entanglement relations),\nmaking strategy complex as each move can collapse the quantum state."
    },
    {
      "id": "2411.06428v1",
      "title": "Neuro-Symbolic Rule Lists",
      "summary": "Machine learning models deployed in sensitive areas such as healthcare must\nbe interpretable to ensure accountability and fairness. Rule lists (if Age < 35\n$\\wedge$ Priors > 0 then Recidivism = True, else if Next Condition . . . )\noffer full transparency, making them well-suited for high-stakes decisions.\nHowever, learning such rule lists presents significant challenges. Existing\nmethods based on combinatorial optimization require feature pre-discretization\nand impose restrictions on rule size. Neuro-symbolic methods use more scalable\ncontinuous optimization yet place similar pre-discretization constraints and\nsuffer from unstable optimization. To address the existing limitations, we\nintroduce NeuRules, an end-to-end trainable model that unifies discretization,\nrule learning, and rule order into a single differentiable framework. We\nformulate a continuous relaxation of the rule list learning problem that\nconverges to a strict rule list through temperature annealing. NeuRules learns\nboth the discretizations of individual features, as well as their combination\ninto conjunctive rules without any pre-processing or restrictions. Extensive\nexperiments demonstrate that NeuRules consistently outperforms both\ncombinatorial and neuro-symbolic methods, effectively learning simple and\ncomplex rules, as well as their order, across a wide range of datasets."
    },
    {
      "id": "2411.06427v1",
      "title": "UniGAD: Unifying Multi-level Graph Anomaly Detection",
      "summary": "Graph Anomaly Detection (GAD) aims to identify uncommon, deviated, or\nsuspicious objects within graph-structured data. Existing methods generally\nfocus on a single graph object type (node, edge, graph, etc.) and often\noverlook the inherent connections among different object types of graph\nanomalies. For instance, a money laundering transaction might involve an\nabnormal account and the broader community it interacts with. To address this,\nwe present UniGAD, the first unified framework for detecting anomalies at node,\nedge, and graph levels jointly. Specifically, we develop the Maximum Rayleigh\nQuotient Subgraph Sampler (MRQSampler) that unifies multi-level formats by\ntransferring objects at each level into graph-level tasks on subgraphs. We\ntheoretically prove that MRQSampler maximizes the accumulated spectral energy\nof subgraphs (i.e., the Rayleigh quotient) to preserve the most significant\nanomaly information. To further unify multi-level training, we introduce a\nnovel GraphStitch Network to integrate information across different levels,\nadjust the amount of sharing required at each level, and harmonize conflicting\ntraining goals. Comprehensive experiments show that UniGAD outperforms both\nexisting GAD methods specialized for a single task and graph prompt-based\napproaches for multiple tasks, while also providing robust zero-shot task\ntransferability. All codes can be found at\nhttps://github.com/lllyyq1121/UniGAD."
    },
    {
      "id": "2411.06426v1",
      "title": "SequentialBreak: Large Language Models Can be Fooled by Embedding Jailbreak Prompts into Sequential Prompt Chains",
      "summary": "As the integration of the Large Language Models (LLMs) into various\napplications increases, so does their susceptibility to misuse, raising\nsignificant security concerns. Numerous jailbreak attacks have been proposed to\nassess the security defense of LLMs. Current jailbreak attacks mainly rely on\nscenario camouflage, prompt obfuscation, prompt optimization, and prompt\niterative optimization to conceal malicious prompts. In particular, sequential\nprompt chains in a single query can lead LLMs to focus on certain prompts while\nignoring others, facilitating context manipulation. This paper introduces\nSequentialBreak, a novel jailbreak attack that exploits this vulnerability. We\ndiscuss several scenarios, not limited to examples like Question Bank, Dialog\nCompletion, and Game Environment, where the harmful prompt is embedded within\nbenign ones that can fool LLMs into generating harmful responses. The distinct\nnarrative structures of these scenarios show that SequentialBreak is flexible\nenough to adapt to various prompt formats beyond those discussed. Extensive\nexperiments demonstrate that SequentialBreak uses only a single query to\nachieve a substantial gain of attack success rate over existing baselines\nagainst both open-source and closed-source models. Through our research, we\nhighlight the urgent need for more robust and resilient safeguards to enhance\nLLM security and prevent potential misuse. All the result files and website\nassociated with this research are available in this GitHub repository:\nhttps://anonymous.4open.science/r/JailBreakAttack-4F3B/."
    },
    {
      "id": "2411.06424v1",
      "title": "Ablation is Not Enough to Emulate DPO: How Neuron Dynamics Drive Toxicity Reduction",
      "summary": "Safety fine-tuning algorithms are commonly used to fine-tune language models\nto reduce harmful outputs, but the exact internal mechanisms of how those\nmodels achieve this remain unclear. In studying direct preference optimisation\n(DPO) for toxicity reduction, current explanations claim that DPO works by\ndampening the most toxic MLP neurons to learn an offset to avert toxic regions\nin the residual stream. However, by ablating the most toxic neurons and\napplying activation patching, we find this explanation incomplete. By\nprojecting neuron activation changes onto a toxicity probe, we find that only\n31.8\\% of toxicity reduction comes from dampened toxic neurons. Instead, DPO\nreduces toxicity by accumulating effects across multiple neuron groups, both\nreducing writing in the toxic direction and promoting anti-toxicity in the\nresidual stream. Moreover, DPO gives noisy adjustments to neuron activations,\nwith many neurons actually increasing toxicity. This indicates that DPO is a\nbalancing process between opposing neuron effects to achieve toxicity\nreduction."
    },
    {
      "id": "2411.06420v1",
      "title": "Generating Mixcode Popular Songs with Artificial Intelligence: Concepts, Plans, and Speculations",
      "summary": "Music is a potent form of expression that can communicate, accentuate or even\ncreate the emotions of an individual or a collective. Both historically and in\ncontemporary experiences, musical expression was and is commonly\ninstrumentalized for social, political and/or economic purposes. Generative\nartificial intelligence provides a wealth of both opportunities and challenges\nwith regard to music and its role in society. This paper discusses a proposed\nproject integrating artificial intelligence and popular music, with the\nultimate goal of creating a powerful tool for implementing music for social\ntransformation, education, healthcare, and emotional well-being. Given that it\nis being presented at the outset of a collaboration between a computer\nscientist/data analyst and an ethnomusicologist/social anthropologist. it is\nmainly conceptual and somewhat speculative in nature."
    },
    {
      "id": "2411.06409v1",
      "title": "Automated Strategy Invention for Confluence of Term Rewrite Systems",
      "summary": "Term rewriting plays a crucial role in software verification and compiler\noptimization. With dozens of highly parameterizable techniques developed to\nprove various system properties, automatic term rewriting tools work in an\nextensive parameter space. This complexity exceeds human capacity for parameter\nselection, motivating an investigation into automated strategy invention. In\nthis paper, we focus on confluence, an important property of term rewrite\nsystems, and apply machine learning to develop the first learning-guided\nautomatic confluence prover. Moreover, we randomly generate a large dataset to\nanalyze confluence for term rewrite systems. Our results focus on improving the\nstate-of-the-art automatic confluence prover CSI: When equipped with our\ninvented strategies, it surpasses its human-designed strategies both on the\naugmented dataset and on the original human-created benchmark dataset Cops,\nproving/disproving the confluence of several term rewrite systems for which no\nautomated proofs were known before."
    },
    {
      "id": "2411.06406v1",
      "title": "Locally Adaptive One-Class Classifier Fusion with Dynamic $\\ell$p-Norm Constraints for Robust Anomaly Detection",
      "summary": "This paper presents a novel approach to one-class classifier fusion through\nlocally adaptive learning with dynamic $\\ell$p-norm constraints. We introduce a\nframework that dynamically adjusts fusion weights based on local data\ncharacteristics, addressing fundamental challenges in ensemble-based anomaly\ndetection. Our method incorporates an interior-point optimization technique\nthat significantly improves computational efficiency compared to traditional\nFrank-Wolfe approaches, achieving up to 19-fold speed improvements in complex\nscenarios. The framework is extensively evaluated on standard UCI benchmark\ndatasets and specialized temporal sequence datasets, demonstrating superior\nperformance across diverse anomaly types. Statistical validation through\nSkillings-Mack tests confirms our method's significant advantages over existing\napproaches, with consistent top rankings in both pure and non-pure learning\nscenarios. The framework's ability to adapt to local data patterns while\nmaintaining computational efficiency makes it particularly valuable for\nreal-time applications where rapid and accurate anomaly detection is crucial."
    },
    {
      "id": "2411.06403v1",
      "title": "Mastering NIM and Impartial Games with Weak Neural Networks: An AlphaZero-inspired Multi-Frame Approach",
      "summary": "This paper provides a theoretical framework that validates and explains the\nresults in the work with Bei Zhou experimentally finding that AlphaZero-style\nreinforcement learning algorithms struggle to learn optimal play in NIM, a\ncanonical impartial game proposed as an AI challenge by Harvey Friedman in\n2017. Our analysis resolves a controversy around these experimental results,\nwhich revealed unexpected difficulties in learning NIM despite its mathematical\nsimplicity compared to games like chess and Go.\n  Our key contributions are as follows:\n  We prove that by incorporating recent game history, these limited AlphaZero\nmodels can, in principle, achieve optimal play in NIM.\n  We introduce a novel search strategy where roll-outs preserve game-theoretic\nvalues during move selection, guided by a specialised policy network.\n  We provide constructive proofs showing that our approach enables optimal play\nwithin the \\(\\text{AC}^0\\) complexity class despite the theoretical limitations\nof these networks.\n  This research demonstrates how constrained neural networks when properly\ndesigned, can achieve sophisticated decision-making even in domains where their\nbasic computational capabilities appear insufficient."
    },
    {
      "id": "2411.06402v1",
      "title": "Fineweb-Edu-Ar: Machine-translated Corpus to Support Arabic Small Language Models",
      "summary": "As large language models (LLMs) grow and develop, so do their data demands.\nThis is especially true for multilingual LLMs, where the scarcity of\nhigh-quality and readily available data online has led to a multitude of\nsynthetic dataset generation approaches. A key technique in this space is\nmachine translation (MT), where high-quality English text is adapted to a\ntarget, comparatively low-resource language. This report introduces\nFineWeb-Edu-Ar, a machine-translated version of the exceedingly popular\n(deduplicated) FineWeb-Edu dataset from HuggingFace. To the best of our\nknowledge, FineWeb-Edu-Ar is the largest publicly available machine-translated\nArabic dataset out there, with its size of 202B tokens of an Arabic-trained\ntokenizer."
    },
    {
      "id": "2411.06396v1",
      "title": "A Variance Minimization Approach to Temporal-Difference Learning",
      "summary": "Fast-converging algorithms are a contemporary requirement in reinforcement\nlearning. In the context of linear function approximation, the magnitude of the\nsmallest eigenvalue of the key matrix is a major factor reflecting the\nconvergence speed. Traditional value-based RL algorithms focus on minimizing\nerrors. This paper introduces a variance minimization (VM) approach for\nvalue-based RL instead of error minimization. Based on this approach, we\nproposed two objectives, the Variance of Bellman Error (VBE) and the Variance\nof Projected Bellman Error (VPBE), and derived the VMTD, VMTDC, and VMETD\nalgorithms. We provided proofs of their convergence and optimal policy\ninvariance of the variance minimization. Experimental studies validate the\neffectiveness of the proposed algorithms."
    },
    {
      "id": "2411.06394v1",
      "title": "Local vs. Global Models for Hierarchical Forecasting",
      "summary": "Hierarchical time series forecasting plays a crucial role in decision-making\nin various domains while presenting significant challenges for modelling as\nthey involve multiple levels of aggregation, constraints, and availability of\ninformation. This study explores the influence of distinct information\nutilisation on the accuracy of hierarchical forecasts, proposing and evaluating\nlocals and a range of Global Forecasting Models (GFMs). In contrast to local\nmodels, which forecast each series independently, we develop GFMs to exploit\ncross-series and cross-hierarchies information, improving both forecasting\nperformance and computational efficiency. We employ reconciliation methods to\nensure coherency in forecasts and use the Mean Absolute Scaled Error (MASE) and\nMultiple Comparisons with the Best (MCB) tests to assess statistical\nsignificance. The findings indicate that GFMs possess significant advantages\nfor hierarchical forecasting, providing more accurate and computationally\nefficient solutions across different levels in a hierarchy. Two specific GFMs\nbased on LightGBM are introduced, demonstrating superior accuracy and lower\nmodel complexity than their counterpart local models and conventional methods\nsuch as Exponential Smoothing (ES) and Autoregressive Integrated Moving Average\n(ARIMA)."
    },
    {
      "id": "2411.06391v1",
      "title": "CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction",
      "summary": "There are two issues in news-driven multi-stock movement prediction tasks\nthat are not well solved in the existing works. On the one hand, \"relation\ndiscovery\" is a pivotal part when leveraging the price information of other\nstocks to achieve accurate stock movement prediction. Given that stock\nrelations are often unidirectional, such as the \"supplier-consumer\"\nrelationship, causal relations are more appropriate to capture the impact\nbetween stocks. On the other hand, there is substantial noise existing in the\nnews data leading to extracting effective information with difficulty. With\nthese two issues in mind, we propose a novel framework called CausalStock for\nnews-driven multi-stock movement prediction, which discovers the temporal\ncausal relations between stocks. We design a lag-dependent temporal causal\ndiscovery mechanism to model the temporal causal graph distribution. Then a\nFunctional Causal Model is employed to encapsulate the discovered causal\nrelations and predict the stock movements. Additionally, we propose a Denoised\nNews Encoder by taking advantage of the excellent text evaluation ability of\nlarge language models (LLMs) to extract useful information from massive news\ndata. The experiment results show that CausalStock outperforms the strong\nbaselines for both news-driven multi-stock movement prediction and multi-stock\nmovement prediction tasks on six real-world datasets collected from the US,\nChina, Japan, and UK markets. Moreover, getting benefit from the causal\nrelations, CausalStock could offer a clear prediction mechanism with good\nexplainability."
    },
    {
      "id": "2411.06389v1",
      "title": "Optimal Execution with Reinforcement Learning",
      "summary": "This study investigates the development of an optimal execution strategy\nthrough reinforcement learning, aiming to determine the most effective approach\nfor traders to buy and sell inventory within a limited time frame. Our proposed\nmodel leverages input features derived from the current state of the limit\norder book.\n  To simulate this environment and overcome the limitations associated with\nrelying on historical data, we utilize the multi-agent market simulator ABIDES,\nwhich provides a diverse range of depth levels within the limit order book.\n  We present a custom MDP formulation followed by the results of our\nmethodology and benchmark the performance against standard execution\nstrategies. Our findings suggest that the reinforcement learning-based approach\ndemonstrates significant potential."
    },
    {
      "id": "2411.06387v1",
      "title": "Self-Training Meets Consistency: Improving LLMs' Reasoning With Consistency-Driven Rationale Evaluation",
      "summary": "Self-training approach for large language models (LLMs) improves reasoning\nabilities by training the models on their self-generated rationales. Previous\napproaches have labeled rationales that produce correct answers for a given\nquestion as appropriate for training. However, a single measure risks\nmisjudging rationale quality, leading the models to learn flawed reasoning\npatterns. To address this issue, we propose CREST (Consistency-driven Rationale\nEvaluation for Self-Training), a self-training framework that further evaluates\neach rationale through follow-up questions and leverages this evaluation to\nguide its training. Specifically, we introduce two methods: (1) filtering out\nrationales that frequently result in incorrect answers on follow-up questions\nand (2) preference learning based on mixed preferences from rationale\nevaluation results of both original and follow-up questions. Experiments on\nthree question-answering datasets using open LLMs show that CREST not only\nimproves the logical robustness and correctness of rationales but also improves\nreasoning abilities compared to previous self-training approaches."
    },
    {
      "id": "2411.06385v1",
      "title": "Class Granularity: How richly does your knowledge graph represent the real world?",
      "summary": "To effectively manage and utilize knowledge graphs, it is crucial to have\nmetrics that can assess the quality of knowledge graphs from various\nperspectives. While there have been studies on knowledge graph quality metrics,\nthere has been a lack of research on metrics that measure how richly\nontologies, which form the backbone of knowledge graphs, are defined or the\nimpact of richly defined ontologies. In this study, we propose a new metric\ncalled Class Granularity, which measures how well a knowledge graph is\nstructured in terms of how finely classes with unique characteristics are\ndefined. Furthermore, this research presents potential impact of Class\nGranularity in knowledge graph's on downstream tasks. In particular, we explore\nits influence on graph embedding and provide experimental results.\nAdditionally, this research goes beyond traditional Linked Open Data comparison\nstudies, which mainly focus on factors like scale and class distribution, by\nusing Class Granularity to compare four different LOD sources."
    },
    {
      "id": "2411.06376v1",
      "title": "Phantom: Constraining Generative Artificial Intelligence Models for Practical Domain Specific Peripherals Trace Synthesizing",
      "summary": "Peripheral Component Interconnect Express (PCIe) is the de facto interconnect\nstandard for high-speed peripherals and CPUs. Prototyping and optimizing PCIe\ndevices for emerging scenarios is an ongoing challenge. Since Transaction Layer\nPackets (TLPs) capture device-CPU interactions, it is crucial to analyze and\ngenerate realistic TLP traces for effective device design and optimization.\nGenerative AI offers a promising approach for creating intricate, custom TLP\ntraces necessary for PCIe hardware and software development. However, existing\nmodels often generate impractical traces due to the absence of PCIe-specific\nconstraints, such as TLP ordering and causality. This paper presents Phantom,\nthe first framework that treats TLP trace generation as a generative AI problem\nwhile incorporating PCIe-specific constraints. We validate Phantom's\neffectiveness by generating TLP traces for an actual PCIe network interface\ncard. Experimental results show that Phantom produces practical, large-scale\nTLP traces, significantly outperforming existing models, with improvements of\nup to 1000$\\times$ in task-specific metrics and up to 2.19$\\times$ in Frechet\nInception Distance (FID) compared to backbone-only methods."
    },
    {
      "id": "2411.06374v1",
      "title": "Metric Learning for Tag Recommendation: Tackling Data Sparsity and Cold Start Issues",
      "summary": "With the rapid growth of digital information, personalized recommendation\nsystems have become an indispensable part of Internet services, especially in\nthe fields of e-commerce, social media, and online entertainment. However,\ntraditional collaborative filtering and content-based recommendation methods\nhave limitations in dealing with data sparsity and cold start problems,\nespecially in the face of largescale heterogeneous data, which makes it\ndifficult to meet user expectations. This paper proposes a new label\nrecommendation algorithm based on metric learning, which aims to overcome the\nchallenges of traditional recommendation systems by learning effective distance\nor similarity metrics to capture the subtle differences between user\npreferences and item features. Experimental results show that the algorithm\noutperforms baseline methods including local response metric learning (LRML),\ncollaborative metric learning (CML), and adaptive tensor factorization (ATF)\nbased on adversarial learning on multiple evaluation metrics. In particular, it\nperforms particularly well in the accuracy of the first few recommended items,\nwhile maintaining high robustness and maintaining high recommendation accuracy."
    },
    {
      "id": "2411.06371v1",
      "title": "LLM Vocabulary Compression for Low-Compute Environments",
      "summary": "We present a method to compress the final linear layer of language models,\nreducing memory usage by up to 3.4x without significant performance loss. By\ngrouping tokens based on Byte Pair Encoding (BPE) merges, we prevent\nmaterialization of the memory-intensive logits tensor. Evaluations on the\nTinyStories dataset show that our method performs on par with GPT-Neo and GPT2\nwhile significantly improving throughput by up to 3x, making it suitable for\nlow-compute environments."
    },
    {
      "id": "2411.06367v1",
      "title": "BayesNAM: Leveraging Inconsistency for Reliable Explanations",
      "summary": "Neural additive model (NAM) is a recently proposed explainable artificial\nintelligence (XAI) method that utilizes neural network-based architectures.\nGiven the advantages of neural networks, NAMs provide intuitive explanations\nfor their predictions with high model performance. In this paper, we analyze a\ncritical yet overlooked phenomenon: NAMs often produce inconsistent\nexplanations, even when using the same architecture and dataset. Traditionally,\nsuch inconsistencies have been viewed as issues to be resolved. However, we\nargue instead that these inconsistencies can provide valuable explanations\nwithin the given data model. Through a simple theoretical framework, we\ndemonstrate that these inconsistencies are not mere artifacts but emerge\nnaturally in datasets with multiple important features. To effectively leverage\nthis information, we introduce a novel framework, Bayesian Neural Additive\nModel (BayesNAM), which integrates Bayesian neural networks and feature\ndropout, with theoretical proof demonstrating that feature dropout effectively\ncaptures model inconsistencies. Our experiments demonstrate that BayesNAM\neffectively reveals potential problems such as insufficient data or structural\nlimitations of the model, providing more reliable explanations and potential\nremedies."
    },
    {
      "id": "2411.06363v1",
      "title": "Layer-Wise Feature Metric of Semantic-Pixel Matching for Few-Shot Learning",
      "summary": "In Few-Shot Learning (FSL), traditional metric-based approaches often rely on\nglobal metrics to compute similarity. However, in natural scenes, the spatial\narrangement of key instances is often inconsistent across images. This spatial\nmisalignment can result in mismatched semantic pixels, leading to inaccurate\nsimilarity measurements. To address this issue, we propose a novel method\ncalled the Layer-Wise Features Metric of Semantic-Pixel Matching (LWFM-SPM) to\nmake finer comparisons. Our method enhances model performance through two key\nmodules: (1) the Layer-Wise Embedding (LWE) Module, which refines the\ncross-correlation of image pairs to generate well-focused feature maps for each\nlayer; (2)the Semantic-Pixel Matching (SPM) Module, which aligns critical\npixels based on semantic embeddings using an assignment algorithm. We conducted\nextensive experiments to evaluate our method on four widely used few-shot\nclassification benchmarks: miniImageNet, tieredImageNet, CUB-200-2011, and\nCIFAR-FS. The results indicate that LWFM-SPM achieves competitive performance\nacross these benchmarks. Our code will be publicly available on\nhttps://github.com/Halo2Tang/Code-for-LWFM-SPM."
    },
    {
      "id": "2411.06360v1",
      "title": "Optimized Inference for 1.58-bit LLMs: A Time and Memory-Efficient Algorithm for Binary and Ternary Matrix Multiplication",
      "summary": "Despite their tremendous success and versatility, Large Language Models\n(LLMs) suffer from inference inefficiency while relying on advanced\ncomputational infrastructure. To address these challenges and make LLMs more\naccessible and cost-effective, in this paper, we propose algorithms to improve\nthe inference time and memory efficiency of 1.58-bit LLMs with ternary weight\nmatrices. Particularly focusing on matrix multiplication as the bottle-neck\noperation of inference, we observe that, once trained, the weight matrices of a\nmodel no longer change. This allows us to preprocess these matrices and create\nindices that help reduce the storage requirements by a logarithmic factor while\nenabling our efficient inference algorithms. Specifically, for a $n$ by $n$\nweight matrix, our efficient algorithm guarantees a time complexity of\n$O(\\frac{n^2}{\\log n})$, a logarithmic factor improvement over the standard\n$O(n^2)$ vector-matrix multiplication. Besides theoretical analysis, we conduct\nextensive experiments to evaluate the practical efficiency of our algorithms.\nOur results confirm the superiority of the approach both with respect to time\nand memory, as we observed a reduction in inference time up to 29x and memory\nusage up to 6x."
    },
    {
      "id": "2411.06353v1",
      "title": "Deep Active Learning in the Open World",
      "summary": "Machine learning models deployed in open-world scenarios often encounter\nunfamiliar conditions and perform poorly in unanticipated situations. As AI\nsystems advance and find application in safety-critical domains, effectively\nhandling out-of-distribution (OOD) data is crucial to building open-world\nlearning systems. In this work, we introduce ALOE, a novel active learning\nalgorithm for open-world environments designed to enhance model adaptation by\nincorporating new OOD classes via a two-stage approach. First, diversity\nsampling selects a representative set of examples, followed by energy-based OOD\ndetection to prioritize likely unknown classes for annotation. This strategy\naccelerates class discovery and learning, even under constrained annotation\nbudgets. Evaluations on three long-tailed image classification benchmarks\ndemonstrate that ALOE outperforms traditional active learning baselines,\neffectively expanding known categories while balancing annotation cost. Our\nfindings reveal a crucial tradeoff between enhancing known-class performance\nand discovering new classes, setting the stage for future advancements in\nopen-world machine learning."
    },
    {
      "id": "2411.06352v1",
      "title": "Client Contribution Normalization for Enhanced Federated Learning",
      "summary": "Mobile devices, including smartphones and laptops, generate decentralized and\nheterogeneous data, presenting significant challenges for traditional\ncentralized machine learning models due to substantial communication costs and\nprivacy risks. Federated Learning (FL) offers a promising alternative by\nenabling collaborative training of a global model across decentralized devices\nwithout data sharing. However, FL faces challenges due to statistical\nheterogeneity among clients, where non-independent and identically distributed\n(non-IID) data impedes model convergence and performance. This paper focuses on\ndata-dependent heterogeneity in FL and proposes a novel approach leveraging\nmean latent representations extracted from locally trained models. The proposed\nmethod normalizes client contributions based on these representations, allowing\nthe central server to estimate and adjust for heterogeneity during aggregation.\nThis normalization enhances the global model's generalization and mitigates the\nlimitations of conventional federated averaging methods. The main contributions\ninclude introducing a normalization scheme using mean latent representations to\nhandle statistical heterogeneity in FL, demonstrating the seamless integration\nwith existing FL algorithms to improve performance in non-IID settings, and\nvalidating the approach through extensive experiments on diverse datasets.\nResults show significant improvements in model accuracy and consistency across\nskewed distributions. Our experiments with six FL schemes: FedAvg, FedProx,\nFedBABU, FedNova, SCAFFOLD, and SGDM highlight the robustness of our approach.\nThis research advances FL by providing a practical and computationally\nefficient solution for statistical heterogeneity, contributing to the\ndevelopment of more reliable and generalized machine learning models."
    },
    {
      "id": "2411.06346v1",
      "title": "Activation Map Compression through Tensor Decomposition for Deep Learning",
      "summary": "Internet of Things and Deep Learning are synergetically and exponentially\ngrowing industrial fields with a massive call for their unification into a\ncommon framework called Edge AI. While on-device inference is a well-explored\ntopic in recent research, backpropagation remains an open challenge due to its\nprohibitive computational and memory costs compared to the extreme resource\nconstraints of embedded devices. Drawing on tensor decomposition research, we\ntackle the main bottleneck of backpropagation, namely the memory footprint of\nactivation map storage. We investigate and compare the effects of activation\ncompression using Singular Value Decomposition and its tensor variant,\nHigh-Order Singular Value Decomposition. The application of low-order\ndecomposition results in considerable memory savings while preserving the\nfeatures essential for learning, and also offers theoretical guarantees to\nconvergence. Experimental results obtained on main-stream architectures and\ntasks demonstrate Pareto-superiority over other state-of-the-art solutions, in\nterms of the trade-off between generalization and memory footprint."
    },
    {
      "id": "2411.06338v1",
      "title": "CRTRE: Causal Rule Generation with Target Trial Emulation Framework",
      "summary": "Causal inference and model interpretability are gaining increasing attention,\nparticularly in the biomedical domain. Despite recent advance, decorrelating\nfeatures in nonlinear environments with human-interpretable representations\nremains underexplored. In this study, we introduce a novel method called causal\nrule generation with target trial emulation framework (CRTRE), which applies\nrandomize trial design principles to estimate the causal effect of association\nrules. We then incorporate such association rules for the downstream\napplications such as prediction of disease onsets. Extensive experiments on six\nhealthcare datasets, including synthetic data, real-world disease collections,\nand MIMIC-III/IV, demonstrate the model's superior performance. Specifically,\nour method achieved a $\\beta$ error of 0.907, outperforming DWR (1.024) and SVM\n(1.141). On real-world datasets, our model achieved accuracies of 0.789, 0.920,\nand 0.300 for Esophageal Cancer, Heart Disease, and Cauda Equina Syndrome\nprediction task, respectively, consistently surpassing baseline models. On the\nICD code prediction tasks, it achieved AUC Macro scores of 92.8 on MIMIC-III\nand 96.7 on MIMIC-IV, outperforming the state-of-the-art models KEPT and MSMN.\nExpert evaluations further validate the model's effectiveness, causality, and\ninterpretability."
    },
    {
      "id": "2411.06336v1",
      "title": "Balancing Power and Ethics: A Framework for Addressing Human Rights Concerns in Military AI",
      "summary": "AI has made significant strides recently, leading to various applications in\nboth civilian and military sectors. The military sees AI as a solution for\ndeveloping more effective and faster technologies. While AI offers benefits\nlike improved operational efficiency and precision targeting, it also raises\nserious ethical and legal concerns, particularly regarding human rights\nviolations. Autonomous weapons that make decisions without human input can\nthreaten the right to life and violate international humanitarian law. To\naddress these issues, we propose a three-stage framework (Design, In\nDeployment, and During/After Use) for evaluating human rights concerns in the\ndesign, deployment, and use of military AI. Each phase includes multiple\ncomponents that address various concerns specific to that phase, ranging from\nbias and regulatory issues to violations of International Humanitarian Law. By\nthis framework, we aim to balance the advantages of AI in military operations\nwith the need to protect human rights."
    },
    {
      "id": "2411.06333v1",
      "title": "A Learned Proximal Alternating Minimization Algorithm and Its Induced Network for a Class of Two-block Nonconvex and Nonsmooth Optimization",
      "summary": "This work proposes a general learned proximal alternating minimization\nalgorithm, LPAM, for solving learnable two-block nonsmooth and nonconvex\noptimization problems. We tackle the nonsmoothness by an appropriate smoothing\ntechnique with automatic diminishing smoothing effect. For smoothed nonconvex\nproblems we modify the proximal alternating linearized minimization (PALM)\nscheme by incorporating the residual learning architecture, which has proven to\nbe highly effective in deep network training, and employing the block\ncoordinate decent (BCD) iterates as a safeguard for the convergence of the\nalgorithm. We prove that there is a subsequence of the iterates generated by\nLPAM, which has at least one accumulation point and each accumulation point is\na Clarke stationary point. Our method is widely applicable as one can employ\nvarious learning problems formulated as two-block optimizations, and is also\neasy to be extended for solving multi-block nonsmooth and nonconvex\noptimization problems. The network, whose architecture follows the LPAM\nexactly, namely LPAM-net, inherits the convergence properties of the algorithm\nto make the network interpretable. As an example application of LPAM-net, we\npresent the numerical and theoretical results on the application of LPAM-net\nfor joint multi-modal MRI reconstruction with significantly under-sampled\nk-space data. The experimental results indicate the proposed LPAM-net is\nparameter-efficient and has favourable performance in comparison with some\nstate-of-the-art methods."
    },
    {
      "id": "2411.06329v1",
      "title": "Regret Minimization and Statistical Inference in Online Decision Making with High-dimensional Covariates",
      "summary": "This paper investigates regret minimization, statistical inference, and their\ninterplay in high-dimensional online decision-making based on the sparse linear\ncontext bandit model. We integrate the $\\varepsilon$-greedy bandit algorithm\nfor decision-making with a hard thresholding algorithm for estimating sparse\nbandit parameters and introduce an inference framework based on a debiasing\nmethod using inverse propensity weighting. Under a margin condition, our method\nachieves either $O(T^{1/2})$ regret or classical $O(T^{1/2})$-consistent\ninference, indicating an unavoidable trade-off between exploration and\nexploitation. If a diverse covariate condition holds, we demonstrate that a\npure-greedy bandit algorithm, i.e., exploration-free, combined with a debiased\nestimator based on average weighting can simultaneously achieve optimal $O(\\log\nT)$ regret and $O(T^{1/2})$-consistent inference. We also show that a simple\nsample mean estimator can provide valid inference for the optimal policy's\nvalue. Numerical simulations and experiments on Warfarin dosing data validate\nthe effectiveness of our methods."
    },
    {
      "id": "2411.06326v1",
      "title": "Emotion-Aware Interaction Design in Intelligent User Interface Using Multi-Modal Deep Learning",
      "summary": "In an era where user interaction with technology is ubiquitous, the\nimportance of user interface (UI) design cannot be overstated. A well-designed\nUI not only enhances usability but also fosters more natural, intuitive, and\nemotionally engaging experiences, making technology more accessible and\nimpactful in everyday life. This research addresses this growing need by\nintroducing an advanced emotion recognition system to significantly improve the\nemotional responsiveness of UI. By integrating facial expressions, speech, and\ntextual data through a multi-branch Transformer model, the system interprets\ncomplex emotional cues in real-time, enabling UIs to interact more\nempathetically and effectively with users. Using the public MELD dataset for\nvalidation, our model demonstrates substantial improvements in emotion\nrecognition accuracy and F1 scores, outperforming traditional methods. These\nfindings underscore the critical role that sophisticated emotion recognition\nplays in the evolution of UIs, making technology more attuned to user needs and\nemotions. This study highlights how enhanced emotional intelligence in UIs is\nnot only about technical innovation but also about fostering deeper, more\nmeaningful connections between users and the digital world, ultimately shaping\nhow people interact with technology in their daily lives."
    },
    {
      "id": "2411.06324v1",
      "title": "Amortized Bayesian Local Interpolation NetworK: Fast covariance parameter estimation for Gaussian Processes",
      "summary": "Gaussian processes (GPs) are a ubiquitous tool for geostatistical modeling\nwith high levels of flexibility and interpretability, and the ability to make\npredictions at unseen spatial locations through a process called Kriging.\nEstimation of Kriging weights relies on the inversion of the process'\ncovariance matrix, creating a computational bottleneck for large spatial\ndatasets. In this paper, we propose an Amortized Bayesian Local Interpolation\nNetworK (A-BLINK) for fast covariance parameter estimation, which uses two\npre-trained deep neural networks to learn a mapping from spatial location\ncoordinates and covariance function parameters to Kriging weights and the\nspatial variance, respectively. The fast prediction time of these networks\nallows us to bypass the matrix inversion step, creating large computational\nspeedups over competing methods in both frequentist and Bayesian settings, and\nalso provides full posterior inference and predictions using Markov chain Monte\nCarlo sampling methods. We show significant increases in computational\nefficiency over comparable scalable GP methodology in an extensive simulation\nstudy with lower parameter estimation error. The efficacy of our approach is\nalso demonstrated using a temperature dataset of US climate normals for\n1991--2020 based on over 7,000 weather stations."
    },
    {
      "id": "2411.06316v1",
      "title": "Prompts Matter: Comparing ML/GAI Approaches for Generating Inductive Qualitative Coding Results",
      "summary": "Inductive qualitative methods have been a mainstay of education research for\ndecades, yet it takes much time and effort to conduct rigorously. Recent\nadvances in artificial intelligence, particularly with generative AI (GAI),\nhave led to initial success in generating inductive coding results. Like human\ncoders, GAI tools rely on instructions to work, and how to instruct it may\nmatter. To understand how ML/GAI approaches could contribute to qualitative\ncoding processes, this study applied two known and two theory-informed novel\napproaches to an online community dataset and evaluated the resulting coding\nresults. Our findings show significant discrepancies between ML/GAI approaches\nand demonstrate the advantage of our approaches, which introduce human coding\nprocesses into GAI prompts."
    },
    {
      "id": "2411.06315v1",
      "title": "NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains",
      "summary": "Medical brain imaging relies heavily on image registration to accurately\ncurate structural boundaries of brain features for various healthcare\napplications. Deep learning models have shown remarkable performance in image\nregistration in recent years. Still, they often struggle to handle the\ndiversity of 3D brain volumes, challenged by their structural and contrastive\nvariations and their imaging domains. In this work, we present NeuReg, a\nNeuro-inspired 3D image registration architecture with the feature of domain\ninvariance. NeuReg generates domain-agnostic representations of imaging\nfeatures and incorporates a shifting window-based Swin Transformer block as the\nencoder. This enables our model to capture the variations across brain imaging\nmodalities and species. We demonstrate a new benchmark in multi-domain publicly\navailable datasets comprising human and mouse 3D brain volumes. Extensive\nexperiments reveal that our model (NeuReg) outperforms the existing baseline\ndeep learning-based image registration models and provides a high-performance\nboost on cross-domain datasets, where models are trained on 'source-only'\ndomain and tested on completely 'unseen' target domains. Our work establishes a\nnew state-of-the-art for domain-agnostic 3D brain image registration,\nunderpinned by Neuro-inspired Transformer-based architecture."
    },
    {
      "id": "2411.06311v1",
      "title": "When are dynamical systems learned from time series data statistically accurate?",
      "summary": "Conventional notions of generalization often fail to describe the ability of\nlearned models to capture meaningful information from dynamical data. A neural\nnetwork that learns complex dynamics with a small test error may still fail to\nreproduce its \\emph{physical} behavior, including associated statistical\nmoments and Lyapunov exponents. To address this gap, we propose an ergodic\ntheoretic approach to generalization of complex dynamical models learned from\ntime series data. Our main contribution is to define and analyze generalization\nof a broad suite of neural representations of classes of ergodic systems,\nincluding chaotic systems, in a way that captures emulating underlying\ninvariant, physical measures. Our results provide theoretical justification for\nwhy regression methods for generators of dynamical systems (Neural ODEs) fail\nto generalize, and why their statistical accuracy improves upon adding Jacobian\ninformation during training. We verify our results on a number of ergodic\nchaotic systems and neural network parameterizations, including MLPs, ResNets,\nFourier Neural layers, and RNNs."
    },
    {
      "id": "2411.06306v1",
      "title": "Optimal Driver Warning Generation in Dynamic Driving Environment",
      "summary": "The driver warning system that alerts the human driver about potential risks\nduring driving is a key feature of an advanced driver assistance system.\nExisting driver warning technologies, mainly the forward collision warning and\nunsafe lane change warning, can reduce the risk of collision caused by human\nerrors. However, the current design methods have several major limitations.\nFirstly, the warnings are mainly generated in a one-shot manner without\nmodeling the ego driver's reactions and surrounding objects, which reduces the\nflexibility and generality of the system over different scenarios.\nAdditionally, the triggering conditions of warning are mostly rule-based\nthreshold-checking given the current state, which lacks the prediction of the\npotential risk in a sufficiently long future horizon. In this work, we study\nthe problem of optimally generating driver warnings by considering the\ninteractions among the generated warning, the driver behavior, and the states\nof ego and surrounding vehicles on a long horizon. The warning generation\nproblem is formulated as a partially observed Markov decision process (POMDP).\nAn optimal warning generation framework is proposed as a solution to the\nproposed POMDP. The simulation experiments demonstrate the superiority of the\nproposed solution to the existing warning generation methods."
    },
    {
      "id": "2411.06299v1",
      "title": "Intelligent Fault Diagnosis of Type and Severity in Low-Frequency, Low Bit-Depth Signals",
      "summary": "This study focuses on Intelligent Fault Diagnosis (IFD) in rotating machinery\nutilizing a single microphone and a data-driven methodology, effectively\ndiagnosing 42 classes of fault types and severities. The research leverages\nsound data from the imbalanced MaFaulDa dataset, aiming to strike a balance\nbetween high performance and low resource consumption. The testing phase\nencompassed a variety of configurations, including sampling, quantization,\nsignal normalization, silence removal, Wiener filtering, data scaling,\nwindowing, augmentation, and classifier tuning using XGBoost. Through the\nanalysis of time, frequency, mel-frequency, and statistical features, we\nachieved an impressive accuracy of 99.54% and an F-Beta score of 99.52% with\njust 6 boosting trees at an 8 kHz, 8-bit configuration. Moreover, when\nutilizing only MFCCs along with their first- and second-order deltas, we\nrecorded an accuracy of 97.83% and an F-Beta score of 97.67%. Lastly, by\nimplementing a greedy wrapper approach, we obtained a remarkable accuracy of\n96.82% and an F-Beta score of 98.86% using 50 selected features, nearly all of\nwhich were first- and second-order deltas of the MFCCs."
    },
    {
      "id": "2411.06295v1",
      "title": "Analyzing the Evolution of Graphs and Texts",
      "summary": "With the recent advance of representation learning algorithms on graphs\n(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the\nstate-of-the art models can even achieve human-level performance over many\ndownstream tasks, particularly for the task of node and sentence\nclassification. However, most algorithms focus on large-scale models for static\ngraphs and text corpus without considering the inherent dynamic characteristics\nor discovering the reasons behind the changes. This dissertation aims to\nefficiently model the dynamics in graphs (such as social networks and citation\ngraphs) and understand the changes in texts (specifically news titles and\npersonal biographies). To achieve this goal, we utilize the renowned\nPersonalized PageRank algorithm to create effective dynamic network embeddings\nfor evolving graphs. Our proposed approaches significantly improve the running\ntime and accuracy for both detecting network abnormal intruders and discovering\nentity meaning shifts over large-scale dynamic graphs. For text changes, we\nanalyze the post-publication changes in news titles to understand the intents\nbehind the edits and discuss the potential impact of titles changes from\ninformation integrity perspective. Moreover, we investigate self-presented\noccupational identities in Twitter users' biographies over five years,\ninvestigating job prestige and demographics effects in how people disclose\njobs, quantifying over-represented jobs and their transitions over time."
    },
    {
      "id": "2411.06291v1",
      "title": "TinyML NLP Approach for Semantic Wireless Sentiment Classification",
      "summary": "Natural Language Processing (NLP) operations, such as semantic sentiment\nanalysis and text synthesis, may often impair users' privacy and demand\nsignificant on device computational resources. Centralized learning (CL) on the\nedge offers an alternative energy-efficient approach, yet requires the\ncollection of raw information, which affects the user's privacy. While\nFederated learning (FL) preserves privacy, it requires high computational\nenergy on board tiny user devices. We introduce split learning (SL) as an\nenergy-efficient alternative, privacy-preserving tiny machine learning (TinyML)\nscheme and compare it to FL and CL in the presence of Rayleigh fading and\nadditive noise. Our results show that SL reduces processing power and CO2\nemissions while maintaining high accuracy, whereas FL offers a balanced\ncompromise between efficiency and privacy. Hence, this study provides insights\ninto deploying energy-efficient, privacy-preserving NLP models on edge devices."
    },
    {
      "id": "2411.06286v1",
      "title": "SPIKANs: Separable Physics-Informed Kolmogorov-Arnold Networks",
      "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a promising method\nfor solving partial differential equations (PDEs) in scientific computing.\nWhile PINNs typically use multilayer perceptrons (MLPs) as their underlying\narchitecture, recent advancements have explored alternative neural network\nstructures. One such innovation is the Kolmogorov-Arnold Network (KAN), which\nhas demonstrated benefits over traditional MLPs, including faster neural\nscaling and better interpretability. The application of KANs to\nphysics-informed learning has led to the development of Physics-Informed KANs\n(PIKANs), enabling the use of KANs to solve PDEs. However, despite their\nadvantages, KANs often suffer from slower training speeds, particularly in\nhigher-dimensional problems where the number of collocation points grows\nexponentially with the dimensionality of the system. To address this challenge,\nwe introduce Separable Physics-Informed Kolmogorov-Arnold Networks (SPIKANs).\nThis novel architecture applies the principle of separation of variables to\nPIKANs, decomposing the problem such that each dimension is handled by an\nindividual KAN. This approach drastically reduces the computational complexity\nof training without sacrificing accuracy, facilitating their application to\nhigher-dimensional PDEs. Through a series of benchmark problems, we demonstrate\nthe effectiveness of SPIKANs, showcasing their superior scalability and\nperformance compared to PIKANs and highlighting their potential for solving\ncomplex, high-dimensional PDEs in scientific computing."
    },
    {
      "id": "2411.06284v1",
      "title": "A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks",
      "summary": "This survey and application guide to multimodal large language models(MLLMs)\nexplores the rapidly developing field of MLLMs, examining their architectures,\napplications, and impact on AI and Generative Models. Starting with\nfoundational concepts, we delve into how MLLMs integrate various data types,\nincluding text, images, video and audio, to enable complex AI systems for\ncross-modal understanding and generation. It covers essential topics such as\ntraining methods, architectural components, and practical applications in\nvarious fields, from visual storytelling to enhanced accessibility. Through\ndetailed case studies and technical analysis, the text examines prominent MLLM\nimplementations while addressing key challenges in scalability, robustness, and\ncross-modal learning. Concluding with a discussion of ethical considerations,\nresponsible AI development, and future directions, this authoritative resource\nprovides both theoretical frameworks and practical insights. It offers a\nbalanced perspective on the opportunities and challenges in the development and\ndeployment of MLLMs, and is highly valuable for researchers, practitioners, and\nstudents interested in the intersection of natural language processing and\ncomputer vision."
    },
    {
      "id": "2411.06278v1",
      "title": "A Natural Primal-Dual Hybrid Gradient Method for Adversarial Neural Network Training on Solving Partial Differential Equations",
      "summary": "We propose a scalable preconditioned primal-dual hybrid gradient algorithm\nfor solving partial differential equations (PDEs). We multiply the PDE with a\ndual test function to obtain an inf-sup problem whose loss functional involves\nlower-order differential operators. The Primal-Dual Hybrid Gradient (PDHG)\nalgorithm is then leveraged for this saddle point problem. By introducing\nsuitable precondition operators to the proximal steps in the PDHG algorithm, we\nobtain an alternative natural gradient ascent-descent optimization scheme for\nupdating the neural network parameters. We apply the Krylov subspace method\n(MINRES) to evaluate the natural gradients efficiently. Such treatment readily\nhandles the inversion of precondition matrices via matrix-vector\nmultiplication. A posterior convergence analysis is established for the\ntime-continuous version of the proposed method. The algorithm is tested on\nvarious types of PDEs with dimensions ranging from $1$ to $50$, including\nlinear and nonlinear elliptic equations, reaction-diffusion equations, and\nMonge-Amp\\`ere equations stemming from the $L^2$ optimal transport problems. We\ncompare the performance of the proposed method with several commonly used deep\nlearning algorithms such as physics-informed neural networks (PINNs), the\nDeepRitz method, weak adversarial networks (WANs), etc, for solving PDEs using\nthe Adam and L-BFGS optimizers. The numerical results suggest that the proposed\nmethod performs efficiently and robustly and converges more stably."
    },
    {
      "id": "2411.06276v1",
      "title": "Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds",
      "summary": "The PAC-Bayesian framework has significantly advanced our understanding of\nstatistical learning, particularly in majority voting methods. However, its\napplication to multi-view learning remains underexplored. In this paper, we\nextend PAC-Bayesian theory to the multi-view setting, introducing novel\nPAC-Bayesian bounds based on R\\'enyi divergence. These bounds improve upon\ntraditional Kullback-Leibler divergence and offer more refined complexity\nmeasures. We further propose first and second-order oracle PAC-Bayesian bounds,\nalong with an extension of the C-bound for multi-view learning. To ensure\npractical applicability, we develop efficient optimization algorithms with\nself-bounding properties."
    },
    {
      "id": "2411.08060v1",
      "title": "Online Collision Risk Estimation via Monocular Depth-Aware Object Detectors and Fuzzy Inference",
      "summary": "This paper presents a monitoring framework that infers the level of\nautonomous vehicle (AV) collision risk based on its object detector's\nperformance using only monocular camera images. Essentially, the framework\ntakes two sets of predictions produced by different algorithms and associates\ntheir inconsistencies with the collision risk via fuzzy inference. The first\nset of predictions is obtained through retrieving safety-critical 2.5D objects\nfrom a depth map, and the second set comes from the AV's 3D object detector. We\nexperimentally validate that, based on Intersection-over-Union (IoU) and a\ndepth discrepancy measure, the inconsistencies between the two sets of\npredictions strongly correlate to the safety-related error of the 3D object\ndetector against ground truths. This correlation allows us to construct a fuzzy\ninference system and map the inconsistency measures to an existing collision\nrisk indicator. In particular, we apply various knowledge- and data-driven\ntechniques and find using particle swarm optimization that learns general fuzzy\nrules gives the best mapping result. Lastly, we validate our monitor's\ncapability to produce relevant risk estimates with the large-scale nuScenes\ndataset and show it can safeguard an AV in closed-loop simulations."
    },
    {
      "id": "2411.06272v1",
      "title": "Golden Touchstone: A Comprehensive Bilingual Benchmark for Evaluating Financial Large Language Models",
      "summary": "As large language models become increasingly prevalent in the financial\nsector, there is a pressing need for a standardized method to comprehensively\nassess their performance. However, existing finance benchmarks often suffer\nfrom limited language and task coverage, as well as challenges such as\nlow-quality datasets and inadequate adaptability for LLM evaluation. To address\nthese limitations, we propose \"Golden Touchstone\", the first comprehensive\nbilingual benchmark for financial LLMs, which incorporates representative\ndatasets from both Chinese and English across eight core financial NLP tasks.\nDeveloped from extensive open source data collection and industry-specific\ndemands, this benchmark includes a variety of financial tasks aimed at\nthoroughly assessing models' language understanding and generation\ncapabilities. Through comparative analysis of major models on the benchmark,\nsuch as GPT-4o Llama3, FinGPT and FinMA, we reveal their strengths and\nlimitations in processing complex financial information. Additionally, we\nopen-sourced Touchstone-GPT, a financial LLM trained through continual\npre-training and financial instruction tuning, which demonstrates strong\nperformance on the bilingual benchmark but still has limitations in specific\ntasks.This research not only provides the financial large language models with\na practical evaluation tool but also guides the development and optimization of\nfuture research. The source code for Golden Touchstone and model weight of\nTouchstone-GPT have been made publicly available at\n\\url{https://github.com/IDEA-FinAI/Golden-Touchstone}, contributing to the\nongoing evolution of FinLLMs and fostering further research in this critical\narea."
    },
    {
      "id": "2411.06269v1",
      "title": "AI's Spatial Intelligence: Evaluating AI's Understanding of Spatial Transformations in PSVT:R and Augmented Reality",
      "summary": "Spatial intelligence is important in Architecture, Construction, Science,\nTechnology, Engineering, and Mathematics (STEM), and Medicine. Understanding\nthree-dimensional (3D) spatial rotations can involve verbal descriptions and\nvisual or interactive examples, illustrating how objects change orientation in\n3D space. Recent studies show Artificial Intelligence (AI) with language and\nvision capabilities still face limitations in spatial reasoning. In this paper,\nwe have studied generative AI's spatial capabilities of understanding rotations\nof objects utilizing its image and language processing features. We examined\nthe spatial intelligence of the GPT-4 model with vision in understanding\nspatial rotation process with diagrams based on the Revised Purdue Spatial\nVisualization Test: Visualization of Rotations (Revised PSVT:R). Next, we\nincorporated a layer of coordinate system axes on Revised PSVT:R to study the\nvariations in GPT-4's performance. We also examined GPT-4's understanding of 3D\nrotations in Augmented Reality (AR) scenes that visualize spatial rotations of\nan object in 3D space and observed increased accuracy of GPT-4's understanding\nof the rotations by adding supplementary textual information depicting the\nrotation process or mathematical representations of the rotation (e.g.,\nmatrices). The results indicate that while GPT-4 as a major current Generative\nAI model lacks the understanding of a spatial rotation process, it has the\npotential to understand the rotation process with additional information that\ncan be provided by methods such as AR. By combining the potentials in spatial\nintelligence of AI with AR's interactive visualization abilities, we expect to\noffer enhanced guidance for students' spatial learning activities. Such spatial\nguidance can benefit understanding spatial transformations and additionally\nsupport processes like assembly, fabrication, and manufacturing."
    },
    {
      "id": "2411.06268v1",
      "title": "Constraints and Variables Reduction for Optimal Power Flow Using Hierarchical Graph Neural Networks with Virtual Node-Splitting",
      "summary": "Power system networks are often modeled as homogeneous graphs, which limits\nthe ability of graph neural network (GNN) to capture individual generator\nfeatures at the same nodes. By introducing the proposed virtual node-splitting\nstrategy, generator-level attributes like costs, limits, and ramp rates can be\nfully captured by GNN models, improving GNN's learning capacity and prediction\naccuracy. Optimal power flow (OPF) problem is used for real-time grid\noperations. Limited timeframe motivates studies to create size-reduced OPF\n(ROPF) models to relieve the computational complexity. In this paper, with\nvirtual node-splitting, a novel two-stage adaptive hierarchical GNN is\ndeveloped to (i) predict critical lines that would be congested, and then (ii)\npredict base generators that would operate at the maximum capacity. This will\nsubstantially reduce the constraints and variables needed for OPF, creating the\nproposed ROPFLG model with reduced monitor lines and reduced generator-specific\nvariables and constraints. Two ROPF models, ROPFL and ROPFG, with just reduced\nlines or generators respectively, are also implemented as additional benchmark\nmodels. Case studies show that the proposed ROPFLG consistently outperforms the\nbenchmark full OPF (FOPF) and the other two ROPF methods, achieving significant\ncomputational time savings while reliably finding optimal solutions."
    },
    {
      "id": "2411.06264v1",
      "title": "GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence",
      "summary": "Although rapid advancements in Large Language Models (LLMs) are facilitating\nthe integration of artificial intelligence-based applications and services in\nhealthcare, limited research has focused on the systematic evaluation of\nmedical notes for guideline adherence. This paper introduces GuidelineGuard, an\nagentic framework powered by LLMs that autonomously analyzes medical notes,\nsuch as hospital discharge and office visit notes, to ensure compliance with\nestablished healthcare guidelines. By identifying deviations from recommended\npractices and providing evidence-based suggestions, GuidelineGuard helps\nclinicians adhere to the latest standards from organizations like the WHO and\nCDC. This framework offers a novel approach to improving documentation quality\nand reducing clinical errors."
    },
    {
      "id": "2411.06263v1",
      "title": "Federated Split Learning for Human Activity Recognition with Differential Privacy",
      "summary": "This paper proposes a novel intelligent human activity recognition (HAR)\nframework based on a new design of Federated Split Learning (FSL) with\nDifferential Privacy (DP) over edge networks. Our FSL-DP framework leverages\nboth accelerometer and gyroscope data, achieving significant improvements in\nHAR accuracy. The evaluation includes a detailed comparison between traditional\nFederated Learning (FL) and our FSL framework, showing that the FSL framework\noutperforms FL models in both accuracy and loss metrics. Additionally, we\nexamine the privacy-performance trade-off under different data settings in the\nDP mechanism, highlighting the balance between privacy guarantees and model\naccuracy. The results also indicate that our FSL framework achieves faster\ncommunication times per training round compared to traditional FL, further\nemphasizing its efficiency and effectiveness. This work provides valuable\ninsight and a novel framework which was tested on a real-life dataset."
    },
    {
      "id": "2411.07269v1",
      "title": "Learning From Graph-Structured Data: Addressing Design Issues and Exploring Practical Applications in Graph Representation Learning",
      "summary": "Graphs serve as fundamental descriptors for systems composed of interacting\nelements, capturing a wide array of data types, from molecular interactions to\nsocial networks and knowledge graphs. In this paper, we present an exhaustive\nreview of the latest advancements in graph representation learning and Graph\nNeural Networks (GNNs). GNNs, tailored to handle graph-structured data, excel\nin deriving insights and predictions from intricate relational information,\nmaking them invaluable for tasks involving such data. Graph representation\nlearning, a pivotal approach in analyzing graph-structured data, facilitates\nnumerous downstream tasks and applications across machine learning, data\nmining, biomedicine, and healthcare.\n  Our work delves into the capabilities of GNNs, examining their foundational\ndesigns and their application in addressing real-world challenges. We introduce\na GNN equipped with an advanced high-order pooling function, adept at capturing\ncomplex node interactions within graph-structured data. This pooling function\nsignificantly enhances the GNN's efficacy in both node- and graph-level tasks.\nAdditionally, we propose a molecular graph generative model with a GNN as its\ncore framework. This GNN backbone is proficient in learning invariant and\nequivariant molecular characteristics. Employing these features, the molecular\ngraph generative model is capable of simultaneously learning and generating\nmolecular graphs with atom-bond structures and precise atom positions. Our\nmodels undergo thorough experimental evaluations and comparisons with\nestablished methods, showcasing their superior performance in addressing\ndiverse real-world challenges with various datasets."
    },
    {
      "id": "2411.06253v1",
      "title": "Knowledge Authoring with Factual English, Rules, and Actions",
      "summary": "Knowledge representation and reasoning systems represent knowledge as\ncollections of facts and rules. KRRs can represent complex concepts and\nrelations, and they can query and manipulate information in sophisticated ways.\nUnfortunately, the KRR technology has been hindered by the fact that specifying\nthe requisite knowledge requires skills that most domain experts do not have,\nand professional knowledge engineers are hard to find. Some recent CNL-based\napproaches, such as the Knowledge Authoring Logic Machine (KALM), have shown to\nhave very high accuracy compared to others, and a natural question is to what\nextent the CNL restrictions can be lifted. Besides the CNL restrictions, KALM\nhas limitations in terms of the types of knowledge it can represent. To address\nthese issues, we propose an extension of KALM called KALM for Factual Language\n(KALMF). KALMF uses a neural parser for natural language, MS, to parse what we\ncall factual English sentences, which require little grammar training to use.\nBuilding upon KALMF, we propose KALM for Rules and Actions (KALMR), to\nrepresent and reason with rules and actions. Furthermore, we identify the\nreasons behind the slow speed of KALM and make optimizations to address this\nissue. Our evaluation using multiple benchmarks shows that our approaches\nachieve a high level of correctness on fact and query authoring (95%) and on\nrule authoring (100%). When used for authoring and reasoning with actions, our\napproach achieves more than 99.3% correctness, demonstrating its effectiveness\nin enabling more sophisticated knowledge representation and reasoning. We also\nillustrate the logical reasoning capabilities of our approach by drawing\nattention to the problems faced by the famous AI, ChatGPT. Finally, the\nevaluation of the newly proposed speed optimization points not only to a 68%\nruntime improvement but also yields better accuracy of the overall system."
    },
    {
      "id": "2411.06251v1",
      "title": "Quasi-random Multi-Sample Inference for Large Language Models",
      "summary": "Large language models (LLMs) are often equipped with multi-sample decoding\nstrategies. An LLM implicitly defines an arithmetic code book, facilitating\nefficient and embarrassingly parallelizable \\textbf{arithmetic sampling} to\nproduce multiple samples using quasi-random codes. Traditional text generation\nmethods, such as beam search and sampling-based techniques, have notable\nlimitations: they lack parallelizability or diversity of sampled sequences.\nThis study explores the potential of arithmetic sampling, contrasting it with\nancestral sampling across two decoding tasks that employ multi-sample\ninference: chain-of-thought reasoning with self-consistency and machine\ntranslation with minimum Bayes risk decoding. Our results demonstrate that\narithmetic sampling produces more diverse samples, significantly improving\nreasoning and translation performance as the sample size increases. We observe\na $\\mathbf{3\\text{-}5\\%}$ point increase in accuracy on the GSM8K dataset and a\n$\\mathbf{0.45\\text{-}0.89\\%}$ point increment in COMET score for WMT19 tasks\nusing arithmetic sampling without any significant computational overhead."
    },
    {
      "id": "2411.06248v1",
      "title": "Robust Detection of LLM-Generated Text: A Comparative Analysis",
      "summary": "The ability of large language models to generate complex texts allows them to\nbe widely integrated into many aspects of life, and their output can quickly\nfill all network resources. As the impact of LLMs grows, it becomes\nincreasingly important to develop powerful detectors for the generated text.\nThis detector is essential to prevent the potential misuse of these\ntechnologies and to protect areas such as social media from the negative\neffects of false content generated by LLMS. The main goal of LLM-generated text\ndetection is to determine whether text is generated by an LLM, which is a basic\nbinary classification task. In our work, we mainly use three different\nclassification methods based on open source datasets: traditional machine\nlearning techniques such as logistic regression, k-means clustering, Gaussian\nNaive Bayes, support vector machines, and methods based on converters such as\nBERT, and finally algorithms that use LLMs to detect LLM-generated text. We\nfocus on model generalization, potential adversarial attacks, and accuracy of\nmodel evaluation. Finally, the possible research direction in the future is\nproposed, and the current experimental results are summarized."
    },
    {
      "id": "2411.06243v1",
      "title": "Towards Establishing Guaranteed Error for Learned Database Operations",
      "summary": "Machine learning models have demonstrated substantial performance\nenhancements over non-learned alternatives in various fundamental data\nmanagement operations, including indexing (locating items in an array),\ncardinality estimation (estimating the number of matching records in a\ndatabase), and range-sum estimation (estimating aggregate attribute values for\nquery-matched records). However, real-world systems frequently favor less\nefficient non-learned methods due to their ability to offer (worst-case) error\nguarantees - an aspect where learned approaches often fall short. The primary\nobjective of these guarantees is to ensure system reliability, ensuring that\nthe chosen approach consistently delivers the desired level of accuracy across\nall databases. In this paper, we embark on the first theoretical study of such\nguarantees for learned methods, presenting the necessary conditions for such\nguarantees to hold when using machine learning to perform indexing, cardinality\nestimation and range-sum estimation. Specifically, we present the first known\nlower bounds on the model size required to achieve the desired accuracy for\nthese three key database operations. Our results bound the required model size\nfor given average and worst-case errors in performing database operations,\nserving as the first theoretical guidelines governing how model size must\nchange based on data size to be able to guarantee an accuracy level. More\nbroadly, our established guarantees pave the way for the broader adoption and\nintegration of learned models into real-world systems."
    },
    {
      "id": "2411.06241v1",
      "title": "Theoretical Analysis of Learned Database Operations under Distribution Shift through Distribution Learnability",
      "summary": "Use of machine learning to perform database operations, such as indexing,\ncardinality estimation, and sorting, is shown to provide substantial\nperformance benefits. However, when datasets change and data distribution\nshifts, empirical results also show performance degradation for learned models,\npossibly to worse than non-learned alternatives. This, together with a lack of\ntheoretical understanding of learned methods undermines their practical\napplicability, since there are no guarantees on how well the models will\nperform after deployment. In this paper, we present the first known theoretical\ncharacterization of the performance of learned models in dynamic datasets, for\nthe aforementioned operations. Our results show novel theoretical\ncharacteristics achievable by learned models and provide bounds on the\nperformance of the models that characterize their advantages over non-learned\nmethods, showing why and when learned models can outperform the alternatives.\nOur analysis develops the distribution learnability framework and novel\ntheoretical tools which build the foundation for the analysis of learned\ndatabase operations in the future."
    },
    {
      "id": "2411.06239v1",
      "title": "Web Scale Graph Mining for Cyber Threat Intelligence",
      "summary": "Defending against today's increasingly sophisticated and large-scale\ncyberattacks demands accurate, real-time threat intelligence. Traditional\napproaches struggle to scale, integrate diverse telemetry, and adapt to a\nconstantly evolving security landscape. We introduce Threat Intelligence\nTracking via Adaptive Networks (TITAN), an industry-scale graph mining\nframework that generates cyber threat intelligence at unprecedented speed and\nscale. TITAN introduces a suite of innovations specifically designed to address\nthe complexities of the modern security landscape, including: (1) a dynamic\nthreat intelligence graph that maps the intricate relationships between\nmillions of entities, incidents, and organizations; (2) real-time update\nmechanisms that automatically decay and prune outdated intel; (3) integration\nof security domain knowledge to bootstrap initial reputation scores; and (4)\nreputation propagation algorithms that uncover hidden threat actor\ninfrastructure. Integrated into Microsoft Unified Security Operations Platform\n(USOP), which is deployed across hundreds of thousands of organizations\nworldwide, TITAN's threat intelligence powers key detection and disruption\ncapabilities. With an impressive average macro-F1 score of 0.89 and a\nprecision-recall AUC of 0.94, TITAN identifies millions of high-risk entities\neach week, enabling a 6x increase in non-file threat intelligence. Since its\ndeployment, TITAN has increased the product's incident disruption rate by a\nremarkable 21%, while reducing the time to disrupt by a factor of 1.9x, and\nmaintaining 99% precision, as confirmed by customer feedback and thorough\nmanual evaluation by security experts--ultimately saving customers from costly\nsecurity breaches."
    },
    {
      "id": "2411.06237v1",
      "title": "Leveraging Retrieval-Augmented Generation for University Knowledge Retrieval",
      "summary": "This paper introduces an innovative approach using Retrieval-Augmented\nGeneration (RAG) pipelines with Large Language Models (LLMs) to enhance\ninformation retrieval and query response systems for university-related\nquestion answering. By systematically extracting data from the university\nofficial webpage and employing advanced prompt engineering techniques, we\ngenerate accurate, contextually relevant responses to user queries.\n  We developed a comprehensive university benchmark, UniversityQuestionBench\n(UQB), to rigorously evaluate our system performance, based on common key\nmetrics in the filed of RAG pipelines, assessing accuracy and reliability\nthrough various metrics and real-world scenarios. Our experimental results\ndemonstrate significant improvements in the precision and relevance of\ngenerated responses, enhancing user experience and reducing the time required\nto obtain relevant answers. In summary, this paper presents a novel application\nof RAG pipelines and LLMs, supported by a meticulously prepared university\nbenchmark, offering valuable insights into advanced AI techniques for academic\ndata retrieval and setting the stage for future research in this domain."
    },
    {
      "id": "2411.06236v2",
      "title": "Zero-Shot NAS via the Suppression of Local Entropy Decrease",
      "summary": "Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS."
    },
    {
      "id": "2411.06229v1",
      "title": "Multimodal Contrastive Learning of Urban Space Representations from POI Data",
      "summary": "Existing methods for learning urban space representations from\nPoint-of-Interest (POI) data face several limitations, including issues with\ngeographical delineation, inadequate spatial information modelling,\nunderutilisation of POI semantic attributes, and computational inefficiencies.\nTo address these issues, we propose CaLLiPer (Contrastive Language-Location\nPre-training), a novel representation learning model that directly embeds\ncontinuous urban spaces into vector representations that can capture the\nspatial and semantic distribution of urban environment. This model leverages a\nmultimodal contrastive learning objective, aligning location embeddings with\ntextual POI descriptions, thereby bypassing the need for complex training\ncorpus construction and negative sampling. We validate CaLLiPer's effectiveness\nby applying it to learning urban space representations in London, UK, where it\ndemonstrates 5-15% improvement in predictive performance for land use\nclassification and socioeconomic mapping tasks compared to state-of-the-art\nmethods. Visualisations of the learned representations further illustrate our\nmodel's advantages in capturing spatial variations in urban semantics with high\naccuracy and fine resolution. Additionally, CaLLiPer achieves reduced training\ntime, showcasing its efficiency and scalability. This work provides a promising\npathway for scalable, semantically rich urban space representation learning\nthat can support the development of geospatial foundation models. The\nimplementation code is available at https://github.com/xlwang233/CaLLiPer."
    },
    {
      "id": "2411.06228v1",
      "title": "An $\\mathbf{L^*}$ Algorithm for Deterministic Weighted Regular Languages",
      "summary": "Extracting finite state automata (FSAs) from black-box models offers a\npowerful approach to gaining interpretable insights into complex model\nbehaviors. To support this pursuit, we present a weighted variant of Angluin's\n(1987) $\\mathbf{L^*}$ algorithm for learning FSAs. We stay faithful to the\noriginal algorithm, devising a way to exactly learn deterministic weighted FSAs\nwhose weights support division. Furthermore, we formulate the learning process\nin a manner that highlights the connection with FSA minimization, showing how\n$\\mathbf{L^*}$ directly learns a minimal automaton for the target language."
    },
    {
      "id": "2411.07268v2",
      "title": "Target-driven Attack for Large Language Models",
      "summary": "Current large language models (LLM) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. Many users can easily inject\nadversarial text or instructions through the user interface, thus causing LLM\nmodel security challenges like the language model not giving the correct\nanswer. Although there is currently a large amount of research on black-box\nattacks, most of these black-box attacks use random and heuristic strategies.\nIt is unclear how these strategies relate to the success rate of attacks and\nthus effectively improve model robustness. To solve this problem, we propose\nour target-driven black-box attack method to maximize the KL divergence between\nthe conditional probabilities of the clean text and the attack text to redefine\nthe attack's goal. We transform the distance maximization problem into two\nconvex optimization problems based on the attack goal to solve the attack text\nand estimate the covariance. Furthermore, the projected gradient descent\nalgorithm solves the vector corresponding to the attack text. Our target-driven\nblack-box attack approach includes two attack strategies: token manipulation\nand misinformation attack. Experimental results on multiple Large Language\nModels and datasets demonstrate the effectiveness of our attack method."
    },
    {
      "id": "2411.06221v1",
      "title": "Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation",
      "summary": "With the rapid development of blockchain technology, smart contract security\nhas become a critical challenge. Existing smart contract vulnerability\ndetection methods face three main issues: (1) Insufficient quality of datasets,\nlacking detailed explanations and precise vulnerability locations. (2) Limited\nadaptability of large language models (LLMs) to the smart contract domain, as\nmost LLMs are pre-trained on general text data but minimal smart\ncontract-specific data. (3) Lack of high-quality explanations for detected\nvulnerabilities, as existing methods focus solely on detection without clear\nexplanations. These limitations hinder detection performance and make it harder\nfor developers to understand and fix vulnerabilities quickly, potentially\nleading to severe financial losses. To address these problems, we propose\nSmart-LLaMA, an advanced detection method based on the LLaMA language model.\nFirst, we construct a comprehensive dataset covering four vulnerability types\nwith labels, detailed explanations, and precise vulnerability locations.\nSecond, we introduce Smart Contract-Specific Continual Pre-Training, using raw\nsmart contract data to enable the LLM to learn smart contract syntax and\nsemantics, enhancing their domain adaptability. Furthermore, we propose\nExplanation-Guided Fine-Tuning, which fine-tunes the LLM using paired\nvulnerable code and explanations, enabling both vulnerability detection and\nreasoned explanations. We evaluate explanation quality through LLM and human\nevaluation, focusing on Correctness, Completeness, and Conciseness.\nExperimental results show that Smart-LLaMA outperforms state-of-the-art\nbaselines, with average improvements of 6.49% in F1 score and 3.78% in\naccuracy, while providing reliable explanations."
    },
    {
      "id": "2411.06214v1",
      "title": "Early Prediction of Natural Gas Pipeline Leaks Using the MKTCN Model",
      "summary": "Natural gas pipeline leaks pose severe risks, leading to substantial economic\nlosses and potential hazards to human safety. In this study, we develop an\naccurate model for the early prediction of pipeline leaks. To the best of our\nknowledge, unlike previous anomaly detection, this is the first application to\nuse internal pipeline data for early prediction of leaks. The modeling process\naddresses two main challenges: long-term dependencies and sample imbalance.\nFirst, we introduce a dilated convolution-based prediction model to capture\nlong-term dependencies, as dilated convolution expands the model's receptive\nfield without added computational cost. Second, to mitigate sample imbalance,\nwe propose the MKTCN model, which incorporates the Kolmogorov-Arnold Network as\nthe fully connected layer in a dilated convolution model, enhancing network\ngeneralization. Finally, we validate the MKTCN model through extensive\nexperiments on two real-world datasets. Results demonstrate that MKTCN\noutperforms in generalization and classification, particularly under severe\ndata imbalance, and effectively predicts leaks up to 5000 seconds in advance.\nOverall, the MKTCN model represents a significant advancement in early pipeline\nleak prediction, providing robust generalization and improved modeling of the\nlong-term dependencies inherent in multi-dimensional time-series data."
    },
    {
      "id": "2411.06213v1",
      "title": "Incorporating Human Explanations for Robust Hate Speech Detection",
      "summary": "Given the black-box nature and complexity of large transformer language\nmodels (LM), concerns about generalizability and robustness present ethical\nimplications for domains such as hate speech (HS) detection. Using the content\nrich Social Bias Frames dataset, containing human-annotated stereotypes,\nintent, and targeted groups, we develop a three stage analysis to evaluate if\nLMs faithfully assess hate speech. First, we observe the need for modeling\ncontextually grounded stereotype intents to capture implicit semantic meaning.\nNext, we design a new task, Stereotype Intent Entailment (SIE), which\nencourages a model to contextually understand stereotype presence. Finally,\nthrough ablation tests and user studies, we find a SIE objective improves\ncontent understanding, but challenges remain in modeling implicit intent."
    },
    {
      "id": "2411.06212v1",
      "title": "Multistage non-deterministic classification using secondary concept graphs and graph convolutional networks for high-level feature extraction",
      "summary": "Graphs, comprising nodes and edges, visually depict relationships and\nstructures, posing challenges in extracting high-level features due to their\nintricate connections. Multiple connections introduce complexities in\ndiscovering patterns, where node weights may affect some features more than\nothers. In domains with diverse topics, graph representations illustrate\ninterrelations among features. Pattern discovery within graphs is recognized as\nNP-hard. Graph Convolutional Networks (GCNs) are a prominent deep learning\napproach for acquiring meaningful representations by leveraging node\nconnectivity and characteristics. Despite achievements, predicting and\nassigning 9 deterministic classes often involves errors. To address this\nchallenge, we present a multi-stage non-deterministic classification method\nbased on a secondary conceptual graph and graph convolutional networks, which\nincludes distinct steps: 1) leveraging GCN for the extraction and generation of\n12 high-level features: 2) employing incomplete, non-deterministic models for\nfeature extraction, conducted before reaching a definitive prediction: and 3)\nformulating definitive forecasts grounded in conceptual (logical) graphs. The\nempirical findings indicate that our proposed approach outperforms contemporary\nmethods in classification tasks. Across three datasets Cora, Citeseer, and\nPubMed the achieved accuracies are 96%, 93%, and 95%, respectively. Code is\navailable at https://github.com/MasoudKargar."
    },
    {
      "id": "2411.06211v1",
      "title": "Artificial Intelligence for Collective Intelligence: A National-Scale Research Strategy",
      "summary": "Advances in artificial intelligence (AI) have great potential to help address\nsocietal challenges that are both collective in nature and present at national\nor trans-national scale. Pressing challenges in healthcare, finance,\ninfrastructure and sustainability, for instance, might all be productively\naddressed by leveraging and amplifying AI for national-scale collective\nintelligence. The development and deployment of this kind of AI faces\ndistinctive challenges, both technical and socio-technical. Here, a research\nstrategy for mobilising inter-disciplinary research to address these challenges\nis detailed and some of the key issues that must be faced are outlined."
    },
    {
      "id": "2411.06208v1",
      "title": "IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization",
      "summary": "In the realm of large language models (LLMs), the ability of models to\naccurately follow instructions is paramount as more agents and applications\nleverage LLMs for construction, where the complexity of instructions are\nrapidly increasing. However, on the one hand, there is only a certain amount of\ncomplex instruction evaluation data; on the other hand, there are no dedicated\nalgorithms to improve the ability to follow complex instructions. To this end,\nthis paper introduces TRACE, a benchmark for improving and evaluating the\ncomplex instructionfollowing ability, which consists of 120K training data and\n1K evaluation data. Furthermore, we propose IOPO (Input-Output Preference\nOptimization) alignment method which takes both input and output preference\npairs into consideration, where LLMs not only rapidly align with response\npreferences but also meticulously explore the instruction preferences.\nExtensive experiments on both in-domain and outof-domain datasets confirm the\neffectiveness of IOPO, showing 8.15%, 2.18% improvements on in-domain data and\n6.29%, 3.13% on outof-domain data compared to SFT and DPO respectively."
    },
    {
      "id": "2411.06207v1",
      "title": "Exploring Knowledge Boundaries in Large Language Models for Retrieval Judgment",
      "summary": "Large Language Models (LLMs) are increasingly recognized for their practical\napplications. However, these models often encounter challenges in dynamically\nchanging knowledge, as well as in managing unknown static knowledge.\nRetrieval-Augmented Generation (RAG) tackles this challenge and has shown a\nsignificant impact on LLMs. Actually, we find that the impact of RAG on the\nquestion answering capabilities of LLMs can be categorized into three groups:\nbeneficial, neutral, and harmful. By minimizing retrieval requests that yield\nneutral or harmful results, we can effectively reduce both time and\ncomputational costs, while also improving the overall performance of LLMs. This\ninsight motivates us to differentiate between types of questions using certain\nmetrics as indicators, to decrease the retrieval ratio without compromising\nperformance. In our work, we propose a method that is able to identify\ndifferent types of questions from this view by training a Knowledge Boundary\nModel (KBM). Experiments conducted on 11 English and Chinese datasets\nillustrate that the KBM effectively delineates the knowledge boundary,\nsignificantly decreasing the proportion of retrievals required for optimal\nend-to-end performance. Specifically, we evaluate the effectiveness of KBM in\nthree complex scenarios: dynamic knowledge, long-tail static knowledge, and\nmulti-hop problems, as well as its functionality as an external LLM plug-in."
    },
    {
      "id": "2411.07267v1",
      "title": "A Survey on Data Markets",
      "summary": "Data is the new oil of the 21st century. The growing trend of trading data\nfor greater welfare has led to the emergence of data markets. A data market is\nany mechanism whereby the exchange of data products including datasets and data\nderivatives takes place as a result of data buyers and data sellers being in\ncontact with one another, either directly or through mediating agents. It\nserves as a coordinating mechanism by which several functions, including the\npricing and the distribution of data as the most important ones, interact to\nmake the value of data fully exploited and enhanced. In this article, we\npresent a comprehensive survey of this important and emerging direction from\nthe aspects of data search, data productization, data transaction, data\npricing, revenue allocation as well as privacy, security, and trust issues. We\nalso investigate the government policies and industry status of data markets\nacross different countries and different domains. Finally, we identify the\nunresolved challenges and discuss possible future directions for the\ndevelopment of data markets."
    },
    {
      "id": "2411.06202v1",
      "title": "Advanced Wildfire Prediction in Morocco: Developing a Deep Learning Dataset from Multisource Observations",
      "summary": "Wildfires pose significant threats to ecosystems, economies, and communities\nworldwide, necessitating advanced predictive methods for effective mitigation.\nThis study introduces a novel and comprehensive dataset specifically designed\nfor wildfire prediction in Morocco, addressing its unique geographical and\nclimatic challenges. By integrating satellite observations and ground station\ndata, we compile essential environmental indicators such as vegetation health\n(NDVI), population density, soil moisture levels, and meteorological data aimed\nat predicting next-day wildfire occurrences with high accuracy. Our methodology\nincorporates state-of-the-art machine learning and deep learning algorithms,\ndemonstrating superior performance in capturing wildfire dynamics compared to\ntraditional models. Preliminary results show that models using this dataset\nachieve an accuracy of up to 90%, significantly improving prediction\ncapabilities. The public availability of this dataset fosters scientific\ncollaboration, aiming to refine predictive models and develop innovative\nwildfire management strategies. Our work not only advances the technical field\nof dataset creation but also emphasizes the necessity for localized research in\nunderrepresented regions, providing a scalable model for other areas facing\nsimilar environmental challenges."
    },
    {
      "id": "2411.06200v1",
      "title": "Weak to Strong Learning from Aggregate Labels",
      "summary": "In learning from aggregate labels, the training data consists of sets or\n\"bags\" of feature-vectors (instances) along with an aggregate label for each\nbag derived from the (usually {0,1}-valued) labels of its instances. In\nlearning from label proportions (LLP), the aggregate label is the average of\nthe bag's instance labels, whereas in multiple instance learning (MIL) it is\nthe OR. The goal is to train an instance-level predictor, typically achieved by\nfitting a model on the training data, in particular one that maximizes the\naccuracy which is the fraction of satisfied bags i.e., those on which the\npredicted labels are consistent with the aggregate label. A weak learner has at\na constant accuracy < 1 on the training bags, while a strong learner's accuracy\ncan be arbitrarily close to 1. We study the problem of using a weak learner on\nsuch training bags with aggregate labels to obtain a strong learner, analogous\nto supervised learning for which boosting algorithms are known. Our first\nresult shows the impossibility of boosting in LLP using weak classifiers of any\naccuracy < 1 by constructing a collection of bags for which such weak learners\n(for any weight assignment) exist, while not admitting any strong learner. A\nvariant of this construction also rules out boosting in MIL for a non-trivial\nrange of weak learner accuracy. In the LLP setting however, we show that a weak\nlearner (with small accuracy) on large enough bags can in fact be used to\nobtain a strong learner for small bags, in polynomial time. We also provide\nmore efficient, sampling based variant of our procedure with probabilistic\nguarantees which are empirically validated on three real and two synthetic\ndatasets. Our work is the first to theoretically study weak to strong learning\nfrom aggregate labels, with an algorithm to achieve the same for LLP, while\nproving the impossibility of boosting for both LLP and MIL."
    },
    {
      "id": "2411.06198v1",
      "title": "OpenAI-o1 AB Testing: Does the o1 model really do good reasoning in math problem solving?",
      "summary": "The Orion-1 model by OpenAI is claimed to have more robust logical reasoning\ncapabilities than previous large language models. However, some suggest the\nexcellence might be partially due to the model \"memorizing\" solutions,\nresulting in less satisfactory performance when prompted with problems not in\nthe training data. We conduct a comparison experiment using two datasets: one\nconsisting of International Mathematics Olympiad (IMO) problems, which is\neasily accessible; the other one consisting of Chinese National Team Training\ncamp (CNT) problems, which have similar difficulty but not as publically\naccessible. We label the response for each problem and compare the performance\nbetween the two datasets. We conclude that there is no significant evidence to\nshow that the model relies on memorizing problems and solutions. Also, we\nperform case studies to analyze some features of the model's response."
    },
    {
      "id": "2411.06194v1",
      "title": "WMT24 Test Suite: Gender Resolution in Speaker-Listener Dialogue Roles",
      "summary": "We assess the difficulty of gender resolution in literary-style dialogue\nsettings and the influence of gender stereotypes. Instances of the test suite\ncontain spoken dialogue interleaved with external meta-context about the\ncharacters and the manner of speaking. We find that character and manner\nstereotypes outside of the dialogue significantly impact the gender agreement\nof referents within the dialogue."
    },
    {
      "id": "2411.06191v1",
      "title": "Generalizing Hyperedge Expansion for Hyper-relational Knowledge Graph Modeling",
      "summary": "By representing knowledge in a primary triple associated with additional\nattribute-value qualifiers, hyper-relational knowledge graph (HKG) that\ngeneralizes triple-based knowledge graph (KG) has been attracting research\nattention recently. Compared with KG, HKG is enriched with the semantic\nqualifiers as well as the hyper-relational graph structure. However, to model\nHKG, existing studies mainly focus on either semantic information or structural\ninformation therein, which however fail to capture both simultaneously. To\ntackle this issue, in this paper, we generalize the hyperedge expansion in\nhypergraph learning and propose an equivalent transformation for HKG modeling,\nreferred to as TransEQ. Specifically, the equivalent transformation transforms\na HKG to a KG, which considers both semantic and structural characteristics.\nThen an encoder-decoder framework is developed to bridge the modeling research\nbetween KG and HKG. In the encoder part, KG-based graph neural networks are\nleveraged for structural modeling; while in the decoder part, various HKG-based\nscoring functions are exploited for semantic modeling. Especially, we design\nthe sharing embedding mechanism in the encoder-decoder framework with semantic\nrelatedness captured. We further theoretically prove that TransEQ preserves\ncomplete information in the equivalent transformation, and also achieves full\nexpressivity. Finally, extensive experiments on three benchmarks demonstrate\nthe superior performance of TransEQ in terms of both effectiveness and\nefficiency. On the largest benchmark WikiPeople, TransEQ significantly improves\nthe state-of-the-art models by 15\\% on MRR."
    },
    {
      "id": "2411.06184v1",
      "title": "Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
      "summary": "In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context."
    },
    {
      "id": "2411.06176v1",
      "title": "M-Longdoc: A Benchmark For Multimodal Super-Long Document Understanding And A Retrieval-Aware Tuning Framework",
      "summary": "The ability to understand and answer questions over documents can be useful\nin many business and practical applications. However, documents often contain\nlengthy and diverse multimodal contents such as texts, figures, and tables,\nwhich are very time-consuming for humans to read thoroughly. Hence, there is an\nurgent need to develop effective and automated methods to aid humans in this\ntask. In this work, we introduce M-LongDoc, a benchmark of 851 samples, and an\nautomated framework to evaluate the performance of large multimodal models. We\nfurther propose a retrieval-aware tuning approach for efficient and effective\nmultimodal document reading. Compared to existing works, our benchmark consists\nof more recent and lengthy documents with hundreds of pages, while also\nrequiring open-ended solutions and not just extractive answers. To our\nknowledge, our training framework is the first to directly address the\nretrieval setting for multimodal long documents. To enable tuning open-source\nmodels, we construct a training corpus in a fully automatic manner for the\nquestion-answering task over such documents. Experiments show that our tuning\napproach achieves a relative improvement of 4.6% for the correctness of model\nresponses, compared to the baseline open-source models. Our data, code, and\nmodels are available at https://multimodal-documents.github.io."
    },
    {
      "id": "2411.06175v1",
      "title": "Clustering Algorithms and RAG Enhancing Semi-Supervised Text Classification with Large LLMs",
      "summary": "This paper introduces an innovative semi-supervised learning approach for\ntext classification, addressing the challenge of abundant data but limited\nlabeled examples. Our methodology integrates few-shot learning with\nretrieval-augmented generation (RAG) and conventional statistical clustering,\nenabling effective learning from a minimal number of labeled instances while\ngenerating high-quality labeled data. To the best of our knowledge, we are the\nfirst to incorporate RAG alongside clustering in text data generation. Our\nexperiments on the Reuters and Web of Science datasets demonstrate\nstate-of-the-art performance, with few-shot augmented data alone producing\nresults nearly equivalent to those achieved with fully labeled datasets.\nNotably, accuracies of 95.41\\% and 82.43\\% were achieved for complex text\ndocument classification tasks, where the number of categories can exceed 100."
    },
    {
      "id": "2411.06174v1",
      "title": "State Chrono Representation for Enhancing Generalization in Reinforcement Learning",
      "summary": "In reinforcement learning with image-based inputs, it is crucial to establish\na robust and generalizable state representation. Recent advancements in metric\nlearning, such as deep bisimulation metric approaches, have shown promising\nresults in learning structured low-dimensional representation space from pixel\nobservations, where the distance between states is measured based on\ntask-relevant features. However, these approaches face challenges in demanding\ngeneralization tasks and scenarios with non-informative rewards. This is\nbecause they fail to capture sufficient long-term information in the learned\nrepresentations. To address these challenges, we propose a novel State Chrono\nRepresentation (SCR) approach. SCR augments state metric-based representations\nby incorporating extensive temporal information into the update step of\nbisimulation metric learning. It learns state distances within a temporal\nframework that considers both future dynamics and cumulative rewards over\ncurrent and long-term future states. Our learning strategy effectively\nincorporates future behavioral information into the representation space\nwithout introducing a significant number of additional parameters for modeling\ndynamics. Extensive experiments conducted in DeepMind Control and Meta-World\nenvironments demonstrate that SCR achieves better performance comparing to\nother recent metric-based methods in demanding generalization tasks. The codes\nof SCR are available in https://github.com/jianda-chen/SCR."
    },
    {
      "id": "2411.06171v1",
      "title": "SEEKR: Selective Attention-Guided Knowledge Retention for Continual Learning of Large Language Models",
      "summary": "Continual learning (CL) is crucial for language models to dynamically adapt\nto the evolving real-world demands. To mitigate the catastrophic forgetting\nproblem in CL, data replay has been proven a simple and effective strategy, and\nthe subsequent data-replay-based distillation can further enhance the\nperformance. However, existing methods fail to fully exploit the knowledge\nembedded in models from previous tasks, resulting in the need for a relatively\nlarge number of replay samples to achieve good results. In this work, we first\nexplore and emphasize the importance of attention weights in knowledge\nretention, and then propose a SElective attEntion-guided Knowledge Retention\nmethod (SEEKR) for data-efficient replay-based continual learning of large\nlanguage models (LLMs). Specifically, SEEKR performs attention distillation on\nthe selected attention heads for finer-grained knowledge retention, where the\nproposed forgettability-based and task-sensitivity-based measures are used to\nidentify the most valuable attention heads. Experimental results on two\ncontinual learning benchmarks for LLMs demonstrate the superiority of SEEKR\nover the existing methods on both performance and efficiency. Explicitly, SEEKR\nachieves comparable or even better performance with only 1/10 of the replayed\ndata used by other methods, and reduces the proportion of replayed data to 1%."
    },
    {
      "id": "2411.06160v1",
      "title": "Expansion Quantization Network: An Efficient Micro-emotion Annotation and Detection Framework",
      "summary": "Text emotion detection constitutes a crucial foundation for advancing\nartificial intelligence from basic comprehension to the exploration of\nemotional reasoning. Most existing emotion detection datasets rely on manual\nannotations, which are associated with high costs, substantial subjectivity,\nand severe label imbalances. This is particularly evident in the inadequate\nannotation of micro-emotions and the absence of emotional intensity\nrepresentation, which fail to capture the rich emotions embedded in sentences\nand adversely affect the quality of downstream task completion. By proposing an\nall-labels and training-set label regression method, we map label values to\nenergy intensity levels, thereby fully leveraging the learning capabilities of\nmachine models and the interdependencies among labels to uncover multiple\nemotions within samples. This led to the establishment of the Emotion\nQuantization Network (EQN) framework for micro-emotion detection and\nannotation. Using five commonly employed sentiment datasets, we conducted\ncomparative experiments with various models, validating the broad applicability\nof our framework within NLP machine learning models. Based on the EQN\nframework, emotion detection and annotation are conducted on the GoEmotions\ndataset. A comprehensive comparison with the results from Google literature\ndemonstrates that the EQN framework possesses a high capability for automatic\ndetection and annotation of micro-emotions. The EQN framework is the first to\nachieve automatic micro-emotion annotation with energy-level scores, providing\nstrong support for further emotion detection analysis and the quantitative\nresearch of emotion computing."
    },
    {
      "id": "2411.06159v1",
      "title": "From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review",
      "summary": "Literature reviews play a crucial role in scientific research for\nunderstanding the current state of research, identifying gaps, and guiding\nfuture studies on specific topics. However, the process of conducting a\ncomprehensive literature review is yet time-consuming. This paper proposes a\nnovel framework, collaborative knowledge minigraph agents (CKMAs), to automate\nscholarly literature reviews. A novel prompt-based algorithm, the knowledge\nminigraph construction agent (KMCA), is designed to identify relationships\nbetween information pieces from academic literature and automatically\nconstructs knowledge minigraphs. By leveraging the capabilities of large\nlanguage models on constructed knowledge minigraphs, the multiple path\nsummarization agent (MPSA) efficiently organizes information pieces and\nrelationships from different viewpoints to generate literature review\nparagraphs. We evaluate CKMAs on three benchmark datasets. Experimental results\ndemonstrate that the proposed techniques generate informative, complete,\nconsistent, and insightful summaries for different research problems, promoting\nthe use of LLMs in more professional fields."
    },
    {
      "id": "2411.06155v1",
      "title": "HiHa: Introducing Hierarchical Harmonic Decomposition to Implicit Neural Compression for Atmospheric Data",
      "summary": "The rapid development of large climate models has created the requirement of\nstoring and transferring massive atmospheric data worldwide. Therefore, data\ncompression is essential for meteorological research, but an efficient\ncompression scheme capable of keeping high accuracy with high compressibility\nis still lacking. As an emerging technique, Implicit Neural Representation\n(INR) has recently acquired impressive momentum and demonstrates high promise\nfor compressing diverse natural data. However, the INR-based compression\nencounters a bottleneck due to the sophisticated spatio-temporal properties and\nvariability. To address this issue, we propose Hierarchical Harmonic\ndecomposition implicit neural compression (HiHa) for atmospheric data. HiHa\nfirstly segments the data into multi-frequency signals through decomposition of\nmultiple complex harmonic, and then tackles each harmonic respectively with a\nfrequency-based hierarchical compression module consisting of sparse storage,\nmulti-scale INR and iterative decomposition sub-modules. We additionally design\na temporal residual compression module to accelerate compression by utilizing\ntemporal continuity. Experiments depict that HiHa outperforms both mainstream\ncompressors and other INR-based methods in both compression fidelity and\ncapabilities, and also demonstrate that using compressed data in existing\ndata-driven models can achieve the same accuracy as raw data."
    },
    {
      "id": "2411.06151v1",
      "title": "Building an Efficient Multilingual Non-Profit IR System for the Islamic Domain Leveraging Multiprocessing Design in Rust",
      "summary": "The widespread use of large language models (LLMs) has dramatically improved\nmany applications of Natural Language Processing (NLP), including Information\nRetrieval (IR). However, domains that are not driven by commercial interest\noften lag behind in benefiting from AI-powered solutions. One such area is\nreligious and heritage corpora. Alongside similar domains, Islamic literature\nholds significant cultural value and is regularly utilized by scholars and the\ngeneral public. Navigating this extensive amount of text is challenging, and\nthere is currently no unified resource that allows for easy searching of this\ndata using advanced AI tools. This work focuses on the development of a\nmultilingual non-profit IR system for the Islamic domain. This process brings a\nfew major challenges, such as preparing multilingual domain-specific corpora\nwhen data is limited in certain languages, deploying a model on\nresource-constrained devices, and enabling fast search on a limited budget. By\nemploying methods like continued pre-training for domain adaptation and\nlanguage reduction to decrease model size, a lightweight multilingual retrieval\nmodel was prepared, demonstrating superior performance compared to larger\nmodels pre-trained on general domain data. Furthermore, evaluating the proposed\narchitecture that utilizes Rust Language capabilities shows the possibility of\nimplementing efficient semantic search in a low-resource setting."
    },
    {
      "id": "2411.06148v1",
      "title": "Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems",
      "summary": "The Digital Twin Oriented Complex Networked System (DT-CNS) aims to build and\nextend a Complex Networked System (CNS) model with progressively increasing\ndynamics complexity towards an accurate reflection of reality -- a Digital Twin\nof reality. Our previous work proposed evolutionary DT-CNSs to model the\nlong-term adaptive network changes in an epidemic outbreak. This study extends\nthis framework by proposeing the temporal DT-CNS model, where reinforcement\nlearning-driven nodes make decisions on temporal directed interactions in an\nepidemic outbreak. We consider cooperative nodes, as well as egocentric and\nignorant \"free-riders\" in the cooperation. We describe this epidemic spreading\nprocess with the Susceptible-Infected-Recovered ($SIR$) model and investigate\nthe impact of epidemic severity on the epidemic resilience for different types\nof nodes. Our experimental results show that (i) the full cooperation leads to\na higher reward and lower infection number than a cooperation with egocentric\nor ignorant \"free-riders\"; (ii) an increasing number of \"free-riders\" in a\ncooperation leads to a smaller reward, while an increasing number of egocentric\n\"free-riders\" further escalate the infection numbers and (iii) higher infection\nrates and a slower recovery weakens networks' resilience to severe epidemic\noutbreaks. These findings also indicate that promoting cooperation and reducing\n\"free-riders\" can improve public health during epidemics."
    },
    {
      "id": "2411.06146v1",
      "title": "AI-Compass: A Comprehensive and Effective Multi-module Testing Tool for AI Systems",
      "summary": "AI systems, in particular with deep learning techniques, have demonstrated\nsuperior performance for various real-world applications. Given the need for\ntailored optimization in specific scenarios, as well as the concerns related to\nthe exploits of subsurface vulnerabilities, a more comprehensive and in-depth\ntesting AI system becomes a pivotal topic. We have seen the emergence of\ntesting tools in real-world applications that aim to expand testing\ncapabilities. However, they often concentrate on ad-hoc tasks, rendering them\nunsuitable for simultaneously testing multiple aspects or components.\nFurthermore, trustworthiness issues arising from adversarial attacks and the\nchallenge of interpreting deep learning models pose new challenges for\ndeveloping more comprehensive and in-depth AI system testing tools. In this\nstudy, we design and implement a testing tool, \\tool, to comprehensively and\neffectively evaluate AI systems. The tool extensively assesses multiple\nmeasurements towards adversarial robustness, model interpretability, and\nperforms neuron analysis. The feasibility of the proposed testing tool is\nthoroughly validated across various modalities, including image classification,\nobject detection, and text classification. Extensive experiments demonstrate\nthat \\tool is the state-of-the-art tool for a comprehensive assessment of the\nrobustness and trustworthiness of AI systems. Our research sheds light on a\ngeneral solution for AI systems testing landscape."
    },
    {
      "id": "2411.06142v1",
      "title": "Aquila-plus: Prompt-Driven Visual-Language Models for Pixel-Level Remote Sensing Image Understanding",
      "summary": "The recent development of vision language models (VLMs) has led to\nsignificant advances in visual-language integration through visual instruction\ntuning, and they have rapidly evolved in the field of remote sensing image\nunderstanding, demonstrating their powerful capabilities. However, existing\nRSVLMs mainly focus on image-level or frame-level understanding, making it\ndifficult to achieve fine-grained pixel-level visual-language alignment.\nAdditionally, the lack of mask-based instructional data limits their further\ndevelopment. In this paper, we propose a mask-text instruction tuning method\ncalled Aquila-plus, which extends the capabilities of RSVLMs to achieve\npixel-level visual understanding by incorporating fine-grained mask regions\ninto language instructions. To achieve this, we first meticulously constructed\na mask region-text dataset containing 100K samples, and then designed a\nvisual-language model by injecting pixel-level representations into a large\nlanguage model (LLM). Specifically, Aquila-plus uses a convolutional CLIP as\nthe visual encoder and employs a mask-aware visual extractor to extract precise\nvisual mask features from high-resolution inputs. Experimental results\ndemonstrate that Aquila-plus outperforms existing methods in various region\nunderstanding tasks, showcasing its novel capabilities in pixel-level\ninstruction tuning."
    },
    {
      "id": "2411.06140v1",
      "title": "Deep Nonparametric Conditional Independence Tests for Images",
      "summary": "Conditional independence tests (CITs) test for conditional dependence between\nrandom variables. As existing CITs are limited in their applicability to\ncomplex, high-dimensional variables such as images, we introduce deep\nnonparametric CITs (DNCITs). The DNCITs combine embedding maps, which extract\nfeature representations of high-dimensional variables, with nonparametric CITs\napplicable to these feature representations. For the embedding maps, we derive\ngeneral properties on their parameter estimators to obtain valid DNCITs and\nshow that these properties include embedding maps learned through (conditional)\nunsupervised or transfer learning. For the nonparametric CITs, appropriate\ntests are selected and adapted to be applicable to feature representations.\nThrough simulations, we investigate the performance of the DNCITs for different\nembedding maps and nonparametric CITs under varying confounder dimensions and\nconfounder relationships. We apply the DNCITs to brain MRI scans and behavioral\ntraits, given confounders, of healthy individuals from the UK Biobank (UKB),\nconfirming null results from a number of ambiguous personality neuroscience\nstudies with a larger data set and with our more powerful tests. In addition,\nin a confounder control study, we apply the DNCITs to brain MRI scans and a\nconfounder set to test for sufficient confounder control, leading to a\npotential reduction in the confounder dimension under improved confounder\ncontrol compared to existing state-of-the-art confounder control studies for\nthe UKB. Finally, we provide an R package implementing the DNCITs."
    },
    {
      "id": "2411.06138v1",
      "title": "StopHC: A Harmful Content Detection and Mitigation Architecture for Social Media Platforms",
      "summary": "The mental health of social media users has started more and more to be put\nat risk by harmful, hateful, and offensive content. In this paper, we propose\n\\textsc{StopHC}, a harmful content detection and mitigation architecture for\nsocial media platforms. Our aim with \\textsc{StopHC} is to create more secure\nonline environments. Our solution contains two modules, one that employs deep\nneural network architecture for harmful content detection, and one that uses a\nnetwork immunization algorithm to block toxic nodes and stop the spread of\nharmful content. The efficacy of our solution is demonstrated by experiments\nconducted on two real-world datasets."
    },
    {
      "id": "2411.06135v1",
      "title": "Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers",
      "summary": "Online multi-task learning (OMTL) enhances streaming data processing by\nleveraging the inherent relations among multiple tasks. It can be described as\nan optimization problem in which a single loss function is defined for multiple\ntasks. Existing gradient-descent-based methods for this problem might suffer\nfrom gradient vanishing and poor conditioning issues. Furthermore, the\ncentralized setting hinders their application to online parallel optimization,\nwhich is vital to big data analytics. Therefore, this study proposes a novel\nOMTL framework based on the alternating direction multiplier method (ADMM), a\nrecent breakthrough in optimization suitable for the distributed computing\nenvironment because of its decomposable and easy-to-implement nature. The\nrelations among multiple tasks are modeled dynamically to fit the constant\nchanges in an online scenario. In a classical distributed computing\narchitecture with a central server, the proposed OMTL algorithm with the ADMM\noptimizer outperforms SGD-based approaches in terms of accuracy and efficiency.\nBecause the central server might become a bottleneck when the data scale grows,\nwe further tailor the algorithm to a decentralized setting, so that each node\ncan work by only exchanging information with local neighbors. Experimental\nresults on a synthetic and several real-world datasets demonstrate the\nefficiency of our methods."
    },
    {
      "id": "2411.06128v1",
      "title": "Research on reinforcement learning based warehouse robot navigation algorithm in complex warehouse layout",
      "summary": "In this paper, how to efficiently find the optimal path in complex warehouse\nlayout and make real-time decision is a key problem. This paper proposes a new\nmethod of Proximal Policy Optimization (PPO) and Dijkstra's algorithm, Proximal\npolicy-Dijkstra (PP-D). PP-D method realizes efficient strategy learning and\nreal-time decision making through PPO, and uses Dijkstra algorithm to plan the\nglobal optimal path, thus ensuring high navigation accuracy and significantly\nimproving the efficiency of path planning. Specifically, PPO enables robots to\nquickly adapt and optimize action strategies in dynamic environments through\nits stable policy updating mechanism. Dijkstra's algorithm ensures global\noptimal path planning in static environment. Finally, through the comparison\nexperiment and analysis of the proposed framework with the traditional\nalgorithm, the results show that the PP-D method has significant advantages in\nimproving the accuracy of navigation prediction and enhancing the robustness of\nthe system. Especially in complex warehouse layout, PP-D method can find the\noptimal path more accurately and reduce collision and stagnation. This proves\nthe reliability and effectiveness of the robot in the study of complex\nwarehouse layout navigation algorithm."
    },
    {
      "id": "2411.06124v1",
      "title": "Exploring Structural Nonlinearity in Binary Polariton-Based Neuromorphic Architectures",
      "summary": "This study investigates the performance of a binarized neuromorphic network\nleveraging polariton dyads, optically excited pairs of interfering polariton\ncondensates within a microcavity to function as binary logic gate neurons.\nEmploying numerical simulations, we explore various neuron configurations, both\nlinear (NAND, NOR) and nonlinear (XNOR), to assess their effectiveness in image\nclassification tasks. We demonstrate that structural nonlinearity, derived from\nthe network's layout, plays a crucial role in facilitating complex\ncomputational tasks, effectively reducing the reliance on the inherent\nnonlinearity of individual neurons. Our findings suggest that the network's\nconfiguration and the interaction among its elements can emulate the benefits\nof nonlinearity, thus potentially simplifying the design and manufacturing of\nneuromorphic systems and enhancing their scalability. This shift in focus from\nindividual neuron properties to network architecture could lead to significant\nadvancements in the efficiency and applicability of neuromorphic computing."
    },
    {
      "id": "2411.06122v1",
      "title": "Characteristics of Political Misinformation Over the Past Decade",
      "summary": "Although misinformation tends to spread online, it can have serious\nreal-world consequences. In order to develop automated tools to detect and\nmitigate the impact of misinformation, researchers must leverage algorithms\nthat can adapt to the modality (text, images and video), the source, and the\ncontent of the false information. However, these characteristics tend to change\ndynamically across time, making it challenging to develop robust algorithms to\nfight misinformation spread. Therefore, this paper uses natural language\nprocessing to find common characteristics of political misinformation over a\ntwelve year period. The results show that misinformation has increased\ndramatically in recent years and that it has increasingly started to be shared\nfrom sources with primary information modalities of text and images (e.g.,\nFacebook and Instagram), although video sharing sources containing\nmisinformation are starting to increase (e.g., TikTok). Moreover, it was\ndiscovered that statements expressing misinformation contain more negative\nsentiment than accurate information. However, the sentiment associated with\nboth accurate and inaccurate information has trended downward, indicating a\ngenerally more negative tone in political statements across time. Finally,\nrecurring misinformation categories were uncovered that occur over multiple\nyears, which may imply that people tend to share inaccurate statements around\ninformation they fear or don't understand (Science and Medicine, Crime,\nReligion), impacts them directly (Policy, Election Integrity, Economic) or\nPublic Figures who are salient in their daily lives. Together, it is hoped that\nthese insights will assist researchers in developing algorithms that are\ntemporally invariant and capable of detecting and mitigating misinformation\nacross time."
    },
    {
      "id": "2411.06120v1",
      "title": "Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle",
      "summary": "Generative Artificial Intelligence offers a powerful tool for adversaries who\nwish to engage in influence operations, such as the Chinese Spamouflage\noperation and the Russian Internet Research Agency effort that both sought to\ninterfere with recent US election cycles. Therefore, this study seeks to\ninvestigate the propensity of current Generative AI models for producing\nharmful disinformation during an election cycle. The probability that different\nGenerative AI models produced disinformation when given adversarial prompts was\nevaluated, in addition the associated harm. This allows for the expected harm\nfor each model to be computed and it was discovered that Copilot and Gemini\ntied for the overall safest performance by realizing the lowest expected harm,\nwhile GPT-4o produced the greatest rates of harmful disinformation, resulting\nin much higher expected harm scores. The impact of disinformation category was\nalso investigated and Gemini was safest within the political category of\ndisinformation, while Copilot was safest for topics related to health.\nMoreover, characteristics of adversarial roles were discovered that led to\ngreater expected harm across all models. Finally, classification models were\ndeveloped that predicted disinformation production based on the conditions\nconsidered in this study, which offers insight into factors important for\npredicting disinformation production. Based on all of these insights,\nrecommendations are provided that seek to mitigate factors that lead to harmful\ndisinformation being produced by Generative AI models. It is hoped that\ndevelopers will use these insights to improve future models."
    },
    {
      "id": "2411.06119v1",
      "title": "Scalable, Tokenization-Free Diffusion Model Architectures with Efficient Initial Convolution and Fixed-Size Reusable Structures for On-Device Image Generation",
      "summary": "Vision Transformers and U-Net architectures have been widely adopted in the\nimplementation of Diffusion Models. However, each architecture presents\nspecific challenges while realizing them on-device. Vision Transformers require\npositional embedding to maintain correspondence between the tokens processed by\nthe transformer, although they offer the advantage of using fixed-size,\nreusable repetitive blocks following tokenization. The U-Net architecture lacks\nthese attributes, as it utilizes variable-sized intermediate blocks for\ndown-convolution and up-convolution in the noise estimation backbone for the\ndiffusion process. To address these issues, we propose an architecture that\nutilizes a fixed-size, reusable transformer block as a core structure, making\nit more suitable for hardware implementation. Our architecture is characterized\nby low complexity, token-free design, absence of positional embeddings,\nuniformity, and scalability, making it highly suitable for deployment on mobile\nand resource-constrained devices. The proposed model exhibit competitive and\nconsistent performance across both unconditional and conditional image\ngeneration tasks. The model achieved a state-of-the-art FID score of 1.6 on\nunconditional image generation with the CelebA."
    },
    {
      "id": "2411.06111v1",
      "title": "Energy-efficient Hybrid Model Predictive Trajectory Planning for Autonomous Electric Vehicles",
      "summary": "To tackle the twin challenges of limited battery life and lengthy charging\ndurations in electric vehicles (EVs), this paper introduces an Energy-efficient\nHybrid Model Predictive Planner (EHMPP), which employs an energy-saving\noptimization strategy. EHMPP focuses on refining the design of the motion\nplanner to be seamlessly integrated with the existing automatic driving\nalgorithms, without additional hardware. It has been validated through\nsimulation experiments on the Prescan, CarSim, and Matlab platforms,\ndemonstrating that it can increase passive recovery energy by 11.74\\% and\neffectively track motor speed and acceleration at optimal power. To sum up,\nEHMPP not only aids in trajectory planning but also significantly boosts energy\nefficiency in autonomous EVs."
    },
    {
      "id": "2411.06106v2",
      "title": "Personalize to generalize: Towards a universal medical multi-modality generalization through personalization",
      "summary": "The differences among medical imaging modalities, driven by distinct\nunderlying principles, pose significant challenges for generalization in\nmulti-modal medical tasks. Beyond modality gaps, individual variations, such as\ndifferences in organ size and metabolic rate, further impede a model's ability\nto generalize effectively across both modalities and diverse populations.\nDespite the importance of personalization, existing approaches to multi-modal\ngeneralization often neglect individual differences, focusing solely on common\nanatomical features. This limitation may result in weakened generalization in\nvarious medical tasks. In this paper, we unveil that personalization is\ncritical for multi-modal generalization. Specifically, we propose an approach\nto achieve personalized generalization through approximating the underlying\npersonalized invariant representation ${X}_h$ across various modalities by\nleveraging individual-level constraints and a learnable biological prior. We\nvalidate the feasibility and benefits of learning a personalized ${X}_h$,\nshowing that this representation is highly generalizable and transferable\nacross various multi-modal medical tasks. Extensive experimental results\nconsistently show that the additionally incorporated personalization\nsignificantly improves performance and generalization across diverse scenarios,\nconfirming its effectiveness."
    },
    {
      "id": "2411.06101v1",
      "title": "Detecting Reference Errors in Scientific Literature with Large Language Models",
      "summary": "Reference errors, such as citation and quotation errors, are common in\nscientific papers. Such errors can result in the propagation of inaccurate\ninformation, but are difficult and time-consuming to detect, posing a\nsignificant challenge to scientific publishing. To support automatic detection\nof reference errors, this work evaluated the ability of large language models\nin OpenAI's GPT family to detect quotation errors. Specifically, we prepared an\nexpert-annotated, general-domain dataset of statement-reference pairs from\njournal articles. Large language models were evaluated in different settings\nwith varying amounts of reference information provided by retrieval\naugmentation. Our results showed that large language models are able to detect\nerroneous citations with limited context and without fine-tuning. This study\ncontributes to the growing literature that seeks to utilize artificial\nintelligence to assist in the writing, reviewing, and publishing of scientific\npapers. Potential avenues for further improvements in this task are also\ndiscussed."
    },
    {
      "id": "2411.06100v1",
      "title": "Mutual-energy inner product optimization method for constructing feature coordinates and image classification in Machine Learning",
      "summary": "As a key task in machine learning, data classification is essentially to find\na suitable coordinate system to represent data features of different classes of\nsamples. This paper proposes the mutual-energy inner product optimization\nmethod for constructing a feature coordinate system. First, by analyzing the\nsolution space and eigenfunctions of partial differential equations describing\na non-uniform membrane, the mutual-energy inner product is defined. Second, by\nexpressing the mutual-energy inner product as a series of eigenfunctions, it\nshows a significant advantage of enhancing low-frequency features and\nsuppressing high-frequency noise, compared with the Euclidean inner product.\nAnd then, a mutual-energy inner product optimization model is built to extract\ndata features, and convexity and concavity properties of its objective function\nare discussed. Next, by combining the finite element method, a stable and\nefficient sequential linearization algorithm is constructed to solve the\noptimization model. This algorithm only solves equations including positive\ndefinite symmetric matrix and linear programming with a few constraints, and\nits vectorized implementation is discussed. Finally, the mutual-energy inner\nproduct optimization method is used to construct feature coordinates, and\nmulti-class Gaussian classifiers are trained on the MINST training set. Good\nprediction results of Gaussian classifiers are achieved on the MINST test set."
    },
    {
      "id": "2411.06098v2",
      "title": "LT-DARTS: An Architectural Approach to Enhance Deep Long-Tailed Learning",
      "summary": "Deep long-tailed recognition has been widely studied to address the issue of\nimbalanced data distributions in real-world scenarios. However, there has been\ninsufficient focus on the design of neural architectures, despite empirical\nevidence suggesting that architecture can significantly impact performance. In\nthis paper, we attempt to mitigate long-tailed issues through architectural\nimprovements. To simplify the design process, we utilize Differential\nArchitecture Search (DARTS) to achieve this goal. Unfortunately, existing DARTS\nmethods struggle to perform well in long-tailed scenarios. To tackle this\nchallenge, we introduce Long-Tailed Differential Architecture Search\n(LT-DARTS). Specifically, we conduct extensive experiments to explore\narchitectural components that demonstrate better performance on long-tailed\ndata and propose a new search space based on our observations. This ensures\nthat the architecture obtained through our search process incorporates superior\ncomponents. Additionally, we propose replacing the learnable linear classifier\nwith an Equiangular Tight Frame (ETF) classifier to further enhance our method.\nThis classifier effectively alleviates the biased search process and prevents\nperformance collapse. Extensive experimental evaluations demonstrate that our\napproach consistently improves upon existing methods from an orthogonal\nperspective and achieves state-of-the-art results with simple enhancements."
    },
    {
      "id": "2411.06097v1",
      "title": "A Multimodal Adaptive Graph-based Intelligent Classification Model for Fake News",
      "summary": "Numerous studies have been proposed to detect fake news focusing on\nmulti-modalities based on machine and/or deep learning. However, studies\nfocusing on graph-based structures using geometric deep learning are lacking.\nTo address this challenge, we introduce the Multimodal Adaptive Graph-based\nIntelligent Classification (aptly referred to as MAGIC) for fake news\ndetection. Specifically, the Encoder Representations from Transformers was used\nfor text vectorization whilst ResNet50 was used for images. A comprehensive\ninformation interaction graph was built using the adaptive Graph Attention\nNetwork before classifying the multimodal input through the Softmax function.\nMAGIC was trained and tested on two fake news datasets, that is, Fakeddit\n(English) and Multimodal Fake News Detection (Chinese), with the model\nachieving an accuracy of 98.8\\% and 86.3\\%, respectively. Ablation experiments\nalso revealed MAGIC to yield superior performance across both the datasets.\nFindings show that a graph-based deep learning adaptive model is effective in\ndetecting multimodal fake news, surpassing state-of-the-art methods."
    },
    {
      "id": "2411.06096v1",
      "title": "ZhoBLiMP: a Systematic Assessment of Language Models with Linguistic Minimal Pairs in Chinese",
      "summary": "Whether and how language models (LMs) acquire the syntax of natural languages\nhas been widely evaluated under the minimal pair paradigm. However, a lack of\nwide-coverage benchmarks in languages other than English has constrained\nsystematic investigations into the issue. Addressing it, we first introduce\nZhoBLiMP, the most comprehensive benchmark of linguistic minimal pairs for\nChinese to date, with 118 paradigms, covering 15 linguistic phenomena. We then\ntrain 20 LMs of different sizes (14M to 1.4B) on Chinese corpora of various\nvolumes (100M to 3B tokens) and evaluate them along with 14 off-the-shelf LLMs\non ZhoBLiMP. The overall results indicate that Chinese grammar can be mostly\nlearned by models with around 500M parameters, trained on 1B tokens with one\nepoch, showing limited benefits for further scaling. Most (N=95) linguistic\nparadigms are of easy or medium difficulty for LMs, while there are still 13\nparadigms that remain challenging even for models with up to 32B parameters. In\nregard to how LMs acquire Chinese grammar, we observe a U-shaped learning\npattern in several phenomena, similar to those observed in child language\nacquisition."
    },
    {
      "id": "2411.06090v1",
      "title": "Concept Bottleneck Language Models For protein design",
      "summary": "We introduce Concept Bottleneck Protein Language Models (CB-pLM), a\ngenerative masked language model with a layer where each neuron corresponds to\nan interpretable concept. Our architecture offers three key benefits: i)\nControl: We can intervene on concept values to precisely control the properties\nof generated proteins, achieving a 3 times larger change in desired concept\nvalues compared to baselines. ii) Interpretability: A linear mapping between\nconcept values and predicted tokens allows transparent analysis of the model's\ndecision-making process. iii) Debugging: This transparency facilitates easy\ndebugging of trained models. Our models achieve pre-training perplexity and\ndownstream task performance comparable to traditional masked protein language\nmodels, demonstrating that interpretability does not compromise performance.\nWhile adaptable to any language model, we focus on masked protein language\nmodels due to their importance in drug discovery and the ability to validate\nour model's capabilities through real-world experiments and expert knowledge.\nWe scale our CB-pLM from 24 million to 3 billion parameters, making them the\nlargest Concept Bottleneck Models trained and the first capable of generative\nlanguage modeling."
    },
    {
      "id": "2411.06087v2",
      "title": "Cross-Domain Transfer Learning using Attention Latent Features for Multi-Agent Trajectory Prediction",
      "summary": "With the advancements of sensor hardware, traffic infrastructure and deep\nlearning architectures, trajectory prediction of vehicles has established a\nsolid foundation in intelligent transportation systems. However, existing\nsolutions are often tailored to specific traffic networks at particular time\nperiods. Consequently, deep learning models trained on one network may struggle\nto generalize effectively to unseen networks. To address this, we proposed a\nnovel spatial-temporal trajectory prediction framework that performs\ncross-domain adaption on the attention representation of a Transformer-based\nmodel. A graph convolutional network is also integrated to construct dynamic\ngraph feature embeddings that accurately model the complex spatial-temporal\ninteractions between the multi-agent vehicles across multiple traffic domains.\nThe proposed framework is validated on two case studies involving the\ncross-city and cross-period settings. Experimental results show that our\nproposed framework achieves superior trajectory prediction and domain\nadaptation performances over the state-of-the-art models."
    },
    {
      "id": "2411.06084v1",
      "title": "Optimizing Large Language Models through Quantization: A Comparative Analysis of PTQ and QAT Techniques",
      "summary": "This paper presents a comprehensive analysis of quantization techniques for\noptimizing Large Language Models (LLMs), specifically focusing on Post-Training\nQuantization (PTQ) and Quantization-Aware Training (QAT). Through empirical\nevaluation across models ranging from 10M to 1B parameters, we demonstrate that\nquantization can achieve up to 68% reduction in model size while maintaining\nperformance within 6% of full-precision baselines when utilizing our proposed\nscaling factor {\\gamma}. Our experiments show that INT8 quantization delivers a\n40% reduction in computational cost and power consumption, while INT4\nquantization further improves these metrics by 60%. We introduce a novel\ntheoretical framework for mixed-precision quantization, deriving optimal bit\nallocation strategies based on layer sensitivity and weight variance. Hardware\nefficiency evaluations on edge devices reveal that our quantization approach\nenables up to 2.4x throughput improvement for INT8 and 3x for INT4, with 60%\npower reduction compared to full-precision models."
    },
    {
      "id": "2411.06078v1",
      "title": "A Survey on Kolmogorov-Arnold Network",
      "summary": "This systematic review explores the theoretical foundations, evolution,\napplications, and future potential of Kolmogorov-Arnold Networks (KAN), a\nneural network model inspired by the Kolmogorov-Arnold representation theorem.\nKANs distinguish themselves from traditional neural networks by using\nlearnable, spline-parameterized functions instead of fixed activation\nfunctions, allowing for flexible and interpretable representations of\nhigh-dimensional functions. This review details KAN's architectural strengths,\nincluding adaptive edge-based activation functions that improve parameter\nefficiency and scalability in applications such as time series forecasting,\ncomputational biomedicine, and graph learning. Key advancements, including\nTemporal-KAN, FastKAN, and Partial Differential Equation (PDE) KAN, illustrate\nKAN's growing applicability in dynamic environments, enhancing\ninterpretability, computational efficiency, and adaptability for complex\nfunction approximation tasks. Additionally, this paper discusses KAN's\nintegration with other architectures, such as convolutional, recurrent, and\ntransformer-based models, showcasing its versatility in complementing\nestablished neural networks for tasks requiring hybrid approaches. Despite its\nstrengths, KAN faces computational challenges in high-dimensional and noisy\ndata settings, motivating ongoing research into optimization strategies,\nregularization techniques, and hybrid models. This paper highlights KAN's role\nin modern neural architectures and outlines future directions to improve its\ncomputational efficiency, interpretability, and scalability in data-intensive\napplications."
    },
    {
      "id": "2411.06076v1",
      "title": "BreakGPT: Leveraging Large Language Models for Predicting Asset Price Surges",
      "summary": "This paper introduces BreakGPT, a novel large language model (LLM)\narchitecture adapted specifically for time series forecasting and the\nprediction of sharp upward movements in asset prices. By leveraging both the\ncapabilities of LLMs and Transformer-based models, this study evaluates\nBreakGPT and other Transformer-based models for their ability to address the\nunique challenges posed by highly volatile financial markets. The primary\ncontribution of this work lies in demonstrating the effectiveness of combining\ntime series representation learning with LLM prediction frameworks. We showcase\nBreakGPT as a promising solution for financial forecasting with minimal\ntraining and as a strong competitor for capturing both local and global\ntemporal dependencies."
    },
    {
      "id": "2411.06074v1",
      "title": "Aquila: A Hierarchically Aligned Visual-Language Model for Enhanced Remote Sensing Image Comprehension",
      "summary": "Recently, large vision language models (VLMs) have made significant strides\nin visual language capabilities through visual instruction tuning, showing\ngreat promise in the field of remote sensing image interpretation. However,\nexisting remote sensing vision language models (RSVLMs) often fall short in\ncapturing the complex characteristics of remote sensing scenes, as they\ntypically rely on low resolution, single scale visual features and simplistic\nmethods to map visual features to language features. In this paper, we present\nAquila, an advanced visual language foundation model designed to enable richer\nvisual feature representation and more precise visual-language feature\nalignment for remote sensing images. Our approach introduces a learnable\nHierarchical Spatial Feature Integration (SFI) module that supports high\nresolution image inputs and aggregates multi scale visual features, allowing\nfor the detailed representation of complex visual information. Additionally,\nthe SFI module is repeatedly integrated into the layers of the large language\nmodel (LLM) to achieve deep visual language feature alignment, without\ncompromising the model's performance in natural language processing tasks.\nThese innovations, capturing detailed visual effects through higher resolution\nand multi scale input, and enhancing feature alignment significantly improve\nthe model's ability to learn from image text data. We validate the\neffectiveness of Aquila through extensive quantitative experiments and\nqualitative analyses, demonstrating its superior performance."
    },
    {
      "id": "2411.06070v1",
      "title": "GFT: Graph Foundation Model with Transferable Tree Vocabulary",
      "summary": "Inspired by the success of foundation models in applications such as ChatGPT,\nas graph data has been ubiquitous, one can envision the far-reaching impacts\nthat can be brought by Graph Foundation Models (GFMs) with broader applications\nin the areas such as scientific research, social network analysis, drug\ndiscovery, and e-commerce. Despite the significant progress of pre-trained\ngraph neural networks, there haven't been GFMs that can achieve desired\nperformance on various graph-learning-related tasks. Building GFMs may rely on\na vocabulary that encodes transferable patterns shared among different tasks\nand domains. Unlike image and text, defining such transferable patterns for\ngraphs remains an open question. In this paper, we aim to bridge this gap by\nrethinking the transferable patterns on graphs as computation trees -- i.e.,\ntree structures derived from the message-passing process. Based on this\ninsight, we propose a cross-task, cross-domain graph foundation model named\nGFT, short for Graph Foundation model with transferable Tree vocabulary. By\ntreating computation trees as tokens within the transferable vocabulary, GFT\nimproves model generalization and reduces the risk of negative transfer. The\ntheoretical analyses and extensive experimental studies have demonstrated the\ntransferability of computation trees and shown the effectiveness of GFT across\ndiverse tasks and domains in graph learning. The open source code and data are\navailable at https://github.com/Zehong-Wang/GFT."
    },
    {
      "id": "2411.06069v1",
      "title": "Model Selection for Average Reward RL with Application to Utility Maximization in Repeated Games",
      "summary": "In standard RL, a learner attempts to learn an optimal policy for a Markov\nDecision Process whose structure (e.g. state space) is known. In online model\nselection, a learner attempts to learn an optimal policy for an MDP knowing\nonly that it belongs to one of $M >1$ model classes of varying complexity.\nRecent results have shown that this can be feasibly accomplished in episodic\nonline RL. In this work, we propose $\\mathsf{MRBEAR}$, an online model\nselection algorithm for the average reward RL setting. The regret of the\nalgorithm is in $\\tilde O(M C_{m^*}^2 \\mathsf{B}_{m^*}(T,\\delta))$ where\n$C_{m^*}$ represents the complexity of the simplest well-specified model class\nand $\\mathsf{B}_{m^*}(T,\\delta)$ is its corresponding regret bound. This result\nshows that in average reward RL, like the episodic online RL, the additional\ncost of model selection scales only linearly in $M$, the number of model\nclasses. We apply $\\mathsf{MRBEAR}$ to the interaction between a learner and an\nopponent in a two-player simultaneous general-sum repeated game, where the\nopponent follows a fixed unknown limited memory strategy. The learner's goal is\nto maximize its utility without knowing the opponent's utility function. The\ninteraction is over $T$ rounds with no episode or discounting which leads us to\nmeasure the learner's performance by average reward regret. In this\napplication, our algorithm enjoys an opponent-complexity-dependent regret in\n$\\tilde O(M(\\mathsf{sp}(h^*) B^{m^*} A^{m^*+1})^{\\frac{3}{2}} \\sqrt{T})$, where\n$m^*\\le M$ is the unknown memory limit of the opponent, $\\mathsf{sp}(h^*)$ is\nthe unknown span of optimal bias induced by the opponent, and $A$ and $B$ are\nthe number of actions for the learner and opponent respectively. We also show\nthat the exponential dependency on $m^*$ is inevitable by proving a lower bound\non the learner's regret."
    },
    {
      "id": "2411.06068v1",
      "title": "Zyda-2: a 5 Trillion Token High-Quality Dataset",
      "summary": "In this technical report, we present Zyda-2: a five trillion token dataset\nfor language model pretraining. Zyda-2 was used to train our Zamba2 series of\nmodels which are state-of-the-art for their weight class. We build Zyda-2 by\ncollating high-quality open-source tokens such as FineWeb and DCLM, then\ndistilling them to the highest-quality subset via cross-deduplication and\nmodel-based quality filtering. Zyda-2 is released under a permissive open\nlicense, and is available at https://huggingface.co/datasets/Zyphra/Zyda-2"
    },
    {
      "id": "2411.06066v1",
      "title": "Diversity and Inclusion in AI for Recruitment: Lessons from Industry Workshop",
      "summary": "Artificial Intelligence (AI) systems for online recruitment markets have the\npotential to significantly enhance the efficiency and effectiveness of job\nplacements and even promote fairness or inclusive hiring practices. Neglecting\nDiversity and Inclusion (D&I) in these systems, however, can perpetuate biases,\nleading to unfair hiring practices and decreased workplace diversity, while\nexposing organisations to legal and reputational risks. Despite the\nacknowledged importance of D&I in AI, there is a gap in research on effectively\nimplementing D&I guidelines in real-world recruitment systems. Challenges\ninclude a lack of awareness and framework for operationalising D&I in a\ncost-effective, context-sensitive manner. This study aims to investigate the\npractical application of D&I guidelines in AI-driven online job-seeking\nsystems, specifically exploring how these principles can be operationalised to\ncreate more inclusive recruitment processes. We conducted a co-design workshop\nwith a large multinational recruitment company focusing on two AI-driven\nrecruitment use cases. User stories and personas were applied to evaluate the\nimpacts of AI on diverse stakeholders. Follow-up interviews were conducted to\nassess the workshop's long-term effects on participants' awareness and\napplication of D&I principles. The co-design workshop successfully increased\nparticipants' understanding of D&I in AI. However, translating awareness into\noperational practice posed challenges, particularly in balancing D&I with\nbusiness goals. The results suggest developing tailored D&I guidelines and\nongoing support to ensure the effective adoption of inclusive AI practices."
    },
    {
      "id": "2411.06060v1",
      "title": "Wild Narratives: Exploring the Effects of Animal Chatbots on Empathy and Positive Attitudes toward Animals",
      "summary": "Rises in the number of animal abuse cases are reported around the world.\nWhile chatbots have been effective in influencing their users' perceptions and\nbehaviors, little if any research has hitherto explored the design of chatbots\nthat embody animal identities for the purpose of eliciting empathy toward\nanimals. We therefore conducted a mixed-methods experiment to investigate how\nspecific design cues in such chatbots can shape their users' perceptions of\nboth the chatbots' identities and the type of animal they represent. Our\nfindings indicate that such chatbots can significantly increase empathy,\nimprove attitudes, and promote prosocial behavioral intentions toward animals,\nparticularly when they incorporate emotional verbal expressions and authentic\ndetails of such animals' lives. These results expand our understanding of\nchatbots with non-human identities and highlight their potential for use in\nconservation initiatives, suggesting a promising avenue whereby technology\ncould foster a more informed and empathetic society."
    },
    {
      "id": "2411.06056v1",
      "title": "Learning Mixtures of Experts with EM",
      "summary": "Mixtures of Experts (MoE) are Machine Learning models that involve\npartitioning the input space, with a separate \"expert\" model trained on each\npartition. Recently, MoE have become popular as components in today's large\nlanguage models as a means to reduce training and inference costs. There, the\npartitioning function and the experts are both learnt jointly via gradient\ndescent on the log-likelihood. In this paper we focus on studying the\nefficiency of the Expectation Maximization (EM) algorithm for the training of\nMoE models. We first rigorously analyze EM for the cases of linear or logistic\nexperts, where we show that EM is equivalent to Mirror Descent with unit step\nsize and a Kullback-Leibler Divergence regularizer. This perspective allows us\nto derive new convergence results and identify conditions for local linear\nconvergence based on the signal-to-noise ratio (SNR). Experiments on synthetic\nand (small-scale) real-world data show that EM outperforms the gradient descent\nalgorithm both in terms of convergence rate and the achieved accuracy."
    },
    {
      "id": "2411.06055v1",
      "title": "Linear Spherical Sliced Optimal Transport: A Fast Metric for Comparing Spherical Data",
      "summary": "Efficient comparison of spherical probability distributions becomes important\nin fields such as computer vision, geosciences, and medicine. Sliced optimal\ntransport distances, such as spherical and stereographic spherical sliced\nWasserstein distances, have recently been developed to address this need. These\nmethods reduce the computational burden of optimal transport by slicing\nhyperspheres into one-dimensional projections, i.e., lines or circles.\nConcurrently, linear optimal transport has been proposed to embed distributions\ninto \\( L^2 \\) spaces, where the \\( L^2 \\) distance approximates the optimal\ntransport distance, thereby simplifying comparisons across multiple\ndistributions. In this work, we introduce the Linear Spherical Sliced Optimal\nTransport (LSSOT) framework, which utilizes slicing to embed spherical\ndistributions into \\( L^2 \\) spaces while preserving their intrinsic geometry,\noffering a computationally efficient metric for spherical probability measures.\nWe establish the metricity of LSSOT and demonstrate its superior computational\nefficiency in applications such as cortical surface registration, 3D point\ncloud interpolation via gradient flow, and shape embedding. Our results\ndemonstrate the significant computational benefits and high accuracy of LSSOT\nin these applications."
    },
    {
      "id": "2411.07814v1",
      "title": "Community Research Earth Digital Intelligence Twin (CREDIT)",
      "summary": "Recent advancements in artificial intelligence (AI) for numerical weather\nprediction (NWP) have significantly transformed atmospheric modeling. AI NWP\nmodels outperform traditional physics-based systems, such as the Integrated\nForecast System (IFS), across several global metrics while requiring fewer\ncomputational resources. However, existing AI NWP models face limitations\nrelated to training datasets and timestep choices, often resulting in artifacts\nthat reduce model performance. To address these challenges, we introduce the\nCommunity Research Earth Digital Intelligence Twin (CREDIT) framework,\ndeveloped at NSF NCAR. CREDIT provides a flexible, scalable, and user-friendly\nplatform for training and deploying AI-based atmospheric models on\nhigh-performance computing systems. It offers an end-to-end pipeline for data\npreprocessing, model training, and evaluation, democratizing access to advanced\nAI NWP capabilities. We demonstrate CREDIT's potential through WXFormer, a\nnovel deterministic vision transformer designed to predict atmospheric states\nautoregressively, addressing common AI NWP issues like compounding error growth\nwith techniques such as spectral normalization, padding, and multi-step\ntraining. Additionally, to illustrate CREDIT's flexibility and state-of-the-art\nmodel comparisons, we train the FUXI architecture within this framework. Our\nfindings show that both FUXI and WXFormer, trained on six-hourly ERA5 hybrid\nsigma-pressure levels, generally outperform IFS HRES in 10-day forecasts,\noffering potential improvements in efficiency and forecast accuracy. CREDIT's\nmodular design enables researchers to explore various models, datasets, and\ntraining configurations, fostering innovation within the scientific community."
    },
    {
      "id": "2411.06048v1",
      "title": "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models",
      "summary": "Large Multimodal Models (LMMs) have achieved strong performance across a\nrange of vision and language tasks. However, their spatial reasoning\ncapabilities are under-investigated. In this paper, we construct a novel VQA\ndataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and\nreasoning capabilities. Our analyses on object-relationship and multi-hop\nreasoning reveal several important findings. Firstly, bounding boxes and scene\ngraphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.\nSecondly, LMMs struggle more with questions posed from the human perspective\nthan the camera perspective about the image. Thirdly, chain of thought (CoT)\nprompting does not improve model performance on complex multi-hop questions\ninvolving spatial relations. % Moreover, spatial reasoning steps are much less\naccurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis\non GQA-spatial reveals that LMMs are much stronger at basic object detection\nthan complex spatial reasoning. We believe our benchmark dataset and in-depth\nanalyses can spark further research on LMMs spatial reasoning. Spatial-MM\nbenchmark is available at: https://github.com/FatemehShiri/Spatial-MM"
    },
    {
      "id": "2411.06046v1",
      "title": "Personalized News Recommendation System via LLM Embedding and Co-Occurrence Patterns",
      "summary": "In the past two years, large language models (LLMs) have achieved rapid\ndevelopment and demonstrated remarkable emerging capabilities. Concurrently,\nwith powerful semantic understanding and reasoning capabilities, LLMs have\nsignificantly empowered the rapid advancement of the recommendation system\nfield. Specifically, in news recommendation (NR), systems must comprehend and\nprocess a vast amount of clicked news text to infer the probability of\ncandidate news clicks. This requirement exceeds the capabilities of traditional\nNR models but aligns well with the strengths of LLMs. In this paper, we propose\na novel NR algorithm to reshape the news model via LLM Embedding and\nCo-Occurrence Pattern (LECOP). On one hand, we fintuned LLM by contrastive\nlearning using large-scale datasets to encode news, which can fully explore the\nsemantic information of news to thoroughly identify user preferences. On the\nother hand, we explored multiple co-occurrence patterns to mine collaborative\ninformation. Those patterns include news ID co-occurrence, Item-Item keywords\nco-occurrence and Intra-Item keywords co-occurrence. The keywords mentioned\nabove are all generated by LLM. As far as we know, this is the first time that\nconstructing such detailed Co-Occurrence Patterns via LLM to capture\ncollaboration. Extensive experiments demonstrate the superior performance of\nour proposed novel method"
    },
    {
      "id": "2411.06042v1",
      "title": "Personalized Hierarchical Split Federated Learning in Wireless Networks",
      "summary": "Extreme resource constraints make large-scale machine learning (ML) with\ndistributed clients challenging in wireless networks. On the one hand,\nlarge-scale ML requires massive information exchange between clients and\nserver(s). On the other hand, these clients have limited battery and\ncomputation powers that are often dedicated to operational computations. Split\nfederated learning (SFL) is emerging as a potential solution to mitigate these\nchallenges, by splitting the ML model into client-side and server-side model\nblocks, where only the client-side block is trained on the client device.\nHowever, practical applications require personalized models that are suitable\nfor the client's personal task. Motivated by this, we propose a personalized\nhierarchical split federated learning (PHSFL) algorithm that is specially\ndesigned to achieve better personalization performance. More specially, owing\nto the fact that regardless of the severity of the statistical data\ndistributions across the clients, many of the features have similar attributes,\nwe only train the body part of the federated learning (FL) model while keeping\nthe (randomly initialized) classifier frozen during the training phase. We\nfirst perform extensive theoretical analysis to understand the impact of model\nsplitting and hierarchical model aggregations on the global model. Once the\nglobal model is trained, we fine-tune each client classifier to obtain the\npersonalized models. Our empirical findings suggest that while the globally\ntrained model with the untrained classifier performs quite similarly to other\nexisting solutions, the fine-tuned models show significantly improved\npersonalized performance."
    },
    {
      "id": "2411.06041v1",
      "title": "PointCG: Self-supervised Point Cloud Learning via Joint Completion and Generation",
      "summary": "The core of self-supervised point cloud learning lies in setting up\nappropriate pretext tasks, to construct a pre-training framework that enables\nthe encoder to perceive 3D objects effectively. In this paper, we integrate two\nprevalent methods, masked point modeling (MPM) and 3D-to-2D generation, as\npretext tasks within a pre-training framework. We leverage the spatial\nawareness and precise supervision offered by these two methods to address their\nrespective limitations: ambiguous supervision signals and insensitivity to\ngeometric information. Specifically, the proposed framework, abbreviated as\nPointCG, consists of a Hidden Point Completion (HPC) module and an\nArbitrary-view Image Generation (AIG) module. We first capture visible points\nfrom arbitrary views as inputs by removing hidden points. Then, HPC extracts\nrepresentations of the inputs with an encoder and completes the entire shape\nwith a decoder, while AIG is used to generate rendered images based on the\nvisible points' representations. Extensive experiments demonstrate the\nsuperiority of the proposed method over the baselines in various downstream\ntasks. Our code will be made available upon acceptance."
    },
    {
      "id": "2411.06040v1",
      "title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
      "summary": "Improving generalization and achieving highly predictive, robust machine\nlearning models necessitates learning the underlying causal structure of the\nvariables of interest. A prominent and effective method for this is learning\ninvariant predictors across multiple environments. In this work, we introduce a\nsimple yet powerful approach, CGLearn, which relies on the agreement of\ngradients across various environments. This agreement serves as a powerful\nindication of reliable features, while disagreement suggests less reliability\ndue to potential differences in underlying causal mechanisms. Our proposed\nmethod demonstrates superior performance compared to state-of-the-art methods\nin both linear and nonlinear settings across various regression and\nclassification tasks. CGLearn shows robust applicability even in the absence of\nseparate environments by exploiting invariance across different subsamples of\nobservational data. Comprehensive experiments on both synthetic and real-world\ndatasets highlight its effectiveness in diverse scenarios. Our findings\nunderscore the importance of leveraging gradient agreement for learning causal\ninvariance, providing a significant step forward in the field of robust machine\nlearning. The source code of the linear and nonlinear implementation of CGLearn\nis open-source and available at: https://github.com/hasanjawad001/CGLearn."
    },
    {
      "id": "2411.06037v1",
      "title": "Sufficient Context: A New Lens on Retrieval Augmented Generation Systems",
      "summary": "Augmenting LLMs with context leads to improved performance across many\napplications. Despite much research on Retrieval Augmented Generation (RAG)\nsystems, an open question is whether errors arise because LLMs fail to utilize\nthe context from retrieval or the context itself is insufficient to answer the\nquery. To shed light on this, we develop a new notion of sufficient context,\nalong with a way to classify instances that have enough information to answer\nthe query. We then use sufficient context to analyze several models and\ndatasets. By stratifying errors based on context sufficiency, we find that\nproprietary LLMs (Gemini, GPT, Claude) excel at answering queries when the\ncontext is sufficient, but often output incorrect answers instead of abstaining\nwhen the context is not. On the other hand, open-source LLMs (Llama, Mistral,\nGemma) hallucinate or abstain often, even with sufficient context. We further\ncategorize cases when the context is useful, and improves accuracy, even though\nit does not fully answer the query and the model errs without the context.\nBuilding on our findings, we explore ways to reduce hallucinations in RAG\nsystems, including a new selective generation method that leverages sufficient\ncontext information for guided abstention. Our method improves the fraction of\ncorrect answers among times where the model responds by 2-10% for Gemini, GPT,\nand Gemma."
    },
    {
      "id": "2411.06034v1",
      "title": "CROPS: A Deployable Crop Management System Over All Possible State Availabilities",
      "summary": "Exploring the optimal management strategy for nitrogen and irrigation has a\nsignificant impact on crop yield, economic profit, and the environment. To\ntackle this optimization challenge, this paper introduces a deployable\n\\textbf{CR}op Management system \\textbf{O}ver all \\textbf{P}ossible\n\\textbf{S}tate availabilities (CROPS). CROPS employs a language model (LM) as a\nreinforcement learning (RL) agent to explore optimal management strategies\nwithin the Decision Support System for Agrotechnology Transfer (DSSAT) crop\nsimulations. A distinguishing feature of this system is that the states used\nfor decision-making are partially observed through random masking.\nConsequently, the RL agent is tasked with two primary objectives: optimizing\nmanagement policies and inferring masked states. This approach significantly\nenhances the RL agent's robustness and adaptability across various real-world\nagricultural scenarios. Extensive experiments on maize crops in Florida, USA,\nand Zaragoza, Spain, validate the effectiveness of CROPS. Not only did CROPS\nachieve State-of-the-Art (SOTA) results across various evaluation metrics such\nas production, profit, and sustainability, but the trained management policies\nare also immediately deployable in over of ten millions of real-world contexts.\nFurthermore, the pre-trained policies possess a noise resilience property,\nwhich enables them to minimize potential sensor biases, ensuring robustness and\ngeneralizability. Finally, unlike previous methods, the strength of CROPS lies\nin its unified and elegant structure, which eliminates the need for pre-defined\nstates or multi-stage training. These advancements highlight the potential of\nCROPS in revolutionizing agricultural practices."
    },
    {
      "id": "2411.06032v1",
      "title": "LLM-GLOBE: A Benchmark Evaluating the Cultural Values Embedded in LLM Output",
      "summary": "Immense effort has been dedicated to minimizing the presence of harmful or\nbiased generative content and better aligning AI output to human intention;\nhowever, research investigating the cultural values of LLMs is still in very\nearly stages. Cultural values underpin how societies operate, providing\nprofound insights into the norms, priorities, and decision making of their\nmembers. In recognition of this need for further research, we draw upon\ncultural psychology theory and the empirically-validated GLOBE framework to\npropose the LLM-GLOBE benchmark for evaluating the cultural value systems of\nLLMs, and we then leverage the benchmark to compare the values of Chinese and\nUS LLMs. Our methodology includes a novel \"LLMs-as-a-Jury\" pipeline which\nautomates the evaluation of open-ended content to enable large-scale analysis\nat a conceptual level. Results clarify similarities and differences that exist\nbetween Eastern and Western cultural value systems and suggest that\nopen-generation tasks represent a more promising direction for evaluation of\ncultural values. We interpret the implications of this research for subsequent\nmodel development, evaluation, and deployment efforts as they relate to LLMs,\nAI cultural alignment more broadly, and the influence of AI cultural value\nsystems on human-AI collaboration outcomes."
    },
    {
      "id": "2411.06022v1",
      "title": "Improved intent classification based on context information using a windows-based approach",
      "summary": "Conversational systems have a Natural Language Understanding (NLU) module. In\nthis module, there is a task known as an intent classification that aims at\nidentifying what a user is attempting to achieve from an utterance. Previous\nworks use only the current utterance to predict the intent of a given query and\nthey do not consider the role of the context (one or a few previous utterances)\nin the dialog flow for this task. In this work, we propose several approaches\nto investigate the role of contextual information for the intent classification\ntask. Each approach is used to carry out a concatenation between the dialogue\nhistory and the current utterance. Our intent classification method is based on\na convolutional neural network that obtains effective vector representations\nfrom BERT to perform accurate intent classification using an approach\nwindow-based. Our experiments were carried out on a real-world Brazilian\nPortuguese corpus with dialog flows provided by Wavy global company. Our\nresults achieved substantial improvements over the baseline, isolated\nutterances (without context), in three approaches using the user's utterance\nand system's response from previous messages as dialogue context."
    },
    {
      "id": "2411.06020v1",
      "title": "Parallel Multi-path Feed Forward Neural Networks (PMFFNN) for Long Columnar Datasets: A Novel Approach to Complexity Reduction",
      "summary": "Traditional Feed-Forward Neural Networks (FFNN) and one-dimensional\nConvolutional Neural Networks (1D CNN) often encounter difficulties when\ndealing with long, columnar datasets that contain numerous features. The\nchallenge arises from two primary factors: the large volume of data and the\npotential absence of meaningful relationships between features. In conventional\ntraining, large datasets can overwhelm the model, causing significant portions\nof the input to remain underutilized. As a result, the model may fail to\ncapture the critical information necessary for effective learning, which leads\nto diminished performance.\n  To overcome these limitations, we introduce a novel architecture called\nParallel Multi-path Feed Forward Neural Networks (PMFFNN). Our approach\nleverages multiple parallel pathways to process distinct subsets of columns\nfrom the input dataset. By doing so, the architecture ensures that each subset\nof features receives focused attention, which is often neglected in traditional\nmodels. This approach maximizes the utilization of feature diversity, ensuring\nthat no critical data sections are overlooked during training.\n  Our architecture offers two key advantages. First, it allows for more\neffective handling of long, columnar data by distributing the learning task\nacross parallel paths. Second, it reduces the complexity of the model by\nnarrowing the feature scope in each path, which leads to faster training times\nand improved resource efficiency. The empirical results indicate that PMFFNN\noutperforms traditional FFNNs and 1D CNNs, providing an optimized solution for\nmanaging large-scale data."
    },
    {
      "id": "2411.06018v1",
      "title": "A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization",
      "summary": "Large language models (LLMs), with demonstrated reasoning abilities across\nmultiple domains, are largely underexplored for time-series reasoning (TsR),\nwhich is ubiquitous in the real world. In this work, we propose TimerBed, the\nfirst comprehensive testbed for evaluating LLMs' TsR performance. Specifically,\nTimerBed includes stratified reasoning patterns with real-world tasks,\ncomprehensive combinations of LLMs and reasoning strategies, and various\nsupervised models as comparison anchors. We perform extensive experiments with\nTimerBed, test multiple current beliefs, and verify the initial failures of\nLLMs in TsR, evidenced by the ineffectiveness of zero shot (ZST) and\nperformance degradation of few shot in-context learning (ICL). Further, we\nidentify one possible root cause: the numerical modeling of data. To address\nthis, we propose a prompt-based solution VL-Time, using visualization-modeled\ndata and language-guided reasoning. Experimental results demonstrate that\nVl-Time enables multimodal LLMs to be non-trivial ZST and powerful ICL\nreasoners for time series, achieving about 140% average performance improvement\nand 99% average token costs reduction."
    },
    {
      "id": "2411.06009v1",
      "title": "A Comprehensive Guide to Enhancing Antibiotic Discovery Using Machine Learning Derived Bio-computation",
      "summary": "Traditional drug discovery is a long, expensive, and complex process.\nAdvances in Artificial Intelligence (AI) and Machine Learning (ML) are\nbeginning to change this narrative. Here, we provide a comprehensive overview\nof different AI and ML tools that can be used to streamline and accelerate the\ndrug discovery process. By using data sets to train ML algorithms, it is\npossible to discover drugs or drug-like compounds relatively quickly, and\nefficiently. Additionally, we address limitations in AI-based drug discovery\nand development, including the scarcity of high-quality data to train AI models\nand ethical considerations. The growing impact of AI on the pharmaceutical\nindustry is also highlighted. Finally, we discuss how AI and ML can expedite\nthe discovery of new antibiotics to combat the problem of worldwide\nantimicrobial resistance (AMR)."
    },
    {
      "id": "2411.06008v2",
      "title": "The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses",
      "summary": "This study explores how the Large Language Models (LLMs) adjust linguistic\nfeatures to create personalized persuasive outputs. While research showed that\nLLMs personalize outputs, a gap remains in understanding the linguistic\nfeatures of their persuasive capabilities. We identified 13 linguistic features\ncrucial for influencing personalities across different levels of the Big Five\nmodel of personality. We analyzed how prompts with personality trait\ninformation influenced the output of 19 LLMs across five model families. The\nfindings show that models use more anxiety-related words for neuroticism,\nincrease achievement-related words for conscientiousness, and employ fewer\ncognitive processes words for openness to experience. Some model families excel\nat adapting language for openness to experience, others for conscientiousness,\nwhile only one model adapts language for neuroticism. Our findings show how\nLLMs tailor responses based on personality cues in prompts, indicating their\npotential to create persuasive content affecting the mind and well-being of the\nrecipients."
    },
    {
      "id": "2411.05998v1",
      "title": "Filling in Missing FX Implied Volatilities with Uncertainties: Improving VAE-Based Volatility Imputation",
      "summary": "Missing data is a common problem in finance and often requires methods to\nfill in the gaps, or in other words, imputation. In this work, we focused on\nthe imputation of missing implied volatilities for FX options. Prior work has\nused variational autoencoders (VAEs), a neural network-based approach, to solve\nthis problem; however, using stronger classical baselines such as Heston with\njumps can significantly outperform their results. We show that simple\nmodifications to the architecture of the VAE lead to significant imputation\nperformance improvements (e.g., in low missingness regimes, nearly cutting the\nerror by half), removing the necessity of using $\\beta$-VAEs. Further, we\nmodify the VAE imputation algorithm in order to better handle the uncertainty\nin data, as well as to obtain accurate uncertainty estimates around imputed\nvalues."
    },
    {
      "id": "2411.05991v1",
      "title": "GUIDEQ: Framework for Guided Questioning for progressive informational collection and classification",
      "summary": "Question Answering (QA) is an important part of tasks like text\nclassification through information gathering. These are finding increasing use\nin sectors like healthcare, customer support, legal services, etc., to collect\nand classify responses into actionable categories. LLMs, although can support\nQA systems, they face a significant challenge of insufficient or missing\ninformation for classification. Although LLMs excel in reasoning, the models\nrely on their parametric knowledge to answer. However, questioning the user\nrequires domain-specific information aiding to collect accurate information.\nOur work, GUIDEQ, presents a novel framework for asking guided questions to\nfurther progress a partial information. We leverage the explainability derived\nfrom the classifier model for along with LLMs for asking guided questions to\nfurther enhance the information. This further information helps in more\naccurate classification of a text. GUIDEQ derives the most significant\nkey-words representative of a label using occlusions. We develop GUIDEQ's\nprompting strategy for guided questions based on the top-3 classifier label\noutputs and the significant words, to seek specific and relevant information,\nand classify in a targeted manner. Through our experimental results, we\ndemonstrate that GUIDEQ outperforms other LLM-based baselines, yielding\nimproved F1-Score through the accurate collection of relevant further\ninformation. We perform various analytical studies and also report better\nquestion quality compared to our method."
    },
    {
      "id": "2411.05990v2",
      "title": "Game-theoretic LLM: Agent Workflow for Negotiation Games",
      "summary": "This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}."
    },
    {
      "id": "2411.05986v1",
      "title": "Fine-Grained Reward Optimization for Machine Translation using Error Severity Mappings",
      "summary": "Reinforcement learning (RL) has been proven to be an effective and robust\nmethod for training neural machine translation systems, especially when paired\nwith powerful reward models that accurately assess translation quality.\nHowever, most research has focused on RL methods that use sentence-level\nfeedback, which leads to inefficient learning signals due to the reward\nsparsity problem -- the model receives a single score for the entire sentence.\nTo address this, we introduce a novel approach that leverages fine-grained\ntoken-level reward mechanisms with RL methods. We use xCOMET, a\nstate-of-the-art quality estimation system as our token-level reward model.\nxCOMET provides detailed feedback by predicting fine-grained error spans and\ntheir severity given source-translation pairs. We conduct experiments on small\nand large translation datasets to compare the impact of sentence-level versus\nfine-grained reward signals on translation quality. Our results show that\ntraining with token-level rewards improves translation quality across language\npairs over baselines according to automatic and human evaluation. Furthermore,\ntoken-level reward optimization also improves training stability, evidenced by\na steady increase in mean rewards over training epochs."
    },
    {
      "id": "2411.05983v1",
      "title": "Longitudinal Ensemble Integration for sequential classification with multimodal data",
      "summary": "Effectively modeling multimodal longitudinal data is a pressing need in\nvarious application areas, especially biomedicine. Despite this, few approaches\nexist in the literature for this problem, with most not adequately taking into\naccount the multimodality of the data. In this study, we developed multiple\nconfigurations of a novel multimodal and longitudinal learning framework,\nLongitudinal Ensemble Integration (LEI), for sequential classification. We\nevaluated LEI's performance, and compared it against existing approaches, for\nthe early detection of dementia, which is among the most studied multimodal\nsequential classification tasks. LEI outperformed these approaches due to its\nuse of intermediate base predictions arising from the individual data\nmodalities, which enabled their better integration over time. LEI's design also\nenabled the identification of features that were consistently important across\ntime for the effective prediction of dementia-related diagnoses. Overall, our\nwork demonstrates the potential of LEI for sequential classification from\nlongitudinal multimodal data."
    },
    {
      "id": "2411.05982v1",
      "title": "Unmasking the Shadows: Pinpoint the Implementations of Anti-Dynamic Analysis Techniques in Malware Using LLM",
      "summary": "Sandboxes and other dynamic analysis processes are prevalent in malware\ndetection systems nowadays to enhance the capability of detecting 0-day\nmalware. Therefore, techniques of anti-dynamic analysis (TADA) are prevalent in\nmodern malware samples, and sandboxes can suffer from false negatives and\nanalysis failures when analyzing the samples with TADAs. In such cases, human\nreverse engineers will get involved in conducting dynamic analysis manually\n(i.e., debugging, patching), which in turn also gets obstructed by TADAs. In\nthis work, we propose a Large Language Model (LLM) based workflow that can\npinpoint the location of the TADA implementation in the code, to help reverse\nengineers place breakpoints used in debugging. Our evaluation shows that we\nsuccessfully identified the locations of 87.80% known TADA implementations\nadopted from public repositories. In addition, we successfully pinpoint the\nlocations of TADAs in 4 well-known malware samples that are documented in\nonline malware analysis blogs."
    },
    {
      "id": "2411.05980v1",
      "title": "FactLens: Benchmarking Fine-Grained Fact Verification",
      "summary": "Large Language Models (LLMs) have shown impressive capability in language\ngeneration and understanding, but their tendency to hallucinate and produce\nfactually incorrect information remains a key limitation. To verify\nLLM-generated contents and claims from other sources, traditional verification\napproaches often rely on holistic models that assign a single factuality label\nto complex claims, potentially obscuring nuanced errors. In this paper, we\nadvocate for a shift toward fine-grained verification, where complex claims are\nbroken down into smaller sub-claims for individual verification, allowing for\nmore precise identification of inaccuracies, improved transparency, and reduced\nambiguity in evidence retrieval. However, generating sub-claims poses\nchallenges, such as maintaining context and ensuring semantic equivalence with\nrespect to the original claim. We introduce FactLens, a benchmark for\nevaluating fine-grained fact verification, with metrics and automated\nevaluators of sub-claim quality. The benchmark data is manually curated to\nensure high-quality ground truth. Our results show alignment between automated\nFactLens evaluators and human judgments, and we discuss the impact of sub-claim\ncharacteristics on the overall verification performance."
    },
    {
      "id": "2411.05979v1",
      "title": "Variance-Aware Linear UCB with Deep Representation for Neural Contextual Bandits",
      "summary": "By leveraging the representation power of deep neural networks, neural upper\nconfidence bound (UCB) algorithms have shown success in contextual bandits. To\nfurther balance the exploration and exploitation, we propose\nNeural-$\\sigma^2$-LinearUCB, a variance-aware algorithm that utilizes\n$\\sigma^2_t$, i.e., an upper bound of the reward noise variance at round $t$,\nto enhance the uncertainty quantification quality of the UCB, resulting in a\nregret performance improvement. We provide an oracle version for our algorithm\ncharacterized by an oracle variance upper bound $\\sigma^2_t$ and a practical\nversion with a novel estimation for this variance bound. Theoretically, we\nprovide rigorous regret analysis for both versions and prove that our oracle\nalgorithm achieves a better regret guarantee than other neural-UCB algorithms\nin the neural contextual bandits setting. Empirically, our practical method\nenjoys a similar computational efficiency, while outperforming state-of-the-art\ntechniques by having a better calibration and lower regret across multiple\nstandard settings, including on the synthetic, UCI, MNIST, and CIFAR-10\ndatasets."
    },
    {
      "id": "2411.05978v1",
      "title": "The Empirical Impact of Data Sanitization on Language Models",
      "summary": "Data sanitization in the context of language modeling involves identifying\nsensitive content, such as personally identifiable information (PII), and\nredacting them from a dataset corpus. It is a common practice used in natural\nlanguage processing (NLP) to maintain privacy. Nevertheless, the impact of data\nsanitization on the language understanding capability of a language model\nremains less studied. This paper empirically analyzes the effects of data\nsanitization across several benchmark language-modeling tasks including\ncomprehension question answering (Q&A), entailment, sentiment analysis, and\ntext classification. Our experiments cover a wide spectrum comprising\nfinetuning small-scale language models, to prompting large language models\n(LLMs), on both original and sanitized datasets, and comparing their\nperformance across the tasks. Interestingly, our results suggest that for some\ntasks such as sentiment analysis or entailment, the impact of redaction is\nquite low, typically around 1-5%, while for tasks such as comprehension Q&A\nthere is a big drop of >25% in performance observed in redacted queries as\ncompared to the original. For tasks that have a higher impact, we perform a\ndeeper dive to inspect the presence of task-critical entities. Finally, we\ninvestigate correlation between performance and number of redacted entities,\nand also suggest a strategy to repair an already redacted dataset by means of\ncontent-based subsampling. Additional details are available at\nhttps://sites.google.com/view/datasan."
    },
    {
      "id": "2411.07264v1",
      "title": "Multi-Document Financial Question Answering using LLMs",
      "summary": "We propose two new methods for multi-document financial question answering.\nFirst, a method that uses semantic tagging, and then, queries the index to get\nthe context (RAG_SEM). And second, a Knowledge Graph (KG_RAG) based method that\nuses semantic tagging, and, retrieves knowledge graph triples from a graph\ndatabase, as context. KG_RAG uses knowledge graphs constructed using a small\nmodel that is fine-tuned using knowledge distillation using a large teacher\nmodel. The data consists of 18 10K reports of Apple, Microsoft, Alphabet,\nNVIDIA, Amazon and Tesla for the years 2021, 2022 and 2023. The list of\nquestions in the data consists of 111 complex questions including many esoteric\nquestions that are difficult to answer and the answers are not completely\nobvious. As evaluation metrics, we use overall scores as well as segmented\nscores for measurement including the faithfulness, relevance, correctness,\nsimilarity, an LLM based overall score and the rouge scores as well as a\nsimilarity of embeddings. We find that both methods outperform plain RAG\nsignificantly. KG_RAG outperforms RAG_SEM in four out of nine metrics."
    },
    {
      "id": "2411.05969v1",
      "title": "Toward Transdisciplinary Approaches to Audio Deepfake Discernment",
      "summary": "This perspective calls for scholars across disciplines to address the\nchallenge of audio deepfake detection and discernment through an\ninterdisciplinary lens across Artificial Intelligence methods and linguistics.\nWith an avalanche of tools for the generation of realistic-sounding fake speech\non one side, the detection of deepfakes is lagging on the other. Particularly\nhindering audio deepfake detection is the fact that current AI models lack a\nfull understanding of the inherent variability of language and the complexities\nand uniqueness of human speech. We see the promising potential in recent\ntransdisciplinary work that incorporates linguistic knowledge into AI\napproaches to provide pathways for expert-in-the-loop and to move beyond expert\nagnostic AI-based methods for more robust and comprehensive deepfake detection."
    },
    {
      "id": "2411.05966v1",
      "title": "Energy Efficient Protein Language Models: Leveraging Small Language Models with LoRA for Controllable Protein Generation",
      "summary": "Large language models (LLMs) have demonstrated significant success in natural\nlanguage processing (NLP) tasks and have shown promising results in other\ndomains such as protein sequence generation. However, there remain salient\ndifferences between LLMs used for NLP, which effectively handle multiple tasks\nand are available in small sizes, and protein language models that are often\nspecialized for specific tasks and only exist in larger sizes. In this work, we\nintroduce two small protein language models, based on Llama-3-8B and\nPhi-3-mini, that are capable of both uncontrollable and controllable protein\ngeneration. For the uncontrollable generation task, our best model achieves an\naverage pLDDT score of 69.75, demonstrating robust performance in generating\nviable protein structures. For the controllable generation task, in which the\nmodel generates proteins according to properties specified in the prompt, we\nachieve a remarkable average TM-Score of 0.84, indicating high structural\nsimilarity to target proteins. We chose 10 properties, including six classes of\nenzymes, to extend the capabilities of prior protein language models. Our\napproach utilizes the Low-Rank Adaptor (LoRA) technique, reducing trainable\nparameters to just 4% of the original model size, lowering computational\nrequirements. By using a subset of the UniRef50 dataset and small models, we\nreduced the overall training time by 70% without compromising performance.\nNotably, Phi-3-mini reduced trainable parameters by 60%, decreasing training\ncost by 30% compared to Llama 3. Consequently, Phi-3 achieved a comparable\nTM-Score of 0.81, demonstrating that smaller models can match the performance\nof larger ones, like Llama 3. We also demonstrate the deployment of our models\non the energy efficient ET-SoC-1 chip, significantly improving the TPS/W by a\nfactor of 3."
    },
    {
      "id": "2411.05963v1",
      "title": "Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI",
      "summary": "Atrial fibrillation (AF), the most common cardiac arrhythmia, is associated\nwith heart failure and stroke. Accurate segmentation of the left atrium (LA) in\n3D late gadolinium-enhanced (LGE) MRI is helpful for evaluating AF, as fibrotic\nremodeling in the LA myocardium contributes to arrhythmia and serves as a key\ndeterminant of therapeutic strategies. However, manual LA segmentation is\nlabor-intensive and challenging. Recent foundational deep learning models, such\nas the Segment Anything Model (SAM), pre-trained on diverse datasets, have\ndemonstrated promise in generic segmentation tasks. MedSAM, a fine-tuned\nversion of SAM for medical applications, enables efficient, zero-shot\nsegmentation without domain-specific training. Despite the potential of MedSAM\nmodel, it has not yet been evaluated for the complex task of LA segmentation in\n3D LGE-MRI. This study aims to (1) evaluate the performance of MedSAM in\nautomating LA segmentation, (2) compare the performance of the MedSAM2 model,\nwhich uses a single prompt with automated tracking, with the MedSAM1 model,\nwhich requires separate prompt for each slice, and (3) analyze the performance\nof MedSAM1 in terms of Dice score(i.e., segmentation accuracy) by varying the\nsize and location of the box prompt."
    },
    {
      "id": "2411.05961v1",
      "title": "Aligned Vector Quantization for Edge-Cloud Collabrative Vision-Language Models",
      "summary": "Vision Language Models (VLMs) are central to Visual Question Answering (VQA)\nsystems and are typically deployed in the cloud due to their high computational\ndemands. However, this cloud-only approach underutilizes edge computational\nresources and requires significant bandwidth for transmitting raw images. In\nthis paper, we introduce an edge-cloud collaborative VQA system, called\nLLaVA-AlignedVQ, which features a novel Aligned Vector Quantization algorithm\n(AlignedVQ) that efficiently compress intermediate features without\ncompromising accuracy to support partitioned execution. Our experiments\ndemonstrate that LLaVA-AlignedVQ achieves approximately 1365x compression rate\nof intermediate features, reducing data transmission overhead by 96.8% compared\nto transmitting JPEG90-compressed images to the cloud. LLaVA-AlignedVQ achieves\nan inference speedup of 2-15x while maintaining high accuracy, remaining within\n-2.23% to +1.6% of the original model's accuracy performance across eight VQA\ndatasets, compared to the cloud-only solution."
    },
    {
      "id": "2411.05960v1",
      "title": "A method based on Generative Adversarial Networks for disentangling physical and chemical properties of stars in astronomical spectra",
      "summary": "Data compression techniques focused on information preservation have become\nessential in the modern era of big data. In this work, an encoder-decoder\narchitecture has been designed, where adversarial training, a modification of\nthe traditional autoencoder, is used in the context of astrophysical spectral\nanalysis. The goal of this proposal is to obtain an intermediate representation\nof the astronomical stellar spectra, in which the contribution to the flux of a\nstar due to the most influential physical properties (its surface temperature\nand gravity) disappears and the variance reflects only the effect of the\nchemical composition over the spectrum. A scheme of deep learning is used with\nthe aim of unraveling in the latent space the desired parameters of the rest of\nthe information contained in the data. This work proposes a version of\nadversarial training that makes use of a discriminator per parameter to be\ndisentangled, thus avoiding the exponential combination that occurs in the use\nof a single discriminator, as a result of the discretization of the values to\nbe untangled. To test the effectiveness of the method, synthetic astronomical\ndata are used from the APOGEE and Gaia surveys. In conjunction with the work\npresented, we also provide a disentangling framework (GANDALF) available to the\ncommunity, which allows the replication, visualization, and extension of the\nmethod to domains of any nature."
    },
    {
      "id": "2411.05958v1",
      "title": "Sentiment Analysis of Cyberbullying Data in Social Media",
      "summary": "Social media has become an integral part of modern life, but it has also\nbrought with it the pervasive issue of cyberbullying a serious menace in\ntoday's digital age. Cyberbullying, a form of harassment that occurs on social\nnetworks, has escalated alongside the growth of these platforms. Sentiment\nanalysis holds significant potential not only for detecting bullying phrases\nbut also for identifying victims who are at high risk of harm, whether to\nthemselves or others. Our work focuses on leveraging deep learning and natural\nlanguage understanding techniques to detect traces of bullying in social media\nposts. We developed a Recurrent Neural Network with Long Short-Term Memory\n(LSTM) cells, using different embeddings. One approach utilizes BERT\nembeddings, while the other replaces the embeddings layer with the recently\nreleased embeddings API from OpenAI. We conducted a performance comparison\nbetween these two approaches to evaluate their effectiveness in sentiment\nanalysis of Formspring Cyberbullying data. Our Code is Available at\nhttps://github.com/ppujari/xcs224u"
    },
    {
      "id": "2411.05952v1",
      "title": "Tackling extreme urban heat: a machine learning approach to assess the impacts of climate change and the efficacy of climate adaptation strategies in urban microclimates",
      "summary": "As urbanization and climate change progress, urban heat becomes a priority\nfor climate adaptation efforts. High temperatures concentrated in urban heat\ncan drive increased risk of heat-related death and illness as well as increased\nenergy demand for cooling. However, estimating the effects of urban heat is an\nongoing field of research typically burdened by an imprecise description of the\nbuilt environment, significant computational cost, and a lack of\nhigh-resolution estimates of the impacts of climate change. Here, we present\nopen-source, computationally efficient machine learning methods that can\nimprove the accuracy of urban temperature estimates when compared to historical\nreanalysis data. These models are applied to residential buildings in Los\nAngeles, and we compare the energy benefits of heat mitigation strategies to\nthe impacts of climate change. We find that cooling demand is likely to\nincrease substantially through midcentury, but engineered high-albedo surfaces\ncould lessen this increase by more than 50%. The corresponding increase in\nheating demand complicates this narrative, but total annual energy use from\ncombined heating and cooling with electric heat pumps in the Los Angeles urban\nclimate is shown to benefit from the engineered cooling strategies under both\ncurrent and future climates."
    },
    {
      "id": "2411.05945v1",
      "title": "NeKo: Toward Post Recognition Generative Correction Large Language Models with Task-Oriented Experts",
      "summary": "Construction of a general-purpose post-recognition error corrector poses a\ncrucial question: how can we most effectively train a model on a large mixture\nof domain datasets? The answer would lie in learning dataset-specific features\nand digesting their knowledge in a single model. Previous methods achieve this\nby having separate correction language models, resulting in a significant\nincrease in parameters. In this work, we present Mixture-of-Experts as a\nsolution, highlighting that MoEs are much more than a scalability tool. We\npropose a Multi-Task Correction MoE, where we train the experts to become an\n``expert'' of speech-to-text, language-to-text and vision-to-text datasets by\nlearning to route each dataset's tokens to its mapped expert. Experiments on\nthe Open ASR Leaderboard show that we explore a new state-of-the-art\nperformance by achieving an average relative $5.0$% WER reduction and\nsubstantial improvements in BLEU scores for speech and translation tasks. On\nzero-shot evaluation, NeKo outperforms GPT-3.5 and Claude-Opus with $15.5$% to\n$27.6$% relative WER reduction in the Hyporadise benchmark. NeKo performs\ncompetitively on grammar and post-OCR correction as a multi-task model."
    },
    {
      "id": "2411.05943v1",
      "title": "Quantifying artificial intelligence through algebraic generalization",
      "summary": "The rapid development of modern artificial intelligence (AI) systems has\ncreated an urgent need for their scientific quantification. While their fluency\nacross a variety of domains is impressive, modern AI systems fall short on\ntests requiring symbolic processing and abstraction - a glaring limitation\ngiven the necessity for interpretable and reliable technology. Despite a surge\nof reasoning benchmarks emerging from the academic community, no comprehensive\nand theoretically-motivated framework exists to quantify reasoning (and more\ngenerally, symbolic ability) in AI systems. Here, we adopt a framework from\ncomputational complexity theory to explicitly quantify symbolic generalization:\nalgebraic circuit complexity. Many symbolic reasoning problems can be recast as\nalgebraic expressions. Thus, algebraic circuit complexity theory - the study of\nalgebraic expressions as circuit models (i.e., directed acyclic graphs) - is a\nnatural framework to study the complexity of symbolic computation. The tools of\nalgebraic circuit complexity enable the study of generalization by defining\nbenchmarks in terms of their complexity-theoretic properties (i.e., the\ndifficulty of a problem). Moreover, algebraic circuits are generic mathematical\nobjects; for a given algebraic circuit, an arbitrarily large number of samples\ncan be generated for a specific circuit, making it an optimal testbed for the\ndata-hungry machine learning algorithms that are used today. Here, we adopt\ntools from algebraic circuit complexity theory, apply it to formalize a science\nof symbolic generalization, and address key theoretical and empirical\nchallenges for its successful application to AI science and its impact on the\nbroader community."
    },
    {
      "id": "2411.05939v1",
      "title": "GCI-ViTAL: Gradual Confidence Improvement with Vision Transformers for Active Learning on Label Noise",
      "summary": "Active learning aims to train accurate classifiers while minimizing labeling\ncosts by strategically selecting informative samples for annotation. This study\nfocuses on image classification tasks, comparing AL methods on CIFAR10,\nCIFAR100, Food101, and the Chest X-ray datasets under varying label noise\nrates. We investigate the impact of model architecture by comparing\nConvolutional Neural Networks (CNNs) and Vision Transformer (ViT)-based models.\nAdditionally, we propose a novel deep active learning algorithm, GCI-ViTAL,\ndesigned to be robust to label noise. GCI-ViTAL utilizes prediction entropy and\nthe Frobenius norm of last-layer attention vectors compared to class-centric\nclean set attention vectors. Our method identifies samples that are both\nuncertain and semantically divergent from typical images in their assigned\nclass. This allows GCI-ViTAL to select informative data points even in the\npresence of label noise while flagging potentially mislabeled candidates. Label\nsmoothing is applied to train a model that is not overly confident about\npotentially noisy labels. We evaluate GCI-ViTAL under varying levels of\nsymmetric label noise and compare it to five other AL strategies. Our results\ndemonstrate that using ViTs leads to significant performance improvements over\nCNNs across all AL strategies, particularly in noisy label settings. We also\nfind that using the semantic information of images as label grounding helps in\ntraining a more robust model under label noise. Notably, we do not perform\nextensive hyperparameter tuning, providing an out-of-the-box comparison that\naddresses the common challenge practitioners face in selecting models and\nactive learning strategies without an exhaustive literature review on training\nand fine-tuning vision models on real-world application data."
    },
    {
      "id": "2411.05937v1",
      "title": "The effect of different feature selection methods on models created with XGBoost",
      "summary": "This study examines the effect that different feature selection methods have\non models created with XGBoost, a popular machine learning algorithm with\nsuperb regularization methods. It shows that three different ways for reducing\nthe dimensionality of features produces no statistically significant change in\nthe prediction accuracy of the model. This suggests that the traditional idea\nof removing the noisy training data to make sure models do not overfit may not\napply to XGBoost. But it may still be viable in order to reduce computational\ncomplexity."
    },
    {
      "id": "2411.05936v1",
      "title": "Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine",
      "summary": "The growth of digital documents presents significant challenges in efficient\nmanagement and knowledge extraction. Traditional methods often struggle with\ncomplex documents, leading to issues such as hallucinations and high latency in\nresponses from Large Language Models (LLMs). ZeroG, an innovative approach,\nsignificantly mitigates these challenges by leveraging knowledge distillation\nand prompt tuning to enhance model performance.\n  ZeroG utilizes a smaller model that replicates the behavior of a larger\nteacher model, ensuring contextually relevant and grounded responses, by\nemploying a black-box distillation approach, it creates a distilled dataset\nwithout relying on intermediate features, optimizing computational efficiency.\nThis method significantly enhances accuracy and reduces response times,\nproviding a balanced solution for modern document management.\n  Incorporating advanced techniques for document ingestion and metadata\nutilization, ZeroG improves the accuracy of question-and-answer systems. The\nintegration of graph databases and robust metadata management further\nstreamlines information retrieval, allowing for precise and context-aware\nresponses. By transforming how organizations interact with complex data, ZeroG\nenhances productivity and user experience, offering a scalable solution for the\ngrowing demands of digital document management."
    },
    {
      "id": "2411.05934v1",
      "title": "Qwen2.5-32B: Leveraging Self-Consistent Tool-Integrated Reasoning for Bengali Mathematical Olympiad Problem Solving",
      "summary": "We present an innovative approach for solving mathematical problems in\nBengali, developed for the DL Sprint 3.0 BUET CSE Fest 2024 Competition. Our\nmethod uses advanced deep learning models, notably the Qwen 2.5 series, with\nimprovements made through prompt engineering, model quantization, and Tool\nIntegrated Reasoning (TIR) to handle complex calculations. Initially, we\nexplored various model architectures, including fine-tuned Mistral and\nquantized Qwen models, refining them with translation techniques,\nRetrieval-Augmented Generation (RAG), and custom dataset curation. Manual\nhyperparameter tuning optimized parameters like temperature and top-p to\nenhance model adaptability and accuracy. Removal of RAG and parameter\nadjustments further improved robustness. Our approach highlights the potential\nof advanced NLP techniques in solving Bengali mathematical problems."
    },
    {
      "id": "2411.05930v1",
      "title": "BERTrend: Neural Topic Modeling for Emerging Trends Detection",
      "summary": "Detecting and tracking emerging trends and weak signals in large, evolving\ntext corpora is vital for applications such as monitoring scientific\nliterature, managing brand reputation, surveilling critical infrastructure and\nmore generally to any kind of text-based event detection. Existing solutions\noften fail to capture the nuanced context or dynamically track evolving\npatterns over time. BERTrend, a novel method, addresses these limitations using\nneural topic modeling in an online setting. It introduces a new metric to\nquantify topic popularity over time by considering both the number of documents\nand update frequency. This metric classifies topics as noise, weak, or strong\nsignals, flagging emerging, rapidly growing topics for further investigation.\nExperimentation on two large real-world datasets demonstrates BERTrend's\nability to accurately detect and track meaningful weak signals while filtering\nout noise, offering a comprehensive solution for monitoring emerging trends in\nlarge-scale, evolving text corpora. The method can also be used for\nretrospective analysis of past events. In addition, the use of Large Language\nModels together with BERTrend offers efficient means for the interpretability\nof trends of events."
    },
    {
      "id": "2411.05928v1",
      "title": "Reducing Distraction in Long-Context Language Models by Focused Learning",
      "summary": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their capacity to process long contexts. However, effectively\nutilizing this long context remains a challenge due to the issue of\ndistraction, where irrelevant information dominates lengthy contexts, causing\nLLMs to lose focus on the most relevant segments. To address this, we propose a\nnovel training method that enhances LLMs' ability to discern relevant\ninformation through a unique combination of retrieval-based data augmentation\nand contrastive learning. Specifically, during fine-tuning with long contexts,\nwe employ a retriever to extract the most relevant segments, serving as\naugmented inputs. We then introduce an auxiliary contrastive learning objective\nto explicitly ensure that outputs from the original context and the retrieved\nsub-context are closely aligned. Extensive experiments on long single-document\nand multi-document QA benchmarks demonstrate the effectiveness of our proposed\nmethod."
    },
    {
      "id": "2411.05927v1",
      "title": "Moving Off-the-Grid: Scene-Grounded Video Representations",
      "summary": "Current vision models typically maintain a fixed correspondence between their\nrepresentation structure and image space. Each layer comprises a set of tokens\narranged \"on-the-grid,\" which biases patches or tokens to encode information at\na specific spatio(-temporal) location. In this work we present Moving\nOff-the-Grid (MooG), a self-supervised video representation model that offers\nan alternative approach, allowing tokens to move \"off-the-grid\" to better\nenable them to represent scene elements consistently, even as they move across\nthe image plane through time. By using a combination of cross-attention and\npositional embeddings we disentangle the representation structure and image\nstructure. We find that a simple self-supervised objective--next frame\nprediction--trained on video data, results in a set of latent tokens which bind\nto specific scene structures and track them as they move. We demonstrate the\nusefulness of MooG's learned representation both qualitatively and\nquantitatively by training readouts on top of the learned representation on a\nvariety of downstream tasks. We show that MooG can provide a strong foundation\nfor different vision tasks when compared to \"on-the-grid\" baselines."
    },
    {
      "id": "2411.05923v1",
      "title": "DNAMite: Interpretable Calibrated Survival Analysis with Discretized Additive Models",
      "summary": "Survival analysis is a classic problem in statistics with important\napplications in healthcare. Most machine learning models for survival analysis\nare black-box models, limiting their use in healthcare settings where\ninterpretability is paramount. More recently, glass-box machine learning models\nhave been introduced for survival analysis, with both strong predictive\nperformance and interpretability. Still, several gaps remain, as no prior\nglass-box survival model can produce calibrated shape functions with enough\nflexibility to capture the complex patterns often found in real data. To fill\nthis gap, we introduce a new glass-box machine learning model for survival\nanalysis called DNAMite. DNAMite uses feature discretization and kernel\nsmoothing in its embedding module, making it possible to learn shape functions\nwith a flexible balance of smoothness and jaggedness. Further, DNAMite produces\ncalibrated shape functions that can be directly interpreted as contributions to\nthe cumulative incidence function. Our experiments show that DNAMite generates\nshape functions closer to true shape functions on synthetic data, while making\npredictions with comparable predictive performance and better calibration than\nprevious glass-box and black-box models."
    },
    {
      "id": "2411.05787v1",
      "title": "Recycled Attention: Efficient inference for long-context language models",
      "summary": "Generating long sequences of tokens given a long-context input imposes a\nheavy computational burden for large language models (LLMs). One of the\ncomputational bottleneck comes from computing attention over a long sequence of\ninput at each generation step. In this paper, we propose Recycled Attention, an\ninference-time method which alternates between full context attention and\nattention over a subset of input tokens. When performing partial attention, we\nrecycle the attention pattern of a previous token that has performed full\nattention and attend only to the top K most attended tokens, reducing the cost\nof data movement and attention computation. Compared to previously proposed\ninference-time acceleration method which attends only to local context or\ntokens with high accumulative attention scores, our approach flexibly chooses\ntokens that are relevant to the current decoding step. We evaluate our methods\non RULER, a suite of tasks designed to comprehensively evaluate long-context\nabilities, and long-context language modeling tasks. Applying our method to\noff-the-shelf LLMs achieves comparable speedup to baselines which only consider\nlocal context while improving the performance by 2x. We further explore two\nideas to improve performance-efficiency trade-offs: (1) dynamically decide when\nto perform recycled or full attention step based on the query similarities and\n(2) continued pre-training the model with Recycled Attention."
    },
    {
      "id": "2411.05783v1",
      "title": "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles",
      "summary": "Deaf and hard-of-hearing (DHH) students face significant barriers in\naccessing science, technology, engineering, and mathematics (STEM) education,\nnotably due to the scarcity of STEM resources in signed languages. To help\naddress this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia\narticles on STEM topics in English, interpreted into over 300 hours of American\nSign Language (ASL). ASL STEM Wiki is the first continuous signing dataset\nfocused on STEM, facilitating the development of AI resources for STEM\neducation in ASL. We identify several use cases of ASL STEM Wiki with\nhuman-centered applications. For example, because this dataset highlights the\nfrequent use of fingerspelling for technical concepts, which inhibits DHH\nstudents' ability to learn, we develop models to identify fingerspelled words\n-- which can later be used to query for appropriate ASL signs to suggest to\ninterpreters."
    },
    {
      "id": "2411.05781v1",
      "title": "Using Language Models to Disambiguate Lexical Choices in Translation",
      "summary": "In translation, a concept represented by a single word in a source language\ncan have multiple variations in a target language. The task of lexical\nselection requires using context to identify which variation is most\nappropriate for a source text. We work with native speakers of nine languages\nto create DTAiLS, a dataset of 1,377 sentence pairs that exhibit cross-lingual\nconcept variation when translating from English. We evaluate recent LLMs and\nneural machine translation systems on DTAiLS, with the best-performing model,\nGPT-4, achieving from 67 to 85% accuracy across languages. Finally, we use\nlanguage models to generate English rules describing target-language concept\nvariations. Providing weaker models with high-quality lexical rules improves\naccuracy substantially, in some cases reaching or outperforming GPT-4."
    },
    {
      "id": "2411.05780v1",
      "title": "GazeSearch: Radiology Findings Search Benchmark",
      "summary": "Medical eye-tracking data is an important information source for\nunderstanding how radiologists visually interpret medical images. This\ninformation not only improves the accuracy of deep learning models for X-ray\nanalysis but also their interpretability, enhancing transparency in\ndecision-making. However, the current eye-tracking data is dispersed,\nunprocessed, and ambiguous, making it difficult to derive meaningful insights.\nTherefore, there is a need to create a new dataset with more focus and\npurposeful eyetracking data, improving its utility for diagnostic applications.\nIn this work, we propose a refinement method inspired by the target-present\nvisual search challenge: there is a specific finding and fixations are guided\nto locate it. After refining the existing eye-tracking datasets, we transform\nthem into a curated visual search dataset, called GazeSearch, specifically for\nradiology findings, where each fixation sequence is purposefully aligned to the\ntask of locating a particular finding. Subsequently, we introduce a scan path\nprediction baseline, called ChestSearch, specifically tailored to GazeSearch.\nFinally, we employ the newly introduced GazeSearch as a benchmark to evaluate\nthe performance of current state-of-the-art methods, offering a comprehensive\nassessment for visual search in the medical imaging domain."
    },
    {
      "id": "2411.05779v1",
      "title": "Curriculum Learning for Few-Shot Domain Adaptation in CT-based Airway Tree Segmentation",
      "summary": "Despite advances with deep learning (DL), automated airway segmentation from\nchest CT scans continues to face challenges in segmentation quality and\ngeneralization across cohorts. To address these, we propose integrating\nCurriculum Learning (CL) into airway segmentation networks, distributing the\ntraining set into batches according to ad-hoc complexity scores derived from CT\nscans and corresponding ground-truth tree features. We specifically investigate\nfew-shot domain adaptation, targeting scenarios where manual annotation of a\nfull fine-tuning dataset is prohibitively expensive. Results are reported on\ntwo large open-cohorts (ATM22 and AIIB23) with high performance using CL for\nfull training (Source domain) and few-shot fine-tuning (Target domain), but\nwith also some insights on potential detrimental effects if using a classic\nBootstrapping scoring function or if not using proper scan sequencing."
    },
    {
      "id": "2411.05778v2",
      "title": "LLMs as Method Actors: A Model for Prompt Engineering and Architecture",
      "summary": "We introduce \"Method Actors\" as a mental model for guiding LLM prompt\nengineering and prompt architecture. Under this mental model, LLMs should be\nthought of as actors; prompts as scripts and cues; and LLM responses as\nperformances. We apply this mental model to the task of improving LLM\nperformance at playing Connections, a New York Times word puzzle game that\nprior research identified as a challenging benchmark for evaluating LLM\nreasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can\nsignificantly improve LLM performance over both a vanilla and \"Chain of\nThoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our\ndataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our\nstrongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's\nnewest model designed specifically for complex reasoning tasks, o1-preview.\nWhen asked to solve a puzzle all at once, o1-preview solves 79% of Connections\npuzzles in our dataset, and when allowed to build puzzle solutions one guess at\na time over multiple API calls, o1-preview solves 100% of the puzzles.\nIncorporating a \"Method Actor\" prompt architecture increases the percentage of\npuzzles that o1-preview solves perfectly from 76% to 87%."
    },
    {
      "id": "2411.05777v2",
      "title": "Quantitative Assessment of Intersectional Empathetic Bias and Understanding",
      "summary": "A growing amount of literature critiques the current operationalizations of\nempathy based on loose definitions of the construct. Such definitions\nnegatively affect dataset quality, model robustness, and evaluation\nreliability. We propose an empathy evaluation framework that operationalizes\nempathy close to its psychological origins. The framework measures the variance\nin responses of LLMs to prompts using existing metrics for empathy and\nemotional valence. The variance is introduced through the controlled generation\nof the prompts by varying social biases affecting context understanding, thus\nimpacting empathetic understanding. The control over generation ensures high\ntheoretical validity of the constructs in the prompt dataset. Also, it makes\nhigh-quality translation, especially into languages that currently have\nlittle-to-no way of evaluating empathy or bias, such as the Slavonic family,\nmore manageable. Using chosen LLMs and various prompt types, we demonstrate the\nempathy evaluation with the framework, including multiple-choice answers and\nfree generation. The variance in our initial evaluation sample is small and we\nwere unable to measure convincing differences between the empathetic\nunderstanding in contexts given by different social groups. However, the\nresults are promising because the models showed significant alterations their\nreasoning chains needed to capture the relatively subtle changes in the\nprompts. This provides the basis for future research into the construction of\nthe evaluation sample and statistical methods for measuring the results."
    },
    {
      "id": "2411.07263v1",
      "title": "Analysis and Forecasting of the Dynamics of a Floating Wind Turbine Using Dynamic Mode Decomposition",
      "summary": "This article presents a data-driven equation-free modeling of the dynamics of\na hexafloat floating offshore wind turbine based on the Dynamic Mode\nDecomposition (DMD). The DMD is here used to provide a modal analysis and\nextract knowledge from the dynamic system. A forecasting algorithm for the\nmotions, accelerations, and forces acting on the floating system, as well as\nthe height of the incoming waves, the wind speed, and the power extracted by\nthe wind turbine, is developed by using a methodological extension called\nHankel-DMD, that includes time-delayed copies of the states in an augmented\nstate vector. All the analyses are performed on experimental data collected\nfrom an operating prototype. The quality of the forecasts obtained varying two\nmain hyperparameters of the algorithm, namely the number of delayed copies and\nthe length of the observation time, is assessed using three different error\nmetrics, each analyzing complementary aspects of the prediction. A statistical\nanalysis exposed the existence of optimal values for the algorithm\nhyperparameters. Results show the approach's capability for short-term future\nestimates of the system's state, which can be used for real-time prediction and\ncontrol. Furthermore, a novel Stochastic Hankel-DMD formulation is introduced\nby considering hyperparameters as stochastic variables. The stochastic version\nof the method not only enriches the prediction with its related uncertainty but\nis also found to improve the normalized root mean square error up to 10% on a\nstatistical basis compared to the deterministic counterpart."
    },
    {
      "id": "2411.05775v1",
      "title": "Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?",
      "summary": "Political misinformation poses significant challenges to democratic\nprocesses, shaping public opinion and trust in media. Manual fact-checking\nmethods face issues of scalability and annotator bias, while machine learning\nmodels require large, costly labelled datasets. This study investigates the use\nof state-of-the-art large language models (LLMs) as reliable annotators for\ndetecting political factuality in news articles. Using open-source LLMs, we\ncreate a politically diverse dataset, labelled for bias through LLM-generated\nannotations. These annotations are validated by human experts and further\nevaluated by LLM-based judges to assess the accuracy and reliability of the\nannotations. Our approach offers a scalable and robust alternative to\ntraditional fact-checking, enhancing transparency and public trust in media."
    },
    {
      "id": "2411.05771v1",
      "title": "Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems",
      "summary": "Equivariant Imaging (EI) regularization has become the de-facto technique for\nunsupervised training of deep imaging networks, without any need of\nground-truth data. Observing that the EI-based unsupervised training paradigm\ncurrently has significant computational redundancy leading to inefficiency in\nhigh-dimensional applications, we propose a sketched EI regularization which\nleverages the randomized sketching techniques for acceleration. We then extend\nour sketched EI regularization to develop an accelerated deep internal learning\nframework -- Sketched Equivariant Deep Image Prior (Sk.EI-DIP), which can be\nefficiently applied for single-image and task-adapted reconstruction. Our\nnumerical study on X-ray CT image reconstruction tasks demonstrate that our\napproach can achieve order-of-magnitude computational acceleration over\nstandard EI-based counterpart in single-input setting, and network adaptation\nat test time."
    },
    {
      "id": "2411.05764v1",
      "title": "FinDVer: Explainable Claim Verification over Long and Hybrid-Content Financial Documents",
      "summary": "We introduce FinDVer, a comprehensive benchmark specifically designed to\nevaluate the explainable claim verification capabilities of LLMs in the context\nof understanding and analyzing long, hybrid-content financial documents.\nFinDVer contains 2,400 expert-annotated examples, divided into three subsets:\ninformation extraction, numerical reasoning, and knowledge-intensive reasoning,\neach addressing common scenarios encountered in real-world financial contexts.\nWe assess a broad spectrum of LLMs under long-context and RAG settings. Our\nresults show that even the current best-performing system, GPT-4o, still lags\nbehind human experts. We further provide in-depth analysis on long-context and\nRAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering\ninsights to drive future advancements. We believe that FinDVer can serve as a\nvaluable benchmark for evaluating LLMs in claim verification over complex,\nexpert-domain documents."
    },
    {
      "id": "2411.05762v1",
      "title": "Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024",
      "summary": "Separating disinformation from fact on the web has long challenged both the\nsearch and the reasoning powers of humans. We show that the reasoning power of\nlarge language models (LLMs) and the retrieval power of modern search engines\ncan be combined to automate this process and explainably verify claims. We\nintegrate LLMs and search under a multi-hop evidence pursuit strategy. This\nstrategy generates an initial question based on an input claim using a sequence\nto sequence model, searches and formulates an answer to the question, and\niteratively generates follow-up questions to pursue the evidence that is\nmissing using an LLM. We demonstrate our system on the FEVER 2024 (AVeriTeC)\nshared task. Compared to a strategy of generating all the questions at once,\nour method obtains .045 higher label accuracy and .155 higher AVeriTeC score\n(evaluating the adequacy of the evidence). Through ablations, we show the\nimportance of various design choices, such as the question generation method,\nmedium-sized context, reasoning with one document at a time, adding metadata,\nparaphrasing, reducing the problem to two classes, and reconsidering the final\nverdict. Our submitted system achieves .510 AVeriTeC score on the dev set and\n.477 AVeriTeC score on the test set."
    },
    {
      "id": "2411.05757v2",
      "title": "Tract-RLFormer: A Tract-Specific RL policy based Decoder-only Transformer Network",
      "summary": "Fiber tractography is a cornerstone of neuroimaging, enabling the detailed\nmapping of the brain's white matter pathways through diffusion MRI. This is\ncrucial for understanding brain connectivity and function, making it a valuable\ntool in neurological applications. Despite its importance, tractography faces\nchallenges due to its complexity and susceptibility to false positives,\nmisrepresenting vital pathways. To address these issues, recent strategies have\nshifted towards deep learning, utilizing supervised learning, which depends on\nprecise ground truth, or reinforcement learning, which operates without it. In\nthis work, we propose Tract-RLFormer, a network utilizing both supervised and\nreinforcement learning, in a two-stage policy refinement process that markedly\nimproves the accuracy and generalizability across various data-sets. By\nemploying a tract-specific approach, our network directly delineates the tracts\nof interest, bypassing the traditional segmentation process. Through rigorous\nvalidation on datasets such as TractoInferno, HCP, and ISMRM-2015, our\nmethodology demonstrates a leap forward in tractography, showcasing its ability\nto accurately map the brain's white matter tracts."
    },
    {
      "id": "2411.05755v1",
      "title": "End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering",
      "summary": "We present VLMnav, an embodied framework to transform a Vision-Language Model\n(VLM) into an end-to-end navigation policy. In contrast to prior work, we do\nnot rely on a separation between perception, planning, and control; instead, we\nuse a VLM to directly select actions in one step. Surprisingly, we find that a\nVLM can be used as an end-to-end policy zero-shot, i.e., without any\nfine-tuning or exposure to navigation data. This makes our approach open-ended\nand generalizable to any downstream navigation task. We run an extensive study\nto evaluate the performance of our approach in comparison to baseline prompting\nmethods. In addition, we perform a design analysis to understand the most\nimpactful design decisions. Visual examples and code for our project can be\nfound at https://jirl-upenn.github.io/VLMnav/"
    },
    {
      "id": "2411.05752v1",
      "title": "FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information",
      "summary": "Deep learning (DL) models are popular across various domains due to their\nremarkable performance and efficiency. However, their effectiveness relies\nheavily on large amounts of labeled data, which are often time-consuming and\nlabor-intensive to generate manually. To overcome this challenge, it is\nessential to develop strategies that reduce reliance on extensive labeled data\nwhile preserving model performance. In this paper, we propose FisherMask, a\nFisher information-based active learning (AL) approach that identifies key\nnetwork parameters by masking them based on their Fisher information values.\nFisherMask enhances batch AL by using Fisher information to select the most\ncritical parameters, allowing the identification of the most impactful samples\nduring AL training. Moreover, Fisher information possesses favorable\nstatistical properties, offering valuable insights into model behavior and\nproviding a better understanding of the performance characteristics within the\nAL pipeline. Our extensive experiments demonstrate that FisherMask\nsignificantly outperforms state-of-the-art methods on diverse datasets,\nincluding CIFAR-10 and FashionMNIST, especially under imbalanced settings.\nThese improvements lead to substantial gains in labeling efficiency. Hence\nserving as an effective tool to measure the sensitivity of model parameters to\ndata samples. Our code is available on\n\\url{https://github.com/sgchr273/FisherMask}."
    },
    {
      "id": "2411.05750v1",
      "title": "On Differentially Private String Distances",
      "summary": "Given a database of bit strings $A_1,\\ldots,A_m\\in \\{0,1\\}^n$, a fundamental\ndata structure task is to estimate the distances between a given query $B\\in\n\\{0,1\\}^n$ with all the strings in the database. In addition, one might further\nwant to ensure the integrity of the database by releasing these distance\nstatistics in a secure manner. In this work, we propose differentially private\n(DP) data structures for this type of tasks, with a focus on Hamming and edit\ndistance. On top of the strong privacy guarantees, our data structures are also\ntime- and space-efficient. In particular, our data structure is $\\epsilon$-DP\nagainst any sequence of queries of arbitrary length, and for any query $B$ such\nthat the maximum distance to any string in the database is at most $k$, we\noutput $m$ distance estimates. Moreover,\n  - For Hamming distance, our data structure answers any query in $\\widetilde\nO(mk+n)$ time and each estimate deviates from the true distance by at most\n$\\widetilde O(k/e^{\\epsilon/\\log k})$;\n  - For edit distance, our data structure answers any query in $\\widetilde\nO(mk^2+n)$ time and each estimate deviates from the true distance by at most\n$\\widetilde O(k/e^{\\epsilon/(\\log k \\log n)})$.\n  For moderate $k$, both data structures support sublinear query operations. We\nobtain these results via a novel adaptation of the randomized response\ntechnique as a bit flipping procedure, applied to the sketched strings."
    },
    {
      "id": "2411.05748v1",
      "title": "Multi-Dimensional Reconfigurable, Physically Composable Hybrid Diffractive Optical Neural Network",
      "summary": "Diffractive optical neural networks (DONNs), leveraging free-space light wave\npropagation for ultra-parallel, high-efficiency computing, have emerged as\npromising artificial intelligence (AI) accelerators. However, their inherent\nlack of reconfigurability due to fixed optical structures post-fabrication\nhinders practical deployment in the face of dynamic AI workloads and evolving\napplications. To overcome this challenge, we introduce, for the first time, a\nmulti-dimensional reconfigurable hybrid diffractive ONN system (MDR-HDONN), a\nphysically composable architecture that unlocks a new degree of freedom and\nunprecedented versatility in DONNs. By leveraging full-system learnability,\nMDR-HDONN repurposes fixed fabricated optical hardware, achieving exponentially\nexpanded functionality and superior task adaptability through the\ndifferentiable learning of system variables. Furthermore, MDR-HDONN adopts a\nhybrid optical/photonic design, combining the reconfigurability of integrated\nphotonics with the ultra-parallelism of free-space diffractive systems.\nExtensive evaluations demonstrate that MDR-HDONN has digital-comparable\naccuracy on various task adaptations with 74x faster speed and 194x lower\nenergy. Compared to prior DONNs, MDR-HDONN shows exponentially larger\nfunctional space with 5x faster training speed, paving the way for a new\nparadigm of versatile, composable, hybrid optical/photonic AI computing. We\nwill open-source our codes."
    },
    {
      "id": "2411.05746v1",
      "title": "Continuous-Time Analysis of Adaptive Optimization and Normalization",
      "summary": "Adaptive optimization algorithms, particularly Adam and its variant AdamW,\nare fundamental components of modern deep learning. However, their training\ndynamics lack comprehensive theoretical understanding, with limited insight\ninto why common practices - such as specific hyperparameter choices and\nnormalization layers - contribute to successful generalization. This work\npresents a continuous-time formulation of Adam and AdamW, facilitating a\ntractable analysis of training dynamics that can shed light on such practical\nquestions. We theoretically derive a stable region for Adam's hyperparameters\n$(\\beta, \\gamma)$ that ensures bounded updates, empirically verifying these\npredictions by observing unstable exponential growth of parameter updates\noutside this region. Furthermore, we theoretically justify the success of\nnormalization layers by uncovering an implicit meta-adaptive effect of\nscale-invariant architectural components. This insight leads to an explicit\noptimizer, $2$-Adam, which we generalize to $k$-Adam - an optimizer that\napplies an adaptive normalization procedure $k$ times, encompassing Adam\n(corresponding to $k=1$) and Adam with a normalization layer (corresponding to\n$k=2$). Overall, our continuous-time formulation of Adam facilitates a\nprincipled analysis, offering deeper understanding of optimal hyperparameter\nchoices and architectural decisions in modern deep learning."
    },
    {
      "id": "2411.05743v1",
      "title": "Free Record-Level Privacy Risk Evaluation Through Artifact-Based Methods",
      "summary": "Membership inference attacks (MIAs) are widely used to empirically assess the\nprivacy risks of samples used to train a target machine learning model.\nState-of-the-art methods however require training hundreds of shadow models,\nwith the same size and architecture of the target model, solely to evaluate the\nprivacy risk. While one might be able to afford this for small models, the cost\noften becomes prohibitive for medium and large models.\n  We here instead propose a novel approach to identify the at-risk samples\nusing only artifacts available during training, with little to no additional\ncomputational overhead. Our method analyzes individual per-sample loss traces\nand uses them to identify the vulnerable data samples. We demonstrate the\neffectiveness of our artifact-based approach through experiments on the CIFAR10\ndataset, showing high precision in identifying vulnerable samples as determined\nby a SOTA shadow model-based MIA (LiRA). Impressively, our method reaches the\nsame precision as another SOTA MIA when measured against LiRA, despite it being\norders of magnitude cheaper. We then show LT-IQR to outperform alternative loss\naggregation methods, perform ablation studies on hyperparameters, and validate\nthe robustness of our method to the target metric. Finally, we study the\nevolution of the vulnerability score distribution throughout training as a\nmetric for model-level risk assessment."
    },
    {
      "id": "2411.05742v1",
      "title": "Topology-aware Reinforcement Feature Space Reconstruction for Graph Data",
      "summary": "Feature space is an environment where data points are vectorized to represent\nthe original dataset. Reconstructing a good feature space is essential to\naugment the AI power of data, improve model generalization, and increase the\navailability of downstream ML models. Existing literature, such as feature\ntransformation and feature selection, is labor-intensive (e.g., heavy reliance\non empirical experience) and mostly designed for tabular data. Moreover, these\nmethods regard data samples as independent, which ignores the unique\ntopological structure when applied to graph data, thus resulting in a\nsuboptimal reconstruction feature space. Can we consider the topological\ninformation to automatically reconstruct feature space for graph data without\nheavy experiential knowledge? To fill this gap, we leverage topology-aware\nreinforcement learning to automate and optimize feature space reconstruction\nfor graph data. Our approach combines the extraction of core subgraphs to\ncapture essential structural information with a graph neural network (GNN) to\nencode topological features and reduce computing complexity. Then we introduce\nthree reinforcement agents within a hierarchical structure to systematically\ngenerate meaningful features through an iterative process, effectively\nreconstructing the feature space. This framework provides a principled solution\nfor attributed graph feature space reconstruction. The extensive experiments\ndemonstrate the effectiveness and efficiency of including topological\nawareness."
    },
    {
      "id": "2411.05735v1",
      "title": "Aioli: A Unified Optimization Framework for Language Model Data Mixing",
      "summary": "Language model performance depends on identifying the optimal mixture of data\ngroups to train on (e.g., law, code, math). Prior work has proposed a diverse\nset of methods to efficiently learn mixture proportions, ranging from fitting\nregression models over training runs to dynamically updating proportions\nthroughout training. Surprisingly, we find that no existing method consistently\noutperforms a simple stratified sampling baseline in terms of average test\nperplexity per group. In this paper, we study the cause of this inconsistency\nby unifying existing methods into a standard optimization framework. We show\nthat all methods set proportions to minimize total loss, subject to a\nmethod-specific mixing law -- an assumption on how loss is a function of\nmixture proportions. We find that existing parameterizations of mixing laws can\nexpress the true loss-proportion relationship empirically, but the methods\nthemselves often set the mixing law parameters inaccurately, resulting in poor\nand inconsistent performance. Finally, we leverage the insights from our\nframework to derive a new online method named Aioli, which directly estimates\nthe mixing law parameters throughout training and uses them to dynamically\nadjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out\nof 6 datasets by an average of 0.28 test perplexity points, whereas existing\nmethods fail to consistently beat stratified sampling, doing up to 6.9 points\nworse. Moreover, in a practical setting where proportions are learned on\nshorter runs due to computational constraints, Aioli can dynamically adjust\nthese proportions over the full training run, consistently improving\nperformance over existing methods by up to 12.01 test perplexity points."
    },
    {
      "id": "2411.05733v1",
      "title": "Differential Privacy Under Class Imbalance: Methods and Empirical Insights",
      "summary": "Imbalanced learning occurs in classification settings where the distribution\nof class-labels is highly skewed in the training data, such as when predicting\nrare diseases or in fraud detection. This class imbalance presents a\nsignificant algorithmic challenge, which can be further exacerbated when\nprivacy-preserving techniques such as differential privacy are applied to\nprotect sensitive training data. Our work formalizes these challenges and\nprovides a number of algorithmic solutions. We consider DP variants of\npre-processing methods that privately augment the original dataset to reduce\nthe class imbalance; these include oversampling, SMOTE, and private synthetic\ndata generation. We also consider DP variants of in-processing techniques,\nwhich adjust the learning algorithm to account for the imbalance; these include\nmodel bagging, class-weighted empirical risk minimization and class-weighted\ndeep learning. For each method, we either adapt an existing imbalanced learning\ntechnique to the private setting or demonstrate its incompatibility with\ndifferential privacy. Finally, we empirically evaluate these privacy-preserving\nimbalanced learning methods under various data and distributional settings. We\nfind that private synthetic data methods perform well as a data pre-processing\nstep, while class-weighted ERMs are an alternative in higher-dimensional\nsettings where private synthetic data suffers from the curse of dimensionality."
    },
    {
      "id": "2411.05730v1",
      "title": "Learning Subsystem Dynamics in Nonlinear Systems via Port-Hamiltonian Neural Networks",
      "summary": "Port-Hamiltonian neural networks (pHNNs) are emerging as a powerful modeling\ntool that integrates physical laws with deep learning techniques. While most\nresearch has focused on modeling the entire dynamics of interconnected systems,\nthe potential for identifying and modeling individual subsystems while\noperating as part of a larger system has been overlooked. This study addresses\nthis gap by introducing a novel method for using pHNNs to identify such\nsubsystems based solely on input-output measurements. By utilizing the inherent\ncompositional property of the port-Hamiltonian systems, we developed an\nalgorithm that learns the dynamics of individual subsystems, without requiring\ndirect access to their internal states. On top of that, by choosing an output\nerror (OE) model structure, we have been able to handle measurement noise\neffectively. The effectiveness of the proposed approach is demonstrated through\ntests on interconnected systems, including multi-physics scenarios,\ndemonstrating its potential for identifying subsystem dynamics and facilitating\ntheir integration into new interconnected models."
    },
    {
      "id": "2411.05729v1",
      "title": "Graph-Dictionary Signal Model for Sparse Representations of Multivariate Data",
      "summary": "Representing and exploiting multivariate signals require capturing complex\nrelations between variables. We define a novel Graph-Dictionary signal model,\nwhere a finite set of graphs characterizes relationships in data distribution\nthrough a weighted sum of their Laplacians. We propose a framework to infer the\ngraph dictionary representation from observed data, along with a bilinear\ngeneralization of the primal-dual splitting algorithm to solve the learning\nproblem. Our new formulation allows to include a priori knowledge on signal\nproperties, as well as on underlying graphs and their coefficients. We show the\ncapability of our method to reconstruct graphs from signals in multiple\nsynthetic settings, where our model outperforms previous baselines. Then, we\nexploit graph-dictionary representations in a motor imagery decoding task on\nbrain activity data, where we classify imagined motion better than standard\nmethods relying on many more features."
    },
    {
      "id": "2411.05718v1",
      "title": "A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-world Robotics",
      "summary": "Machine learning methods have a groundbreaking impact in many application\ndomains, but their application on real robotic platforms is still limited.\nDespite the many challenges associated with combining machine learning\ntechnology with robotics, robot learning remains one of the most promising\ndirections for enhancing the capabilities of robots. When deploying\nlearning-based approaches on real robots, extra effort is required to address\nthe challenges posed by various real-world factors. To investigate the key\nfactors influencing real-world deployment and to encourage original solutions\nfrom different researchers, we organized the Robot Air Hockey Challenge at the\nNeurIPS 2023 conference. We selected the air hockey task as a benchmark,\nencompassing low-level robotics problems and high-level tactics. Different from\nother machine learning-centric benchmarks, participants need to tackle\npractical challenges in robotics, such as the sim-to-real gap, low-level\ncontrol issues, safety problems, real-time requirements, and the limited\navailability of real-world data. Furthermore, we focus on a dynamic\nenvironment, removing the typical assumption of quasi-static motions of other\nreal-world benchmarks. The competition's results show that solutions combining\nlearning-based approaches with prior knowledge outperform those relying solely\non data when real-world deployment is challenging. Our ablation study reveals\nwhich real-world factors may be overlooked when building a learning-based\nsolution. The successful real-world air hockey deployment of best-performing\nagents sets the foundation for future competitions and follow-up research\ndirections."
    },
    {
      "id": "2411.05714v1",
      "title": "STARS: Sensor-agnostic Transformer Architecture for Remote Sensing",
      "summary": "We present a sensor-agnostic spectral transformer as the basis for spectral\nfoundation models. To that end, we introduce a Universal Spectral\nRepresentation (USR) that leverages sensor meta-data, such as sensing kernel\nspecifications and sensing wavelengths, to encode spectra obtained from any\nspectral instrument into a common representation, such that a single model can\ningest data from any sensor. Furthermore, we develop a methodology for\npre-training such models in a self-supervised manner using a novel random\nsensor-augmentation and reconstruction pipeline to learn spectral features\nindependent of the sensing paradigm. We demonstrate that our architecture can\nlearn sensor independent spectral features that generalize effectively to\nsensors not seen during training. This work sets the stage for training\nfoundation models that can both leverage and be effective for the growing\ndiversity of spectral data."
    },
    {
      "id": "2411.05903v1",
      "title": "Towards Multi-Modal Mastery: A 4.5B Parameter Truly Multi-Modal Small Language Model",
      "summary": "We present a novel 4.5B parameter small language model that can handle\nmultiple input and output modalities, including text, images, videos, and\naudio. Despite its small size, the model achieves near state-of-the-art\nperformance on a variety of tasks, demonstrating the potential of multi-modal\nmodels to tackle complex real-world problems. Our approach leverages recent\nadvancements in language modeling and multi-task learning to create a versatile\nand high-performing model that can even be deployed for edge inference.\nExperimental results show the model's strong performance across multiple\nbenchmarks, paving the way for further progress in multi-modal artificial\nintelligence."
    },
    {
      "id": "2411.05902v1",
      "title": "Autoregressive Models in Vision: A Survey",
      "summary": "Autoregressive modeling has been a huge success in the field of natural\nlanguage processing (NLP). Recently, autoregressive models have emerged as a\nsignificant area of focus in computer vision, where they excel in producing\nhigh-quality visual content. Autoregressive models in NLP typically operate on\nsubword tokens. However, the representation strategy in computer vision can\nvary in different levels, \\textit{i.e.}, pixel-level, token-level, or\nscale-level, reflecting the diverse and hierarchical nature of visual data\ncompared to the sequential structure of language. This survey comprehensively\nexamines the literature on autoregressive models applied to vision. To improve\nreadability for researchers from diverse research backgrounds, we start with\npreliminary sequence representation and modeling in vision. Next, we divide the\nfundamental frameworks of visual autoregressive models into three general\nsub-categories, including pixel-based, token-based, and scale-based models\nbased on the strategy of representation. We then explore the interconnections\nbetween autoregressive models and other generative models. Furthermore, we\npresent a multi-faceted categorization of autoregressive models in computer\nvision, including image generation, video generation, 3D generation, and\nmulti-modal generation. We also elaborate on their applications in diverse\ndomains, including emerging domains such as embodied AI and 3D medical AI, with\nabout 250 related references. Finally, we highlight the current challenges to\nautoregressive models in vision with suggestions about potential research\ndirections. We have also set up a Github repository to organize the papers\nincluded in this survey at:\n\\url{https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey}."
    },
    {
      "id": "2411.05712v1",
      "title": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream",
      "summary": "When trained on large-scale object classification datasets, certain\nartificial neural network models begin to approximate core object recognition\n(COR) behaviors and neural response patterns in the primate visual ventral\nstream (VVS). While recent machine learning advances suggest that scaling model\nsize, dataset size, and compute resources improve task performance, the impact\nof scaling on brain alignment remains unclear. In this study, we explore\nscaling laws for modeling the primate VVS by systematically evaluating over 600\nmodels trained under controlled conditions on benchmarks spanning V1, V2, V4,\nIT and COR behaviors. We observe that while behavioral alignment continues to\nscale with larger models, neural alignment saturates. This observation remains\ntrue across model architectures and training datasets, even though models with\nstronger inductive bias and datasets with higher-quality images are more\ncompute-efficient. Increased scaling is especially beneficial for higher-level\nvisual areas, where small models trained on few samples exhibit only poor\nalignment. Finally, we develop a scaling recipe, indicating that a greater\nproportion of compute should be allocated to data samples over model size. Our\nresults suggest that while scaling alone might suffice for alignment with human\ncore object recognition behavior, it will not yield improved models of the\nbrain's visual ventral stream with current architectures and datasets,\nhighlighting the need for novel strategies in building brain-like models."
    },
    {
      "id": "2411.05708v1",
      "title": "Sample and Computationally Efficient Robust Learning of Gaussian Single-Index Models",
      "summary": "A single-index model (SIM) is a function of the form\n$\\sigma(\\mathbf{w}^{\\ast} \\cdot \\mathbf{x})$, where $\\sigma: \\mathbb{R} \\to\n\\mathbb{R}$ is a known link function and $\\mathbf{w}^{\\ast}$ is a hidden unit\nvector. We study the task of learning SIMs in the agnostic (a.k.a. adversarial\nlabel noise) model with respect to the $L^2_2$-loss under the Gaussian\ndistribution. Our main result is a sample and computationally efficient\nagnostic proper learner that attains $L^2_2$-error of\n$O(\\mathrm{OPT})+\\epsilon$, where $\\mathrm{OPT}$ is the optimal loss. The\nsample complexity of our algorithm is $\\tilde{O}(d^{\\lceil\nk^{\\ast}/2\\rceil}+d/\\epsilon)$, where $k^{\\ast}$ is the information-exponent of\n$\\sigma$ corresponding to the degree of its first non-zero Hermite coefficient.\nThis sample bound nearly matches known CSQ lower bounds, even in the realizable\nsetting. Prior algorithmic work in this setting had focused on learning in the\nrealizable case or in the presence of semi-random noise. Prior computationally\nefficient robust learners required significantly stronger assumptions on the\nlink function."
    },
    {
      "id": "2411.05706v1",
      "title": "Image2Text2Image: A Novel Framework for Label-Free Evaluation of Image-to-Text Generation with Text-to-Image Diffusion Models",
      "summary": "Evaluating the quality of automatically generated image descriptions is a\ncomplex task that requires metrics capturing various dimensions, such as\ngrammaticality, coverage, accuracy, and truthfulness. Although human evaluation\nprovides valuable insights, its cost and time-consuming nature pose\nlimitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr\nattempt to fill this gap, but they often exhibit weak correlations with human\njudgment. To address this challenge, we propose a novel evaluation framework\ncalled Image2Text2Image, which leverages diffusion models, such as Stable\nDiffusion or DALL-E, for text-to-image generation. In the Image2Text2Image\nframework, an input image is first processed by a selected image captioning\nmodel, chosen for evaluation, to generate a textual description. Using this\ngenerated description, a diffusion model then creates a new image. By comparing\nfeatures extracted from the original and generated images, we measure their\nsimilarity using a designated similarity metric. A high similarity score\nsuggests that the model has produced a faithful textual description, while a\nlow score highlights discrepancies, revealing potential weaknesses in the\nmodel's performance. Notably, our framework does not rely on human-annotated\nreference captions, making it a valuable tool for assessing image captioning\nmodels. Extensive experiments and human evaluations validate the efficacy of\nour proposed Image2Text2Image evaluation framework. The code and dataset will\nbe published to support further research in the community."
    },
    {
      "id": "2411.05698v1",
      "title": "Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification",
      "summary": "Convolutional Neural Networks (CNNs) have seen significant performance\nimprovements in recent years. However, due to their size and complexity, they\nfunction as black-boxes, leading to transparency concerns. State-of-the-art\nsaliency methods generate local explanations that highlight the area in the\ninput image where a class is identified but cannot explain how a concept of\ninterest contributes to the prediction, which is essential for bias mitigation.\nOn the other hand, concept-based methods, such as TCAV (Testing with Concept\nActivation Vectors), provide insights into how sensitive is the network to a\nconcept, but cannot compute its attribution in a specific prediction nor show\nits location within the input image. This paper introduces a novel post-hoc\nexplainability framework, Visual-TCAV, which aims to bridge the gap between\nthese methods by providing both local and global explanations for CNN-based\nimage classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to\ngenerate saliency maps that show where concepts are recognized by the network.\nMoreover, it can estimate the attribution of these concepts to the output of\nany class using a generalization of Integrated Gradients. This framework is\nevaluated on popular CNN architectures, with its validity further confirmed via\nexperiments where ground truth for explanations is known, and a comparison with\nTCAV. Our code will be made available soon."
    },
    {
      "id": "2411.05697v1",
      "title": "IPMN Risk Assessment under Federated Learning Paradigm",
      "summary": "Accurate classification of Intraductal Papillary Mucinous Neoplasms (IPMN) is\nessential for identifying high-risk cases that require timely intervention. In\nthis study, we develop a federated learning framework for multi-center IPMN\nclassification utilizing a comprehensive pancreas MRI dataset. This dataset\nincludes 653 T1-weighted and 656 T2-weighted MRI images, accompanied by\ncorresponding IPMN risk scores from 7 leading medical institutions, making it\nthe largest and most diverse dataset for IPMN classification to date. We assess\nthe performance of DenseNet-121 in both centralized and federated settings for\ntraining on distributed data. Our results demonstrate that the federated\nlearning approach achieves high classification accuracy comparable to\ncentralized learning while ensuring data privacy across institutions. This work\nmarks a significant advancement in collaborative IPMN classification,\nfacilitating secure and high-accuracy model training across multiple centers."
    },
    {
      "id": "2411.05693v1",
      "title": "YOSO: You-Only-Sample-Once via Compressed Sensing for Graph Neural Network Training",
      "summary": "Graph neural networks (GNNs) have become essential tools for analyzing\nnon-Euclidean data across various domains. During training stage, sampling\nplays an important role in reducing latency by limiting the number of nodes\nprocessed, particularly in large-scale applications. However, as the demand for\nbetter prediction performance grows, existing sampling algorithms become\nincreasingly complex, leading to significant overhead. To mitigate this, we\npropose YOSO (You-Only-Sample-Once), an algorithm designed to achieve efficient\ntraining while preserving prediction accuracy. YOSO introduces a compressed\nsensing (CS)-based sampling and reconstruction framework, where nodes are\nsampled once at input layer, followed by a lossless reconstruction at the\noutput layer per epoch. By integrating the reconstruction process with the loss\nfunction of specific learning tasks, YOSO not only avoids costly computations\nin traditional compressed sensing (CS) methods, such as orthonormal basis\ncalculations, but also ensures high-probability accuracy retention which\nequivalent to full node participation. Experimental results on node\nclassification and link prediction demonstrate the effectiveness and efficiency\nof YOSO, reducing GNN training by an average of 75\\% compared to\nstate-of-the-art methods, while maintaining accuracy on par with top-performing\nbaselines."
    },
    {
      "id": "2411.05691v1",
      "title": "Asterisk*: Keep it Simple",
      "summary": "This paper describes Asterisk, a compact GPT-based model for generating text\nembeddings. The model uses a minimalist architecture with two layers, two\nattention heads, and 256 embedding dimensions. By applying knowledge\ndistillation from larger pretrained models, we explore the trade-offs between\nmodel size and performance while minimizing computational and memory\nrequirements. The model is primarily evaluated and optimized for classification\ntasks, with experimental results showing its moderate performance in zero-shot\nclassification across various downstream applications. With additional\nconfiguration, the model performance can approach or even surpass that of\nlarger architectures on specific classification tasks."
    },
    {
      "id": "2411.05901v1",
      "title": "ViT Enhanced Privacy-Preserving Secure Medical Data Sharing and Classification",
      "summary": "Privacy-preserving and secure data sharing are critical for medical image\nanalysis while maintaining accuracy and minimizing computational overhead are\nalso crucial. Applying existing deep neural networks (DNNs) to encrypted\nmedical data is not always easy and often compromises performance and security.\nTo address these limitations, this research introduces a secure framework\nconsisting of a learnable encryption method based on the block-pixel operation\nto encrypt the data and subsequently integrate it with the Vision Transformer\n(ViT). The proposed framework ensures data privacy and security by creating\nunique scrambling patterns per key, providing robust performance against\nleading bit attacks and minimum difference attacks."
    },
    {
      "id": "2411.05900v1",
      "title": "Enhancing Cardiovascular Disease Prediction through Multi-Modal Self-Supervised Learning",
      "summary": "Accurate prediction of cardiovascular diseases remains imperative for early\ndiagnosis and intervention, necessitating robust and precise predictive models.\nRecently, there has been a growing interest in multi-modal learning for\nuncovering novel insights not available through uni-modal datasets alone. By\ncombining cardiac magnetic resonance images, electrocardiogram signals, and\navailable medical information, our approach enables the capture of holistic\nstatus about individuals' cardiovascular health by leveraging shared\ninformation across modalities. Integrating information from multiple modalities\nand benefiting from self-supervised learning techniques, our model provides a\ncomprehensive framework for enhancing cardiovascular disease prediction with\nlimited annotated datasets.\n  We employ a masked autoencoder to pre-train the electrocardiogram ECG\nencoder, enabling it to extract relevant features from raw electrocardiogram\ndata, and an image encoder to extract relevant features from cardiac magnetic\nresonance images. Subsequently, we utilize a multi-modal contrastive learning\nobjective to transfer knowledge from expensive and complex modality, cardiac\nmagnetic resonance image, to cheap and simple modalities such as\nelectrocardiograms and medical information. Finally, we fine-tuned the\npre-trained encoders on specific predictive tasks, such as myocardial\ninfarction. Our proposed method enhanced the image information by leveraging\ndifferent available modalities and outperformed the supervised approach by 7.6%\nin balanced accuracy."
    },
    {
      "id": "2411.05683v1",
      "title": "Data-Driven Distributed Common Operational Picture from Heterogeneous Platforms using Multi-Agent Reinforcement Learning",
      "summary": "The integration of unmanned platforms equipped with advanced sensors promises\nto enhance situational awareness and mitigate the \"fog of war\" in military\noperations. However, managing the vast influx of data from these platforms\nposes a significant challenge for Command and Control (C2) systems. This study\npresents a novel multi-agent learning framework to address this challenge. Our\nmethod enables autonomous and secure communication between agents and humans,\nwhich in turn enables real-time formation of an interpretable Common\nOperational Picture (COP). Each agent encodes its perceptions and actions into\ncompact vectors, which are then transmitted, received and decoded to form a COP\nencompassing the current state of all agents (friendly and enemy) on the\nbattlefield. Using Deep Reinforcement Learning (DRL), we jointly train COP\nmodels and agent's action selection policies. We demonstrate resilience to\ndegraded conditions such as denied GPS and disrupted communications.\nExperimental validation is performed in the Starcraft-2 simulation environment\nto evaluate the precision of the COPs and robustness of policies. We report\nless than 5% error in COPs and policies resilient to various adversarial\nconditions. In summary, our contributions include a method for autonomous COP\nformation, increased resilience through distributed prediction, and joint\ntraining of COP models and multi-agent RL policies. This research advances\nadaptive and resilient C2, facilitating effective control of heterogeneous\nunmanned platforms."
    },
    {
      "id": "2411.05679v1",
      "title": "Tell What You Hear From What You See -- Video to Audio Generation Through Text",
      "summary": "The content of visual and audio scenes is multi-faceted such that a video can\nbe paired with various audio and vice-versa. Thereby, in video-to-audio\ngeneration task, it is imperative to introduce steering approaches for\ncontrolling the generated audio. While Video-to-Audio generation is a\nwell-established generative task, existing methods lack such controllability.\nIn this work, we propose VATT, a multi-modal generative framework that takes a\nvideo and an optional text prompt as input, and generates audio and optional\ntextual description of the audio. Such a framework has two advantages: i)\nVideo-to-Audio generation process can be refined and controlled via text which\ncomplements the context of visual information, and ii) The model can suggest\nwhat audio to generate for the video by generating audio captions. VATT\nconsists of two key modules: VATT Converter, a LLM that is fine-tuned for\ninstructions and includes a projection layer that maps video features to the\nLLM vector space; and VATT Audio, a transformer that generates audio tokens\nfrom visual frames and from optional text prompt using iterative parallel\ndecoding. The audio tokens are converted to a waveform by pretrained neural\ncodec. Experiments show that when VATT is compared to existing video-to-audio\ngeneration methods in objective metrics, it achieves competitive performance\nwhen the audio caption is not provided. When the audio caption is provided as a\nprompt, VATT achieves even more refined performance (lowest KLD score of 1.41).\nFurthermore, subjective studies show that VATT Audio has been chosen as\npreferred generated audio than audio generated by existing methods. VATT\nenables controllable video-to-audio generation through text as well as\nsuggesting text prompts for videos through audio captions, unlocking novel\napplications such as text-guided video-to-audio generation and video-to-audio\ncaptioning."
    },
    {
      "id": "2411.05676v1",
      "title": "Improving Molecular Graph Generation with Flow Matching and Optimal Transport",
      "summary": "Generating molecular graphs is crucial in drug design and discovery but\nremains challenging due to the complex interdependencies between nodes and\nedges. While diffusion models have demonstrated their potentiality in molecular\ngraph design, they often suffer from unstable training and inefficient\nsampling. To enhance generation performance and training stability, we propose\nGGFlow, a discrete flow matching generative model incorporating optimal\ntransport for molecular graphs and it incorporates an edge-augmented graph\ntransformer to enable the direct communications among chemical bounds.\nAdditionally, GGFlow introduces a novel goal-guided generation framework to\ncontrol the generative trajectory of our model, aiming to design novel\nmolecular structures with the desired properties. GGFlow demonstrates superior\nperformance on both unconditional and conditional molecule generation tasks,\noutperforming existing baselines and underscoring its effectiveness and\npotential for wider application."
    },
    {
      "id": "2411.05665v1",
      "title": "Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal",
      "summary": "This paper sheds light on the limitations of Large Language Models (LLMs) by\nrigorously evaluating their ability to process masked text. We introduce two\nnovel tasks: MskQA, measuring reasoning on masked question-answering datasets\nlike RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic\nproblems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some\nresilience to masked text, their performance is highly contingent on masking\nrates and semantic cues. Specifically, \"solid masking,\" where semantic clues\nare entirely absent, leads to a significant performance drop compared to\n\"partial lifting,\" where some semantic information is retained, indicating\nLLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently\noutperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to\nhandle numerical reasoning with masked text. This underscores the crucial role\nof semantic cues in the reasoning process of LLMs. Our study illuminates the\ninterplay between background knowledge and reasoning ability in masked text\nprocessing, paving the way for a deeper understanding of LLM capabilities and\nlimitations, and highlighting the need for more robust evaluation methods to\naccurately assess their true comprehension abilities."
    },
    {
      "id": "2411.05663v1",
      "title": "Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation",
      "summary": "Catastrophic forgetting is a significant challenge in online continual\nlearning (OCL), especially for non-stationary data streams that do not have\nwell-defined task boundaries. This challenge is exacerbated by the memory\nconstraints and privacy concerns inherent in rehearsal buffers. To tackle\ncatastrophic forgetting, in this paper, we introduce Online-LoRA, a novel\nframework for task-free OCL. Online-LoRA allows to finetune pre-trained Vision\nTransformer (ViT) models in real-time to address the limitations of rehearsal\nbuffers and leverage pre-trained models' performance benefits. As the main\ncontribution, our approach features a novel online weight regularization\nstrategy to identify and consolidate important model parameters. Moreover,\nOnline-LoRA leverages the training dynamics of loss values to enable the\nautomatic recognition of the data distribution shifts. Extensive experiments\nacross many task-free OCL scenarios and benchmark datasets (including\nCIFAR-100, ImageNet-R, ImageNet-S, CUB-200 and CORe50) demonstrate that\nOnline-LoRA can be robustly adapted to various ViT architectures, while\nachieving better performance compared to SOTA methods. Our code will be\npublicly available at:\nhttps://github.com/Christina200/Online-LoRA-official.git."
    },
    {
      "id": "2411.05661v1",
      "title": "Multi-armed Bandits with Missing Outcome",
      "summary": "While significant progress has been made in designing algorithms that\nminimize regret in online decision-making, real-world scenarios often introduce\nadditional complexities, perhaps the most challenging of which is missing\noutcomes. Overlooking this aspect or simply assuming random missingness\ninvariably leads to biased estimates of the rewards and may result in linear\nregret. Despite the practical relevance of this challenge, no rigorous\nmethodology currently exists for systematically handling missingness,\nespecially when the missingness mechanism is not random. In this paper, we\naddress this gap in the context of multi-armed bandits (MAB) with missing\noutcomes by analyzing the impact of different missingness mechanisms on\nachievable regret bounds. We introduce algorithms that account for missingness\nunder both missing at random (MAR) and missing not at random (MNAR) models.\nThrough both analytical and simulation studies, we demonstrate the drastic\nimprovements in decision-making by accounting for missingness in these\nsettings."
    },
    {
      "id": "2411.07165v1",
      "title": "Acoustic-based 3D Human Pose Estimation Robust to Human Position",
      "summary": "This paper explores the problem of 3D human pose estimation from only\nlow-level acoustic signals. The existing active acoustic sensing-based approach\nfor 3D human pose estimation implicitly assumes that the target user is\npositioned along a line between loudspeakers and a microphone. Because\nreflection and diffraction of sound by the human body cause subtle acoustic\nsignal changes compared to sound obstruction, the existing model degrades its\naccuracy significantly when subjects deviate from this line, limiting its\npracticality in real-world scenarios. To overcome this limitation, we propose a\nnovel method composed of a position discriminator and reverberation-resistant\nmodel. The former predicts the standing positions of subjects and applies\nadversarial learning to extract subject position-invariant features. The latter\nutilizes acoustic signals before the estimation target time as references to\nenhance robustness against the variations in sound arrival times due to\ndiffraction and reflection. We construct an acoustic pose estimation dataset\nthat covers diverse human locations and demonstrate through experiments that\nour proposed method outperforms existing approaches."
    },
    {
      "id": "2411.05899v1",
      "title": "Streaming Bayes GFlowNets",
      "summary": "Bayes' rule naturally allows for inference refinement in a streaming fashion,\nwithout the need to recompute posteriors from scratch whenever new data\narrives. In principle, Bayesian streaming is straightforward: we update our\nprior with the available data and use the resulting posterior as a prior when\nprocessing the next data chunk. In practice, however, this recipe entails i)\napproximating an intractable posterior at each time step; and ii) encapsulating\nresults appropriately to allow for posterior propagation. For continuous state\nspaces, variational inference (VI) is particularly convenient due to its\nscalability and the tractability of variational posteriors. For discrete state\nspaces, however, state-of-the-art VI results in analytically intractable\napproximations that are ill-suited for streaming settings. To enable streaming\nBayesian inference over discrete parameter spaces, we propose streaming Bayes\nGFlowNets (abbreviated as SB-GFlowNets) by leveraging the recently proposed\nGFlowNets -- a powerful class of amortized samplers for discrete compositional\nobjects. Notably, SB-GFlowNet approximates the initial posterior using a\nstandard GFlowNet and subsequently updates it using a tailored procedure that\nrequires only the newly observed data. Our case studies in linear preference\nlearning and phylogenetic inference showcase the effectiveness of SB-GFlowNets\nin sampling from an unnormalized posterior in a streaming setting. As expected,\nwe also observe that SB-GFlowNets is significantly faster than repeatedly\ntraining a GFlowNet from scratch to sample from the full posterior."
    },
    {
      "id": "2411.05898v1",
      "title": "Integrating Object Detection Modality into Visual Language Model for Enhanced Autonomous Driving Agent",
      "summary": "In this paper, we propose a novel framework for enhancing visual\ncomprehension in autonomous driving systems by integrating visual language\nmodels (VLMs) with additional visual perception module specialised in object\ndetection. We extend the Llama-Adapter architecture by incorporating a\nYOLOS-based detection network alongside the CLIP perception network, addressing\nlimitations in object detection and localisation. Our approach introduces\ncamera ID-separators to improve multi-view processing, crucial for\ncomprehensive environmental awareness. Experiments on the DriveLM visual\nquestion answering challenge demonstrate significant improvements over baseline\nmodels, with enhanced performance in ChatGPT scores, BLEU scores, and CIDEr\nmetrics, indicating closeness of model answer to ground truth. Our method\nrepresents a promising step towards more capable and interpretable autonomous\ndriving systems. Possible safety enhancement enabled by detection modality is\nalso discussed."
    },
    {
      "id": "2411.05897v1",
      "title": "Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators",
      "summary": "Although large language models (LLMs) have been assessed for general medical\nknowledge using medical licensing exams, their ability to effectively support\nclinical decision-making tasks, such as selecting and using medical\ncalculators, remains uncertain. Here, we evaluate the capability of both\nmedical trainees and LLMs to recommend medical calculators in response to\nvarious multiple-choice clinical scenarios such as risk stratification,\nprognosis, and disease diagnosis. We assessed eight LLMs, including\nopen-source, proprietary, and domain-specific models, with 1,009\nquestion-answer pairs across 35 clinical calculators and measured human\nperformance on a subset of 100 questions. While the highest-performing LLM,\nGPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human\nannotators, on average, outperformed LLMs with an accuracy of 79.5% (CI:\n73.5-85.0%). With error analysis showing that the highest-performing LLMs\ncontinue to make mistakes in comprehension (56.6%) and calculator knowledge\n(8.1%), our findings emphasize that humans continue to surpass LLMs on complex\nclinical tasks such as calculator recommendation."
    },
    {
      "id": "2411.05653v1",
      "title": "The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent",
      "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nconversational tasks. Embodying an LLM as a virtual human allows users to\nengage in face-to-face social interactions in Virtual Reality. However, the\ninfluence of person- and task-related factors in social interactions with\nLLM-controlled agents remains unclear. In this study, forty-six participants\ninteracted with a virtual agent whose persona was manipulated as extravert or\nintrovert in three different conversational tasks (small talk, knowledge test,\nconvincing). Social-evaluation, emotional experience, and realism were assessed\nusing ratings. Interactive engagement was measured by quantifying participants'\nwords and conversational turns. Finally, we measured participants' willingness\nto ask the agent for help during the knowledge test. Our findings show that the\nextraverted agent was more positively evaluated, elicited a more pleasant\nexperience and greater engagement, and was assessed as more realistic compared\nto the introverted agent. Whereas persona did not affect the tendency to ask\nfor help, participants were generally more confident in the answer when they\nhad help of the LLM. Variation of personality traits of LLM-controlled embodied\nvirtual agents, therefore, affects social-emotional processing and behavior in\nvirtual interactions. Embodied virtual agents allow the presentation of\nnaturalistic social encounters in a virtual environment."
    },
    {
      "id": "2411.05648v1",
      "title": "Enhancing Model Fairness and Accuracy with Similarity Networks: A Methodological Approach",
      "summary": "In this paper, we propose an innovative approach to thoroughly explore\ndataset features that introduce bias in downstream machine-learning tasks.\nDepending on the data format, we use different techniques to map instances into\na similarity feature space. Our method's ability to adjust the resolution of\npairwise similarity provides clear insights into the relationship between the\ndataset classification complexity and model fairness. Experimental results\nconfirm the promising applicability of the similarity network in promoting fair\nmodels. Moreover, leveraging our methodology not only seems promising in\nproviding a fair downstream task such as classification, it also performs well\nin imputation and augmentation of the dataset satisfying the fairness criteria\nsuch as demographic parity and imbalanced classes."
    },
    {
      "id": "2411.05641v1",
      "title": "Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation",
      "summary": "Large Language Models (LLMs), with gradually improving reading comprehension\nand reasoning capabilities, are being applied to a range of complex language\ntasks, including the automatic generation of language data for various\npurposes. However, research on applying LLMs for automatic data generation in\nlow-resource languages like Vietnamese is still underdeveloped and lacks\ncomprehensive evaluation. In this paper, we explore the use of LLMs for\nautomatic data generation for the Vietnamese fact-checking task, which faces\nsignificant data limitations. Specifically, we focus on fact-checking data\nwhere claims are synthesized from multiple evidence sentences to assess the\ninformation synthesis capabilities of LLMs. We develop an automatic data\nconstruction process using simple prompt techniques on LLMs and explore several\nmethods to improve the quality of the generated data. To evaluate the quality\nof the data generated by LLMs, we conduct both manual quality assessments and\nperformance evaluations using language models. Experimental results and manual\nevaluations illustrate that while the quality of the generated data has\nsignificantly improved through fine-tuning techniques, LLMs still cannot match\nthe data quality produced by humans."
    },
    {
      "id": "2411.05639v1",
      "title": "Assessing Open-Source Large Language Models on Argumentation Mining Subtasks",
      "summary": "We explore the capability of four open-sourcelarge language models (LLMs) in\nargumentation mining (AM). We conduct experiments on three different corpora;\npersuasive essays(PE), argumentative microtexts (AMT) Part 1 and Part 2, based\non two argumentation mining sub-tasks: (i) argumentative discourse units\nclassifications (ADUC), and (ii) argumentative relation classification (ARC).\nThis work aims to assess the argumentation capability of open-source LLMs,\nincluding Mistral 7B, Mixtral8x7B, LlamA2 7B and LlamA3 8B in both, zero-shot\nand few-shot scenarios. Our analysis contributes to further assessing\ncomputational argumentation with open-source LLMs in future research efforts."
    },
    {
      "id": "2411.05638v1",
      "title": "Impact of Fake News on Social Media Towards Public Users of Different Age Groups",
      "summary": "This study examines how fake news affects social media users across a range\nof age groups and how machine learning (ML) and artificial intelligence (AI)\ncan help reduce the spread of false information. The paper evaluates various\nmachine learning models for their efficacy in identifying and categorizing fake\nnews and examines current trends in the spread of fake news, including deepfake\ntechnology. The study assesses four models using a Kaggle dataset: Random\nForest, Support Vector Machine (SVM), Neural Networks, and Logistic Regression.\nThe results show that SVM and neural networks perform better than other models,\nwith accuracies of 93.29% and 93.69%, respectively. The study also emphasises\nhow people in the elder age group diminished capacity for critical analysis of\nnews content makes them more susceptible to disinformation. Natural language\nprocessing (NLP) and deep learning approaches have the potential to improve the\naccuracy of false news detection. Biases in AI and ML models and difficulties\nin identifying information generated by AI continue to be major problems in\nspite of the developments. The study recommends that datasets be expanded to\nencompass a wider range of languages and that detection algorithms be\ncontinuously improved to keep up with the latest advancements in disinformation\ntactics. In order to combat fake news and promote an informed and resilient\nsociety, this study emphasizes the value of cooperative efforts between AI\nresearchers, social media platforms, and governments."
    },
    {
      "id": "2411.05636v1",
      "title": "Video RWKV:Video Action Recognition Based RWKV",
      "summary": "To address the challenges of high computational costs and long-distance\ndependencies in exist ing video understanding methods, such as CNNs and\nTransformers, this work introduces RWKV to the video domain in a novel way. We\npropose a LSTM CrossRWKV (LCR) framework, designed for spatiotemporal\nrepresentation learning to tackle the video understanding task. Specifically,\nthe proposed linear complexity LCR incorporates a novel Cross RWKV gate to\nfacilitate interaction be tween current frame edge information and past\nfeatures, enhancing the focus on the subject through edge features and globally\naggregating inter-frame features over time. LCR stores long-term mem ory for\nvideo processing through an enhanced LSTM recurrent execution mechanism. By\nleveraging the Cross RWKV gate and recurrent execution, LCR effectively\ncaptures both spatial and temporal features. Additionally, the edge information\nserves as a forgetting gate for LSTM, guiding long-term memory management.Tube\nmasking strategy reduces redundant information in food and reduces\noverfitting.These advantages enable LSTM CrossRWKV to set a new benchmark in\nvideo under standing, offering a scalable and efficient solution for\ncomprehensive video analysis. All code and models are publicly available."
    },
    {
      "id": "2411.05633v1",
      "title": "SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection",
      "summary": "Developing robust drone detection systems is often constrained by the limited\navailability of large-scale annotated training data and the high costs\nassociated with real-world data collection. However, leveraging synthetic data\ngenerated via game engine-based simulations provides a promising and\ncost-effective solution to overcome this issue. Therefore, we present\nSynDroneVision, a synthetic dataset specifically designed for RGB-based drone\ndetection in surveillance applications. Featuring diverse backgrounds, lighting\nconditions, and drone models, SynDroneVision offers a comprehensive training\nfoundation for deep learning algorithms. To evaluate the dataset's\neffectiveness, we perform a comparative analysis across a selection of recent\nYOLO detection models. Our findings demonstrate that SynDroneVision is a\nvaluable resource for real-world data enrichment, achieving notable\nenhancements in model performance and robustness, while significantly reducing\nthe time and costs of real-world data acquisition. SynDroneVision will be\npublicly released upon paper acceptance."
    },
    {
      "id": "2411.05631v1",
      "title": "Physics-constrained coupled neural differential equations for one dimensional blood flow modeling",
      "summary": "Computational cardiovascular flow modeling plays a crucial role in\nunderstanding blood flow dynamics. While 3D models provide acute details, they\nare computationally expensive, especially with fluid-structure interaction\n(FSI) simulations. 1D models offer a computationally efficient alternative, by\nsimplifying the 3D Navier-Stokes equations through axisymmetric flow assumption\nand cross-sectional averaging. However, traditional 1D models based on finite\nelement methods (FEM) often lack accuracy compared to 3D averaged solutions.\nThis study introduces a novel physics-constrained machine learning technique\nthat enhances the accuracy of 1D blood flow models while maintaining\ncomputational efficiency. Our approach, utilizing a physics-constrained coupled\nneural differential equation (PCNDE) framework, demonstrates superior\nperformance compared to conventional FEM-based 1D models across a wide range of\ninlet boundary condition waveforms and stenosis blockage ratios. A key\ninnovation lies in the spatial formulation of the momentum conservation\nequation, departing from the traditional temporal approach and capitalizing on\nthe inherent temporal periodicity of blood flow. This spatial neural\ndifferential equation formulation switches space and time and overcomes issues\nrelated to coupling stability and smoothness, while simplifying boundary\ncondition implementation. The model accurately captures flow rate, area, and\npressure variations for unseen waveforms and geometries. We evaluate the\nmodel's robustness to input noise and explore the loss landscapes associated\nwith the inclusion of different physics terms. This advanced 1D modeling\ntechnique offers promising potential for rapid cardiovascular simulations,\nachieving computational efficiency and accuracy. By combining the strengths of\nphysics-based and data-driven modeling, this approach enables fast and accurate\ncardiovascular simulations."
    },
    {
      "id": "2411.05625v1",
      "title": "Cross-validating causal discovery via Leave-One-Variable-Out",
      "summary": "We propose a new approach to falsify causal discovery algorithms without\nground truth, which is based on testing the causal model on a pair of variables\nthat has been dropped when learning the causal model. To this end, we use the\n\"Leave-One-Variable-Out (LOVO)\" prediction where $Y$ is inferred from $X$\nwithout any joint observations of $X$ and $Y$, given only training data from\n$X,Z_1,\\dots,Z_k$ and from $Z_1,\\dots,Z_k,Y$. We demonstrate that causal models\non the two subsets, in the form of Acyclic Directed Mixed Graphs (ADMGs), often\nentail conclusions on the dependencies between $X$ and $Y$, enabling this type\nof prediction. The prediction error can then be estimated since the joint\ndistribution $P(X, Y)$ is assumed to be available, and $X$ and $Y$ have only\nbeen omitted for the purpose of falsification. After presenting this graphical\nmethod, which is applicable to general causal discovery algorithms, we\nillustrate how to construct a LOVO predictor tailored towards algorithms\nrelying on specific a priori assumptions, such as linear additive noise models.\nSimulations indicate that the LOVO prediction error is indeed correlated with\nthe accuracy of the causal outputs, affirming the method's effectiveness."
    },
    {
      "id": "2411.05619v1",
      "title": "WHALE: Towards Generalizable and Scalable World Models for Embodied Decision-making",
      "summary": "World models play a crucial role in decision-making within embodied\nenvironments, enabling cost-free explorations that would otherwise be expensive\nin the real world. To facilitate effective decision-making, world models must\nbe equipped with strong generalizability to support faithful imagination in\nout-of-distribution (OOD) regions and provide reliable uncertainty estimation\nto assess the credibility of the simulated experiences, both of which present\nsignificant challenges for prior scalable approaches. This paper introduces\nWHALE, a framework for learning generalizable world models, consisting of two\nkey techniques: behavior-conditioning and retracing-rollout.\nBehavior-conditioning addresses the policy distribution shift, one of the\nprimary sources of the world model generalization error, while\nretracing-rollout enables efficient uncertainty estimation without the\nnecessity of model ensembles. These techniques are universal and can be\ncombined with any neural network architecture for world model learning.\nIncorporating these two techniques, we present Whale-ST, a scalable\nspatial-temporal transformer-based world model with enhanced generalizability.\nWe demonstrate the superiority of Whale-ST in simulation tasks by evaluating\nboth value estimation accuracy and video generation fidelity. Additionally, we\nexamine the effectiveness of our uncertainty estimation technique, which\nenhances model-based policy optimization in fully offline scenarios.\nFurthermore, we propose Whale-X, a 414M parameter world model trained on 970K\ntrajectories from Open X-Embodiment datasets. We show that Whale-X exhibits\npromising scalability and strong generalizability in real-world manipulation\nscenarios using minimal demonstrations."
    },
    {
      "id": "2411.05618v1",
      "title": "Knowledge Distillation Neural Network for Predicting Car-following Behaviour of Human-driven and Autonomous Vehicles",
      "summary": "As we move towards a mixed-traffic scenario of Autonomous vehicles (AVs) and\nHuman-driven vehicles (HDVs), understanding the car-following behaviour is\nimportant to improve traffic efficiency and road safety. Using a real-world\ntrajectory dataset, this study uses descriptive and statistical analysis to\ninvestigate the car-following behaviours of three vehicle pairs: HDV-AV, AV-HDV\nand HDV-HDV in mixed traffic. The ANOVA test showed that car-following\nbehaviours across different vehicle pairs are statistically significant\n(p-value < 0.05).\n  We also introduce a data-driven Knowledge Distillation Neural Network (KDNN)\nmodel for predicting car-following behaviour in terms of speed. The KDNN model\ndemonstrates comparable predictive accuracy to its teacher network, a Long\nShort-Term Memory (LSTM) network, and outperforms both the standalone student\nnetwork, a Multilayer Perceptron (MLP), and traditional physics-based models\nlike the Gipps model. Notably, the KDNN model better prevents collisions,\nmeasured by minimum Time-to-Collision (TTC), and operates with lower\ncomputational power, making it ideal for AVs or driving simulators requiring\nefficient computing."
    },
    {
      "id": "2411.05614v1",
      "title": "Acceleration for Deep Reinforcement Learning using Parallel and Distributed Computing: A Survey",
      "summary": "Deep reinforcement learning has led to dramatic breakthroughs in the field of\nartificial intelligence for the past few years. As the amount of rollout\nexperience data and the size of neural networks for deep reinforcement learning\nhave grown continuously, handling the training process and reducing the time\nconsumption using parallel and distributed computing is becoming an urgent and\nessential desire. In this paper, we perform a broad and thorough investigation\non training acceleration methodologies for deep reinforcement learning based on\nparallel and distributed computing, providing a comprehensive survey in this\nfield with state-of-the-art methods and pointers to core references. In\nparticular, a taxonomy of literature is provided, along with a discussion of\nemerging topics and open issues. This incorporates learning system\narchitectures, simulation parallelism, computing parallelism, distributed\nsynchronization mechanisms, and deep evolutionary reinforcement learning.\nFurther, we compare 16 current open-source libraries and platforms with\ncriteria of facilitating rapid development. Finally, we extrapolate future\ndirections that deserve further research."
    },
    {
      "id": "2411.05609v1",
      "title": "A Two-Step Concept-Based Approach for Enhanced Interpretability and Trust in Skin Lesion Diagnosis",
      "summary": "The main challenges hindering the adoption of deep learning-based systems in\nclinical settings are the scarcity of annotated data and the lack of\ninterpretability and trust in these systems. Concept Bottleneck Models (CBMs)\noffer inherent interpretability by constraining the final disease prediction on\na set of human-understandable concepts. However, this inherent interpretability\ncomes at the cost of greater annotation burden. Additionally, adding new\nconcepts requires retraining the entire system. In this work, we introduce a\nnovel two-step methodology that addresses both of these challenges. By\nsimulating the two stages of a CBM, we utilize a pretrained Vision Language\nModel (VLM) to automatically predict clinical concepts, and a Large Language\nModel (LLM) to generate disease diagnoses based on the predicted concepts. We\nvalidate our approach on three skin lesion datasets, demonstrating that it\noutperforms traditional CBMs and state-of-the-art explainable methods, all\nwithout requiring any training and utilizing only a few annotated examples. The\ncode is available at\nhttps://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis."
    },
    {
      "id": "2411.05895v1",
      "title": "One Small and One Large for Document-level Event Argument Extraction",
      "summary": "Document-level Event Argument Extraction (EAE) faces two challenges due to\nincreased input length: 1) difficulty in distinguishing semantic boundaries\nbetween events, and 2) interference from redundant information. To address\nthese issues, we propose two methods. The first method introduces the Co and\nStructure Event Argument Extraction model (CsEAE) based on Small Language\nModels (SLMs). CsEAE includes a co-occurrences-aware module, which integrates\ninformation about all events present in the current input through context\nlabeling and co-occurrences event prompts extraction. Additionally, CsEAE\nincludes a structure-aware module that reduces interference from redundant\ninformation by establishing structural relationships between the sentence\ncontaining the trigger and other sentences in the document. The second method\nintroduces new prompts to transform the extraction task into a generative task\nsuitable for Large Language Models (LLMs), addressing gaps in EAE performance\nusing LLMs under Supervised Fine-Tuning (SFT) conditions. We also fine-tuned\nmultiple datasets to develop an LLM that performs better across most datasets.\nFinally, we applied insights from CsEAE to LLMs, achieving further performance\nimprovements. This suggests that reliable insights validated on SLMs are also\napplicable to LLMs. We tested our models on the Rams, WikiEvents, and MLEE\ndatasets. The CsEAE model achieved improvements of 2.1\\%, 2.3\\%, and 3.2\\% in\nthe Arg-C F1 metric compared to the baseline, PAIE~\\cite{PAIE}. For LLMs, we\ndemonstrated that their performance on document-level datasets is comparable to\nthat of SLMs~\\footnote{All code is available at\nhttps://github.com/simon-p-j-r/CsEAE}."
    },
    {
      "id": "2411.05599v1",
      "title": "Expectation vs. Reality: Towards Verification of Psychological Games",
      "summary": "Game theory provides an effective way to model strategic interactions among\nrational agents. In the context of formal verification, these ideas can be used\nto produce guarantees on the correctness of multi-agent systems, with a diverse\nrange of applications from computer security to autonomous driving.\nPsychological games (PGs) were developed as a way to model and analyse agents\nwith belief-dependent motivations, opening up the possibility to model how\nhuman emotions can influence behaviour. In PGs, players' utilities depend not\nonly on what actually happens (which strategies players choose to adopt), but\nalso on what the players had expected to happen (their belief as to the\nstrategies that would be played). Despite receiving much attention in fields\nsuch as economics and psychology, very little consideration has been given to\ntheir applicability to problems in computer science, nor to practical\nalgorithms and tool support. In this paper, we start to bridge that gap,\nproposing methods to solve PGs and implementing them within PRISM-games, a\nformal verification tool for stochastic games. We discuss how to model these\ngames, highlight specific challenges for their analysis and illustrate the\nusefulness of our approach on several case studies, including human behaviour\nin traffic scenarios."
    },
    {
      "id": "2411.05597v1",
      "title": "Predicting Stroke through Retinal Graphs and Multimodal Self-supervised Learning",
      "summary": "Early identification of stroke is crucial for intervention, requiring\nreliable models. We proposed an efficient retinal image representation together\nwith clinical information to capture a comprehensive overview of cardiovascular\nhealth, leveraging large multimodal datasets for new medical insights. Our\napproach is one of the first contrastive frameworks that integrates graph and\ntabular data, using vessel graphs derived from retinal images for efficient\nrepresentation. This method, combined with multimodal contrastive learning,\nsignificantly enhances stroke prediction accuracy by integrating data from\nmultiple sources and using contrastive learning for transfer learning. The\nself-supervised learning techniques employed allow the model to learn\neffectively from unlabeled data, reducing the dependency on large annotated\ndatasets. Our framework showed an AUROC improvement of 3.78% from supervised to\nself-supervised approaches. Additionally, the graph-level representation\napproach achieved superior performance to image encoders while significantly\nreducing pre-training and fine-tuning runtimes. These findings indicate that\nretinal images are a cost-effective method for improving cardiovascular disease\npredictions and pave the way for future research into retinal and cerebral\nvessel connections and the use of graph-based retinal vessel representations."
    },
    {
      "id": "2411.05596v1",
      "title": "Machine learning-driven Anomaly Detection and Forecasting for Euclid Space Telescope Operations",
      "summary": "State-of-the-art space science missions increasingly rely on automation due\nto spacecraft complexity and the costs of human oversight. The high volume of\ndata, including scientific and telemetry data, makes manual inspection\nchallenging. Machine learning offers significant potential to meet these\ndemands.\n  The Euclid space telescope, in its survey phase since February 2024,\nexemplifies this shift. Euclid's success depends on accurate monitoring and\ninterpretation of housekeeping telemetry and science-derived data. Thousands of\ntelemetry parameters, monitored as time series, may or may not impact the\nquality of scientific data. These parameters have complex interdependencies,\noften due to physical relationships (e.g., proximity of temperature sensors).\nOptimising science operations requires careful anomaly detection and\nidentification of hidden parameter states. Moreover, understanding the\ninteractions between known anomalies and physical quantities is crucial yet\ncomplex, as related parameters may display anomalies with varied timing and\nintensity.\n  We address these challenges by analysing temperature anomalies in Euclid's\ntelemetry from February to August 2024, focusing on eleven temperature\nparameters and 35 covariates. We use a predictive XGBoost model to forecast\ntemperatures based on historical values, detecting anomalies as deviations from\npredictions. A second XGBoost model predicts anomalies from covariates,\ncapturing their relationships to temperature anomalies. We identify the top\nthree anomalies per parameter and analyse their interactions with covariates\nusing SHAP (Shapley Additive Explanations), enabling rapid, automated analysis\nof complex parameter relationships.\n  Our method demonstrates how machine learning can enhance telemetry\nmonitoring, offering scalable solutions for other missions with similar data\nchallenges."
    },
    {
      "id": "2411.05593v1",
      "title": "Evaluating and Adapting Large Language Models to Represent Folktales in Low-Resource Languages",
      "summary": "Folktales are a rich resource of knowledge about the society and culture of a\ncivilisation. Digital folklore research aims to use automated techniques to\nbetter understand these folktales, and it relies on abstract representations of\nthe textual data. Although a number of large language models (LLMs) claim to be\nable to represent low-resource langauges such as Irish and Gaelic, we present\ntwo classification tasks to explore how useful these representations are, and\nthree adaptations to improve the performance of these models. We find that\nadapting the models to work with longer sequences, and continuing pre-training\non the domain of folktales improves classification performance, although these\nfindings are tempered by the impressive performance of a baseline SVM with\nnon-contextual features."
    },
    {
      "id": "2411.05591v1",
      "title": "Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning",
      "summary": "We systematically study various network Expectation-Maximization (EM)\nalgorithms for the Gaussian mixture model within the framework of decentralized\nfederated learning. Our theoretical investigation reveals that directly\nextending the classical decentralized supervised learning method to the EM\nalgorithm exhibits poor estimation accuracy with heterogeneous data across\nclients and struggles to converge numerically when Gaussian components are\npoorly-separated. To address these issues, we propose two novel solutions.\nFirst, to handle heterogeneous data, we introduce a momentum network EM (MNEM)\nalgorithm, which uses a momentum parameter to combine information from both the\ncurrent and historical estimators. Second, to tackle the challenge of\npoorly-separated Gaussian components, we develop a semi-supervised MNEM\n(semi-MNEM) algorithm, which leverages partially labeled data. Rigorous\ntheoretical analysis demonstrates that MNEM can achieve statistical efficiency\ncomparable to that of the whole sample estimator when the mixture components\nsatisfy certain separation conditions, even in heterogeneous scenarios.\nMoreover, the semi-MNEM estimator enhances the convergence speed of the MNEM\nalgorithm, effectively addressing the numerical convergence challenges in\npoorly-separated scenarios. Extensive simulation and real data analyses are\nconducted to justify our theoretical findings."
    },
    {
      "id": "2411.05894v1",
      "title": "SSSD: Simply-Scalable Speculative Decoding",
      "summary": "Over the past year, Speculative Decoding has gained popularity as a technique\nfor accelerating Large Language Model inference. While several methods have\nbeen introduced, most struggle to deliver satisfactory performance at batch\nsizes typical for data centers ($\\geq 8$) and often involve significant\ndeployment complexities. In this work, we offer a theoretical explanation of\nhow Speculative Decoding can be effectively utilized with larger batch sizes.\nWe also introduce a method that integrates seamlessly into existing systems\nwithout additional training or the complexity of deploying a small LLM. In a\ncontinuous batching setting, we achieve a 4x increase in throughput without any\nlatency impact for short context generation, and a 1.7-2x improvement in both\nlatency and throughput for longer contexts."
    },
    {
      "id": "2411.05586v1",
      "title": "Tangled Program Graphs as an alternative to DRL-based control algorithms for UAVs",
      "summary": "Deep reinforcement learning (DRL) is currently the most popular AI-based\napproach to autonomous vehicle control. An agent, trained for this purpose in\nsimulation, can interact with the real environment with a human-level\nperformance. Despite very good results in terms of selected metrics, this\napproach has some significant drawbacks: high computational requirements and\nlow explainability. Because of that, a DRL-based agent cannot be used in some\ncontrol tasks, especially when safety is the key issue. Therefore we propose to\nuse Tangled Program Graphs (TPGs) as an alternative for deep reinforcement\nlearning in control-related tasks. In this approach, input signals are\nprocessed by simple programs that are combined in a graph structure. As a\nresult, TPGs are less computationally demanding and their actions can be\nexplained based on the graph structure. In this paper, we present our studies\non the use of TPGs as an alternative for DRL in control-related tasks. In\nparticular, we consider the problem of navigating an unmanned aerial vehicle\n(UAV) through the unknown environment based solely on the on-board LiDAR\nsensor. The results of our work show promising prospects for the use of TPGs in\ncontrol related-tasks."
    },
    {
      "id": "2411.05575v1",
      "title": "Towards a Real-Time Simulation of Elastoplastic Deformation Using Multi-Task Neural Networks",
      "summary": "This study introduces a surrogate modeling framework merging proper\northogonal decomposition, long short-term memory networks, and multi-task\nlearning, to accurately predict elastoplastic deformations in real-time.\nSuperior to single-task neural networks, this approach achieves a mean absolute\nerror below 0.40\\% across various state variables, with the multi-task model\nshowing enhanced generalization by mitigating overfitting through shared\nlayers. Moreover, in our use cases, a pre-trained multi-task model can\neffectively train additional variables with as few as 20 samples, demonstrating\nits deep understanding of complex scenarios. This is notably efficient compared\nto single-task models, which typically require around 100 samples.\n  Significantly faster than traditional finite element analysis, our model\naccelerates computations by approximately a million times, making it a\nsubstantial advancement for real-time predictive modeling in engineering\napplications. While it necessitates further testing on more intricate models,\nthis framework shows substantial promise in elevating both efficiency and\naccuracy in engineering applications, particularly for real-time scenarios."
    },
    {
      "id": "2411.05565v1",
      "title": "Solving 7x7 Killall-Go with Seki Database",
      "summary": "Game solving is the process of finding the theoretical outcome for a game,\nassuming that all player choices are optimal. This paper focuses on a technique\nthat can reduce the heuristic search space significantly for 7x7 Killall-Go. In\nGo and Killall-Go, live patterns are stones that are protected from opponent\ncapture. Mutual life, also referred to as seki, is when both players' stones\nachieve life by sharing liberties with their opponent. Whichever player\nattempts to capture the opponent first will leave their own stones vulnerable.\nTherefore, it is critical to recognize seki patterns to avoid putting oneself\nin jeopardy. Recognizing seki can reduce the search depth significantly. In\nthis paper, we enumerate all seki patterns up to a predetermined area size,\nthen store these patterns into a seki table. This allows us to recognize seki\nduring search, which significantly improves solving efficiency for the game of\nKillall-Go. Experiments show that a day-long, unsolvable position can be solved\nin 482 seconds with the addition of a seki table. For general positions, a 10%\nto 20% improvement in wall clock time and node count is observed."
    },
    {
      "id": "2411.05564v1",
      "title": "Open-set object detection: towards unified problem formulation and benchmarking",
      "summary": "In real-world applications where confidence is key, like autonomous driving,\nthe accurate detection and appropriate handling of classes differing from those\nused during training are crucial. Despite the proposal of various unknown\nobject detection approaches, we have observed widespread inconsistencies among\nthem regarding the datasets, metrics, and scenarios used, alongside a notable\nabsence of a clear definition for unknown objects, which hampers meaningful\nevaluation. To counter these issues, we introduce two benchmarks: a unified\nVOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear\nhierarchical object definition besides new evaluation metrics. Complementing\nthe benchmark, we exploit recent self-supervised Vision Transformers\nperformance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD),\nthrough OW-DETR++. State-of-the-art methods are extensively evaluated on the\nproposed benchmarks. This study provides a clear problem definition, ensures\nconsistent evaluations, and draws new conclusions about effectiveness of OSOD\nstrategies."
    },
    {
      "id": "2411.05561v1",
      "title": "Training objective drives the consistency of representational similarity across datasets",
      "summary": "The Platonic Representation Hypothesis claims that recent foundation models\nare converging to a shared representation space as a function of their\ndownstream task performance, irrespective of the objectives and data modalities\nused to train these models. Representational similarity is generally measured\nfor individual datasets and is not necessarily consistent across datasets.\nThus, one may wonder whether this convergence of model representations is\nconfounded by the datasets commonly used in machine learning. Here, we propose\na systematic way to measure how representational similarity between models\nvaries with the set of stimuli used to construct the representations. We find\nthat the objective function is the most crucial factor in determining the\nconsistency of representational similarities across datasets. Specifically,\nself-supervised vision models learn representations whose relative pairwise\nsimilarities generalize better from one dataset to another compared to those of\nimage classification or image-text models. Moreover, the correspondence between\nrepresentational similarities and the models' task behavior is\ndataset-dependent, being most strongly pronounced for single-domain datasets.\nOur work provides a framework for systematically measuring similarities of\nmodel representations across datasets and linking those similarities to\ndifferences in task behavior."
    },
    {
      "id": "2411.05557v1",
      "title": "A Nerf-Based Color Consistency Method for Remote Sensing Images",
      "summary": "Due to different seasons, illumination, and atmospheric conditions, the\nphotometric of the acquired image varies greatly, which leads to obvious\nstitching seams at the edges of the mosaic image. Traditional methods can be\ndivided into two categories, one is absolute radiation correction and the other\nis relative radiation normalization. We propose a NeRF-based method of color\nconsistency correction for multi-view images, which weaves image features\ntogether using implicit expressions, and then re-illuminates feature space to\ngenerate a fusion image with a new perspective. We chose Superview-1 satellite\nimages and UAV images with large range and time difference for the experiment.\nExperimental results show that the synthesize image generated by our method has\nexcellent visual effect and smooth color transition at the edges."
    },
    {
      "id": "2411.05547v1",
      "title": "Assessing the Answerability of Queries in Retrieval-Augmented Code Generation",
      "summary": "Thanks to unprecedented language understanding and generation capabilities of\nlarge language model (LLM), Retrieval-augmented Code Generation (RaCG) has\nrecently been widely utilized among software developers. While this has\nincreased productivity, there are still frequent instances of incorrect codes\nbeing provided. In particular, there are cases where plausible yet incorrect\ncodes are generated for queries from users that cannot be answered with the\ngiven queries and API descriptions. This study proposes a task for evaluating\nanswerability, which assesses whether valid answers can be generated based on\nusers' queries and retrieved APIs in RaCG. Additionally, we build a benchmark\ndataset called Retrieval-augmented Code Generability Evaluation (RaCGEval) to\nevaluate the performance of models performing this task. Experimental results\nshow that this task remains at a very challenging level, with baseline models\nexhibiting a low performance of 46.7%. Furthermore, this study discusses\nmethods that could significantly improve performance."
    },
    {
      "id": "2411.05544v1",
      "title": "Towards Lifelong Few-Shot Customization of Text-to-Image Diffusion",
      "summary": "Lifelong few-shot customization for text-to-image diffusion aims to\ncontinually generalize existing models for new tasks with minimal data while\npreserving old knowledge. Current customization diffusion models excel in\nfew-shot tasks but struggle with catastrophic forgetting problems in lifelong\ngenerations. In this study, we identify and categorize the catastrophic\nforgetting problems into two folds: relevant concepts forgetting and previous\nconcepts forgetting. To address these challenges, we first devise a data-free\nknowledge distillation strategy to tackle relevant concepts forgetting. Unlike\nexisting methods that rely on additional real data or offline replay of\noriginal concept data, our approach enables on-the-fly knowledge distillation\nto retain the previous concepts while learning new ones, without accessing any\nprevious data. Second, we develop an In-Context Generation (ICGen) paradigm\nthat allows the diffusion model to be conditioned upon the input vision\ncontext, which facilitates the few-shot generation and mitigates the issue of\nprevious concepts forgetting. Extensive experiments show that the proposed\nLifelong Few-Shot Diffusion (LFS-Diffusion) method can produce high-quality and\naccurate images while maintaining previously learned knowledge."
    },
    {
      "id": "2411.05540v1",
      "title": "CRepair: CVAE-based Automatic Vulnerability Repair Technology",
      "summary": "Software vulnerabilities are flaws in computer software systems that pose\nsignificant threats to the integrity, security, and reliability of modern\nsoftware and its application data. These vulnerabilities can lead to\nsubstantial economic losses across various industries. Manual vulnerability\nrepair is not only time-consuming but also prone to errors. To address the\nchallenges of vulnerability repair, researchers have proposed various\nsolutions, with learning-based automatic vulnerability repair techniques\ngaining widespread attention. However, existing methods often focus on learning\nmore vulnerability data to improve repair outcomes, while neglecting the\ndiverse characteristics of vulnerable code, and suffer from imprecise\nvulnerability localization.To address these shortcomings, this paper proposes\nCRepair, a CVAE-based automatic vulnerability repair technology aimed at fixing\nsecurity vulnerabilities in system code. We first preprocess the vulnerability\ndata using a prompt-based method to serve as input to the model. Then, we apply\ncausal inference techniques to map the vulnerability feature data to\nprobability distributions. By employing multi-sample feature fusion, we capture\ndiverse vulnerability feature information. Finally, conditional control is used\nto guide the model in repairing the vulnerabilities.Experimental results\ndemonstrate that the proposed method significantly outperforms other benchmark\nmodels, achieving a perfect repair rate of 52%. The effectiveness of the\napproach is validated from multiple perspectives, advancing AI-driven code\nvulnerability repair and showing promising applications."
    },
    {
      "id": "2411.05536v1",
      "title": "Towards Active Flow Control Strategies Through Deep Reinforcement Learning",
      "summary": "This paper presents a deep reinforcement learning (DRL) framework for active\nflow control (AFC) to reduce drag in aerodynamic bodies. Tested on a 3D\ncylinder at Re = 100, the DRL approach achieved a 9.32% drag reduction and a\n78.4% decrease in lift oscillations by learning advanced actuation strategies.\nThe methodology integrates a CFD solver with a DRL model using an in-memory\ndatabase for efficient communication between"
    },
    {
      "id": "2411.05892v1",
      "title": "Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models",
      "summary": "This study explores the effectiveness of Large Language Models in meal\nplanning, focusing on their ability to identify and decompose compound\ningredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral\n(8x7b)-to assess their proficiency in recognizing and breaking down complex\ningredient combinations. Preliminary results indicate that while Llama-3 (70b)\nand GPT-4o excels in accurate decomposition, all models encounter difficulties\nwith identifying essential elements like seasonings and oils. Despite strong\noverall performance, variations in accuracy and completeness were observed\nacross models. These findings underscore LLMs' potential to enhance\npersonalized nutrition but highlight the need for further refinement in\ningredient decomposition. Future research should address these limitations to\nimprove nutritional recommendations and health outcomes."
    },
    {
      "id": "2411.05527v1",
      "title": "How Good is Your Wikipedia?",
      "summary": "Wikipedia's perceived high quality and broad language coverage have\nestablished it as a fundamental resource in multilingual NLP. In the context of\nlow-resource languages, however, these quality assumptions are increasingly\nbeing scrutinised. This paper critically examines the data quality of Wikipedia\nin a non-English setting by subjecting it to various quality filtering\ntechniques, revealing widespread issues such as a high percentage of one-line\narticles and duplicate articles. We evaluate the downstream impact of quality\nfiltering on Wikipedia and find that data quality pruning is an effective means\nfor resource-efficient training without hurting performance, especially for\nlow-resource languages. Moreover, we advocate for a shift in perspective from\nseeking a general definition of data quality towards a more language- and\ntask-specific one. Ultimately, we aim for this study to serve as a guide to\nusing Wikipedia for pretraining in a multilingual setting."
    },
    {
      "id": "2411.05521v2",
      "title": "SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark",
      "summary": "Electronic health records (EHRs) are stored in various database systems with\ndifferent database models on heterogeneous storage architectures, such as\nrelational databases, document stores, or graph databases. These different\ndatabase models have a big impact on query complexity and performance. While\nthis has been a known fact in database research, its implications for the\ngrowing number of Text-to-Query systems have surprisingly not been investigated\nso far. In this paper, we present SM3-Text-to-Query, the first multi-model\nmedical Text-to-Query benchmark based on synthetic patient data from Synthea,\nfollowing the SNOMED-CT taxonomy -- a widely used knowledge graph ontology\ncovering medical terminology. SM3-Text-to-Query provides data representations\nfor relational databases (PostgreSQL), document stores (MongoDB), and graph\ndatabases (Neo4j and GraphDB (RDF)), allowing the evaluation across four\npopular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically\nand manually develop 408 template questions, which we augment to construct a\nbenchmark of 10K diverse natural language question/query pairs for these four\nquery languages (40K pairs overall). On our dataset, we evaluate several common\nin-context-learning (ICL) approaches for a set of representative closed and\nopen-source LLMs. Our evaluation sheds light on the trade-offs between database\nmodels and query languages for different ICL strategies and LLMs. Last,\nSM3-Text-to-Query is easily extendable to additional query languages or real,\nstandard-based patient databases."
    }
  ],
  "links": [
    {
      "source": "2411.09702v1",
      "target": "2411.09453v1",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.09420v1",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.07501v2",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.06786v1",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.06657v1",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.07794v1",
      "weight": 1.0
    },
    {
      "source": "2411.09702v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.09694v1",
      "target": "2411.06710v1",
      "weight": 1.0
    },
    {
      "source": "2411.09689v1",
      "target": "2411.09255v1",
      "weight": 1.0
    },
    {
      "source": "2411.09689v1",
      "target": "2411.07870v2",
      "weight": 1.0
    },
    {
      "source": "2411.09689v1",
      "target": "2411.07457v1",
      "weight": 1.0
    },
    {
      "source": "2411.09688v1",
      "target": "2411.08982v1",
      "weight": 1.0
    },
    {
      "source": "2411.09688v1",
      "target": "2411.08610v1",
      "weight": 1.0
    },
    {
      "source": "2411.09688v1",
      "target": "2411.08147v1",
      "weight": 1.0
    },
    {
      "source": "2411.09688v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.09688v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.09688v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.09683v1",
      "target": "2411.09645v1",
      "weight": 1.0
    },
    {
      "source": "2411.09661v1",
      "target": "2411.08553v1",
      "weight": 1.0
    },
    {
      "source": "2411.09661v1",
      "target": "2411.07641v1",
      "weight": 1.0
    },
    {
      "source": "2411.09661v1",
      "target": "2411.06251v1",
      "weight": 1.0
    },
    {
      "source": "2411.09639v1",
      "target": "2411.08875v1",
      "weight": 1.0
    },
    {
      "source": "2411.09639v1",
      "target": "2411.08478v1",
      "weight": 1.0
    },
    {
      "source": "2411.09639v1",
      "target": "2411.06367v1",
      "weight": 1.0
    },
    {
      "source": "2411.09639v1",
      "target": "2411.06040v1",
      "weight": 1.0
    },
    {
      "source": "2411.09613v1",
      "target": "2411.09607v1",
      "weight": 1.0
    },
    {
      "source": "2411.09613v1",
      "target": "2411.09116v1",
      "weight": 1.0
    },
    {
      "source": "2411.09613v1",
      "target": "2411.08275v1",
      "weight": 1.0
    },
    {
      "source": "2411.09613v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.09613v1",
      "target": "2411.07466v1",
      "weight": 1.0
    },
    {
      "source": "2411.09612v1",
      "target": "2411.09214v1",
      "weight": 1.0
    },
    {
      "source": "2411.09612v1",
      "target": "2411.08347v1",
      "weight": 1.0
    },
    {
      "source": "2411.09612v1",
      "target": "2411.05958v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.09213v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.08438v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.08324v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.08275v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.07466v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.07140v2",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.09607v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.09604v1",
      "target": "2411.09453v1",
      "weight": 1.0
    },
    {
      "source": "2411.09604v1",
      "target": "2411.09420v1",
      "weight": 1.0
    },
    {
      "source": "2411.09604v1",
      "target": "2411.06869v1",
      "weight": 1.0
    },
    {
      "source": "2411.09604v1",
      "target": "2411.06836v1",
      "weight": 1.0
    },
    {
      "source": "2411.09587v1",
      "target": "2411.08868v1",
      "weight": 1.0
    },
    {
      "source": "2411.09587v1",
      "target": "2411.08610v1",
      "weight": 1.0
    },
    {
      "source": "2411.09587v1",
      "target": "2411.06672v1",
      "weight": 1.0
    },
    {
      "source": "2411.09576v1",
      "target": "2411.06409v1",
      "weight": 1.0
    },
    {
      "source": "2411.09558v1",
      "target": "2411.08755v1",
      "weight": 1.0
    },
    {
      "source": "2411.09558v1",
      "target": "2411.07574v1",
      "weight": 1.0
    },
    {
      "source": "2411.09558v1",
      "target": "2411.06406v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.09273v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.09266v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.09018v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.06018v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.05980v1",
      "weight": 1.0
    },
    {
      "source": "2411.09547v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.09116v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.09073v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08968v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08868v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08785v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08610v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08553v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08147v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07854v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07715v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07340v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07191v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07185v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07175v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07075v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.06710v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.06672v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.05945v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.09539v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.08181v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.08003v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.07690v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.07528v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.06837v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.09523v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.09512v1",
      "target": "2411.07941v1",
      "weight": 1.0
    },
    {
      "source": "2411.09512v1",
      "target": "2411.07348v1",
      "weight": 1.0
    },
    {
      "source": "2411.09510v1",
      "target": "2411.07942v1",
      "weight": 1.0
    },
    {
      "source": "2411.09510v1",
      "target": "2411.06465v1",
      "weight": 1.0
    },
    {
      "source": "2411.09510v1",
      "target": "2411.06371v1",
      "weight": 1.0
    },
    {
      "source": "2411.09510v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.09492v1",
      "target": "2411.09116v1",
      "weight": 1.0
    },
    {
      "source": "2411.09492v1",
      "target": "2411.07474v1",
      "weight": 1.0
    },
    {
      "source": "2411.09492v1",
      "target": "2411.07140v2",
      "weight": 1.0
    },
    {
      "source": "2411.09492v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.09492v1",
      "target": "2411.06839v1",
      "weight": 1.0
    },
    {
      "source": "2411.09476v1",
      "target": "2411.08764v1",
      "weight": 1.0
    },
    {
      "source": "2411.09476v1",
      "target": "2411.05631v1",
      "weight": 1.0
    },
    {
      "source": "2411.09475v1",
      "target": "2411.09199v1",
      "weight": 1.0
    },
    {
      "source": "2411.09475v1",
      "target": "2411.08224v1",
      "weight": 1.0
    },
    {
      "source": "2411.09475v1",
      "target": "2411.07501v2",
      "weight": 1.0
    },
    {
      "source": "2411.09475v1",
      "target": "2411.06916v1",
      "weight": 1.0
    },
    {
      "source": "2411.09475v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.09475v1",
      "target": "2411.06020v1",
      "weight": 1.0
    },
    {
      "source": "2411.09420v1",
      "target": "2411.08758v1",
      "weight": 1.0
    },
    {
      "source": "2411.09420v1",
      "target": "2411.06786v1",
      "weight": 1.0
    },
    {
      "source": "2411.09420v1",
      "target": "2411.07794v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.08552v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.07276v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.06919v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.06863v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.06650v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.06600v1",
      "weight": 1.0
    },
    {
      "source": "2411.09403v1",
      "target": "2411.06429v1",
      "weight": 1.0
    },
    {
      "source": "2411.09400v1",
      "target": "2411.09243v1",
      "weight": 1.0
    },
    {
      "source": "2411.09393v1",
      "target": "2411.07691v1",
      "weight": 1.0
    },
    {
      "source": "2411.09389v1",
      "target": "2411.06097v1",
      "weight": 1.0
    },
    {
      "source": "2411.09388v1",
      "target": "2411.05676v1",
      "weight": 1.0
    },
    {
      "source": "2411.09373v1",
      "target": "2411.06583v1",
      "weight": 1.0
    },
    {
      "source": "2411.09365v1",
      "target": "2411.07889v1",
      "weight": 1.0
    },
    {
      "source": "2411.09365v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.09365v1",
      "target": "2411.06135v1",
      "weight": 1.0
    },
    {
      "source": "2411.09365v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.09361v1",
      "target": "2411.09434v1",
      "weight": 1.0
    },
    {
      "source": "2411.09361v1",
      "target": "2411.07885v1",
      "weight": 1.0
    },
    {
      "source": "2411.09361v1",
      "target": "2411.07871v1",
      "weight": 1.0
    },
    {
      "source": "2411.09361v1",
      "target": "2411.06106v2",
      "weight": 1.0
    },
    {
      "source": "2411.09361v1",
      "target": "2411.05900v1",
      "weight": 1.0
    },
    {
      "source": "2411.09359v1",
      "target": "2411.07795v1",
      "weight": 1.0
    },
    {
      "source": "2411.09356v1",
      "target": "2411.09174v1",
      "weight": 1.0
    },
    {
      "source": "2411.09356v1",
      "target": "2411.08017v1",
      "weight": 1.0
    },
    {
      "source": "2411.09341v1",
      "target": "2411.08733v2",
      "weight": 1.0
    },
    {
      "source": "2411.09341v1",
      "target": "2411.08302v1",
      "weight": 1.0
    },
    {
      "source": "2411.09341v1",
      "target": "2411.07595v1",
      "weight": 1.0
    },
    {
      "source": "2411.09341v1",
      "target": "2411.07007v1",
      "weight": 1.0
    },
    {
      "source": "2411.09339v1",
      "target": "2411.07826v1",
      "weight": 1.0
    },
    {
      "source": "2411.09329v1",
      "target": "2411.08760v1",
      "weight": 1.0
    },
    {
      "source": "2411.09329v1",
      "target": "2411.06286v1",
      "weight": 1.0
    },
    {
      "source": "2411.09317v1",
      "target": "2411.07447v1",
      "weight": 1.0
    },
    {
      "source": "2411.09317v1",
      "target": "2411.08719v1",
      "weight": 1.0
    },
    {
      "source": "2411.09317v1",
      "target": "2411.06465v1",
      "weight": 1.0
    },
    {
      "source": "2411.09312v1",
      "target": "2411.07506v1",
      "weight": 1.0
    },
    {
      "source": "2411.09312v1",
      "target": "2411.07413v1",
      "weight": 1.0
    },
    {
      "source": "2411.09311v1",
      "target": "2411.05960v1",
      "weight": 1.0
    },
    {
      "source": "2411.09302v1",
      "target": "2411.09243v1",
      "weight": 1.0
    },
    {
      "source": "2411.09302v1",
      "target": "2411.06928v1",
      "weight": 1.0
    },
    {
      "source": "2411.09289v1",
      "target": "2411.09242v1",
      "weight": 1.0
    },
    {
      "source": "2411.09289v1",
      "target": "2411.08432v1",
      "weight": 1.0
    },
    {
      "source": "2411.09289v1",
      "target": "2411.07446v1",
      "weight": 1.0
    },
    {
      "source": "2411.09289v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.09289v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.09289v1",
      "target": "2411.05755v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.09266v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.09018v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.08666v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.08334v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.07975v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.07722v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.07516v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.07076v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.06908v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.06869v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.05903v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.05902v1",
      "weight": 1.0
    },
    {
      "source": "2411.09273v1",
      "target": "2411.05898v1",
      "weight": 1.0
    },
    {
      "source": "2411.09269v1",
      "target": "2411.06823v1",
      "weight": 1.0
    },
    {
      "source": "2411.09267v1",
      "target": "2411.07182v1",
      "weight": 1.0
    },
    {
      "source": "2411.09267v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.09266v1",
      "target": "2411.07650v1",
      "weight": 1.0
    },
    {
      "source": "2411.09266v1",
      "target": "2411.07076v1",
      "weight": 1.0
    },
    {
      "source": "2411.09266v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.09266v1",
      "target": "2411.05969v1",
      "weight": 1.0
    },
    {
      "source": "2411.09261v1",
      "target": "2411.08254v1",
      "weight": 1.0
    },
    {
      "source": "2411.09259v1",
      "target": "2411.09125v1",
      "weight": 1.0
    },
    {
      "source": "2411.09259v1",
      "target": "2411.07559v1",
      "weight": 1.0
    },
    {
      "source": "2411.09259v1",
      "target": "2411.07494v1",
      "weight": 1.0
    },
    {
      "source": "2411.09259v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.09018v1",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.08348v1",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.07870v2",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.07466v1",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.07457v1",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.06590v1",
      "weight": 1.0
    },
    {
      "source": "2411.09255v1",
      "target": "2411.06445v1",
      "weight": 1.0
    },
    {
      "source": "2411.09251v1",
      "target": "2411.07537v1",
      "weight": 1.0
    },
    {
      "source": "2411.09251v1",
      "target": "2411.06917v1",
      "weight": 1.0
    },
    {
      "source": "2411.09251v1",
      "target": "2411.06836v1",
      "weight": 1.0
    },
    {
      "source": "2411.09251v1",
      "target": "2411.06087v2",
      "weight": 1.0
    },
    {
      "source": "2411.09249v1",
      "target": "2411.08404v1",
      "weight": 1.0
    },
    {
      "source": "2411.09249v1",
      "target": "2411.06852v1",
      "weight": 1.0
    },
    {
      "source": "2411.09249v1",
      "target": "2411.06272v1",
      "weight": 1.0
    },
    {
      "source": "2411.09243v1",
      "target": "2411.09211v1",
      "weight": 1.0
    },
    {
      "source": "2411.09243v1",
      "target": "2411.06928v1",
      "weight": 1.0
    },
    {
      "source": "2411.09242v1",
      "target": "2411.08244v1",
      "weight": 1.0
    },
    {
      "source": "2411.09224v1",
      "target": "2411.08932v1",
      "weight": 1.0
    },
    {
      "source": "2411.09224v1",
      "target": "2411.07529v1",
      "weight": 1.0
    },
    {
      "source": "2411.09220v1",
      "target": "2411.07559v1",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.07417v1",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.06855v2",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.06850v1",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.06477v1",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.06248v1",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.06213v1",
      "weight": 1.0
    },
    {
      "source": "2411.09214v1",
      "target": "2411.05958v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.08870v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.08438v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.08324v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.07611v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.05897v1",
      "weight": 1.0
    },
    {
      "source": "2411.09213v1",
      "target": "2411.05547v1",
      "weight": 1.0
    },
    {
      "source": "2411.09210v1",
      "target": "2411.06600v1",
      "weight": 1.0
    },
    {
      "source": "2411.09204v1",
      "target": "2411.07941v1",
      "weight": 1.0
    },
    {
      "source": "2411.09199v1",
      "target": "2411.09127v1",
      "weight": 1.0
    },
    {
      "source": "2411.09199v1",
      "target": "2411.07501v2",
      "weight": 1.0
    },
    {
      "source": "2411.09199v1",
      "target": "2411.07066v1",
      "weight": 1.0
    },
    {
      "source": "2411.09199v1",
      "target": "2411.06463v1",
      "weight": 1.0
    },
    {
      "source": "2411.09189v1",
      "target": "2411.06326v1",
      "weight": 1.0
    },
    {
      "source": "2411.09180v1",
      "target": "2411.05633v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.09056v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.08791v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.08297v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.07889v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.07691v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.07468v2",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.07317v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.06624v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.06613v1",
      "weight": 1.0
    },
    {
      "source": "2411.09178v1",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.09175v1",
      "target": "2411.08085v1",
      "weight": 1.0
    },
    {
      "source": "2411.09175v1",
      "target": "2411.06078v1",
      "weight": 1.0
    },
    {
      "source": "2411.09174v1",
      "target": "2411.08034v2",
      "weight": 1.0
    },
    {
      "source": "2411.09174v1",
      "target": "2411.07348v1",
      "weight": 1.0
    },
    {
      "source": "2411.09174v1",
      "target": "2411.07199v1",
      "weight": 1.0
    },
    {
      "source": "2411.09174v1",
      "target": "2411.07126v1",
      "weight": 1.0
    },
    {
      "source": "2411.09169v1",
      "target": "2411.09168v1",
      "weight": 1.0
    },
    {
      "source": "2411.09166v1",
      "target": "2411.07152v1",
      "weight": 1.0
    },
    {
      "source": "2411.09127v1",
      "target": "2411.07066v1",
      "weight": 1.0
    },
    {
      "source": "2411.09127v1",
      "target": "2411.06463v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.08862v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.08248v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07858v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07843v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07559v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07528v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07494v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07122v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.09125v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.09073v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.08324v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.08275v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07854v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07715v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07474v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07466v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07464v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07336v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07127v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.06506v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.06272v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.06251v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.06151v1",
      "weight": 1.0
    },
    {
      "source": "2411.09116v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.09111v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.09105v1",
      "target": "2411.07516v1",
      "weight": 1.0
    },
    {
      "source": "2411.09105v1",
      "target": "2411.06908v1",
      "weight": 1.0
    },
    {
      "source": "2411.09077v1",
      "target": "2411.05633v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.08979v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.08745v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.08302v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.08147v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.07474v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.07464v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.09073v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.09065v1",
      "target": "2411.06374v1",
      "weight": 1.0
    },
    {
      "source": "2411.09065v1",
      "target": "2411.06046v1",
      "weight": 1.0
    },
    {
      "source": "2411.09064v1",
      "target": "2411.08791v1",
      "weight": 1.0
    },
    {
      "source": "2411.09064v1",
      "target": "2411.07094v1",
      "weight": 1.0
    },
    {
      "source": "2411.09056v1",
      "target": "2411.08425v1",
      "weight": 1.0
    },
    {
      "source": "2411.09056v1",
      "target": "2411.08297v1",
      "weight": 1.0
    },
    {
      "source": "2411.09056v1",
      "target": "2411.06624v1",
      "weight": 1.0
    },
    {
      "source": "2411.09056v1",
      "target": "2411.05648v1",
      "weight": 1.0
    },
    {
      "source": "2411.09055v1",
      "target": "2411.08699v1",
      "weight": 1.0
    },
    {
      "source": "2411.09055v1",
      "target": "2411.07391v1",
      "weight": 1.0
    },
    {
      "source": "2411.09055v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.09055v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.09052v1",
      "target": "2411.08432v1",
      "weight": 1.0
    },
    {
      "source": "2411.09052v1",
      "target": "2411.08027v1",
      "weight": 1.0
    },
    {
      "source": "2411.09052v1",
      "target": "2411.07223v1",
      "weight": 1.0
    },
    {
      "source": "2411.09052v1",
      "target": "2411.06048v1",
      "weight": 1.0
    },
    {
      "source": "2411.09052v1",
      "target": "2411.05755v1",
      "weight": 1.0
    },
    {
      "source": "2411.09047v1",
      "target": "2411.06406v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.08334v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.07975v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.07516v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.07076v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.06908v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.06869v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.06142v1",
      "weight": 1.0
    },
    {
      "source": "2411.09018v1",
      "target": "2411.05706v1",
      "weight": 1.0
    },
    {
      "source": "2411.09009v1",
      "target": "2411.08868v1",
      "weight": 1.0
    },
    {
      "source": "2411.09009v1",
      "target": "2411.06465v1",
      "weight": 1.0
    },
    {
      "source": "2411.09009v1",
      "target": "2411.06371v1",
      "weight": 1.0
    },
    {
      "source": "2411.09009v1",
      "target": "2411.06360v1",
      "weight": 1.0
    },
    {
      "source": "2411.09003v1",
      "target": "2411.08745v1",
      "weight": 1.0
    },
    {
      "source": "2411.08982v1",
      "target": "2411.08968v1",
      "weight": 1.0
    },
    {
      "source": "2411.08982v1",
      "target": "2411.08610v1",
      "weight": 1.0
    },
    {
      "source": "2411.08982v1",
      "target": "2411.07464v1",
      "weight": 1.0
    },
    {
      "source": "2411.08982v1",
      "target": "2411.07279v1",
      "weight": 1.0
    },
    {
      "source": "2411.08982v1",
      "target": "2411.05945v1",
      "weight": 1.0
    },
    {
      "source": "2411.08982v1",
      "target": "2411.05894v1",
      "weight": 1.0
    },
    {
      "source": "2411.08979v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.08979v1",
      "target": "2411.06767v1",
      "weight": 1.0
    },
    {
      "source": "2411.08977v1",
      "target": "2411.06213v1",
      "weight": 1.0
    },
    {
      "source": "2411.08975v1",
      "target": "2411.08936v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.08610v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.07618v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.07501v2",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.07447v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.07340v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.06672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08968v1",
      "target": "2411.06068v1",
      "weight": 1.0
    },
    {
      "source": "2411.08954v1",
      "target": "2411.08378v1",
      "weight": 1.0
    },
    {
      "source": "2411.08954v1",
      "target": "2411.06503v2",
      "weight": 1.0
    },
    {
      "source": "2411.08875v1",
      "target": "2411.08478v1",
      "weight": 1.0
    },
    {
      "source": "2411.08870v1",
      "target": "2411.08868v1",
      "weight": 1.0
    },
    {
      "source": "2411.08870v1",
      "target": "2411.06469v1",
      "weight": 1.0
    },
    {
      "source": "2411.08870v1",
      "target": "2411.05897v1",
      "weight": 1.0
    },
    {
      "source": "2411.08868v1",
      "target": "2411.07854v1",
      "weight": 1.0
    },
    {
      "source": "2411.08868v1",
      "target": "2411.07715v1",
      "weight": 1.0
    },
    {
      "source": "2411.08868v1",
      "target": "2411.06437v1",
      "weight": 1.0
    },
    {
      "source": "2411.08868v1",
      "target": "2411.05945v1",
      "weight": 1.0
    },
    {
      "source": "2411.08868v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.08868v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.08862v1",
      "target": "2411.07559v1",
      "weight": 1.0
    },
    {
      "source": "2411.08862v1",
      "target": "2411.07494v1",
      "weight": 1.0
    },
    {
      "source": "2411.08862v1",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.08862v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.08843v1",
      "target": "2411.07814v1",
      "weight": 1.0
    },
    {
      "source": "2411.08813v1",
      "target": "2411.05982v1",
      "weight": 1.0
    },
    {
      "source": "2411.08794v1",
      "target": "2411.08432v1",
      "weight": 1.0
    },
    {
      "source": "2411.08791v1",
      "target": "2411.07889v1",
      "weight": 1.0
    },
    {
      "source": "2411.08791v1",
      "target": "2411.07841v1",
      "weight": 1.0
    },
    {
      "source": "2411.08791v1",
      "target": "2411.07094v1",
      "weight": 1.0
    },
    {
      "source": "2411.08791v1",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.08768v1",
      "target": "2411.08409v1",
      "weight": 1.0
    },
    {
      "source": "2411.08768v1",
      "target": "2411.07223v1",
      "weight": 1.0
    },
    {
      "source": "2411.08760v1",
      "target": "2411.06286v1",
      "weight": 1.0
    },
    {
      "source": "2411.08758v1",
      "target": "2411.07672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08758v1",
      "target": "2411.07663v1",
      "weight": 1.0
    },
    {
      "source": "2411.08755v1",
      "target": "2411.06406v1",
      "weight": 1.0
    },
    {
      "source": "2411.08750v1",
      "target": "2411.06324v1",
      "weight": 1.0
    },
    {
      "source": "2411.08745v1",
      "target": "2411.08348v1",
      "weight": 1.0
    },
    {
      "source": "2411.08745v1",
      "target": "2411.07533v1",
      "weight": 1.0
    },
    {
      "source": "2411.08745v1",
      "target": "2411.07474v1",
      "weight": 1.0
    },
    {
      "source": "2411.08745v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.08739v1",
      "target": "2411.08687v1",
      "weight": 1.0
    },
    {
      "source": "2411.08739v1",
      "target": "2411.08197v1",
      "weight": 1.0
    },
    {
      "source": "2411.08739v1",
      "target": "2411.05561v1",
      "weight": 1.0
    },
    {
      "source": "2411.08733v2",
      "target": "2411.07618v1",
      "weight": 1.0
    },
    {
      "source": "2411.08733v2",
      "target": "2411.06208v1",
      "weight": 1.0
    },
    {
      "source": "2411.08728v1",
      "target": "2411.06565v1",
      "weight": 1.0
    },
    {
      "source": "2411.08728v1",
      "target": "2411.08063v1",
      "weight": 1.0
    },
    {
      "source": "2411.08726v1",
      "target": "2411.07560v1",
      "weight": 1.0
    },
    {
      "source": "2411.08708v1",
      "target": "2411.05895v1",
      "weight": 1.0
    },
    {
      "source": "2411.08706v1",
      "target": "2411.07279v1",
      "weight": 1.0
    },
    {
      "source": "2411.08706v1",
      "target": "2411.07107v1",
      "weight": 1.0
    },
    {
      "source": "2411.08703v1",
      "target": "2411.07611v1",
      "weight": 1.0
    },
    {
      "source": "2411.08703v1",
      "target": "2411.05900v1",
      "weight": 1.0
    },
    {
      "source": "2411.08703v1",
      "target": "2411.05597v1",
      "weight": 1.0
    },
    {
      "source": "2411.08699v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.08699v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.08687v1",
      "target": "2411.07983v1",
      "weight": 1.0
    },
    {
      "source": "2411.08687v1",
      "target": "2411.07150v1",
      "weight": 1.0
    },
    {
      "source": "2411.08687v1",
      "target": "2411.06363v1",
      "weight": 1.0
    },
    {
      "source": "2411.08687v1",
      "target": "2411.05561v1",
      "weight": 1.0
    },
    {
      "source": "2411.08666v1",
      "target": "2411.07975v1",
      "weight": 1.0
    },
    {
      "source": "2411.08666v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.08666v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.08666v1",
      "target": "2411.05902v1",
      "weight": 1.0
    },
    {
      "source": "2411.08664v1",
      "target": "2411.08414v1",
      "weight": 1.0
    },
    {
      "source": "2411.08652v1",
      "target": "2411.06268v1",
      "weight": 1.0
    },
    {
      "source": "2411.08638v1",
      "target": "2411.07672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08638v1",
      "target": "2411.07150v1",
      "weight": 1.0
    },
    {
      "source": "2411.08637v1",
      "target": "2411.08392v1",
      "weight": 1.0
    },
    {
      "source": "2411.08637v1",
      "target": "2411.07585v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.08553v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.07715v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.07340v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.07191v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.06710v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.06672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08610v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.08599v1",
      "target": "2411.08165v1",
      "weight": 1.0
    },
    {
      "source": "2411.08599v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.08599v1",
      "target": "2411.07466v1",
      "weight": 1.0
    },
    {
      "source": "2411.08937v1",
      "target": "2411.07483v1",
      "weight": 1.0
    },
    {
      "source": "2411.08563v1",
      "target": "2411.05892v1",
      "weight": 1.0
    },
    {
      "source": "2411.08562v1",
      "target": "2411.06916v1",
      "weight": 1.0
    },
    {
      "source": "2411.08562v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.08561v1",
      "target": "2411.08182v1",
      "weight": 1.0
    },
    {
      "source": "2411.08561v1",
      "target": "2411.07528v1",
      "weight": 1.0
    },
    {
      "source": "2411.08561v1",
      "target": "2411.07314v1",
      "weight": 1.0
    },
    {
      "source": "2411.08561v1",
      "target": "2411.07272v1",
      "weight": 1.0
    },
    {
      "source": "2411.08553v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.08553v1",
      "target": "2411.06722v1",
      "weight": 1.0
    },
    {
      "source": "2411.08553v1",
      "target": "2411.06251v1",
      "weight": 1.0
    },
    {
      "source": "2411.08552v1",
      "target": "2411.07276v1",
      "weight": 1.0
    },
    {
      "source": "2411.08552v1",
      "target": "2411.06919v1",
      "weight": 1.0
    },
    {
      "source": "2411.08552v1",
      "target": "2411.06863v1",
      "weight": 1.0
    },
    {
      "source": "2411.08552v1",
      "target": "2411.06650v1",
      "weight": 1.0
    },
    {
      "source": "2411.08550v1",
      "target": "2411.07672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08550v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.08936v1",
      "target": "2411.08530v1",
      "weight": 1.0
    },
    {
      "source": "2411.08506v1",
      "target": "2411.07528v1",
      "weight": 1.0
    },
    {
      "source": "2411.08506v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.08506v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.08478v1",
      "target": "2411.06367v1",
      "weight": 1.0
    },
    {
      "source": "2411.08469v1",
      "target": "2411.08463v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.08148v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.08133v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.08003v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.07691v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.07468v2",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.06613v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.05743v1",
      "weight": 1.0
    },
    {
      "source": "2411.08460v1",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.08449v1",
      "target": "2411.08165v1",
      "weight": 1.0
    },
    {
      "source": "2411.08449v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.08449v1",
      "target": "2411.05521v2",
      "weight": 1.0
    },
    {
      "source": "2411.08443v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.08275v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.08438v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.08432v1",
      "target": "2411.07464v1",
      "weight": 1.0
    },
    {
      "source": "2411.08432v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.08432v1",
      "target": "2411.06736v2",
      "weight": 1.0
    },
    {
      "source": "2411.08432v1",
      "target": "2411.06559v1",
      "weight": 1.0
    },
    {
      "source": "2411.08432v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.08425v1",
      "target": "2411.08297v1",
      "weight": 1.0
    },
    {
      "source": "2411.08425v1",
      "target": "2411.06624v1",
      "weight": 1.0
    },
    {
      "source": "2411.08425v1",
      "target": "2411.05648v1",
      "weight": 1.0
    },
    {
      "source": "2411.08414v1",
      "target": "2411.06804v1",
      "weight": 1.0
    },
    {
      "source": "2411.08414v1",
      "target": "2411.06565v1",
      "weight": 1.0
    },
    {
      "source": "2411.08404v1",
      "target": "2411.07142v1",
      "weight": 1.0
    },
    {
      "source": "2411.08404v1",
      "target": "2411.06852v1",
      "weight": 1.0
    },
    {
      "source": "2411.08404v1",
      "target": "2411.06272v1",
      "weight": 1.0
    },
    {
      "source": "2411.08404v1",
      "target": "2411.06076v1",
      "weight": 1.0
    },
    {
      "source": "2411.08400v1",
      "target": "2411.07104v2",
      "weight": 1.0
    },
    {
      "source": "2411.08392v1",
      "target": "2411.07200v1",
      "weight": 1.0
    },
    {
      "source": "2411.08384v1",
      "target": "2411.07213v1",
      "weight": 1.0
    },
    {
      "source": "2411.08378v1",
      "target": "2411.08326v1",
      "weight": 1.0
    },
    {
      "source": "2411.08374v1",
      "target": "2411.07672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08374v1",
      "target": "2411.07182v1",
      "weight": 1.0
    },
    {
      "source": "2411.08374v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.08374v1",
      "target": "2411.06070v1",
      "weight": 1.0
    },
    {
      "source": "2411.08355v1",
      "target": "2411.06501v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.08147v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.07870v2",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.07457v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.07404v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.08348v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.08347v1",
      "target": "2411.06160v1",
      "weight": 1.0
    },
    {
      "source": "2411.08344v1",
      "target": "2411.05945v1",
      "weight": 1.0
    },
    {
      "source": "2411.08335v1",
      "target": "2411.08171v1",
      "weight": 1.0
    },
    {
      "source": "2411.08334v1",
      "target": "2411.07516v1",
      "weight": 1.0
    },
    {
      "source": "2411.08334v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.08334v1",
      "target": "2411.07076v1",
      "weight": 1.0
    },
    {
      "source": "2411.08334v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.08334v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.08334v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.08275v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.08249v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.08147v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.07681v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.06469v1",
      "weight": 1.0
    },
    {
      "source": "2411.08324v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.08306v1",
      "target": "2411.06608v1",
      "weight": 1.0
    },
    {
      "source": "2411.08302v1",
      "target": "2411.07618v1",
      "weight": 1.0
    },
    {
      "source": "2411.08302v1",
      "target": "2411.07595v1",
      "weight": 1.0
    },
    {
      "source": "2411.08302v1",
      "target": "2411.05986v1",
      "weight": 1.0
    },
    {
      "source": "2411.08299v1",
      "target": "2411.05683v1",
      "weight": 1.0
    },
    {
      "source": "2411.08297v1",
      "target": "2411.06624v1",
      "weight": 1.0
    },
    {
      "source": "2411.08297v1",
      "target": "2411.05648v1",
      "weight": 1.0
    },
    {
      "source": "2411.08278v2",
      "target": "2411.08165v1",
      "weight": 1.0
    },
    {
      "source": "2411.08278v2",
      "target": "2411.07019v1",
      "weight": 1.0
    },
    {
      "source": "2411.08278v2",
      "target": "2411.06046v1",
      "weight": 1.0
    },
    {
      "source": "2411.08275v1",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.08275v1",
      "target": "2411.07127v1",
      "weight": 1.0
    },
    {
      "source": "2411.08275v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.08267v1",
      "target": "2411.06728v1",
      "weight": 1.0
    },
    {
      "source": "2411.08254v1",
      "target": "2411.07240v1",
      "weight": 1.0
    },
    {
      "source": "2411.08248v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.08248v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.08243v1",
      "target": "2411.08181v1",
      "weight": 1.0
    },
    {
      "source": "2411.08243v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.08243v1",
      "target": "2411.06899v1",
      "weight": 1.0
    },
    {
      "source": "2411.08243v1",
      "target": "2411.06528v1",
      "weight": 1.0
    },
    {
      "source": "2411.08243v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.08244v1",
      "target": "2411.07826v1",
      "weight": 1.0
    },
    {
      "source": "2411.08244v1",
      "target": "2411.06465v1",
      "weight": 1.0
    },
    {
      "source": "2411.08244v1",
      "target": "2411.06360v1",
      "weight": 1.0
    },
    {
      "source": "2411.08244v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.08232v1",
      "target": "2411.06965v1",
      "weight": 1.0
    },
    {
      "source": "2411.08227v1",
      "target": "2411.06353v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.07959v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.07413v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.07175v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.06916v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.06659v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.06618v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.08224v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.08221v1",
      "target": "2411.06792v1",
      "weight": 1.0
    },
    {
      "source": "2411.08197v1",
      "target": "2411.05561v1",
      "weight": 1.0
    },
    {
      "source": "2411.08187v1",
      "target": "2411.05757v2",
      "weight": 1.0
    },
    {
      "source": "2411.08182v1",
      "target": "2411.05982v1",
      "weight": 1.0
    },
    {
      "source": "2411.08171v1",
      "target": "2411.06202v1",
      "weight": 1.0
    },
    {
      "source": "2411.08167v1",
      "target": "2411.06501v1",
      "weight": 1.0
    },
    {
      "source": "2411.08165v1",
      "target": "2411.07820v2",
      "weight": 1.0
    },
    {
      "source": "2411.08165v1",
      "target": "2411.07019v1",
      "weight": 1.0
    },
    {
      "source": "2411.08165v1",
      "target": "2411.06866v1",
      "weight": 1.0
    },
    {
      "source": "2411.08165v1",
      "target": "2411.06660v1",
      "weight": 1.0
    },
    {
      "source": "2411.08165v1",
      "target": "2411.06191v1",
      "weight": 1.0
    },
    {
      "source": "2411.08165v1",
      "target": "2411.06046v1",
      "weight": 1.0
    },
    {
      "source": "2411.08164v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.08164v1",
      "target": "2411.06212v1",
      "weight": 1.0
    },
    {
      "source": "2411.08148v1",
      "target": "2411.06146v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.08028v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07858v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07681v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07466v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07404v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07279v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07237v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07213v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07175v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06899v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06655v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06387v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.06018v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.08147v1",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.08034v2",
      "target": "2411.06119v1",
      "weight": 1.0
    },
    {
      "source": "2411.08033v1",
      "target": "2411.08017v1",
      "weight": 1.0
    },
    {
      "source": "2411.08033v1",
      "target": "2411.07135v1",
      "weight": 1.0
    },
    {
      "source": "2411.08033v1",
      "target": "2411.06041v1",
      "weight": 1.0
    },
    {
      "source": "2411.08028v1",
      "target": "2411.07715v1",
      "weight": 1.0
    },
    {
      "source": "2411.08028v1",
      "target": "2411.07191v1",
      "weight": 1.0
    },
    {
      "source": "2411.08028v1",
      "target": "2411.07175v1",
      "weight": 1.0
    },
    {
      "source": "2411.08028v1",
      "target": "2411.06672v1",
      "weight": 1.0
    },
    {
      "source": "2411.08028v1",
      "target": "2411.06200v1",
      "weight": 1.0
    },
    {
      "source": "2411.08019v1",
      "target": "2411.07180v1",
      "weight": 1.0
    },
    {
      "source": "2411.08019v1",
      "target": "2411.06590v1",
      "weight": 1.0
    },
    {
      "source": "2411.08003v1",
      "target": "2411.07843v1",
      "weight": 1.0
    },
    {
      "source": "2411.08003v1",
      "target": "2411.07691v1",
      "weight": 1.0
    },
    {
      "source": "2411.08003v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.08003v1",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.08003v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.07990v1",
      "target": "2411.07533v1",
      "weight": 1.0
    },
    {
      "source": "2411.07983v1",
      "target": "2411.05561v1",
      "weight": 1.0
    },
    {
      "source": "2411.07979v2",
      "target": "2411.08085v1",
      "weight": 1.0
    },
    {
      "source": "2411.07979v2",
      "target": "2411.06848v1",
      "weight": 1.0
    },
    {
      "source": "2411.07979v2",
      "target": "2411.06770v2",
      "weight": 1.0
    },
    {
      "source": "2411.07979v2",
      "target": "2411.05746v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.07854v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.07516v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.07501v2",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.07132v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.06657v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.07794v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.06142v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.05902v1",
      "weight": 1.0
    },
    {
      "source": "2411.07975v1",
      "target": "2411.05691v1",
      "weight": 1.0
    },
    {
      "source": "2411.07971v1",
      "target": "2411.07087v2",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.07182v1",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.07175v1",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.06916v1",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.06770v2",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.06618v1",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.07959v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.07954v2",
      "target": "2411.06736v2",
      "weight": 1.0
    },
    {
      "source": "2411.07942v1",
      "target": "2411.06371v1",
      "weight": 1.0
    },
    {
      "source": "2411.07942v1",
      "target": "2411.06360v1",
      "weight": 1.0
    },
    {
      "source": "2411.07942v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.07941v1",
      "target": "2411.05771v1",
      "weight": 1.0
    },
    {
      "source": "2411.07934v2",
      "target": "2411.06815v1",
      "weight": 1.0
    },
    {
      "source": "2411.08085v1",
      "target": "2411.06728v1",
      "weight": 1.0
    },
    {
      "source": "2411.08085v1",
      "target": "2411.06367v1",
      "weight": 1.0
    },
    {
      "source": "2411.08085v1",
      "target": "2411.06098v2",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.07841v1",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.07816v1",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.07806v1",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.07468v2",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.06881v1",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.06263v1",
      "weight": 1.0
    },
    {
      "source": "2411.07889v1",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.07870v2",
      "target": "2411.07457v1",
      "weight": 1.0
    },
    {
      "source": "2411.07870v2",
      "target": "2411.07122v1",
      "weight": 1.0
    },
    {
      "source": "2411.07870v2",
      "target": "2411.06549v1",
      "weight": 1.0
    },
    {
      "source": "2411.07870v2",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07863v1",
      "target": "2411.06836v1",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.07457v1",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.07404v1",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.07133v2",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.05665v1",
      "weight": 1.0
    },
    {
      "source": "2411.07858v1",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.07854v1",
      "target": "2411.07715v1",
      "weight": 1.0
    },
    {
      "source": "2411.07854v1",
      "target": "2411.06506v1",
      "weight": 1.0
    },
    {
      "source": "2411.07850v1",
      "target": "2411.05958v1",
      "weight": 1.0
    },
    {
      "source": "2411.07843v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.07841v1",
      "target": "2411.07816v1",
      "weight": 1.0
    },
    {
      "source": "2411.07841v1",
      "target": "2411.07806v1",
      "weight": 1.0
    },
    {
      "source": "2411.07841v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.07837v1",
      "target": "2411.07340v1",
      "weight": 1.0
    },
    {
      "source": "2411.07826v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.07773v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06524v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07820v2",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07816v1",
      "target": "2411.07391v1",
      "weight": 1.0
    },
    {
      "source": "2411.07816v1",
      "target": "2411.07182v1",
      "weight": 1.0
    },
    {
      "source": "2411.07816v1",
      "target": "2411.06881v1",
      "weight": 1.0
    },
    {
      "source": "2411.07816v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.07816v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.07806v1",
      "target": "2411.07391v1",
      "weight": 1.0
    },
    {
      "source": "2411.07806v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.07806v1",
      "target": "2411.06263v1",
      "weight": 1.0
    },
    {
      "source": "2411.07806v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07598v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07446v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07404v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07396v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07279v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07237v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07075v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.06524v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.05991v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.07773v1",
      "target": "2411.05547v1",
      "weight": 1.0
    },
    {
      "source": "2411.07762v1",
      "target": "2411.07191v1",
      "weight": 1.0
    },
    {
      "source": "2411.07762v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.07760v1",
      "target": "2411.06174v1",
      "weight": 1.0
    },
    {
      "source": "2411.07759v1",
      "target": "2411.06601v1",
      "weight": 1.0
    },
    {
      "source": "2411.07759v1",
      "target": "2411.07271v1",
      "weight": 1.0
    },
    {
      "source": "2411.07724v1",
      "target": "2411.07061v1",
      "weight": 1.0
    },
    {
      "source": "2411.07715v1",
      "target": "2411.06068v1",
      "weight": 1.0
    },
    {
      "source": "2411.07715v1",
      "target": "2411.05945v1",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.07528v1",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.07494v1",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.07468v2",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.06613v1",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.07691v1",
      "target": "2411.05743v1",
      "weight": 1.0
    },
    {
      "source": "2411.07688v1",
      "target": "2411.06142v1",
      "weight": 1.0
    },
    {
      "source": "2411.07688v1",
      "target": "2411.06074v1",
      "weight": 1.0
    },
    {
      "source": "2411.07681v1",
      "target": "2411.07279v1",
      "weight": 1.0
    },
    {
      "source": "2411.07681v1",
      "target": "2411.07175v1",
      "weight": 1.0
    },
    {
      "source": "2411.07681v1",
      "target": "2411.07133v2",
      "weight": 1.0
    },
    {
      "source": "2411.07681v1",
      "target": "2411.06655v1",
      "weight": 1.0
    },
    {
      "source": "2411.07681v1",
      "target": "2411.06198v1",
      "weight": 1.0
    },
    {
      "source": "2411.07681v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.07672v1",
      "target": "2411.07663v1",
      "weight": 1.0
    },
    {
      "source": "2411.07672v1",
      "target": "2411.07150v1",
      "weight": 1.0
    },
    {
      "source": "2411.07672v1",
      "target": "2411.07123v1",
      "weight": 1.0
    },
    {
      "source": "2411.07672v1",
      "target": "2411.06634v1",
      "weight": 1.0
    },
    {
      "source": "2411.07672v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.07672v1",
      "target": "2411.06070v1",
      "weight": 1.0
    },
    {
      "source": "2411.07663v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.07663v1",
      "target": "2411.06212v1",
      "weight": 1.0
    },
    {
      "source": "2411.07663v1",
      "target": "2411.05742v1",
      "weight": 1.0
    },
    {
      "source": "2411.07650v1",
      "target": "2411.05969v1",
      "weight": 1.0
    },
    {
      "source": "2411.07641v1",
      "target": "2411.07191v1",
      "weight": 1.0
    },
    {
      "source": "2411.07641v1",
      "target": "2411.06251v1",
      "weight": 1.0
    },
    {
      "source": "2411.07634v1",
      "target": "2411.05614v1",
      "weight": 1.0
    },
    {
      "source": "2411.07611v1",
      "target": "2411.07163v1",
      "weight": 1.0
    },
    {
      "source": "2411.07611v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.07591v1",
      "target": "2411.07087v2",
      "weight": 1.0
    },
    {
      "source": "2411.07586v1",
      "target": "2411.06767v1",
      "weight": 1.0
    },
    {
      "source": "2411.07586v1",
      "target": "2411.06638v1",
      "weight": 1.0
    },
    {
      "source": "2411.07586v1",
      "target": "2411.05540v1",
      "weight": 1.0
    },
    {
      "source": "2411.07585v1",
      "target": "2411.06389v1",
      "weight": 1.0
    },
    {
      "source": "2411.07574v1",
      "target": "2411.06406v1",
      "weight": 1.0
    },
    {
      "source": "2411.07560v1",
      "target": "2411.06076v1",
      "weight": 1.0
    },
    {
      "source": "2411.07559v1",
      "target": "2411.07494v1",
      "weight": 1.0
    },
    {
      "source": "2411.07559v1",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.07559v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.07559v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.07546v1",
      "target": "2411.07527v1",
      "weight": 1.0
    },
    {
      "source": "2411.07538v1",
      "target": "2411.06646v1",
      "weight": 1.0
    },
    {
      "source": "2411.07537v1",
      "target": "2411.06214v1",
      "weight": 1.0
    },
    {
      "source": "2411.07537v1",
      "target": "2411.05618v1",
      "weight": 1.0
    },
    {
      "source": "2411.07533v1",
      "target": "2411.07474v1",
      "weight": 1.0
    },
    {
      "source": "2411.07533v1",
      "target": "2411.06096v1",
      "weight": 1.0
    },
    {
      "source": "2411.07528v1",
      "target": "2411.07519v1",
      "weight": 1.0
    },
    {
      "source": "2411.07528v1",
      "target": "2411.07224v1",
      "weight": 1.0
    },
    {
      "source": "2411.07528v1",
      "target": "2411.07089v1",
      "weight": 1.0
    },
    {
      "source": "2411.07528v1",
      "target": "2411.07070v2",
      "weight": 1.0
    },
    {
      "source": "2411.07528v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.07528v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.07461v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.07076v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.06908v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.06142v1",
      "weight": 1.0
    },
    {
      "source": "2411.07516v1",
      "target": "2411.05898v1",
      "weight": 1.0
    },
    {
      "source": "2411.07514v1",
      "target": "2411.06815v1",
      "weight": 1.0
    },
    {
      "source": "2411.07501v2",
      "target": "2411.06786v1",
      "weight": 1.0
    },
    {
      "source": "2411.07501v2",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.07501v2",
      "target": "2411.06657v1",
      "weight": 1.0
    },
    {
      "source": "2411.07501v2",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.07494v1",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.07494v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.07494v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.07483v1",
      "target": "2411.06448v1",
      "weight": 1.0
    },
    {
      "source": "2411.07474v1",
      "target": "2411.07140v2",
      "weight": 1.0
    },
    {
      "source": "2411.07474v1",
      "target": "2411.06096v1",
      "weight": 1.0
    },
    {
      "source": "2411.07474v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.07468v2",
      "target": "2411.06613v1",
      "weight": 1.0
    },
    {
      "source": "2411.07468v2",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.07466v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.07466v1",
      "target": "2411.07127v1",
      "weight": 1.0
    },
    {
      "source": "2411.07466v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07466v1",
      "target": "2411.05980v1",
      "weight": 1.0
    },
    {
      "source": "2411.07466v1",
      "target": "2411.05781v1",
      "weight": 1.0
    },
    {
      "source": "2411.07466v1",
      "target": "2411.05895v1",
      "weight": 1.0
    },
    {
      "source": "2411.07464v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.07461v1",
      "target": "2411.07076v1",
      "weight": 1.0
    },
    {
      "source": "2411.07461v1",
      "target": "2411.06908v1",
      "weight": 1.0
    },
    {
      "source": "2411.07461v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.07461v1",
      "target": "2411.06869v1",
      "weight": 1.0
    },
    {
      "source": "2411.07461v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.07461v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.07457v1",
      "target": "2411.07180v1",
      "weight": 1.0
    },
    {
      "source": "2411.07457v1",
      "target": "2411.06590v1",
      "weight": 1.0
    },
    {
      "source": "2411.07453v1",
      "target": "2411.06765v1",
      "weight": 1.0
    },
    {
      "source": "2411.07447v1",
      "target": "2411.06465v1",
      "weight": 1.0
    },
    {
      "source": "2411.07446v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07432v1",
      "target": "2411.07150v1",
      "weight": 1.0
    },
    {
      "source": "2411.07426v1",
      "target": "2411.07376v1",
      "weight": 1.0
    },
    {
      "source": "2411.07417v1",
      "target": "2411.06855v2",
      "weight": 1.0
    },
    {
      "source": "2411.07417v1",
      "target": "2411.06213v1",
      "weight": 1.0
    },
    {
      "source": "2411.07413v1",
      "target": "2411.06618v1",
      "weight": 1.0
    },
    {
      "source": "2411.07407v1",
      "target": "2411.07300v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.07237v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.07213v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07404v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.07075v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07396v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07392v1",
      "target": "2411.06353v1",
      "weight": 1.0
    },
    {
      "source": "2411.07392v1",
      "target": "2411.05564v1",
      "weight": 1.0
    },
    {
      "source": "2411.07391v1",
      "target": "2411.07182v1",
      "weight": 1.0
    },
    {
      "source": "2411.07391v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.07391v1",
      "target": "2411.06263v1",
      "weight": 1.0
    },
    {
      "source": "2411.07391v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.07340v1",
      "target": "2411.07191v1",
      "weight": 1.0
    },
    {
      "source": "2411.07340v1",
      "target": "2411.06646v1",
      "weight": 1.0
    },
    {
      "source": "2411.07317v1",
      "target": "2411.06549v1",
      "weight": 1.0
    },
    {
      "source": "2411.07314v1",
      "target": "2411.07272v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.07240v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.07107v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.06655v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.06198v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.06018v1",
      "weight": 1.0
    },
    {
      "source": "2411.07279v1",
      "target": "2411.05665v1",
      "weight": 1.0
    },
    {
      "source": "2411.07240v1",
      "target": "2411.06198v1",
      "weight": 1.0
    },
    {
      "source": "2411.07238v1",
      "target": "2411.07111v1",
      "weight": 1.0
    },
    {
      "source": "2411.07237v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07237v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.07232v2",
      "target": "2411.07199v1",
      "weight": 1.0
    },
    {
      "source": "2411.07232v2",
      "target": "2411.07132v1",
      "weight": 1.0
    },
    {
      "source": "2411.07232v2",
      "target": "2411.05706v1",
      "weight": 1.0
    },
    {
      "source": "2411.07223v1",
      "target": "2411.06736v2",
      "weight": 1.0
    },
    {
      "source": "2411.07223v1",
      "target": "2411.06174v1",
      "weight": 1.0
    },
    {
      "source": "2411.07223v1",
      "target": "2411.05927v1",
      "weight": 1.0
    },
    {
      "source": "2411.07223v1",
      "target": "2411.05755v1",
      "weight": 1.0
    },
    {
      "source": "2411.07213v1",
      "target": "2411.07130v1",
      "weight": 1.0
    },
    {
      "source": "2411.07213v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07213v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.07207v2",
      "target": "2411.06917v1",
      "weight": 1.0
    },
    {
      "source": "2411.07207v2",
      "target": "2411.06500v1",
      "weight": 1.0
    },
    {
      "source": "2411.07191v1",
      "target": "2411.06506v1",
      "weight": 1.0
    },
    {
      "source": "2411.07191v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.07191v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.07191v1",
      "target": "2411.05665v1",
      "weight": 1.0
    },
    {
      "source": "2411.07185v1",
      "target": "2411.06070v1",
      "weight": 1.0
    },
    {
      "source": "2411.07182v1",
      "target": "2411.06881v1",
      "weight": 1.0
    },
    {
      "source": "2411.07182v1",
      "target": "2411.06770v2",
      "weight": 1.0
    },
    {
      "source": "2411.07182v1",
      "target": "2411.06618v1",
      "weight": 1.0
    },
    {
      "source": "2411.07182v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.07182v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.07182v1",
      "target": "2411.05697v1",
      "weight": 1.0
    },
    {
      "source": "2411.07180v1",
      "target": "2411.06590v1",
      "weight": 1.0
    },
    {
      "source": "2411.07176v2",
      "target": "2411.07132v1",
      "weight": 1.0
    },
    {
      "source": "2411.07176v2",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.07175v1",
      "target": "2411.06916v1",
      "weight": 1.0
    },
    {
      "source": "2411.07175v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07175v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.07175v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.07171v1",
      "target": "2411.05979v1",
      "weight": 1.0
    },
    {
      "source": "2411.07171v1",
      "target": "2411.05661v1",
      "weight": 1.0
    },
    {
      "source": "2411.07163v1",
      "target": "2411.05958v1",
      "weight": 1.0
    },
    {
      "source": "2411.07152v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07150v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.07142v1",
      "target": "2411.06852v1",
      "weight": 1.0
    },
    {
      "source": "2411.07142v1",
      "target": "2411.06272v1",
      "weight": 1.0
    },
    {
      "source": "2411.07142v1",
      "target": "2411.07264v1",
      "weight": 1.0
    },
    {
      "source": "2411.07140v2",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07140v2",
      "target": "2411.06096v1",
      "weight": 1.0
    },
    {
      "source": "2411.07140v2",
      "target": "2411.05980v1",
      "weight": 1.0
    },
    {
      "source": "2411.07140v2",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.07133v2",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07133v2",
      "target": "2411.06208v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.07075v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.07037v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.06018v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.07130v1",
      "target": "2411.05903v1",
      "weight": 1.0
    },
    {
      "source": "2411.07127v1",
      "target": "2411.06590v1",
      "weight": 1.0
    },
    {
      "source": "2411.07127v1",
      "target": "2411.06445v1",
      "weight": 1.0
    },
    {
      "source": "2411.07122v1",
      "target": "2411.06248v1",
      "weight": 1.0
    },
    {
      "source": "2411.07120v1",
      "target": "2411.07102v1",
      "weight": 1.0
    },
    {
      "source": "2411.07120v1",
      "target": "2411.06770v2",
      "weight": 1.0
    },
    {
      "source": "2411.07104v2",
      "target": "2411.06782v1",
      "weight": 1.0
    },
    {
      "source": "2411.07102v1",
      "target": "2411.07061v1",
      "weight": 1.0
    },
    {
      "source": "2411.07086v1",
      "target": "2411.06773v1",
      "weight": 1.0
    },
    {
      "source": "2411.07076v1",
      "target": "2411.06908v1",
      "weight": 1.0
    },
    {
      "source": "2411.07076v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.07076v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.07076v1",
      "target": "2411.05679v1",
      "weight": 1.0
    },
    {
      "source": "2411.07075v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.07075v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.07075v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.07070v2",
      "target": "2411.06835v1",
      "weight": 1.0
    },
    {
      "source": "2411.07070v2",
      "target": "2411.05743v1",
      "weight": 1.0
    },
    {
      "source": "2411.07276v1",
      "target": "2411.06919v1",
      "weight": 1.0
    },
    {
      "source": "2411.07276v1",
      "target": "2411.06863v1",
      "weight": 1.0
    },
    {
      "source": "2411.07276v1",
      "target": "2411.06650v1",
      "weight": 1.0
    },
    {
      "source": "2411.07276v1",
      "target": "2411.06600v1",
      "weight": 1.0
    },
    {
      "source": "2411.07061v1",
      "target": "2411.06573v1",
      "weight": 1.0
    },
    {
      "source": "2411.07061v1",
      "target": "2411.06333v1",
      "weight": 1.0
    },
    {
      "source": "2411.07043v1",
      "target": "2411.05983v1",
      "weight": 1.0
    },
    {
      "source": "2411.07037v1",
      "target": "2411.06899v1",
      "weight": 1.0
    },
    {
      "source": "2411.07037v1",
      "target": "2411.06805v1",
      "weight": 1.0
    },
    {
      "source": "2411.07037v1",
      "target": "2411.06208v1",
      "weight": 1.0
    },
    {
      "source": "2411.07037v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.07019v1",
      "target": "2411.06660v1",
      "weight": 1.0
    },
    {
      "source": "2411.07019v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.07019v1",
      "target": "2411.06191v1",
      "weight": 1.0
    },
    {
      "source": "2411.07006v1",
      "target": "2411.05625v1",
      "weight": 1.0
    },
    {
      "source": "2411.06946v1",
      "target": "2411.06469v1",
      "weight": 1.0
    },
    {
      "source": "2411.06946v1",
      "target": "2411.05897v1",
      "weight": 1.0
    },
    {
      "source": "2411.06919v1",
      "target": "2411.06863v1",
      "weight": 1.0
    },
    {
      "source": "2411.06919v1",
      "target": "2411.06650v1",
      "weight": 1.0
    },
    {
      "source": "2411.06919v1",
      "target": "2411.06600v1",
      "weight": 1.0
    },
    {
      "source": "2411.06917v1",
      "target": "2411.06836v1",
      "weight": 1.0
    },
    {
      "source": "2411.06917v1",
      "target": "2411.06087v2",
      "weight": 1.0
    },
    {
      "source": "2411.06916v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.06916v1",
      "target": "2411.06659v1",
      "weight": 1.0
    },
    {
      "source": "2411.06916v1",
      "target": "2411.06618v1",
      "weight": 1.0
    },
    {
      "source": "2411.06916v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.06916v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.06916v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.06908v1",
      "target": "2411.06872v1",
      "weight": 1.0
    },
    {
      "source": "2411.06881v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.06881v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.06872v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.06872v1",
      "target": "2411.05679v1",
      "weight": 1.0
    },
    {
      "source": "2411.06869v1",
      "target": "2411.06284v1",
      "weight": 1.0
    },
    {
      "source": "2411.06869v1",
      "target": "2411.06176v1",
      "weight": 1.0
    },
    {
      "source": "2411.06869v1",
      "target": "2411.06048v1",
      "weight": 1.0
    },
    {
      "source": "2411.06855v2",
      "target": "2411.06850v1",
      "weight": 1.0
    },
    {
      "source": "2411.06855v2",
      "target": "2411.06213v1",
      "weight": 1.0
    },
    {
      "source": "2411.06855v2",
      "target": "2411.06138v1",
      "weight": 1.0
    },
    {
      "source": "2411.06855v2",
      "target": "2411.05958v1",
      "weight": 1.0
    },
    {
      "source": "2411.06852v1",
      "target": "2411.06272v1",
      "weight": 1.0
    },
    {
      "source": "2411.06852v1",
      "target": "2411.07264v1",
      "weight": 1.0
    },
    {
      "source": "2411.06850v1",
      "target": "2411.06213v1",
      "weight": 1.0
    },
    {
      "source": "2411.06839v1",
      "target": "2411.06448v1",
      "weight": 1.0
    },
    {
      "source": "2411.06836v1",
      "target": "2411.06087v2",
      "weight": 1.0
    },
    {
      "source": "2411.06836v1",
      "target": "2411.05927v1",
      "weight": 1.0
    },
    {
      "source": "2411.06835v1",
      "target": "2411.06426v1",
      "weight": 1.0
    },
    {
      "source": "2411.06805v1",
      "target": "2411.06237v1",
      "weight": 1.0
    },
    {
      "source": "2411.06805v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.06805v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.06805v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.06805v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.06798v1",
      "target": "2411.05966v1",
      "weight": 1.0
    },
    {
      "source": "2411.06786v1",
      "target": "2411.06764v1",
      "weight": 1.0
    },
    {
      "source": "2411.06786v1",
      "target": "2411.07794v1",
      "weight": 1.0
    },
    {
      "source": "2411.06773v1",
      "target": "2411.06263v1",
      "weight": 1.0
    },
    {
      "source": "2411.06772v1",
      "target": "2411.06749v1",
      "weight": 1.0
    },
    {
      "source": "2411.06772v1",
      "target": "2411.05638v1",
      "weight": 1.0
    },
    {
      "source": "2411.06767v1",
      "target": "2411.06638v1",
      "weight": 1.0
    },
    {
      "source": "2411.06764v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.06764v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.06764v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.06739v1",
      "target": "2411.06501v1",
      "weight": 1.0
    },
    {
      "source": "2411.06739v1",
      "target": "2411.06329v1",
      "weight": 1.0
    },
    {
      "source": "2411.06739v1",
      "target": "2411.06069v1",
      "weight": 1.0
    },
    {
      "source": "2411.06739v1",
      "target": "2411.05979v1",
      "weight": 1.0
    },
    {
      "source": "2411.06735v1",
      "target": "2411.06616v1",
      "weight": 1.0
    },
    {
      "source": "2411.06697v1",
      "target": "2411.05708v1",
      "weight": 1.0
    },
    {
      "source": "2411.06685v1",
      "target": "2411.06442v1",
      "weight": 1.0
    },
    {
      "source": "2411.06660v1",
      "target": "2411.07269v1",
      "weight": 1.0
    },
    {
      "source": "2411.06660v1",
      "target": "2411.06191v1",
      "weight": 1.0
    },
    {
      "source": "2411.06659v1",
      "target": "2411.06634v1",
      "weight": 1.0
    },
    {
      "source": "2411.06657v1",
      "target": "2411.06142v1",
      "weight": 1.0
    },
    {
      "source": "2411.06655v1",
      "target": "2411.06018v1",
      "weight": 1.0
    },
    {
      "source": "2411.06655v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.06650v1",
      "target": "2411.06429v1",
      "weight": 1.0
    },
    {
      "source": "2411.06635v2",
      "target": "2411.05900v1",
      "weight": 1.0
    },
    {
      "source": "2411.06624v1",
      "target": "2411.05648v1",
      "weight": 1.0
    },
    {
      "source": "2411.06618v1",
      "target": "2411.06352v1",
      "weight": 1.0
    },
    {
      "source": "2411.06618v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.06618v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.06618v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.07794v1",
      "target": "2411.05927v1",
      "weight": 1.0
    },
    {
      "source": "2411.06613v1",
      "target": "2411.05743v1",
      "weight": 1.0
    },
    {
      "source": "2411.06613v1",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.06608v1",
      "target": "2411.05676v1",
      "weight": 1.0
    },
    {
      "source": "2411.06606v1",
      "target": "2411.06248v1",
      "weight": 1.0
    },
    {
      "source": "2411.06601v1",
      "target": "2411.07271v1",
      "weight": 1.0
    },
    {
      "source": "2411.06590v1",
      "target": "2411.06535v1",
      "weight": 1.0
    },
    {
      "source": "2411.06590v1",
      "target": "2411.05980v1",
      "weight": 1.0
    },
    {
      "source": "2411.06590v1",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.07272v1",
      "target": "2411.06406v1",
      "weight": 1.0
    },
    {
      "source": "2411.06535v1",
      "target": "2411.06528v1",
      "weight": 1.0
    },
    {
      "source": "2411.06528v1",
      "target": "2411.05980v1",
      "weight": 1.0
    },
    {
      "source": "2411.06528v1",
      "target": "2411.05978v1",
      "weight": 1.0
    },
    {
      "source": "2411.06528v1",
      "target": "2411.05775v1",
      "weight": 1.0
    },
    {
      "source": "2411.06506v1",
      "target": "2411.06402v1",
      "weight": 1.0
    },
    {
      "source": "2411.06501v1",
      "target": "2411.05661v1",
      "weight": 1.0
    },
    {
      "source": "2411.08719v1",
      "target": "2411.06465v1",
      "weight": 1.0
    },
    {
      "source": "2411.06477v1",
      "target": "2411.05958v1",
      "weight": 1.0
    },
    {
      "source": "2411.06469v1",
      "target": "2411.05897v1",
      "weight": 1.0
    },
    {
      "source": "2411.06465v1",
      "target": "2411.06371v1",
      "weight": 1.0
    },
    {
      "source": "2411.06465v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.06437v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.06437v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.06426v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.06402v1",
      "target": "2411.06151v1",
      "weight": 1.0
    },
    {
      "source": "2411.06402v1",
      "target": "2411.06068v1",
      "weight": 1.0
    },
    {
      "source": "2411.06360v1",
      "target": "2411.06084v1",
      "weight": 1.0
    },
    {
      "source": "2411.06353v1",
      "target": "2411.05939v1",
      "weight": 1.0
    },
    {
      "source": "2411.06353v1",
      "target": "2411.05752v1",
      "weight": 1.0
    },
    {
      "source": "2411.06353v1",
      "target": "2411.05633v1",
      "weight": 1.0
    },
    {
      "source": "2411.06353v1",
      "target": "2411.05564v1",
      "weight": 1.0
    },
    {
      "source": "2411.06352v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.06352v1",
      "target": "2411.05591v1",
      "weight": 1.0
    },
    {
      "source": "2411.06329v1",
      "target": "2411.06069v1",
      "weight": 1.0
    },
    {
      "source": "2411.06329v1",
      "target": "2411.05979v1",
      "weight": 1.0
    },
    {
      "source": "2411.06329v1",
      "target": "2411.05661v1",
      "weight": 1.0
    },
    {
      "source": "2411.06291v1",
      "target": "2411.06042v1",
      "weight": 1.0
    },
    {
      "source": "2411.06286v1",
      "target": "2411.06078v1",
      "weight": 1.0
    },
    {
      "source": "2411.06284v1",
      "target": "2411.05903v1",
      "weight": 1.0
    },
    {
      "source": "2411.06284v1",
      "target": "2411.05679v1",
      "weight": 1.0
    },
    {
      "source": "2411.06272v1",
      "target": "2411.07264v1",
      "weight": 1.0
    },
    {
      "source": "2411.06269v1",
      "target": "2411.06048v1",
      "weight": 1.0
    },
    {
      "source": "2411.07269v1",
      "target": "2411.06212v1",
      "weight": 1.0
    },
    {
      "source": "2411.07269v1",
      "target": "2411.06070v1",
      "weight": 1.0
    },
    {
      "source": "2411.07269v1",
      "target": "2411.05742v1",
      "weight": 1.0
    },
    {
      "source": "2411.07269v1",
      "target": "2411.05676v1",
      "weight": 1.0
    },
    {
      "source": "2411.06251v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.06248v1",
      "target": "2411.07268v2",
      "weight": 1.0
    },
    {
      "source": "2411.06243v1",
      "target": "2411.06241v1",
      "weight": 1.0
    },
    {
      "source": "2411.06237v1",
      "target": "2411.06207v1",
      "weight": 1.0
    },
    {
      "source": "2411.06237v1",
      "target": "2411.05547v1",
      "weight": 1.0
    },
    {
      "source": "2411.06212v1",
      "target": "2411.06070v1",
      "weight": 1.0
    },
    {
      "source": "2411.06207v1",
      "target": "2411.06171v1",
      "weight": 1.0
    },
    {
      "source": "2411.06207v1",
      "target": "2411.06037v1",
      "weight": 1.0
    },
    {
      "source": "2411.06207v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.06198v1",
      "target": "2411.05778v2",
      "weight": 1.0
    },
    {
      "source": "2411.06176v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.06171v1",
      "target": "2411.05928v1",
      "weight": 1.0
    },
    {
      "source": "2411.06171v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.06171v1",
      "target": "2411.05663v1",
      "weight": 1.0
    },
    {
      "source": "2411.06171v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.06142v1",
      "target": "2411.06074v1",
      "weight": 1.0
    },
    {
      "source": "2411.06122v1",
      "target": "2411.05775v1",
      "weight": 1.0
    },
    {
      "source": "2411.06106v2",
      "target": "2411.05900v1",
      "weight": 1.0
    },
    {
      "source": "2411.06097v1",
      "target": "2411.05638v1",
      "weight": 1.0
    },
    {
      "source": "2411.06090v1",
      "target": "2411.05966v1",
      "weight": 1.0
    },
    {
      "source": "2411.06090v1",
      "target": "2411.05609v1",
      "weight": 1.0
    },
    {
      "source": "2411.06056v1",
      "target": "2411.05735v1",
      "weight": 1.0
    },
    {
      "source": "2411.06056v1",
      "target": "2411.05591v1",
      "weight": 1.0
    },
    {
      "source": "2411.06048v1",
      "target": "2411.06018v1",
      "weight": 1.0
    },
    {
      "source": "2411.06048v1",
      "target": "2411.05755v1",
      "weight": 1.0
    },
    {
      "source": "2411.06037v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.06037v1",
      "target": "2411.05547v1",
      "weight": 1.0
    },
    {
      "source": "2411.05980v1",
      "target": "2411.05775v1",
      "weight": 1.0
    },
    {
      "source": "2411.05980v1",
      "target": "2411.05764v1",
      "weight": 1.0
    },
    {
      "source": "2411.05980v1",
      "target": "2411.05762v1",
      "weight": 1.0
    },
    {
      "source": "2411.05980v1",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.05980v1",
      "target": "2411.05895v1",
      "weight": 1.0
    },
    {
      "source": "2411.05979v1",
      "target": "2411.05661v1",
      "weight": 1.0
    },
    {
      "source": "2411.05939v1",
      "target": "2411.05752v1",
      "weight": 1.0
    },
    {
      "source": "2411.05928v1",
      "target": "2411.05787v1",
      "weight": 1.0
    },
    {
      "source": "2411.05927v1",
      "target": "2411.05636v1",
      "weight": 1.0
    },
    {
      "source": "2411.05775v1",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.05762v1",
      "target": "2411.05641v1",
      "weight": 1.0
    },
    {
      "source": "2411.05743v1",
      "target": "2411.05733v1",
      "weight": 1.0
    },
    {
      "source": "2411.05900v1",
      "target": "2411.05597v1",
      "weight": 1.0
    },
    {
      "source": "2411.05683v1",
      "target": "2411.05586v1",
      "weight": 1.0
    },
    {
      "source": "2411.05663v1",
      "target": "2411.05544v1",
      "weight": 1.0
    },
    {
      "source": "2411.05898v1",
      "target": "2411.05564v1",
      "weight": 1.0
    },
    {
      "source": "2411.05639v1",
      "target": "2411.05895v1",
      "weight": 1.0
    },
    {
      "source": "2411.05633v1",
      "target": "2411.05564v1",
      "weight": 1.0
    }
  ]
}